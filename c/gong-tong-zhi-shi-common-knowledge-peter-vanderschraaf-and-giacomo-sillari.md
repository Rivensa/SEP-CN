# 共同知识 common knowledge (Peter Vanderschraaf and Giacomo Sillari)

_首次发表于 2001 年 8 月 28 日星期二；实质性修订于 2022 年 8 月 5 日星期五_

一个命题 A 在一组代理人中是共知的，如果每个代理人都知道 A。共知本身并不意味着任何关于任何人将什么样的知识归因给其他人的信息。假设每个学生都知道教师会迟到的情况下到达上课。教师会迟到是共知的，但每个学生可能只认为她知道教师会迟到。然而，如果其中一个学生公开说“彼得告诉我他会再次迟到”，那么每个学生都知道每个学生都知道教师会迟到，每个学生都知道每个学生都知道每个学生都知道教师会迟到，依此类推，无穷无尽。这一公告使得这一共知事实成为学生们之间的共同知识。

共同知识是支撑社会生活许多方面的现象。为了成功地进行沟通或协调行为，个体通常需要相互或共同理解或背景知识。事实上，如果特定的互动导致“失败”，通常的解释是参与其中的个体缺乏可能导致成功的共同知识。如果一对已婚夫妇在百货商店里走散，他们有很大机会找到彼此，因为他们对彼此的品味和经历有共同的了解，这使得他们各自在商店的某个区域寻找对方，因为他们都知道对方可能经常去那里。由于夫妻双方都喜欢卡布奇诺，所以每个人都期望对方去咖啡吧，他们最终找到了彼此。但在一个不那么愉快的情况下，如果一名行人因为闯红灯导致了轻微交通堵塞，她会解释自己的错误是因为没有注意到，因此不知道所有司机都知道的交通信号的状态。夫妻之间通过共同知识成功协调，而行人和司机之间由于共同知识的破裂而导致协调失败。

鉴于共同知识在社会互动中的重要性，令人瞩目的是，哲学家和社会科学家直到最近才尝试分析这一概念。大卫·休谟（1740）或许是最早明确提到相互知识在协调中的作用的人。在他在《人性论》中对约定的描述中，休谟认为，协调活动的一个必要条件是，各方都知道彼此可以期待什么样的行为。休谟坚持认为，如果没有必要的相互知识，互惠社会惯例将会消失。迈克尔·利特伍德（1953）稍后提出了一些关于共同知识类型推理的例子，托马斯·谢林（1960）和约翰·哈尔萨尼（1967-1968）则认为，解释人们对彼此做出的某些推断需要类似共同知识的东西。哲学家罗伯特·诺齐克在其博士论文中描述了共同知识的概念，但并未深入发展（诺齐克，1963），而对共同知识概念的第一次数学分析和应用则见于弗里德尔的技术报告（1967），后来发表为（弗里德尔，1969）。第一部全面的共同知识哲学分析由大卫·刘易斯（1969）在专著《约定》中提出。斯蒂芬·希弗（1972）、罗伯特·奥曼（1976）和吉尔伯特·哈曼（1977）独立提出了共同知识的替代定义。乔恩·巴威斯（1988，1989）对哈曼直观描述给出了精确的表述。20 世纪 80 年代，来自哲学和计算机科学领域的许多认识逻辑学家研究了共同知识的逻辑结构，感兴趣的读者应查阅两部重要专著（法金等，1995）和（迈耶和范德霍克，1995）的相关部分。玛格丽特·吉尔伯特（1989）提出了一个略有不同的共同知识概念，她认为这个概念比标准概念更可取。其他人发展了相互知识、近似共同知识和共同信念的概念，这些概念需要比标准概念更少的严格假设，并且在严格共同知识似乎不可能的情况下作为更合理的模型，展示了代理人在某些情况下所知道的内容（布兰登伯格和德克尔，1987；蒙德勒和萨梅特，1989；鲁宾斯坦，1992）。共同知识及相关多主体知识概念的分析和应用已成为一个充满活力的研究领域。

本文的目的是概述一些源自当代研究的最重要结果。本文各部分讨论的主题如下：第 1 部分提供了激励性例子，说明代理人的行为在很大程度上取决于他们是否具有或缺乏某些共同知识。第 2 部分讨论了共同知识的替代分析。第 3 部分回顾了多主体知识概念的应用，特别是对博弈论（von Neumann 和 Morgenstern，1944 年）的应用，在这些应用中，共同知识假设被发现在为数学博弈提供解决方案概念方面具有重要意义。第 4 部分讨论了对共同知识的实现可能性的怀疑。最后，第 5 部分讨论了通过削弱 Lewis 对共同知识的描述的假设而产生的共同信念概念。

* [激励性例子](https://plato.stanford.edu/entries/common-knowledge/#1)
  * [1.1 笨拙的服务员](https://plato.stanford.edu/entries/common-knowledge/#1.1)
  * [1.2 烧烤问题](https://plato.stanford.edu/entries/common-knowledge/#1.2)
  * [1.3 农民的困境](https://plato.stanford.edu/entries/common-knowledge/#1.3)
  * [1.4 蜈蚣](https://plato.stanford.edu/entries/common-knowledge/#1.4)
  * [1.5 百货商店](https://plato.stanford.edu/entries/common-knowledge/#1.5)
* [2. 共同知识的替代解释](https://plato.stanford.edu/entries/common-knowledge/#2)
  * [2.1 分层账户](https://plato.stanford.edu/entries/common-knowledge/#2.1)
  * [2.2 路易斯（Lewis）的观点](https://plato.stanford.edu/entries/common-knowledge/#2.2)
  * [2.3 奥曼的观点](https://plato.stanford.edu/entries/common-knowledge/#2.3)
  * [2.4 Barwise 的观点](https://plato.stanford.edu/entries/common-knowledge/#2.4)
  * [2.5 吉尔伯特的论述](https://plato.stanford.edu/entries/common-knowledge/#2.5)
* [相互和共同知识的应用](https://plato.stanford.edu/entries/common-knowledge/#3)
  * [3.1 “无分歧”定理](https://plato.stanford.edu/entries/common-knowledge/#3.1)
  * [3.2 传统](https://plato.stanford.edu/entries/common-knowledge/#3.2)
  * [3.3 战略型博弈](https://plato.stanford.edu/entries/common-knowledge/#3.3)
  * [3.4 完全信息博弈](https://plato.stanford.edu/entries/common-knowledge/#3.4)
  * [3.5 通信网络](https://plato.stanford.edu/entries/common-knowledge/#3.5)
* [4. 共同知识是否可获得？](https://plato.stanford.edu/entries/common-knowledge/#4)
* [5. 协调与共同 p-信念](https://plato.stanford.edu/entries/common-knowledge/#5)
  * [5.1 电子邮件协调示例](https://plato.stanford.edu/entries/common-knowledge/#5.1)
  * [5.2 共同 p-信念](https://plato.stanford.edu/entries/common-knowledge/#5.2)
* [参考文献](https://plato.stanford.edu/entries/common-knowledge/#Bib)
* [学术工具](https://plato.stanford.edu/entries/common-knowledge/#Aca)
* [其他互联网资源](https://plato.stanford.edu/entries/common-knowledge/#Oth)
* [相关条目](https://plato.stanford.edu/entries/common-knowledge/#Rel)

***

## 激励性例子

本节中的大多数例子在共同知识文献中是熟悉的，尽管这里呈现的一些细节和解释是新的。读者可能想问自己，每个例子展示了互相和共同知识推理的哪些独特方面（IGNORE）。

### 1.1. 笨拙的服务员

一名侍者在上菜时滑倒，将肉汁溅到了客人的白色丝绸晚礼服上。客人瞪了侍者一眼，侍者说：“对不起，这是我的错。”为什么侍者说是自己的错呢？他知道这是他的错，而且从客人生气的表情中也知道她知道这是他的错。然而，这位抱歉的侍者希望得到客人知道他知道自己的错的保证。通过公开表示自己有错，侍者知道客人知道他希望她知道的事实，也就是他知道自己有错。请注意，侍者的声明建立了至少三个嵌套知识层次。

在前述故事中，有一些假设是隐含的。特别是，服务员必须知道客人知道他说的是真话，并且她能从他在这种情况下所说的内容中得出所需的结论。更根本地，服务员必须知道，如果他对客人宣布“这是我的错”，她会正确解释他的意图，并推断出在这种情况下他做出这一宣布通常意味着什么。这反过来又意味着客人必须知道，如果服务员在这种情况下宣布“这是我的错”，那么服务员确实知道他有过错。然后，由于他的宣布，服务员知道客人知道他知道他有过错。服务员的宣布旨在产生每个人已经知道的事实的更高阶知识水平。

仅仅加强所述的假设就会导致更高级别的嵌套知识。假设服务员和客人都知道对方可以推断出他从服务员的公告中推断出的内容。客人现在能否相信服务员不知道她知道他知道自己有错？如果客人考虑这个问题，她会推理，如果服务员错误地认为她可能不知道他知道自己有错，那么服务员必须认为她可能无法从自己的声明中推断出他知道自己有错。由于她知道她可以从他的声明中推断出服务员知道他有错，她知道服务员知道她也可以推断出这一点。因此，服务员的公告建立了第四阶知识主张：客人知道服务员知道她知道他知道自己有错。通过类似的、尽管更冗长的论证，代理人可以验证在这些假设下，甚至更高阶的相应知识主张也必须成立。

### 1.2 烧烤问题

这是 Littlewood (1953) 首次发表的一个变种示例，尽管他指出他的版本当时已经众所周知。N 个人一起享用野餐晚餐，其中包括烤排骨。在餐后，其中 k≥1 个用餐者脸上沾满了烧烤酱。由于没有人能看到自己的脸，这些弄脏了的用餐者都不知道自己是否弄脏了。然后，端出烤排骨的厨师拿着一盒冰淇淋回来。厨师看到了什么很有趣，于是敲响了晚餐钟，并做出了以下宣布：“你们中至少有一个人脸上沾有烧烤酱。我将一遍又一遍地敲响晚餐钟，直到任何弄脏了的人擦干净脸。然后我会上甜点。”在前 k−1 次敲响钟声时，没有人做任何事情。然后，在第 k 次敲响时，每个弄脏了的人突然伸手拿餐巾，不久之后，用餐者们都在享用他们的冰淇淋。

混乱的用餐者们最终是如何意识到他们的脸需要清洁的呢？当 k=1 时很容易，因为在这种情况下，孤独的混乱个体会立即意识到自己很乱，因为他看到其他人都很干净。接下来考虑 k=2 的情况。在第一圈，混乱的个体 i1 知道另一个人 i2 是混乱的，但还不知道自己。在第二圈， i1 意识到自己必须是混乱的，因为如果 i2 是唯一混乱的人，那么在第一圈时，当厨师宣布时， i2 会知道这一点，并会在那时清洁自己的脸。通过对称的论证，混乱的用餐者 i2 也在第二圈得出结论，她也认为自己是混乱的，两人在那时拿起了餐巾。

一般情况通过归纳得出。假设如果 k=j，则每个 j 个凌乱的用餐者在 j 次环节后可以确定自己凌乱。那么如果 k=j+1，则在第 j+1 次环节，每个 j+1 个个体都会意识到自己凌乱。因为如果他不凌乱，那么其他 j 个凌乱的人在第 j 次环节时就会意识到自己的凌乱并进行清洁。由于没有人在第 j 次环节后清洁自己，在第 j+1 次环节中，每个凌乱的人都会得出结论：除了其他 j 个凌乱的人之外，还必须有其他人也是凌乱的，也就是他自己。

这个论点的“悖论”在于对于 k>1 的情况，就像例 1.1 中那个笨拙的服务员一样，厨师的宣布告诉了用餐者每个人都已经知道的事情。然而显然，厨师的宣布也给了用餐者有用的信息。这怎么可能呢？通过宣布每个用餐者已经知道的事实，厨师使这个事实在他们之间成为共同知识，从而使他们每个人最终能够推断出在响铃足够多次后自己脸上的条件。

### 1.3 农民的困境

是否履行对他人的义务符合自身利益？柏拉图及其继承者认识到，在某些情况下，答案似乎是“不”。霍布斯（1651 年，第 101-102 页）考虑了一个“愚者”的挑战，后者声称尊重与已经履行其协议的他人达成的协议是不理性的。愚者指出，在这种情况下，一个人已经获得了他人遵守的所有好处，愚者认为现在最好的做法是打破协议，从而节省自己遵守协议的成本。当然，如果愚者对情况的分析是正确的，那么协议的另一方难道不会预料到愚者对尊重协议的反应，并相应地采取行动吗？

休谟（1740 年，第 520-521 页）提出了这个问题，举例说明：两个相邻的农民都预期将会有丰收的玉米。当玉米成熟时，每个农民都需要邻居的帮助来收割玉米，否则将有相当一部分玉米在田地里腐烂。由于他们的玉米成熟的时间不同，这两个农民可以通过在各自的玉米成熟时互相帮助来确保自己的丰收，而且他们都知道这一点。然而，这两个农民并不互相帮助。后熟的农民认为，如果她帮助另一个农民，那么当她的玉米成熟时，他将处于霍布斯的“愚人”（Hobbes’ Foole）的位置，已经从她的帮助中受益。他将不再从她那里获益，因此他不会帮助她，从而避免自己进行第二次收割的辛苦劳动。由于她无法指望另一个农民在需要时回报她的帮助，所以当另一个农民的玉米先成熟时，她也不会帮助，当然，当她的玉米后成熟时，另一个农民也不会帮助她。

Hume 的《农夫困境》问题的结构可以用以下树状图总结：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure1.1a.gif)

图 1.1a

这棵树是一个广义形式博弈的例子。在每个阶段 i，移动的代理可以选择 Ci，对应于帮助或合作，或者选择 Di，对应于不帮助或背叛。两个代理对各种结果的相对偏好通过他们在任何特定结果中收到的有序支付对来反映。例如，如果 Fiona 选择 Ci 而 Alan 选择 Di，那么 Fiona 的支付为 0，是她的最差支付，而 Alan 的支付为 4，是他的最佳支付。在诸如图 1.1.a 的博弈中，如果每个代理根据自己所知选择最大化其预期支付的行为，那么代理是（贝叶斯）理性的。

在《农民困境》游戏中，对于两位农民来说，遵循 C1，C2 路径比遵循 D1，D2 路径严格更好。然而，Fiona 选择了 D1，原因是以下简单的论证结果：“如果我选择了 C1，那么理性的 Alan，他了解游戏的收益结构，会选择 D2。我也是理性的，了解游戏的收益结构。所以我应该选择 D1。”由于 Fiona 知道 Alan 是理性的并了解游戏的收益，她得出结论只需分析下图中简化的游戏：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure1.1b.gif)

图 1.1b

在这个简化的博弈中，Fiona 选择 D1 比选择 C1 能够获得严格更高的回报，因此 D1 是她唯一的最佳选择。当 Fiona 选择 D1 时，理性的 Alan 会选择 D2 作为回应。如果 Fiona 和 Alan 知道：(i) 他们都是理性的，(ii) 他们都知道博弈的回报结构，以及(iii) 他们都知道(i)和(ii)，那么他们都可以预测对方在图 1.1.a 的每个节点上会做什么，并得出结论他们可以排除图 1.1.b 中的 D1，C2 分支，并仅分析以下图中的简化博弈：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure1.1c.gif)

图 1.1c

基于这种共同知识，双方都知道 Fiona 会选择 D1，而 Alan 会做出 D2 的回应。因此，如果拥有这种共同知识的代理人玩农民困境博弈，D1，D2-结果就会出现，尽管这是次优的，因为双方在 C1，C2-分支上会表现更好。这一论点，本质上是休谟的论点，是解决顺序博弈的标准技术的一个例子，被称为逆向归纳。逆向归纳背后的基本思想是，参与顺序博弈的代理人通过排除对于最后移动的代理人来说不是最大化回报的行为，然后排除对于倒数第二个移动的代理人来说不是最大化回报的行为，依此类推，推断出每个人在整个游戏中的行为。显然，逆向归纳论证在很大程度上依赖于代理人对于他们所处情境的共同知识，通常需要代理人评估某些虚拟条件句的真值，比如“如果我（Fiona）选择 C1，那么 Alan 会选择 D2”。

### 1.4 蜈蚣

构建一个游戏的逆向归纳解决方案所需的相互知识假设随着游戏阶段数量的增加而变得更加复杂。为了看到这一点，请考虑下图所示的顺序蜈蚣游戏：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure1.2.gif)

图 1.2

在每个阶段 i)，移动的代理可以选择 Ri，在前三个阶段中这会给另一个代理一个移动的机会，或者选择 Li，结束游戏。

像农民困境一样，这个游戏对代理者来说是一个承诺问题。如果每个代理者都能相信对方在每个阶段选择 Ri，那么他们每个人都会期望获得 3 的回报。然而，艾伦选择了 L1，导致每个人只能得到 1 的回报，这是以下逆向归纳论证的结果：“如果节点 n4 被达到，那么菲奥娜（理性地）会选择 L4。我知道这一点，如果节点 n3 被达到，我（理性地）会选择 L3。菲奥娜知道这一点，如果节点 n2 被达到，她（理性地）会选择 L2。因此，我（理性地）应该选择 L1。”为了进行这种逆向归纳论证，艾伦隐含地假设：（i）他知道菲奥娜知道他是理性的，以及（ii）他知道菲奥娜知道他知道她是理性的。换句话说，为了进行逆向归纳论证，艾伦必须在节点 n1 知道菲奥娜在节点 n2 必须知道什么，以使 L2 成为她在 n2 被达到时的最佳选择。在农民困境中，菲奥娜只需要对艾伦的理性有一级知识和对艾伦对游戏的知识有二级知识，就可以得出逆向归纳解决方案，而在图 1.2 游戏中，为了艾伦能够得出逆向归纳解决方案，代理者必须对游戏有三级相互知识和对理性有二级相互知识，而艾伦必须对这种游戏的相互知识有四级知识和对他们的理性的相互知识有三级知识。这个论证还涉及几个反事实，因为为了构建它，代理者必须能够评估“如果节点 ni 被达到，艾伦（菲奥娜）会选择 Li（Ri）”这种形式的条件句，对于 i>1 来说，这些是反事实的，因为对理性的三级相互知识意味着节点 n2、n3 和 n4 永远不会被达到。

逆向归纳法可以应用于任何具有完全信息的顺序博弈，其中参与者可以依次观察彼此的动作，并可以回忆整个博弈历史。然而，随着潜在博弈阶段数量的增加，逆向归纳论证显然变得更难构建。这引发了一些问题：(1) 为了证明特定顺序博弈的逆向归纳论证，究竟需要什么样的相互或共同知识假设？(2) 随着顺序博弈复杂性的增加，我们是否会预期逆向归纳所需的共同知识开始出现失败？

### 1.5 百货商店

> 当一个男人在百货商店里失去了他的妻子，而双方之前没有约定好分开后应该在哪里见面时，他们再次相遇的机会很大。每个人都可能会想到一些显而易见的地方去见面，以至于每个人都会确信这个地方对双方来说都是“显而易见”的。一个人不仅仅是预测另一个人会去哪里，而是预测第一个人预测第二个人会去哪里，第二个人预测第一个人会去哪里，如此循环往复。不是“如果我是她，我会怎么做？”而是“如果我是她，我会怎么做，如果她在想如果她是我会怎么做，如果她在想如果她是我会怎么做……？” —— 托马斯·谢林，《冲突的策略》

Schelling 的百货商店问题是一个纯协调问题的例子，即，一个互动问题，其中代理的利益完全一致。Schelling (1960)和 Lewis (1969)是第一批明确阐明共同知识在社会协调中发挥作用的人，他们也是最早主张可以使用博弈论的分析词汇来建模协调问题的人之一。下图给出了一个非常简单的协调问题的例子：

|                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                            | Robert                                                                                                                                                                                                                                           |                                                                                                                                                                                    |                                                                                                                                                                  |       |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----- |
|                                                                                                                                                                                                                   |                                                                                                                                                                                                                                                                                            | I'm sorry, but it seems like there was an error in your request. It appears that you only provided "s1" without any accompanying text for translation. Could you please provide the text you would like me to translate into Simplified Chinese? | I'm sorry, but it seems like your input "s2" does not contain any text to be translated. Could you please provide the text you would like me to translate into Simplified Chinese? | I'm sorry, but it seems like you have only provided "s3" as the text to be translated. Could you please provide more context or additional text for translation? | s4    |
| ---                                                                                                                                                                                                               | ---                                                                                                                                                                                                                                                                                        | ---                                                                                                                                                                                                                                              | ---                                                                                                                                                                                | ---                                                                                                                                                              | ---   |
| 莉兹                                                                                                                                                                                                                | I'm sorry, but it seems like there was an error in your request. It appears that the text you provided for translation is just "s1," which does not contain any content to be translated. Could you please provide the actual text you would like me to translate into Simplified Chinese? | (4,3)                                                                                                                                                                                                                                            | (1,2)                                                                                                                                                                              | (1,2)                                                                                                                                                            | (3,4) |
| I'm sorry, but it seems like you have only provided "s3" without any context or text to translate. Could you please provide the full text or context that you would like me to translate into Simplified Chinese? | (3,4)                                                                                                                                                                                                                                                                                      | (1,3)                                                                                                                                                                                                                                            | (1,3)                                                                                                                                                                              | (4,3)                                                                                                                                                            |       |
| s3                                                                                                                                                                                                                | (3,4)                                                                                                                                                                                                                                                                                      | (1,3)                                                                                                                                                                                                                                            | (1,3)                                                                                                                                                                              | (4,3)                                                                                                                                                            |       |
| I'm sorry, but it seems like there was a misunderstanding. Could you please provide the text you would like me to translate into Simplified Chinese?                                                              | (3,4)                                                                                                                                                                                                                                                                                      | (1,3)                                                                                                                                                                                                                                            | (1,3)                                                                                                                                                                              | (4,3)                                                                                                                                                            |       |

si= 搜索在地板上 i, 1≤i≤4

图 1.3

图 1.3 的矩阵是战略形式博弈的一个例子。在游戏的每个结果，对应于矩阵中的一个单元格，行（列）代理人的回报是相应单元格中有序对的第一个（第二个）元素。然而，在战略形式博弈中，每个代理人在观察到任何其他代理人的选择之前都会进行选择，因此所有人必须像同时选择一样进行选择。图 1.3 的游戏是一个纯协调游戏（Lewis，1969），也就是说，在每个结果中，每个代理人获得完全相同的回报。对这个游戏的一种解释是，舍林的配偶丽兹和罗伯特正在四层百货商店里寻找彼此，只有当他们去同一层时才能找到对方。配偶协调的四个结果对应于图 1.3 游戏的策略配置（sj，sj），1≤j≤4。这四个配置是游戏的严格纳什均衡（Nash，1950，1951），也就是说，每个代理人都有充分的理由遵循这些策略配置的一端，前提是另一个代理人也遵循这个配置。

Agents 面临的困难在于尝试选择要遵循的均衡。假设 Robert 希望与 Liz 协调游戏的特定均衡，比如（s2，s2）。Robert 的推理如下：“由于我们可能遵循几个严格的均衡，如果且仅如果我有足够高的期望值认为 Liz 会遵循她的（s2，s2）端，我应该遵循我的（s2，s2）端。但是，我只有在 Liz 有足够高的期望值认为我会遵循（s2，s2）时，才能有足够高的期望值认为 Liz 会遵循（s2，s2）。为了使 Liz 具有这样的期望，Liz 必须有足够高的（二阶）期望认为我有足够高的期望值认为她会遵循（s2，s2），因为如果 Liz 没有这些（二阶）期望，那么她会认为我没有足够的理由遵循（s2，s2），因此可能会偏离（s2，s2）。因此，我需要有足够高的（三阶）期望认为 Liz 有足够高的（二阶）期望认为我有足够高的期望值认为她会遵循（s2，s2），这涉及到她对我有关的四阶期望，涉及到我对 Liz 有关的五阶期望，依此类推。”对于 Robert 和 Liz 来说，什么足以让他们有决定性理由遵循（s2，s2）是，他们各自知道对方知道……对方会遵循（s2，s2）的任何知识层次，也就是说，在 Liz 和 Robert 之间，他们会遵循（s2，s2）是共同知识。如果代理根据对游戏的共同知识，他们的理性和遵循这种均衡的意图，而不是其他任何均衡，来遵循纯协调游戏中的严格均衡，那么就说代理在遵循 Lewis 约定（Lewis 1969）。

Lewis 的约定理论适用于比纯协调游戏更一般的游戏类别，但纯协调游戏已经模拟了各种重要的社会互动。特别是，Lewis 将语言约定建模为纯协调游戏的均衡点。上述纯协调游戏中共同知识的作用当然引发了进一步的问题：（1）人们是否能够获得表征 Lewis 约定的共同知识？（2）在协调问题中，是否有更少严格的认识假设足以证明纳什均衡行为？

## 2. 共同知识的替代解释

* [2.1 分层账户](https://plato.stanford.edu/entries/common-knowledge/#2.1)
* [2.2 路易斯（Lewis）的观点](https://plato.stanford.edu/entries/common-knowledge/#2.2)
* [2.3 奥曼的观点](https://plato.stanford.edu/entries/common-knowledge/#2.3)
* [2.4 Barwise 的观点](https://plato.stanford.edu/entries/common-knowledge/#2.4)
* [2.5 吉尔伯特的论述](https://plato.stanford.edu/entries/common-knowledge/#2.5)

非正式地，如果一命题 A 在一组代理人中是相互已知的，那么每个代理人都知道 A。相互知晓本身并不意味着任何关于任何人认为其他人有什么知识的信息。假设每个学生都知道上课时教师会迟到。教师会迟到是相互已知的，但每个学生可能只认为她知道教师会迟到。然而，如果其中一个学生公开说：“彼得告诉我他会再次迟到”，那么现在这个相互已知的事实就成为共同已知。每个学生现在都知道教师会迟到，依此类推，无穷无尽。代理人在 Schelling（1960）非正式表述的意义上具有共同知识，更确切地说是在 Lewis（1969）和 Schiffer（1972）的论述中。Schiffer 使用认识逻辑的形式词汇（Hintikka 1962）来阐述他对共同知识的定义。Schiffer 的一般方法是在命题逻辑系统中增加一组与代理人对应的知识算子，然后在增强系统中定义共同知识的命题层次结构。Bacharach（1992）和 Bicchieri（1993）采用了这种方法，并发展了关于共同知识的逻辑理论，其中包括类似于（Fagin 等人 1995）的完备性和正确性定理。人们也可以用集合论术语发展关于共同知识的形式化描述，就像在 Friedell（1969）早期和 Aumann（1976）之后的经济文献中所做的那样。这种方法在形式上被证明等价于认识逻辑中的方法，本文也采用了这种方法。

### 2.1 分层账户

Monderer 和 Samet（1988）以及 Binmore 和 Brandenburger（1989）给出了一个特别优雅的集合论定义的共同知识。我将在这里回顾这个定义，然后展示它在逻辑上等价于 Lewis（1969）和 Schiffer（1972）认为表征共同知识的“i 知道 j 知道...k 知道 A”的层次结构。

首先必须阐明一些初步概念。遵循 C. I. 路易斯（1943-1944）和卡尔纳普（1947）的观点，命题在形式上是状态描述或可能世界集合Ω的子集。可以将Ω的元素视为代表莱布尼茨的可能世界或维特根斯坦的可能事务的元素。共同知识文献中的一些结果预设Ω具有有限的基数。如果在任何情境中需要这一明显不切实际的假设，本文将明确说明，否则可以假定Ω可以是有限集或无限集。一个显著的实际世界ωα是Ω的一个元素。如果实际世界ωα∈A，则命题 A⊆Ω成立（或为真）。一般来说，我们说在世界ω∈Ω处命题 A 成立，如果ω∈A。关于可能世界的一个代理 i 所知道的内容在形式上是用知识算子 Ki 来表述的。给定命题 A⊆Ω，Ki(A)表示一个新命题，对应于代理 i 知道 A 成立的可能世界集合。Ki(A)可读作“i 知道 A（为真）”。知识算子 Ki 满足一些公理，包括：

(K1)(K2)(K3)(K4)(K5)Ki(A)⊆AΩ⊆Ki(Ω)Ki(⋂kAk)=⋂kKi(Ak)Ki(A)⊆KiKi(A)−Ki(A)⊆Ki−Ki(A)

用文字表达，K1 说如果 i 知道 A，那么 A 必然成立。K2 说 i 知道Ω中的某个可能世界发生，无论发生哪个可能世界ω。K3\[10]说如果且仅如果 i 知道一个连词，那么 i 知道每个连词。K4 是一个反射公理，有时也被称为透明性公理（或积极内省公理），它说如果 i 知道 A，那么 i 知道她知道 A。最后，K5 说如果代理人不知道一个事件，那么她知道自己不知道。这个公理被称为负面内省公理，或者被称为智慧公理（因为代理人拥有苏格拉底的智慧，知道自己不知道）。请注意，根据 K3，如果 A⊆B，则 Ki(A)⊆Ki(B)，根据 K1 和 K2，Ki(Ω)=Ω，根据 K1 和 K4，Ki(A)=KiKi(A)。任何满足 K1-K5 的知识系统对应于模态系统 S5，而任何满足 K1-K4 的系统对应于 S4（Kripke 1963）。如果去掉 K1 公理并保留其他公理，得到的系统将对一个代理人的信仰给出一个形式化解释，但不一定是知识。

在知识的形式分析中，一个有用的概念是可能性集。在世界状态Ω下，代理 i 的可能性集是 i 认为如果ω是实际世界，可能成立的最小可能世界集合。更确切地说，

\*\* 定义 2.1\*\* 代理人 i 在 ω∈Ω 处的可能性集合 Hi(ω) 被定义为

你好(ω)≡⋂{E∣ω∈Ki(E)}

集合的收集

嗨=⋃ω∈ΩHi(ω)

这是 i 的私人信息系统。

由于在语言中，Hi(ω) 是 i 在ω时刻所知道的所有命题的交集，Hi(ω) 是 i 在ω时刻所知道的Ω中最小的命题。换句话说，Hi(ω) 是 i 对可能世界ω拥有的最具体信息。为代理人分配私人信息系统的直觉在于，虽然代理人 i 可能无法感知或理解其所生活的世界的每一个细节，但 i 确实知道关于那个世界的某些事实。i 信息系统的元素代表了 i 在可能世界中立即知道的内容。我们还有以下内容：

\*\* 命题 2.2\*\* Ki(A)={ω∣Hi(ω)⊆A}

在文献中对知识进行的许多形式分析中，可能性集被视为原始的，命题 2.2 被给定为知识的定义。如果采纳这一观点，那么公理 K1-K5 将作为知识定义的结果而得出。在许多应用中，假定代理的可能性集对集合进行了划分，此时 Hi 被称为 i 的私人信息划分。请注意，如果公理 K1-K5 成立，那么每个代理的可能性集总是对状态集进行划分，反之亦然。

为了说明可能性集合的概念，让我们回到示例 1.2 中描述的烧烤问题。假设有三位用餐者：Cathy、Jennifer 和 Mark。那么根据表 2.1 总结的世界的 8 个相关状态。

\| | | | | | | | | | --- | --- | --- | --- | --- | --- | --- | --- | --- |表 2.1 | | ω1 | ω2 | ω3 | ω4 | ω5 | ω6 | ω7 | ω8 | | Cathy | 干净 | 凌乱 | 干净 | 干净 | 凌乱 | 凌乱 | 干净 | 凌乱 | | Jennifer | 干净 | 干净 | 凌乱 | 干净 | 凌乱 | 干净 | 凌乱 | 凌乱 | | Mark | 干净 | 干净 | 干净 | 凌乱 | 干净 | 凌乱 | 凌乱 | 凌乱 |

每位用餐者都知道其他用餐者的面孔状况，但不知道自己的。假设厨师最终没有做任何宣布。那么，无论实际世界的状态ω∈Ω是什么，没有一个用餐者知道世界的真实状态，但他们确实先验地知道在世界的各种状态下某些命题是真实的。例如，卡西在任何宣布之前的信息系统如图 2.1a 所示：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure2.1a.gif)

图 2.1a

在这种情况下，Cathy 的信息系统是Ω的一个分区 H1

H1={HCC，HCM，HMC，HMM}

在哪里

HCC={ω1,ω2}（即，Jennifer 和 Mark 都干净）HCM={ω4,ω6}（即，Jennifer 干净而 Mark 肮脏）HMC={ω3,ω5}（即，Jennifer 肮脏而 Mark 干净）HMM={ω7,ω8}（即，Jennifer 和 Mark 都肮脏）

Cathy 立即知道她的分区中在世界的任何状态下是哪个单元 H1(ω)，但不知道在任何ω∈Ω中哪个是真实状态。

如果我们在示例 1.2 中提到的假设中加入这样一个假设，即如果至少有一个吃饭的人弄脏了，那么厨师会宣布这个事实，那么凯西的信息分割由图 2.1b 描述：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure2.1b.gif)

图 2.1b

在这种情况下，Cathy 的信息系统是Ω的一个分区 H1

H1={HCCC,HMCC,HCM,HMC,HMM}

在哪里

HCCC={ω1}（即，Jennifer、Mark 和我都是干净的）HMCC={ω2}（即，Jennifer 和 Mark 是干净的，而我是凌乱的）HCM={ω4,ω6}（即，Jennifer 是干净的，而 Mark 是凌乱的）HMC={ω3,ω5}（即，Jennifer 是凌乱的，而 Mark 是干净的）HMM={ω7,ω8}（即，Jennifer 和 Mark 都是凌乱的）

在这种情况下，凯西的信息分割是她在没有公告时的分割的细化，因为在这种情况下，凯西事先知道如果ω1 成立，就不会有公告，并且会立即知道自己是干净的，凯西也事先知道如果ω2 成立，那么她将立即从厨师的公告中知道自己是脏的。

同样，如果厨师只在看到至少两个凌乱的用餐者时才会做出通告，卡西的可能性集合就是图 2.1c 中所代表的那个。

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure2.1c.gif)

图 2.1c

凯西的信息分区现在被定义为

H1={HCC，HCMC，HCCM，HMMC，HMCM，HMM}

在哪里

HCC={ω1,ω2} (即，Jennifer 和 Mark 都干净) HCMC={ω3} (即，Mark 和我干净，Jennifer 乱七八糟) HCCM={ω4} (即，Jennifer 和我干净，Mark 乱七八糟) HCCM={ω5} (即，Jennifer 和我乱七八糟，Mark 干净) HCCM={ω6} (即，Mark 和我乱七八糟，Jennifer 干净) HMM={ω7,ω8} (即，Jennifer 和 Mark 都乱七八糟)

在这种情况下，Cathy 从先验知识知道如果 ω3 发生，就不会有公告，对于 ω4 也是如此。因此，她将能够分辨这些状态与分别的 ω5 和 ω6。

正如本小节前面提到的，假设代理人的可能性集将状态空间划分取决于建模者对知识运算符的具体公理的选择。例如，如果我们放弃公理 K5（保持 K1-K4 的有效性），代理人的可能性集不需要划分空间集（请参阅示例的链接。有关更多细节和应用，请参阅 Samet 1990）。有人猜测（参见 Geanakoplos 1989），缺乏负面内省（即没有 K5 的系统）将允许在认知模型中纳入无法预见的偶发事件，通过代表代理人对某些事件的无意识（即代理人不知道事件发生，也不知道自己不知道发生的情况）。后来由 Dekel 等人（1998）证明，标准模型不适合表示代理人的无意识。Heifetz 等人（2006）提供了一个原始的非标准模型来表示无意识。有关建模无意识和该概念应用的全面参考书目，请参阅本条目末尾的外部链接。

我们现在可以将相互和共同知识定义如下：

\*\* 定义 2.3\*\* 让给定一组可能世界Ω以及一组代理者 N。

1. 命题 A 是 N 的代理人之间的（第一级或第一阶）共知，即 K1N(A)定义的集合

K1N(A)≡⋂i∈NKi(A).

2. 命题 A 是 N 个代理人之间的 m 级（或 m 阶）相互知识，KmN(A)，被递归地定义为集合

KmN(A)≡⋂i∈NKi(Km−1N(A)).

3. 命题 A 在 N 的代理人中是共同知识，即定义为集合\[12]

K∗N(A)≡∞⋂m=1KmN(A).

命题 E 的共同知识意味着 E 所蕴含的一切的共同知识，如下所示：

\*\* 命题 2.4\*\* 如果 ω∈K∗N(E) 并且 E⊆F，则 ω∈K∗N(F)。 证明。

请注意，(KmN(E))m≥1 是一系列事件的递减序列，即对于所有 m≥1，Km+1N(E)⊆KmN(E)。很容易验证，如果每个人都知道 E，那么 E 必须为真，即 K1N(E)⊆E。如果 Ω 被假定为有限的，那么如果 E 在 ω 处是共同知识，这意味着必须存在一个有限的 m，使得

KmN(E)=∞⋂n=1KnN(E).

以下结果将集合论定义的共同知识与“我知道 j 知道…知道 A”的层次结构相关联。

\*\* 命题 2.5\*\* ω∈KmN(A)当且仅当

(1) 对于所有代理 i1，i2，…，im∈N，ω∈Ki1Ki2…Kim(A)

因此，ω∈K∗N(A)当且仅当对于每个 m≥1 都满足(1)的情况。 证明。

对于所有的 m≥1 和所有的 i1，i2，…，im∈N，ω∈Ki1Ki2…Kim(A)的条件是 Schiffer 对共同知识的定义，并且经常被用作文献中对共同知识的定义。

### 2.2 路易斯（Lewis）的观点

Lewis 被认为是将共同知识表征为“i 知道 j 知道 … 知道 A”命题的层次结构的构想者。然而，Lewis 意识到这种无穷定义所引发的困难。第一个问题是是否可能将层次化描述中固有的无穷减少为可行的有限定义。第二个问题是有限的代理无法涉及必要用于获得共同知识的无穷知识状态。Lewis 解决了这两个问题，但他的表述是非正式的。Aumann 经常被认为是提出生成共同知识层次的第一个有限方法的人（Aumann，1976），尽管实际上（Friedell，1969）早于 Aumann 和 Lewis 的工作。最近，Cubitt 和 Sugden（2003）认为 Aumann 和 Lewis 对共同知识的描述是根本不同且无法调和的。

尽管 Lewis 引入了技术术语“共同知识”，但他的分析是关于信念，而不是知识。事实上，Lewis 通过引入实际信念和理由信念之间的区别来提出他对上述第二问题的解决方案。理由信念被解释为代理人的潜在信念，使得认识状态的无限层次变得无害，由无限数量的潜在信念状态组成。对第一个问题的解决方案是通过提供一组有限条件来生成无限系列的理由信念。这些条件共同构成了 Lewis 对共同知识的官方定义。请注意，更恰当的说法应该是“共同理由信念”，或者至少是“共同信念”。Lewis 本人后来承认“那个术语\[共同知识]是不幸的，因为没有保证它会成为知识，甚至没有保证它会是真实的。”参见（Lewis 1978，第 44 页，注 13）。忽略理由信念和实际信念之间的区别，我们遵循（Vanderschraaf 1998）在此给出 Lewis 定义的正式解释的细节，并展示 Lewis 的分析确实导致了从一组有限公理推导出的共同知识层次结构。然而，可能存在争议的是，可能世界方法是否能够恰当地呈现 Lewis 表征的微妙之处。例如，Cubitt 和 Sugden（2003）完全放弃了可能世界框架，并提出了对 Lewis 的不同形式解释，其中包括理由信念和实际信念之间的区别。试图调和这两种立场的尝试可以在（Sillari 2005）中找到，Lewis 的表征在其中以更丰富的可能世界语义框架中形式化，其中包括理由信念和实际信念之间的区别。

Lewis 在《公约》的第 52-57 页提出了他对共同知识的观点。Lewis 没有明确指出共同知识需要什么知识账户。事实证明，Lewis 的观点对于任何形式的知识账户都是令人满意的，其中知识运算符 Ki，i∈N 满足 K1、K2 和 K3。Lewis 在对共同知识的分析中的一个关键假设是，代理知道他们在“理性、归纳标准和背景信息”方面与关于某一事态 A′ 的状态相同（Lewis 1969 年，第 53 页），也就是说，如果一个代理可以从 A′ 中得出任何结论，她知道所有人也可以做同样。这个想法在以下内容中得到了明确阐述：

\*\* 定义 2.6\*\* 给定一组代理人 N 和一个命题 A′⊆Ω，如果 N 的代理人在 A′ 方面是对称推理者（或 A′-对称推理者），则对于每个 i，j∈N 和任何命题 E⊆Ω，如果 Ki(A′)⊆Ki(E) 并且 Ki(A′)⊆KiKj(A′)，那么 Ki(A′)⊆KiKj(E)。\[13]

定义者说，对于每个代理人 i，如果 i 可以从 A'推断出 E 是真的，并且每个人都知道 A'是真的，那么 i 也可以推断出每个人都知道 E 是真的。

\*\* 定义 2.7\*\* 命题 E 在 ω∈Ω 时在一组代理人 N={1,…,n} 中是 Lewis-共同知识，当且仅当存在一个命题 A _，使得 ω∈A_，N 的代理人是 A\*-对称推理者，并且对于每个 i∈N，ω∈Ki(A∗)Ki(A∗)⊆Ki(⋂j∈NKj(A∗))Ki(A∗)⊆Ki(E)

A\* 是代理人共同知识的基础。L∗N(E) 表示对于一组 A\* 对称推理者 N 定义的命题，因此我们可以说如果 ω∈L∗N(E)，那么 E 对于 N 的代理人是 Lewis 共同知识。

用文字表达，L1 表示我在ω处知道 A _。L2 表示如果我知道 A_发生，那么我知道每个人都知道 A_发生。这个公理旨在捕捉基于公开已知命题 A_的共同知识的概念，就像代理听到公开公告时的情况一样。如果代理的知识由分割表示，那么代理的共同知识的典型基础将是它们分割的 meet\[14]中的元素 M(ω)。L3 表示我可以从 A\*推断出 E。刘易斯的定义暗示了整个共同知识层次结构，如下结果所示。

\*\* 命题 2.8\*\* L∗N(E)⊆K∗N(E)，即，E 的 Lewis-共同知识蕴含 E 的共同知识。 证明。

正如上文所提到的，最近有人质疑是否对 Lewis 的定义进行正式诠释，如上所述，充分代表了 Lewis 方法的所有方面。 Cubitt 和 Sugden（2003）认为并非如此，他们的批评关键在于 Lewis 分析中一个在可能世界框架中丢失的特征，即 Lewis 使用的指示的三元关系。指示的定义可以在《约定》的 52-53 页找到。

\*\* 定义 2.9\*\* 一个事态 A 对于主体 i 表示 E (AindiE) 当且仅当，如果 i 有理由相信 A 是真实的，那么 i 将由此有理由相信 E

Lewis 的定义措辞以及他在共同知识的定义性条款中使用的指示关系，表明 Lewis 在区分指示和物质蕴涵方面非常谨慎。Cubitt 和 Sugden（2003）在他们的形式重建中融入了这种区别。结合他们对“i 有理由相信 x”的解释，即“x 是由 i 认可的某种推理逻辑产生的”，我们得出结论，如果 Aindix，则 i 相信 A 的理由也为 i 提供了相信 x 的理由。考虑到 Lewis 确实希望赋予代理人推理能力，（Cubitt 和 Sugden 2003）列出以下公理，声称这些公理捕捉了指示的期望特性。对于所有代理人 i、j，其中 RiA 代表“代理人 i 有理由相信 A”，我们有

(CS1)(CS2)(CS3)(CS4)(CS5)(RiA∧Aindix)→Rix(A 含蕴 B)→AindiB(Aindix∧Aindiy)→Aindi(x∧y)(AindiB∧Bindix)→Aindix((AindiRjB)∧Ri(Bindjx))→AindiRjx

第一个公理捕捉了指示背后的直觉。它说，如果一个 agent 有理由相信 A 成立，那么如果 A 向她指示 x，她也有理由相信 x。CS2 说指示扩展了物质蕴涵。CS3 说如果两个命题 x 和 y 被一个命题 A 向一个 agent 指示，那么 A 也向她指示 x 和 y 的合取。下一个公理陈述了指示是传递的。CS5 说如果一个命题 A 向 i 指示 agent j 有理由相信 B，而 i 有理由相信 B 指示 x 给 j，那么 A 也向 i 指示 j 有理由相信 x。

凭借这些公理，我们可以给出以下定义。

\*\* 定义 2.10\*\* 在任何给定的人口 P 中，命题 A 是一个反身的共同指标，即当且仅当，对于所有 i，j∈P 和所有命题 x，y，以下四个条件成立：

(RCI1)(RCI2)(RCI3)(RCI4)A→RiAAindiRjAAindixAindjy→Ri(Aindjy)

以上的 RCI1–RCI3 条款将上述定义 2.7 中的 L1–L3 表达为支撑公理 CS1–CS5 的形式语言；而 RCI4 确认（参见上述定义 2.6）代理人是对称推理者，即如果一个命题向某个特定代理人指示另一个命题，那么它也会向人群中的所有代理人指示。

以下命题表明，RCI1-RCI4 是“共同相信的”产生的充分条件：

\*\* 命题 2.11\*\* 如果 A 成立，并且如果 A 是人口 P 中普遍的反身指示器，表明 x，那么在 P 中有共同的理由相信 x。 证明。

一组（理想的）无缺陷的推理者，他们有共同的理由相信 p，将会达成对 p 的共同信念。

能否在不放弃可能世界框架的情况下正式考虑刘易斯对共同知识定义的见解？（Sillari 2005）试图通过在可能世界语义中阐明实际信念和相信理由之间的区别来积极回答这个问题。正如（Cubitt and Sugden 2003）中所述，基本的认知运算符代表相信的理由。然后的想法是在可能世界上施加一个意识结构，采用了 Fagin 和 Halpern（1988）首次引入的框架。简而言之，一个意识结构将与每个代理相关联，对于每个可能的世界，代理被认为意识到的一组事件。如果一个代理有理由相信某个事件发生，并且这个事件在考虑的世界中在她的意识集合中，那么代理就会对某个事件的实际信念感到满意。对于形式化刘易斯共同知识观点的另一种途径是由 Paternotte（2011）提出的，其中核心概念是概率共同信念（见下文 5.2 节）。

### 2.3 奥曼的观点

Aumann (1976) 给出了一个不同的共同知识表征，为确定什么信息是共同已知提供了另一个简单算法。Aumann 的原始描述假定每个代理的可能性集合形成了可能世界空间 Ω 的私人信息分区。Aumann 表明，一个命题 C 是共同知识当且仅当 C 包含代理分区的 meet 的一个单元。计算分区 Hi,i∈N 的 meet M 的一种方法是使用“可达性”的概念。

\*\* 定义 2.13\*\* 从 ω∈Ω 到 ω′∈Ω 的状态 ω′ 可达 当且仅当存在一个序列

ω=ω0, ω1, ω2,…, ωm=ω′ ω=ω0, ω1, ω2,…, ωm=ω′

使得对于每个 k∈{0,1,…,m−1}，存在一个代理 ik∈N，使得 Hik(ωk)=Hik(ωk+1)。

用文字描述，如果存在一系列状态或“链”，从ω到ω′，使得两个连续状态在某个代理的信息分割的同一单元格中，那么ω′可以从ω到达。为了说明可达性的概念，让我们回到修改后的烧烤问题，其中凯西（Cathy）、詹妮弗（Jennifer）和马克（Mark）没有收到任何公告。他们的信息分割如图 2.1d 所示：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure2.1d.gif)

图 2.1d

一个人可以通过以下方式理解可达性概念的重要性：如果从ω到ω′是可达的，那么如果ω发生，那么某个代理可以推断出另一个代理认为ω′是可能的。看图 2.1d，如果ω=ω1 发生，那么只知道{ω1, ω2}发生的 Cathy 知道 Jennifer 认为ω5 可能发生（尽管 Cathy 知道ω5 没有发生）。因此，Cathy 无法排除 Jennifer 认为 Mark 认为ω8 可能发生的可能性。Cathy 也无法排除 Jennifer 认为 Mark 认为 Cathy 相信ω7 是可能的可能性。从这个意义上说，ω7 是从ω1 可达的。建立这一点的状态链是ω1, ω2, ω5, ω8, ω7，因为 H1(ω1)=H1(ω2)，H2(ω2)=H2(ω5)，H3(ω5)=H3(ω8)，以及 H1(ω8)=H1(ω7)。请注意，可以类似地表明在这个例子中任何状态都可以从任何其他状态到达。这个例子还说明了以下直接结果：

\*\* 命题 2.14\*\* ω' 可以从 ω 达到，当且仅当存在一个序列 i1，i2，…，im∈N，使得

ω′∈Him(⋯(Hi2(Hi1(ω))))

一个人可以将（1）理解为：“在ω时，i1 认为 i2 认为...，im 认为ω'是可能的。”

我们现在有：

\*\* 引理 2.15\*\* ω′∈M(ω)当且仅当从ω可达ω′。 证明。

和

\*\* 引理 2.16\*\* M(ω)是 N 的代理人在ω处的共同知识。 证明。

和

命题 2.17 (Aumann 1976) 设 M 为每个 i∈N 的代理分区 Hi 的交集。对于ω处于Ω的代理 N 来说，命题 E⊆Ω是共同知识，当且仅当 M(ω)⊆E。（在 Aumann (1976)中，若 M(ω)⊆E，则 E 被定义为在ω处是共同知识。） 证明。

如果 E=K1N(E)，那么 E 是一个公共事件（Milgrom 1981）或一个共同的真理（Binmore 和 Brandenburger 1989）。显然，每当共同真理发生时，它就是共同知识，因为在这种情况下 E=K1N(E)=K2N(E)=…，所以 E=K∗N(E)。命题 2.17 的证明表明，共同真理恰好是 M 的元素和 M 的元素的并集，因此任何共同已知的事件都是共同真理的结果。

### 2.4 巴威斯的观点

Barwise (1988)提出了另一种关于共同知识的定义，避免了明确提及“i 知道 j 知道…知道 A”的层次结构。Barwise 的分析建立在 Harman (1977)的一项非正式提议之上。考虑示例 1 中客人和笨拙的服务员的情况，当服务员宣布自己出错时。他们现在处于一个他们听到服务员宣布并知道自己处于这种情况的环境中。Harman 采纳了这种对环境的特征化中的循环性作为基础，并提出了一个关于共同知识的定义，涉及到这种循环性。Barwise 的形式分析对 Harman 对共同知识的直观分析给出了一个精确的表述，即一个固定点。给定一个函数 f，如果 f(A)=A，则 A 是 f 的一个固定点。现在注意到

K1N(E∩∞⋂m=1KmN(E))=K1N(E)∩K1N(∞⋂m=1KmN(E))=K1N(E)∩(∞⋂m=1K1N(KmN(E)))=K1N(E)∩(∞⋂m=1KmN(E))=∞⋂m=1KmN(E)

因此，我们已经确定了 K∗N(E)是由 fE 定义的函数 fE 的不动点，其中 fE(X)=K1N(E∩X)。fE 还有其他不动点。例如，任何矛盾 B∩Bc=∅都是 fE 的一个不动点。\[15] 还要注意，如果 A⊆B，则 E∩A⊆E∩B，因此

fE(A)=K1N(E∩A)⊆K1N(E∩B)=fE(B)

也就是说，fE 是单调的。（我们在命题 2.4 的证明中看到 K1N 也是单调的。）Barwise 对共同知识的分析可以利用集合论中以下结果进行发展：

\*\* 命题\*\* 一个单调函数 f 具有一个唯一的不动点 C，使得如果 B 是 f 的一个不动点，则 B⊆C。C 是 f 的最大不动点。

这个命题建立了 fE 有一个最大不动点的观点，这一点在 Barwise 的描述中表征了共同知识。正如 Barwise 本人所观察到的，共同知识的不动点分析与奥曼的分割描述密切相关。当人们将不动点分析与奥曼描述生成的共同真理概念进行比较时，很容易看出这一点。一些作者认为不动点分析是奥曼分析的一种替代表述。那些特别关注将共同知识应用于逻辑问题的人更喜欢 Barwise 对共同知识的不动点分析，而那些希望将共同知识应用于社会哲学和社会科学的人更喜欢分层和分割描述。当知识运算符满足(K1)-(K5)的公理时，Barwise 对共同知识的描述等同于分层描述。

\*\* 命题 2.18\*\* 让 C∗N 成为 fE 的最大不动点。那么 C∗N(E)=K∗N(E)。（在 Barwise (1988, 1989)中，如果ω∈C∗N(E)，则 E 被定义为ω处的共同知识。） 证明。

Barwise 认为，实际上固定点分析比分层账户更灵活，因此更一般。这可能会让读者感到惊讶，因为命题 2.18 表明 Barwise 的固定点定义等同于分层账户。事实上，Barwise（1988 年，1989 年）证明了一个结果，表明固定点账户蕴含了分层账户，并且给出了满足共同知识层次结构但不是固定点的例子，一些在 Barwise 之后撰写的作者给出了两个定义等价的各种证明，正如命题 2.18 所示。事实上，正如（Heifetz 1999）所示，对于所有有限层次的迭代，分层和固定点账户是等价的，而固定点共同知识蕴含了任何超限序数的相互知识的合取，但从未被任何这样的合取所蕴含。

### 2.5 吉尔伯特的论述

Gilbert (1989, 第 3 章) 提出了一个关于共同知识的替代解释，旨在比 Lewis 和 Aumann 的解释更具直观可信性。 Gilbert 对代理人拥有共同知识的情况进行了高度详细的描述。

\*\* 定义 2.19\*\* 一组代理 N 在一个关于命题 A 的共同知识情境 S(A)中，当且仅当，ω∈A 且对于每个 i∈N 时，

(G1)

i 具有认识正常性，即 i 具有正常运作的感知器官和正常的推理能力。\[16]

(G2)

i 具备了实现其他条件所需的概念。

(G3)

我感知了 N 的其他代理。

(G4)

我认为 G1 和 G2 是这种情况。

(G5)

我认为 A 所描述的情况是事实。

(G6)

我感知到所有 N 的代理人感知到 A 是事实。

吉尔伯特的定义似乎包含了一些冗余，因为可以假定一个主体不会感知到 A，除非 A 是事实。吉尔伯特显然试图比刘易斯和奥曼给出更明确的单一主体知识解释。对于吉尔伯特来说，如果且仅如果ω∈E，即 E 为真，并且 i 感知到 E 描述的事态发生，或者 i 可以根据 i 知道的其他命题推断 E，前提是具有足够的推理能力，那么主体 i 知道命题 E 为真。

像 Lewis 一样，Gilbert 认识到人类并没有无限的推理能力。为了生成无限的相互知识层次，Gilbert 引入了一个代理人的“平滑推理者”对应物的概念。代理人 i 的平滑推理者对应物 i′是一个代理人，从 i 所知的每个事实中得出每个逻辑结论。Gilbert 规定 i′没有 i 可能具有的任何时间、记忆或推理能力的限制，因此 i′可以真正地思考共同知识层次的无限多个层次。

\*\* 定义 2.20\*\* 如果一组代理 N 在关于 A 的共同知识情况 SN(A)中，那么它们的平滑推理对应集合 N'在平行情况 S'N'(A)中，当且仅当对于每个 i'∈N 时

| (G′1) | i′ can perceive anything that the counterpart i can perceive. |
| ----- | ------------------------------------------------------------- |
| (G′2) | G2-G6 对于 i'相对于 A 和 N'的获取与相对于 A 和 N 的对应 i 相同。                  |
| (G′3) | i′ 察觉到 N′ 的所有代理人都是顺畅推理者。                                      |

根据这个定义，我们得到以下直接的结果：

\*\* 命题 2.21\*\* 如果一组光滑推理者对应于一组代理人 N，并处于与 N 的共同知识情况 SN(A)平行的情况 S'N'(A)中，则

对于所有 m∈N 和任意 i′1,…,i′m,Ki′1Ki′2…Ki′m(A)。

因此，对于任意的 m∈N，KmN′(A)。

Gilbert 认为，鉴于 S′N′(A)，N 的代理人的平滑推理对应物实际上满足一个更强的条件，即相互知识 KαN′(A)达到任意序数α的水平，无论是有限还是无限。当满足这一更强的条件时，命题 A 被称为对 N 的代理人是开放的。通过开放性的概念，Gilbert 给出了她对共同知识的定义。

\*\* 定义 2.22\*\* 一个命题 E⊆Ω 在集合 N={1,…,n} 的代理人中是 Gilbert-共同知识，当且仅当，

| (G∗1) | E is open\* to the agents of N. |
| ----- | ------------------------------- |
| (G∗2) | 对于每个 i∈N，Ki(G∗1)。               |

G∗N(E)表示由 A∗-对称推理者集合 N 定义的命题，因此我们可以说 E 是 N 的代理人的 Lewis-共同知识，当且仅当ω∈G∗N(E)。

有人可能认为，吉尔伯特的定义的一个直接推论是，吉尔伯特-共同知识意味着命题 2.5 的分层共同知识。然而，这一说法仅在一个假设上成立，即一个代理知道她的平滑推理者对所有命题的推理。吉尔伯特并没有明确支持这一立场，尽管她正确地观察到，刘易斯和奥曼对类似观点做出了承诺。吉尔伯特认为，她对共同知识的描述更能表达我们对共同知识的直觉，而不像刘易斯和奥曼的描述，因为“开放性”的概念明显地表明，当一个命题是共同知识时，它是“公开的”，可以说。

## 3. 相互和共同知识的应用

对于主要关心共同知识哲学应用的读者，可能希望专注于《无分歧定理》和《约定》小节。对于对共同知识在博弈论中的应用感兴趣的读者，可以继续阅读《战略形式博弈》和《完全信息博弈》小节。

* [3.1 “无分歧”定理](https://plato.stanford.edu/entries/common-knowledge/#3.1)
* [3.2 传统](https://plato.stanford.edu/entries/common-knowledge/#3.2)
* [3.3 战略型博弈](https://plato.stanford.edu/entries/common-knowledge/#3.3)
* [3.4 完全信息博弈](https://plato.stanford.edu/entries/common-knowledge/#3.4)
* [3.5 通信网络](https://plato.stanford.edu/entries/common-knowledge/#3.5)

### 3.1 “无分歧”定理

Aumann (1976) 最初使用他对共同知识的定义来证明一个著名的结果，即在某种意义上，如果代理人从共同的先验信念出发，他们不能“同意不同意”他们的信念，形式化为概率分布。由于社区中的代理人经常持有不同的观点并且知道这一点，人们可能将这种差异归因于代理人拥有不同的私人信息。奥曼（Aumann）令人惊讶的结果是，即使代理人将他们的信念置于私人信息之上，仅仅是对他们的调整信念有共同知识以及共同的先验概率分布，也意味着他们的信念毕竟不能不同！

\*\* 命题 3.1\*\* 让Ω是一个有限的世界状态集合。假设

1. 代理人 i 和 j 对 Ω 中事件的共同先验概率分布 μ(⋅)，使得对于每个 ω∈Ω，μ(ω)>0
2. 这是共同知识，在ω处，i 对事件 E 的后验概率是 qi(E)，而 j 对 E 的后验概率是 qj(E)。

那么 qi(E) = qj(E)。

证明。 \[请注意，在这个命题的证明中，以及接下来的内容中，μ(⋅∣B)表示条件概率；也就是说，给定μ(B)>0，μ(A∣B)=μ(A∩B)/μ(B)。]

在后来的一篇文章中，奥曼（Aumann，1987）认为Ω是有限的假设和对于每个ω∈Ω都有μ(ω)>0 的假设反映了代理人只将有限一组显著世界视为“真正”可能，因此可以从状态空间的描述中删除概率为 0 的状态。奥曼还指出，这一结果隐含地假定代理人对其分区有共同知识，因为每个可能世界的描述包括代理人的可能性集的描述。当然，这一结果至关重要地依赖于（i），即被称为共同先验假设（CPA）的假设。

Aumann 的“无分歧”定理在文献中以多种方式被概括。Cave 1983 将论证概括为 3 个代理人。Bacharach 1985 将其扩展到代理人观察彼此决策而不是后验的情况。Milgrom 和 Stokey，1982 年在他们的无交易定理中关键地使用它，应用无分歧来表明投机交易是不可能的。Geanakoplos 和 Polemarchakis 1982 将论证概括为一个动态设置，在这个设置中，两个代理人互相交流他们的后验概率，直到他们达成一致意见 - 这种关于一致定理的特定看法已经被 Dégremont 和 Roy，2009 年以动态认知逻辑的术语表征，并由 Sillari 2019 年应用于认知同行分歧的案例。McKelvey 和 Page 1986 进一步将 Geanakoplos 和 Polemarchakis 的结果扩展到 n 个个体的情况。（另请参见 Monderer 和 Samet 1989 年，以及有关调查的 Geanakoplos 1994 年。）

然而，所有这些“无分歧”的结果都引发了奥曼原始结果提出的相同哲学难题：我们如何解释信念上的差异？奥曼的结果给我们留下了两个选择：（1）承认在某个层面上，代理人的信念的共同知识或者他们形成信念的方式存在失败，或者（2）否认 CPA。因此，即使代理人对某事件分配了精确的后验概率，奥曼表明，如果他们仅仅具有对后验概率的一阶互相知识，他们可以“同意不同意”。另一种奥曼结果可能失败的方式是，如果代理人没有共同知识，即他们通过贝叶斯条件化更新他们的信念。那么显然，代理人可以将不同意见解释为其他人以“错误”的方式修改了他们的信念。然而，在某些情况下，这两种解释都不会令人信服，否认必要的共同知识似乎是一个相当临时的举措。为什么有人会认为这种共同知识的失败提供了对不同信念的普遍解释？

第二个选择呢，也就是否认 CPA？支持 CPA 的主要论点是，代理人概率上的任何差异应该只是由于他们拥有不同信息的结果，也就是说，没有理由认为代理人对同一事件持有不同信念是由于其他原因而不是他们拥有不同信息。然而，有人可以回答说，这个论点实际上只是哈尔萨尼信条的重申。

### 3.2 传统

Schelling 的《例 1.5 的百货商店问题》是一个非常简单的例子，代理商通过建立惯例适当地解决了协调问题。（参见本百科全书中有关惯例的条目。）利用博弈论的词汇，Lewis（1969）将惯例定义为一种严格的协调均衡，代理商们因为共同知识而遵循这种协调均衡，他们都更喜欢在一个经常性的协调问题中遵循这种协调均衡。一个博弈的协调均衡是一种策略组合，使得如果任何一个代理商单方面偏离这种组合，那么没有一个代理商会因此变得更好。与一般均衡一样，协调均衡是严格的，如果任何一个代理商单方面偏离均衡，那么他会变得严格更糟。图 1.3 的战略形式博弈总结了 Liz 和 Robert 的情况。百货商店博弈有四个纯策略的纳什均衡结果：（s1，s1），（s2，s2），（s3，s3）和（s4，s4）。这四个均衡都是严格的协调均衡。如果代理商遵循这些均衡中的任何一个，那么他们将成功协调。在这种情况下，要代理商们遵循 Lewis 的惯例，他们必须遵循游戏的协调均衡之一。然而，Lewis 遵循协调均衡并不是代理商遵循惯例的充分条件。假设 Liz 和 Robert 根本没有正确分析他们的困境，但 Liz 选择 s2，Robert 选择 s2，以至于他们仅仅凭运气在（s2，s2）协调。Lewis 不认为这种偶然的协调是一种惯例。

假设接下来两位代理人都是贝叶斯理性的，并且每位代理人所知道的一部分是交叉游戏的收益结构。如果代理人们期望彼此遵循（s2，s2）并因此成功协调，那么他们是否在遵循一项惯例？在《惯例》第 59 页上，刘易斯提出了一个微妙的论证，认为不一定。因为虽然每位代理人都知道游戏并且知道自己是理性的，但她可能不会将相同的知识归因于另一位代理人。如果每位代理人都相信另一位代理人会毫无思考地遵循她的（s2，s2）均衡的一端，那么她最佳的反应就是遵循她的（s2，s2）一端。但在这种情况下，代理人们协调是因为他们每个人都错误地认为对方像自动机一样行事，而刘易斯认为，对惯例的任何恰当解释都必须要求代理人对彼此有正确的信念。特别是，刘易斯要求参与惯例的每位代理人必须相互期望，每个人都在以协调与对方为目标行动。这个论证可以进一步展开。如果两位代理人都相信他们将遵循（s2，s2），并且相信彼此会这样做，认为对方会理性地选择 s2 而不是毫无思考地选择？那么，比如说，丽兹将会协调，因为她错误地具有第二阶信念，即罗伯特相信丽兹是毫无思考地行动。对于第三阶信念以及任何更高阶知识，情况也是类似的。

Lewis 得出结论，代理人遵循惯例的一个必要条件是，他们遵循相应协调均衡的偏好是共同知识（最近有争论是否惯例需要是共同知识，参见 Cubitt 和 Sugden 2003 年，Binmore 2008 年，Sillari 2008 年，以及关于实验方法的 Devetag 等人 2013 年，关于规则遵循主题的联系，请参见 Sillari 2013 年）。因此，在 Lewis 的观点中，一组代理人的惯例是一个协调均衡，代理人们由于对他们的理性、相关博弈的收益结构以及每个代理人遵循均衡的部分的共同知识而遵循。

> 人口 P 的成员在循环情境 S 中作为代理人的行为中的规律性 R 是一种惯例，当且仅当以下条件成立：在 P 中是共同知识，在 P 的成员中的任何 S 实例中，
>
> 1. 每个人都遵从 R
> 2. 每个人都期望其他人遵循 R
> 3. 每个人对所有可能的行动组合大致具有相同的偏好
> 4. 每个人都更喜欢每个人都遵守 R，条件是至少除了一个人之外的所有人都遵守 R
> 5. 每个人都希望每个人都遵守 R′，条件是至少除了一个人外，所有人都遵守 R′
>
> 其中，R′是 P 成员在 S 中行为的某种可能的规律，以至于在 P 成员的任何 S 实例中，没有人能够同时符合 R′和 R。 (Lewis 1969, p. 76)\[22]

Lewis 包括了一个要求，即除了所有人都遵循的平衡 R 外，还需要一个备用协调平衡 R'，以捕捉一个基本直觉，即遵循惯例的代理人的行为取决于他们如何期望其他人行为的关键性。

Sugden (1986) 和 Vanderschraaf (1998) 认为，对于惯例的概念来说，相应的均衡并不一定是协调均衡。 路易斯的关键洞察是，惯例是一种相互有利的行为模式，这取决于代理人的共同知识，即所有人都遵循这种模式，而不是其他模式。 Vanderschraaf 给出了一个更一般的惯例定义，即一个严格均衡，加上所有人都遵循这个均衡的共同知识，如果他们对彼此的信念不同，所有人都会遵循不同的均衡。 在下面对图 3.1 示例的讨论中给出了这种更一般类型的惯例的一个例子。

### 3.3 战略型博弈

Lewis 在他对约定的一般解释中制定了共同知识的概念。在《约定》出版后的几年里，博弈论者意识到，对游戏中特定玩法的任何解释都至关重要地依赖于相互和共同知识的假设。更具体地说，博弈论中的解决方案概念在很大程度上是由玩家对自己处境的相互或共同知识所激发和证明的。

为了建立接下来讨论中将要使用的符号表示法，这里给出了战略形式游戏、期望效用和代理人对对手策略的分布的通常定义：

\*\* 定义 3.2\*\* 一个游戏Γ是由以下元素组成的有序三元组(N,S,u)：

1. 一个有限集合 N={1,2,…,n}，称为代理人或玩家的集合。
2. 对于每个代理人 k∈N，存在一个有限集合 Sk={sk1,sk2,…,sknk}，称为代理人 k 的备选纯策略。笛卡尔积 S=S1×…×Sn 被称为博弈 Γ 的纯策略集。
3. 一个映射 u：S→Rn，称为在纯策略集上的效用或收益函数。在每个策略组合 s=(s1j1,…,snjn)∈S 处，代理 k 的特定收益或效用由 u 的值的第 k 个分量给出，即，代理 k 在 s 处的效用 uk 由 uk(s)=Ik(u(s1j1,…,snjn))确定。

将 Ik(x) 投影到其第 k 个分量。

下标‘−k’表示去除 n 元组或 n 重笛卡尔积的第 k 个分量的结果。例如，

S−k=S1×…×Sk−1×Sk+1×…×Sn

表示代理 k 的对手可能采取的纯策略组合。

现在让我们正式将代理人信念系统引入这个框架中。 Δk(S−k)表示可测空间(S−k,Fk)上的概率分布集合，其中 Fk 表示由策略组合 S−k 生成的布尔代数。每个代理人 k 都有一个概率分布μk∈Δk(S−k)，这个分布决定了 k 的每个可能行为的（Savage）期望效用：

E(uk(skj))=∑A−k∈S−kuk(skj,s−k)μk(s−k), j=1,2,…,nk

如果 i 是 k 的对手，则 i 的个体策略 sij 可以被描述为策略组合的并集⋃{s−k∣sij∈s−k}∈Fk，因此 k 对 i 的策略 sij 的边际概率可以如下计算：

μk(sij)=∑{s−k∣sij∈s−k}μk(s−k)

μk(⋅∣A)表示给定集合 A 的 k 的条件概率分布，而 E(⋅∣A)表示给定μk(⋅∣A)的条件期望。

假设首先，代理人们共同知晓他们参与的游戏的完整收益结构，并且他们都是理性的，而且没有其他信息是共同知识。换句话说，每个代理人都知道她的对手是期望效用最大化者，但通常不知道对手将选择哪些策略或者她的行为的概率是多少。这些共同知识的假设是非合作博弈的解决概念——称为合理性的基础，由伯恩海姆（1984 年）和皮尔斯（1984 年）独立引入。粗略地说，一个合理的策略是代理人可以选择的任何策略，而不违反贝叶斯理性的共同知识。伯恩海姆和皮尔斯认为，当只有游戏的结构和代理人的贝叶斯理性是共同知识时，如果每个代理人都采用一个合理的策略，那么游戏应该被认为是“解决”的。例如，在由图 3.1 定义的收益结构的“鸡”游戏中，

|                                                                                                                 |                                                                                                                                                                                                                                                   | Joanna                                                                                                                                                                                                                                                                                                             |                                                                                                                                                                                             |
| --------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|                                                                                                                 |                                                                                                                                                                                                                                                   | I'm sorry, but it seems like there was an error in your request. It appears that the text you provided for translation is only "s1," which does not contain any actual content to be translated. Could you please provide the full text or let me know if there is anything else you would like me to assist with? | I'm sorry, but it seems like you only provided "s2" which does not contain any text to translate. Could you please provide the text you would like me to translate into Simplified Chinese? |
| ---                                                                                                             | ---                                                                                                                                                                                                                                               | ---                                                                                                                                                                                                                                                                                                                | ---                                                                                                                                                                                         |
| Lizzi                                                                                                           | I'm sorry, but it seems like there was an error in your request. It appears that you only provided "s1" without any accompanying text to be translated. Could you please provide the text you would like me to translate into Simplified Chinese? | (3,3)                                                                                                                                                                                                                                                                                                              | (2,4)                                                                                                                                                                                       |
| I'm sorry, but your request is unclear. Could you please provide more context or clarify what you mean by "s2"? | (4,2)                                                                                                                                                                                                                                             | (0,0)                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                             |

图 3.1

如果 Joanna 和 Lizzi 对每种策略组合的所有收益都有共同知识，并且他们共同知道彼此都是贝叶斯理性的话，那么四种纯策略配置中的任何一种都是可以理性化的。因为如果他们对彼此的信念是由概率定义的，

α1=μ1（Joanna plays s1），而α2=μ2（Lizzi plays s1）

然后

E(ui(s1))=3αi+2(1−αi)=αi+2

和

E(ui(s2))=4αi+0(1−αi)=4αi, i=1,2

因此，如果αi+2≥4αi 或αi≤2/3，则每个代理通过选择 s1 来最大化其预期效用，并且如果αi≥2/3，则通过选择 s2 来最大化其预期效用。如果恰好对于两个代理都有αi>2/3，那么根据各自的信念，两者都会遵循贝叶斯理性，选择他们的策略组合的端点（s2，s2），即使每个人在发现对方实际上会选择 s2 时都想要背叛这个策略组合。请注意，游戏的纯策略纳什均衡（s1，s2）和（s2，s1）是可理性化的，因为对于 Lizzi 和 Joanna 来说，根据适当的分布，遵循任一均衡都是理性的。一般来说，一个游戏的可理性化策略组合集合包含了游戏的纯策略纳什均衡集合。【23】

理性可证明性可以在几种形式上进行正式定义。这里给出了伯恩海姆原始（1984 年）定义的一个变体。

\*\* 定义 3.3\*\* 考虑到每个代理 k∈N 都有一个概率分布μk∈Δk(s−k)，信念系统μ=(μ1,…,μn)∈Δ1(S−1)×⋯×Δn(S−n)

贝叶斯一致的条件是当且仅当，

(3.i)

对于 i≠k，μi(skj)>0⇒skj 最大化 k 的期望效用，对于某些σk∈Δk(s−k)

而（3.i）是共同知识。如果并且仅当代理人拥有一个贝叶斯一致的信念系统μ，并且对于每个代理人 k∈N，一个纯策略组合 s=(s1j1,…,snjn)∈S 是合理化的。

(3.ii)

E(uk(skjk)) ≥ E(uk(skik)), 对于 ik≠jk。\[24]

以下结果显示，对于定义 3.1 中的分布的共同知识限制形式化了代理人具有贝叶斯理性的假设。

\*\* 命题 3.4\*\* 在一个博弈Γ中，如果且仅如果贝叶斯理性的共同知识得到满足，那么(3.i)就是共同知识。 证明。

当代理人对游戏有共同知识并且只有他们的贝叶斯理性时，可以预测他们将遵循一个可理性化的策略配置。然而，如果代理人们了解彼此更多信息，可理性性将成为一个不稳定的解决概念。例如，在上面的 Chicken 示例中，如果αi>2/3，i=1,2，如果任一代理人发现另一代理人对她的信念，她就有充分理由不遪随(s2,s2)配置并修改自己对另一代理人的信念。另一方面，如果α1=1 且α2=0，使得代理人通过遵循(s2,s1)配置最大化预期收益，那么如果代理人们发现彼此对彼此的信念，他们仍然会遵循(s2,s1)。实际上，如果他们的信念是共同知识，那么可以肯定地预测他们将遵循(s2,s1)。纳什均衡(s2,s1)的特征是由α1=1 和α2=0 定义的信念分布。

纳什均衡是相关均衡概念的一个特例，这些概念是根据博弈中代理人的信念分布来定义的。一般来说，信念中的相关均衡是代理人概率分布的系统，在博弈的共同知识、理性和信念本身的情况下保持稳定。我们将回顾两种替代的相关均衡概念（Aumann 1974, 1987；Vanderschraaf 1995, 2001），并展示每种如何推广纳什均衡概念。

\*\* 定义 3.5\*\* 鉴于每个代理人 k∈N 都有一个概率分布 μk∈Δk(s−k)，信念系统

μ∗=(μ∗1,…,μ∗n)∈Δ1(s−1)×…×Δn(s−n) μ∗=(μ∗1,…,μ∗n)∈Δ1(s−1)×…×Δn(s−n)

是内生相关均衡，当且仅当

(3.iii)

对于 i≠k，μ∗i(skj)>0⇒skj 在给定μ∗k 的情况下最大化 k 的预期效用。

如果μ∗是内生相关均衡，纯策略组合 s∗=(s∗1,…,s∗n)∈S 是给定μ∗的内生相关均衡策略组合，当且仅当对于每个代理人 k∈N 时，

(3.iv)

E(uk(s∗k))≥E(uk(ski)) 对于 ski≠s∗k。

因此，内生相关均衡μ∗限制了代理可能遵循的策略集，正如理性可证实性的贝叶斯一致信念所做的那样。然而，内生相关均衡概念是理性可证实性的一个适当细化，因为后者并不假设条件（3.iii）关于对手实际持有的信念是否成立。如果恰好有一个纯策略组合 s∗满足给定μ∗的（3.iv），那么μ∗就是一个严格均衡，在这种情况下，可以在对博弈的共同知识、理性和他们的信念的基础上确定代理将会做什么。请注意，定义 3.5 并未说明代理是否认为对手的策略组合在概率上是独立的。此外，这个定义也不要求代理的概率是一致的，即代理对于对手行为的概率是否一致。内生相关均衡概念的一个简单细化刻画了纳什均衡概念。

\*\* 定义 3.6\*\* 代理人信念μ∗的系统是纳什均衡，当且仅当，

1. 条件（3.iii）得到满足，
2. 对于每个 k∈N，μ∗k 满足概率独立性
3. 对于每个 skj∈sk，如果 i，l≠k，则μ∗i(skj)=μ∗l(skj)。

换句话说，内生相关均衡是一种纳什均衡中的信念均衡，当每个参与者将对手的动作视为概率独立，并且参与者的概率是一致的时。请注意，在两个参与者的情况下，定义 3.6 的条件(b)和(c)总是满足的，因此对于两个参与者的博弈，内生相关均衡概念归结为纳什均衡概念。条件(b)和(c)在博弈论中传统上被假定，但 Skyrms（1991）和 Vanderschraaf（1995，2001）认为，在涉及 3 个或更多参与者的博弈中，放宽这些假设可能有充分的理由。

Brandenburger 和 Dekel（1988）表明，在 2 人博弈中，如果代理的信念是共同知识，条件（3.iii）表征了信念中的纳什均衡。正如他们所指出的，如果概率分布是一致的并且满足概率独立性，条件（3.iii）表征了 n 人情况下信念中的纳什均衡。命题 3.7 通过放宽一致性和概率独立性假设，将 Brandenburger 和 Dekel 的结果扩展到内生相关均衡概念。

\*\* 命题 3.7\*\* 假设概率..

μ=(μ1,…,μn)∈Δ1(s−1)×…×Δn(s−n)

共同知识。然后，只有当μ是内生相关均衡时，贝叶斯理性的共同知识才得到满足。 证明。

此外，我们还有：

推论 3.8（Brandenburger and Dekel, 1988） 假设在一个双方参与的博弈中，概率..

μ=(μ1,μ2)∈Δ1(s−1)×Δ2(s−2)

共同知识。然后，只有当μ是纳什均衡时，贝叶斯理性的共同知识才得到满足。

\*\* 证明。\*\* 内生相关均衡概念在两个代理人情况下归结为纳什均衡概念，因此推论由命题 3.7 得出。

如果μ∗是一个严格均衡，那么在共同知识、理性和μ∗的情况下，可以预测游戏中的代理人将遵循哪种纯策略配置。但是，如果μ∗是这样的，以至于有几种不同的纯策略配置满足关于μ∗的（3.iv）条件，那么就不能确定代理人将做出什么行动。例如，在图 3.1 的 Chicken 博弈中，由α1=α2=2/3 定义的信念分布一起构成了一个信念中的纳什均衡。在共同知识下的这种均衡，对于每个代理人来说，任何一种纯策略都是最佳回应，即任何一种纯策略都最大化了预期效用。实际上，如果代理人还可以采用随机化或混合策略，在这些策略中，他们根据一个机会实验的结果选择几种纯策略中的一种，那么在 Chicken 博弈中代理人可能采用的任何无限混合策略都是最佳回应，鉴于μ∗。因此，内生相关均衡概念并不能确定在所有情况下游戏的确切结果，即使假设概率一致性和独立性，以便均衡是一个纳什均衡。

Aumann（1974, 1987）形式化的另一个相关均衡概念确实可以确定地预测在博弈中代理人会做什么，前提是有适当的共同知识。为了说明 Aumann 的相关均衡概念，让我们再次考虑图 3.1 中的博弈。如果 Joanna 和 Lizzi 可以将他们的策略与他们对可能世界的知识以某种方式联系起来，他们可以遵循一套相关策略体系，这将产生一个收益向量，他们都更喜欢这个向量而不是混合纳什均衡的向量，并且这本身就是一个均衡。他们可以实现这一点的一种方式是让他们的朋友 Ron 玩一个熟悉的壳游戏的变体，即在三个核桃壳（编号为 1、2 和 3）下藏一个豌豆。Joanna 和 Lizzi 都认为与ωk={豌豆在壳 k 下}对应的三个相关可能世界中的每一个同等可能。然后，Ron 根据游戏结果给 Lizzi 和 Joanna 各自提供一个私人建议，这个建议基于游戏的结果，定义了一个策略组合 f 的体系。

(⋆)f(ω)=⎧⎨⎩(s1,s1) 如果 ωk=ω1(s1,s2) 如果 ωk=ω2(s2,s1) 如果 ωk=ω3

f 是一个相关策略系统，因为代理人将他们的策略与世界Ω的相同状态集相关联，通过遵循他们的建议。f 也是一个严格的奥曼相关均衡，因为如果每个代理人都知道 Ron 如何做出他的建议，但只知道他给她的建议，那么如果她偏离她的建议，她会做得更差。由于“Chicken”有几个严格均衡，f 对应于 Vanderschraaf（1998）中定义的传统。f 的整体预期收益向量为（3,3），位于游戏纳什均衡的收益凸包之外，并且压倒了由α1=2/3，i=1,2 定义的混合纳什均衡的预期收益向量（4/3,4/3）。相关均衡 f 的特征是代理人在给定策略配置上的游戏中的概率分布，如图 3.3 所示：

|                                                                                                                                                                                             |                                                                                                                                                                                                                                                   | Joanna                                                                                                                                                                                                                                            |                                                                                                                                                                                                                                             |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|                                                                                                                                                                                             |                                                                                                                                                                                                                                                   | I'm sorry, but it seems like there was an error in your request. It appears that you only provided "s1" without any accompanying text to be translated. Could you please provide the text you would like me to translate into Simplified Chinese? | I'm sorry, but it seems like there was an error in your request. It appears that you only provided "s2" without any context or text to translate. Could you please provide the text you would like me to translate into Simplified Chinese? |
| ---                                                                                                                                                                                         | ---                                                                                                                                                                                                                                               | ---                                                                                                                                                                                                                                               | ---                                                                                                                                                                                                                                         |
| Lizzi                                                                                                                                                                                       | I'm sorry, but it seems like there was an error in your request. It appears that you only provided "s1" without any accompanying text to be translated. Could you please provide the text you would like me to translate into Simplified Chinese? | ⅓ (IGNORE)                                                                                                                                                                                                                                        | ⅓ (IGNORE)                                                                                                                                                                                                                                  |
| I'm sorry, but it seems like you only provided "s2" which does not contain any text to translate. Could you please provide the text you would like me to translate into Simplified Chinese? | ⅓                                                                                                                                                                                                                                                 | 0                                                                                                                                                                                                                                                 |                                                                                                                                                                                                                                             |

图 3.3

Aumann (1987)证明了一个将他的相关均衡概念与共同知识联系起来的结果。为了回顾这一结果，我们必须给出 Aumann 相关均衡的正式定义。

\*\* 定义 3.9\*\* 给定一个博弈Γ=(N,S,u)，以及一个可能世界的有限集合Ω，向量值函数 f:Ω→S 是一个相关的 n 元组。如果 f(ω)=(f1(ω),…,fn(ω)) 表示 N 个代理的 f 的分量，那么在ω处代理 k 的推荐策略是 fk(ω)。如果 f 是奥曼相关均衡，当且仅当 E(uk∘f)≥E(uk(f−k,gk))。

对于每个 k∈N 和任意的关于 fi 的函数 gk。

代理人在奥曼相关均衡中，如果在每个可能的世界 ω∈Ω 中，没有代理人会希望偏离他的推荐策略，前提是其他人遵循他们的推荐策略。因此，奥曼相关均衡唯一地指定了每个代理人的策略，通过明确引入一个可能的世界空间，代理人可以将他们的行为相关联。偏离 gi 必须是 fi 的函数，即 fi 的一些其他函数与 fi 的组合，因为 i 只知道 fi(ω)，所以只能区分 Ω 中由 fi 区分的可能世界。正如已经指出的，奥曼相关均衡和内生相关均衡之间的主要区别在于，在奥曼的相关均衡中，代理人将他们的策略与某个外部于游戏的事件 ω∈Ω 相关联。观察这种差异的一种方式是，将他们的策略外生相关的代理人可以计算条件于自己策略的预期效用。

在奥曼（Aumann）的模型中，每个可能世界ω的描述包括以下内容：博弈Γ，代理人的私人信息分区，以及在ω处每个代理人选择的行动，以及每个代理人对Ω上的先验概率分布μk(⋅)。基本思想是，在ω的条件下，每个人都知道任何代理人可能存在不确定性的对象，但一般来说，没有代理人必然知道哪个世界ω是实际世界。代理人可以利用他们的先验概率来计算各种行动组合 s∈S 被执行的概率。如果代理人的先验概率是这样的，即对于所有 i，j∈N，当且仅当μi(ω)=0 时μj(ω)=0，则代理人的先验概率是相互绝对连续的。如果代理人的先验概率都一致，即对于每个ω∈Ω，μ1(ω)=…=μn(ω)=μ(ω)，则称为共同先验假设，或 CPA，得到满足。如果代理人遵循奥曼相关均衡 f 并且满足 CPA，则 f 是客观的奥曼相关均衡。如果满足 CPA 且代理人的分布满足概率独立性，则奥曼相关均衡是纳什均衡。

让 si(ω)表示代理 i 在可能世界ω上选择的策略。那么 s:Ω→S 定义为 s(ω)=(s1(ω),…,sn(ω))是一个相关的 n 元组。假设 Hi 是Ω的一个分割，\[29]对于每个 Hij∈Hi，如果对于每个ω′∈Hij，si:Ω→si 定义为 s 是 Hi 可测的，那么 si(ω′)是常数。Hi 可测性是一种形式化的说法，即 i 知道在每个可能的世界中她将会做什么，考虑到她的信息。

\*\* 定义 3.10\*\* 代理人 i 相对于 ω∈Ω 是贝叶斯理性的（或者说，ω _-贝叶斯理性_）当且仅当 si 是 Hi 可测的，

E(ui∘s∣Hi)(ω)≥E(ui(vi,s−i)∣Hi)(ω)

对于任意可测函数 vi:Ω→si。

请注意，奥曼（Aumann）对ω-贝叶斯理性的定义意味着μi(Hi(ω))>0，因此条件期望被定义。接下来给出的奥曼的主要结果隐含地假定对于每个代理 i∈N 和每个可能的世界ω∈Ω，都有μi(Hi(ω))>0。如果满足了 CPA，或者即使先验只是相互绝对连续的，这并不会带来技术上的困难，因为如果是这种情况，那么可以简单地从考虑中排除任何先验为零的ω。

命题 3.11 (Aumann 1987) 如果每个代理 i∈N 在每个可能的世界ω∈Ω上都是ω-Bayes 理性的话，那么代理们遵循的是奥曼相关均衡。如果满足 CPA 条件，那么相关均衡是客观的。 证明。

代理人可能对自己所处情况的一部分不确定性在于是否所有代理人都是理性的。但是，如果假设所有代理人在每个ω∈Ω处都是ω-贝叶斯理性的，那么这一事实的描述构成了每个可能的ω的描述的一部分，因此位于代理人分割的交集中。正如已经指出的，代理人的先验描述、他们的分割以及游戏的描述也构成了每个可能世界的描述的一部分，因此与这些事实对应的命题也位于代理人分割的交集中。因此，另一种陈述奥曼主要结果的方式如下：在每个可能世界的ω-贝叶斯理性的共同知识意味着代理人遵循奥曼相关均衡。

命题 3.7 和 3.11 是强有力的结果。它们表明，理性的共同知识和关于彼此信念的代理人的概率分布，即他们可能遵循的策略配置文件，意味着代理人的信念表征了博弈的均衡。如果代理人的信念是无条件的，命题 3.7 表明代理人理性地遵循与相应内生相关均衡一致的策略配置文件。如果他们的信念是有条件的，那么命题 3.11 表明他们理性地遵循相应的奥曼相关均衡建议的策略。然而，我们不应高估这些结果的重要性，因为它们并未涉及理性和信念的共同知识的起源。例如，在图 3.1 的 Chicken 游戏中，我们考虑了一个相关均衡的例子，假设 Lizzi 和 Joanna 共同知道由(⋆)定义的推荐策略系统。在这种共同知识的情况下，Joanna 和 Lizzi 确实有充分理由遵循奥曼相关均衡 f。但这种共同知识是从何而来的？一般来说，代理人如何获得证明他们遵从均衡的共同知识？哲学家和社会科学家在回答这个问题上取得的进展有限。

### 3.4 完全信息博弈

在广泛形式博弈中，代理者按顺序移动。在每个阶段，即将移动的代理者必须根据她对之前移动的了解来做决策。代理者知识的这部分特征由信息集来描述，即代理者知道她的前任可能选择的备选移动集合。例如，考虑图 3.4 的广泛形式博弈：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure3.4.gif)

图 3.4

当 Joanna 移动时，她处于她的信息集 I22={C1,D1}，也就是说，她移动时知道 Lizzi 可能选择 C1 或 D1，因此这个游戏是图 3.1 中 Chicken 游戏的广泛形式表示。

在完全信息的游戏中，每个信息集由游戏树中的单个节点组成，因为根据定义，在每个状态下，要移动的代理知道她的前辈们如何移动。在示例 1.4 中指出，可以将反向归纳方法应用于任何完全信息的游戏。反向归纳解是完全信息游戏的唯一纳什均衡。以下结果给出了足够的条件来证明在完全信息的游戏中进行反向归纳游戏的合理性：

命题 3.12 (Bicchieri, 1993) 在一个完全信息的广义博弈中，如果对于每个代理 i 在每个信息集合 Iik，满足以下条件，代理会遵循逆向归纳解：

1. i 是理性的，i 知道这一点，i 知道这个游戏
2. 在任何紧随 Iik 的信息集 Ijk+1 中，i 在 Iik 知道 j 在 Ijk+1 知道的内容。

证明。

命题 3.12 指出，远远不需要对游戏和理性的共同知识就足以使得在完全信息博弈中获得逆向归纳解。所需的仅仅是每个代理在她的信息集中都是理性的，知道游戏并知道下一个移动的代理知道什么！例如，在图 1.2 中的游戏中，如果 R1(R2)代表“Alan（Fiona）是理性的”，Ki(Γ)代表“i 知道游戏Γ”，那么逆向归纳解可以由以下内容暗示：

1. 在 I24，R2 和 K2(Γ)。
2. 在 I13，R1，K1(Γ)，K1(R2)，和 K1K2(Γ)。
3. 在 I22，K2（R1），K2K1（R2）和 K2K1K2（Γ）。
4. 在 I11，K1K2(R1)，K1K2K1(R2)，和 K1K2K1K2(Γ)。\[31]

有人可能认为命题 3.11 的一个推论是，在一个完全信息的博弈中，对博弈和理性的共同知识意味着反向归纳解。这是反向归纳解的经典论证。许多博弈论者继续接受这一经典论证，但近年来，由 Reny（1988 年，1992 年）、Binmore（1987 年）和 Bicchieri（1989 年，1993 年）的研究所带来的强有力挑战已经出现。他们对反向归纳的批评的基本思想可以用图 1.2 的博弈来说明。根据经典论证，如果 Alan 和 Fiona 对理性和博弈有共同知识，那么每个人都会预测对方会遵循她的反向归纳解的一端，而他的反向归纳解的一端是他的唯一最佳响应。然而，如果 Fiona 重新考虑在发现自己处于信息集 I22 时该做什么怎么办？如果到达信息集 I22，那么 Alan 当然没有遵循反向归纳解。如果我们假设在 I22，Fiona 只知道(iii)中所述的内容，那么她可以解释自己处于 I22 的原因是 I11 处的 K1K2K1(R2)或 K1K2K1K2(Γ)的失败。在这种情况下，Fiona 认为在 I11 处的¬K1K2K1(R2)或¬K1K2K1K2(Γ)与 Alan 实际上在 I11 处所知道的内容是一致的，因此 Fiona 不应该对自己发现自己处于 I22 感到惊讶，而且鉴于她在那里所知道的内容由(iii)描述，遵循反向归纳解是她的最佳策略。但是，如果理性和博弈是共同知识，或者即使 Fiona 和 Alan 只是对(iii)和(iv)所描述的陈述有相互知识，那么在 I22，Fiona 知道在 I11 处 K1K2K1(R2)或 K1K2K1K2(Γ)。因此，鉴于这么多的相互知识，Fiona 不再能解释为什么 Alan 偏离了反向归纳解，因为这种偏离与他们的相互知识的一部分相矛盾。因此，如果她发现自己处于 I22，Fiona 不一定有充分的理由认为 Alan 会遵循从 I22 开始的子博弈的反向归纳解，因此她可能没有充分的理由遵循反向归纳解。Bicchieri（1993 年）与 Binmore（1987 年）和 Reny（1988 年，1992 年）一起将这一论点扩展到具有任意长度的完全信息博弈，得出了一个惊人的结论：如果代理人对理性和博弈的相互知识的层次过少或过多，相对于潜在移动的数量，就无法预测他们会遵循反向归纳解。这将削弱反向归纳在广义博弈分析中所起的核心作用。因为为什么代理人的相互知识层次应该取决于博弈的长度呢？

经典的逆向归纳论证隐含地假设，在游戏的每个阶段，参与者会将之前的动作视为战略上无关紧要。支持经典论证的人可以辩称这种假设是合理的，因为根据定义，在任何参与者的决策节点上，导致该节点的先前动作现在已经确定。对经典论证的批评者质疑这一假设，他们认为，在考虑如何在任何信息集上移动时，包括那些不在逆向归纳均衡路径上的信息集，参与者必须考虑的一部分是什么条件可能导致他处于该信息集。换句话说，参与者应该将对先前移动者的推理，或称为正向归纳推理，纳入到他们在给定信息集上如何移动的思考中。Binmore (1987) 和 Bicchieri (1993) 认为，对于一个游戏的逆向归纳解，应该与相应的正向归纳论证推荐的解一致。正如我们所见，鉴于对游戏和理性的共同知识，正向归纳推理可以导致参与者陷入明显的矛盾：逆向归纳的经典论证建立在参与者预测他们在树中从未到达的节点上会做出什么决策的基础上。他们基于对游戏和理性的共同知识做出这些预测。但正向归纳推理似乎暗示，如果任何非均衡节点已经到达，那么对理性和游戏的共同知识必定已经失败，那么参与者如何能够预测在这些节点上会发生什么呢？

### 3.5 通信网络

在人口 P 的成员愿意参与某种行动的情况下，只要 P 的足够大部分参与某种适当行为，这些都是典型的集体行动问题。考虑一个正在考虑是否加入一场起义的代理人的情况。她决定加入或不加入将取决于她预计会加入起义的其他代理人的数量。如果这个数量太低，她会更倾向于不起义，而如果数量足够大，她会更倾向于起义。迈克尔·Chwe 提出了一个模型，用博弈论的方式对这种情况进行建模。玩家对其他玩家意图的了解取决于玩家所处的社交网络。每个玩家的个体“阈值”（需要其他代理人数量达到特定值才能发动起义）只有网络中的直接邻居知道。除了 Chwe 分析关于集体行动主题的结果的内在价值之外，他的模型还提供了关于社交网络和共同知识之间关系以及共同知识在集体行动中的作用的见解。例如，在某些情况下，对其他代理人个人阈值的一阶知识不足以激励代理人采取行动，而更高阶的知识或者在极限情况下的共同知识则可以。

我们按照 Chwe 的模型（Chwe 1999）和（Chwe 2000）进行介绍。假设有一个由 n 个人组成的群体 P，每个代理人有两种策略：r（反抗，即参与集体行动）和 s（呆在家里不参与）。每个代理人都有自己的个人阈值θ∈{1,2,…,n+1}，当且仅当反抗的玩家总数大于或等于她的阈值时，她更喜欢 r 而不是 s。阈值为 1 的代理人总是反抗；阈值为 2 的代理人只有在另一个代理人反抗时才反抗；阈值为 n 的代理人只有在所有代理人都反抗时才反抗；阈值为 n+1 的代理人永远不反抗，依此类推。这些代理人位于一个由二元关系→表示的社交网络中。i→j 的预期含义是代理人 i“与”代理人 j 交流，也就是说，代理人 i 知道代理人 j 的阈值。如果我们定义 B(i)为集合{j∈P:j→i}，我们可以将 B(i)解释为 i 的“邻居”，并且可以说，一般来说，i 知道她邻居的所有代理人的阈值。进一步的假设是，对于所有的 j，k∈B(i)，i 知道 j→k 或不知道，也就是说，每个代理人知道她的邻居是否在互相交流。关系→被视为是自反的（一个人知道自己的阈值）。

玩家的知识通常在可能世界框架中表示。例如，考虑有两个代理，每个代理的阈值为 1、2 或 3 的情况。有九个可能的世界，由表示第一和第二玩家各自阈值的有序数对表示：11、12、13，…，32、33。如果玩家不进行沟通，每个人只知道自己的阈值。玩家 1 的信息分割反映了她对玩家 2 阈值的无知，它由集合 {11,12,13}，{21,22,23}，{31,32,33} 组成；同样，玩家 2 的分割由集合 {11,21,31}，{12,22,32}，{13,23,33} 组成。如果玩家 1 的阈值为 1，无论玩家 2 的阈值是什么，她都会造反。因此，玩家 1 在 {11,12,13} 中造反。如果玩家 1 的阈值为 3，她永远不会造反。因此，她在 {31,32,33} 中选择 s。如果她的阈值为 2，她只有在另一个玩家也造反时才会造反。由于在这个例子中我们假设代理之间没有沟通，玩家 1 无法确定玩家 2 的行动，因此在 {21,22,23} 中选择不冒险的 s。同样，玩家 2 在 {11,21,31} 中选择 r，在其他情况下选择 s。现在考虑 1→2 和 2→1 的情况。现在两个玩家都有最精细的信息分割。阈值为 1 和 3 的情况再次使两个玩家分别选择 r 和 s。然而，在玩家 1 的单元 {21} 和 {22} 中，她知道玩家 2 会造反，而且由于阈值为 2，她也会造反。对于玩家 2 在他的单元 {12} 和 {22} 中也是如此。请注意，在两个玩家阈值都为 2 的情况下，既有两个玩家都造反的均衡，也有每个玩家都待在家中的均衡。假设在多个均衡的情况下，会出现造反最多的那个均衡。

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure3.5.gif)

图 3.5

以上示例的分析适用于具有 n 个代理的一般网络。例如考虑三人网络 1→2, 2→1, 2→3，如图 3.5a 所示（请注意，对称链接由没有箭头的线表示），并假设每个玩家的阈值为 2。玩家 1 和 2 之间的网络与上面的相同，因此如果它们的阈值为 2，无论玩家 3 的阈值如何，它们都会同时起义。另一方面，玩家 3 知道自己的阈值和玩家 2 的阈值。因此，如果它们都有阈值 2，她无法区分集合{122, 222, 322, 422}中的可能性。特别是在 422 时，玩家 1 和玩家 2 都不会起义，因此玩家 3 不能冒险，不会起义，即使事实上她有一个起义的邻居。将链接 1→3 添加到网络中（参见图 3.5b），我们为玩家 3 提供了关于玩家 1 行动的知识，因此在这种情况下，如果它们都有阈值 2，它们都会同时起义。请注意，如果我们断开玩家 1 和 2 之间的链接（使网络变为 1→3 和 2→3），玩家 3 知道 1 和 2 无法沟通，因此在 222 时不会起义，因此她也选择 s。了解其他玩家对其他玩家的了解是至关重要的。

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure3.6.gif)

图 3.6

下一个例子揭示了在某些情况下，甚至一阶知识都不足以引发行动，需要更高级别的知识。考虑四名玩家，每个阈值为 3，在图 3.6 中表示的两个不同网络中（图 3.6a 中的“正方形”和图 3.6b 中的“风筝”）。在正方形网络中，玩家 1 知道 2 和 4 的阈值都为 3。然而，她不知道玩家 3 的阈值。如果玩家 3 的阈值为 5，那么玩家 2 永远不会造反，因为他不知道玩家 4 的阈值，他可能认为玩家 4 的阈值也是 5。玩家 1 对玩家 3 的不确定性以及玩家 1 对玩家 2 对玩家 4 的不确定性的了解迫使她不造反，尽管她的阈值为 3，而且有两个阈值也为 3 的邻居。类似的推理适用于所有其他玩家，因此在正方形中没有人造反。现在考虑风筝网络。玩家 4 忽略了玩家 1 和玩家 2 的阈值，因此他不造反。然而，玩家 1 知道玩家 2 和玩家 3 的阈值为 3，他们知道他们的阈值是 3，并且他们知道玩家 1 知道他们的阈值是 3。这足以触发三人的行动 r，如果玩家 1、2 和 3 在{3331,3332,3333,3334,3335}中的所有状态中都造反，这是一个均衡状态，因为在所有状态中至少有三个人造反，每个人的阈值都为 3。

在方形网络和风筝网络之间的区别在于，虽然在方形网络中有足够的代理人愿意为了一场起义而起义，以至于实际上会发生起义，而且他们每个人都知道这一点，但没有一个代理人知道其他人知道这一点。另一方面，在风筝网络中，三角形中的代理人不仅知道有三个阈值为 3 的代理人，而且他们也知道彼此知道这一点，知道彼此知道彼此知道这一点，依此类推。在他们之间存在这样的共同知识。值得注意的是，在 Chwe 的模型中，共同知识是在没有公开已知事实的情况下获得的（参见第 2.2 节）。命题“玩家 1、2 和 3 的阈值都为 3”（语义上：事件{3331,3332,3333,3334,3335}）被玩家 1、2 和 3 知晓，因为网络结构的存在，并且因为玩家知晓网络结构，这一命题变成了共同知识。当然，网络结构不仅仅是被知晓，而且实际上是被玩家们共同知晓的。例如，玩家 1 不仅知道玩家 2 和 3 互相沟通。她还知道玩家 2 和 3 知道她知道他们互相沟通，依此类推。

在完全网络中（即所有玩家彼此通信的网络，如风筝网络中的三角形），玩家的信息分区是重合的，并且它们是可能世界集合的最精细分区。因此，如果玩家具有足够低的门槛，这一事实是众所周知的，并且存在一种均衡状态，所有玩家都会发动叛乱。

\*\* 定义 3.13\*\* 我们说如果存在一个均衡，所有玩家都选择反抗，那么→就是一个充分的网络。

对于所有玩家都具有足够低门槛的游戏来说，完全网络显然是足够的。完全网络是否是获得所有玩家都反叛的均衡所必需的？事实证明并非如此。类似于风筝网络中的“三角形”群体的结构，称为圈子，发挥着至关重要的作用。在这种结构中，“本地”共同知识（即仅限于结构中的玩家部分的知识）自然产生。在一个完全网络中（即一个网络，在其中有足够但不是多余的沟通使其完全反叛），如果圈子覆盖整个人口，那么如果一个圈子与另一个圈子交谈，那么该圈子的每个成员都会与另一个圈子的每个成员交谈。此外，对于每两个圈子，其中一个正在与另一个交谈的情况，存在一个具有起始元素的圈子“链”。换句话说，关系中的每对圈子都是一个链的一部分（至少长度为 2）并具有一个起始元素（一个领先的圈子）。反叛在网络中传播，从“领先采纳者”到“追随者”，根据圈子及其关系所定义的社会角色层次结构。考虑以下示例，其中圈子由圆圈表示，数字代表个体玩家的门槛：

![missing text, please inform](https://plato.stanford.edu/entries/common-knowledge/figure3.7.gif)

图 3.7

这里阈值 3 团体是领导团体，引发了阈值 5 从属团体的反抗。反过来，一个单一阈值 3 元素的团体跟随。请注意，尽管她不需要知道领导团体实际上发动了反抗才愿意反抗，但这一信息是必要的，以确保阈值 5 团体会发动反抗，从而她可以安全地加入反抗。在每个团体中，关于阈值和因此愿意反抗的信息是共同知识，但在一系列团体中，信息是“线性”的；每个团体都知道它是哪个团体的从属，但不知道之前的团体。

分析 Chwe 先生在弱联系与强联系方面的集体行动模型（参见 Chwe, 1999 和 Chwe, 2000），可以进一步了解沟通网络和共同知识之间的互动。粗略地说，强联系连接亲密朋友，而弱联系连接熟人。强联系的增长速度往往比弱联系慢，因为人们通常有共同的亲密朋友，而不是共同的熟人。因此，在传播信息和连接社会方面，弱联系比强联系做得更好，因为它们能够更快地穿越社会，因此具有更广泛的影响。强联系和弱联系在集体行动中扮演什么角色？在 Chwe 先生的动态分析中，当门槛较低时，强联系表现更好，而当玩家的门槛较高时，弱联系表现更好。直觉上，人们会发现强联系往往会立即形成小团体（因为其中固有的对称性：我的朋友的朋友往往也是我的朋友）；共同知识会迅速在本地水平上产生，如果门槛较低，那么由强联系联系的团体更有可能成为引发革命的领导团体。另一方面，如果门槛较高，小团体中的本地共同知识是无效的，而弱联系能够更快地到达更远的距离，加快了通信和建立所需的大团体以促进集体行动。这些考虑为社会网络和共同知识之间的关系提供了一些启示。尽管在弱联系占主导地位的网络中知识传播更快，但更高阶的知识（因此也是共同知识）在这种网络中往往更慢产生。另一方面，具有更多强联系的网络有助于在本地水平上形成共同知识。

## 4. 共同知识是否可达到？

Lewis 提出了一个关于共同知识的解释，该解释生成了“我知道 j 知道…k 知道 A”的层次结构，以确保在他对约定的解释中，代理人对彼此有正确的信念。但由于人类代理显然无法通过这样一个无限层次的推理，自然会想知道是否有任何一组人可以对任何命题拥有完全的共同知识。更广泛地说，在第 3 节中审查的共同知识的分析，如果这种共同知识超出了人类代理的能力范围，那么对社会科学家和哲学家来说将毫无价值。

幸运的是，对于刘易斯（Lewis）的方案来说，有强有力的论据表明共同知识确实是可以获得的。刘易斯（1969）认为，共同知识层次结构应被视为一系列蕴涵，而不是任何人实际推理中的步骤。他提出非正式论证，表明共同知识层次结构是从有限的公理集合中生成的。我们在第 2 节中看到，可以精确地阐述刘易斯的公理，并从这些公理和作为共同知识基础的公共事件推导出共同知识层次结构。再次，刘易斯论证背后的基本思想是，对于一组代理人，如果命题 A 在他们中间是公开已知的，并且每个代理人都知道每个人都可以从 A 中得出与她相同的结论 p，那么 p 就是共同知识。这些条件显然是依赖于上下文的，就像一个人知道或不知道一个命题取决于上下文一样。然而，有许多情况下，自然地假设一个公共事件产生共同知识，因为它得到了适当的广播，群体中的代理人处于理想的条件下来感知它，从公共事件到共同知识对象的推理是直接的等等。然而，如果一些人没有察觉到公共事件，或者如果其中一些人认为其他人中的一些人无法理解公告，或者听不到它，或者无法得出必要的推理等等，共同知识可能会失败。

实际上，对于共同知识的可达性存在怀疑是完全可能的。最近，Lederman (2018b) 提出了一个强有力的怀疑论证。Lederman 构建了一个旨在削弱在第 2 节中所做的共同知识层次推导的论证，其基础是一个公共事件或者正如 Lederman 所称的公共信息。Lederman 所针对的原则是他所称的理想共同知识（或信念），即：如果 p 是群体 G 中的公共信息，那么只要 G 中的代理人是理想推理者，那么 p 就是 G 中的共同知识。这一论证建立在代理人之间心理状态的私密性和人际不可比性之上，尽管它是以感知知识的术语提出的，但其范围超越了感知，质疑了共同知识的可能性。

Lederman (2018b) 使用以下情景：两名参赛者，Alice 和 Bob，观察一个玩具帆船的桅杆高度（100 厘米），随后这个帆船被一个随机选择的帆船替换，其桅杆可能比 100 厘米更高或更矮。事实上，所选帆船的桅杆高度为 300 厘米。因此，众所周知桅杆比 100 厘米更高。上述理想的共同知识原则，结合对 Alice 和 Bob 视觉系统及其公开性的假设，应该导致 Alice 和 Bob 共同知晓桅杆比 100 厘米更高，然而 Lederman 的论点表明他们并没有。主要观点是人类在感知高度等事物时存在一定程度的近似。因此，对于 Alice 而言，如果桅杆看起来有 300 厘米高，那么对 Bob 而言，桅杆看起来可能略矮一些，比如 299 厘米。此外，Alice 知道如果桅杆对 Bob 看起来有 299 厘米高，那么对他而言，桅杆看起来可能有 298 厘米高。同样，Bob 知道 Alice 知道如果桅杆对 Alice 看起来有 298 厘米高，那么对她而言，桅杆看起来可能有 297 厘米高。这种推理可以重复进行，直到 Alice 和 Bob 共同知晓桅杆并非比 100 厘米更高，这与他们共同知晓桅杆高于 100 厘米的直觉相悖！

Lederman (2018b) 将这一论点推广到任意情况和公共信息来源，得出结论：人们永远无法达成共同知识或信念。在他看来，共同知识的无法实现并不会导致社会行为解释力量的可能丧失。尽管长期以来，共同知识和由此产生的公共信息被认为是协调行为至关重要的因素，Lederman 声称实际上协调并不需要共同知识（详见下一节对 Lederman 2018a 的讨论）。Immerman (2021) 反对 Lederman，认为这里勾勒的怀疑论证在许多情况下都是失败的，因此未能证明共同知识的无法实现。Immerman 试图驳斥 Lederman 的论点的关键思想是，有许多感知价值是代理人根本不会考虑的，就像在最初的帆船示例中，他们知道所有高度在 100 和 300 厘米之间的桅杆都被偷走了一样。根据 Immerman 的观点，这种“知识缺口”情况并不罕见，它们的存在阻止了 Lederman 的论证的成立。

即使一个人拒绝莱德曼的怀疑论证（无论是通过赞同上面的伊默曼的论证，还是通过托马森（2021）在下一节中讨论的论证，或其他方式），在将共同知识归因于一组人类代理时，必须谨慎。共同知识是一种对代理人情境非常敏感的现象。接下来的部分提供了一个示例，表明为了使 A 成为一组代理人的共同真理，他们通常必须感知暗示 A 的事件，同时且公开地。

## 5. 协调与共同 p-信念

在某些情境下，代理可能无法达成共同知识。Lederman (2018b)提出的怀疑论据实际上建立在并概括了有关共同知识的可达性的相关论点之上，这些论点在理论计算机科学中与协调攻击问题有关（参见 Lederman 2018a，Halpern 和 Moses，1990 以及 Fagin 等人，1995，特别是第 6 章和第 11 章）。在分布式系统的背景下，使用上述提到的认知逻辑的形式系统，这些系统等同于经济学家所青睐的语义方法，可以正式证明：(i) 共同知识对于协调是必要的，(ii) 共同知识的可达性取决于对系统所做的假设。特别是，异步系统不允许出现关于通信消息的共同知识，从而使协调变得不可能。代理能否实现与共同知识“接近”的东西？有各种对共同知识概念的削弱可能会有所帮助：ε-共同知识（代理将在时间ε内达成共同知识，因此他们将在时间ε内协调），最终共同知识（代理最终将达成共同知识，从而最终协调），概率共同知识（代理将达成概率 p 的共同信念，因此以概率 p 成功协调），等等。这些对共同知识概念的削弱可能会根据预期的应用而证明有用。

另一个需要考虑的共同知识的削弱当然是 m 级相互知识。对于较大的 m 值，KmN(A)可能看起来是 K∗N(A)的一个很好的近似。然而，上述观点(i)指出，任意高的 m 值都不会帮助实现协调的实际任务，因此需要共同知识的全部力量。我们通过以下由 Rubinstein (1989, 1992)提出的例子来说明这一点，该例子表明简单地在任何有限级别截断共同知识层次可能导致代理人表现得好像他们根本没有相互知识。

### 5.1 电子邮件协调示例

Lizzi 和 Joanna 面临的协调问题总结如下图所示：

|                                                                                                                                                    |                                                                                                                                                              | Joanna                                                                                                                                                       |                                                                                                                                                    |
| -------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |
|                                                                                                                                                    |                                                                                                                                                              | I'm sorry, but it seems like your request is incomplete. Could you please provide the full text that you would like me to translate into Simplified Chinese? | I'm sorry, but it seems like your request is incomplete. Could you please provide the text you would like me to translate into Simplified Chinese? |
| ---                                                                                                                                                | ---                                                                                                                                                          | ---                                                                                                                                                          | ---                                                                                                                                                |
| Lizzi                                                                                                                                              | I'm sorry, but it seems like your request is incomplete. Could you please provide the full text that you would like me to translate into Simplified Chinese? | (2,2)                                                                                                                                                        | (0,−4)                                                                                                                                             |
| I'm sorry, but it seems like your request is incomplete. Could you please provide the text you would like me to translate into Simplified Chinese? | (−4,0)                                                                                                                                                       | (0,0)                                                                                                                                                        |                                                                                                                                                    |

图 5.1a ω1,μ(ω1)=0.51

|                                                                                                                                                    |                                                                                                                                                              | Joanna                                                                                                                                                  |                                                                                                                                                    |
| -------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
|                                                                                                                                                    |                                                                                                                                                              | I'm sorry, but your request seems to be incomplete. Could you please provide the full text that you would like me to translate into Simplified Chinese? | I'm sorry, but it seems like your request is incomplete. Could you please provide the text you would like me to translate into Simplified Chinese? |
| ---                                                                                                                                                | ---                                                                                                                                                          | ---                                                                                                                                                     | ---                                                                                                                                                |
| Lizzi                                                                                                                                              | I'm sorry, but it seems like your request is incomplete. Could you please provide the full text that you would like me to translate into Simplified Chinese? | (2,2)                                                                                                                                                   | (0,−4)                                                                                                                                             |
| I'm sorry, but it seems like your request is incomplete. Could you please provide the text you would like me to translate into Simplified Chinese? | (−4,0)                                                                                                                                                       | (0,0)                                                                                                                                                   |                                                                                                                                                    |

图 5.1b ω2,μ(ω2)=0.49

在图 5.1 中，收益取决于一对可能的世界。世界ω1 以概率μ(ω1)=.51 发生，而世界ω2 以概率μ(ω2)=.49 发生。因此，只有当世界的状态为ω1(ω2)时，他们通过选择 A(B)来完全成功地协调。

假设 Lizzi 能观察世界的状态，但 Joanna 不能。我们可以这样解释这个游戏：Joanna 和 Lizzi 想要一起吃由他们最喜爱的厨师 Aldo 准备的晚餐。Aldo 在 Sorriso 这家他们最喜欢的餐厅的 A 和 B 两个分店之间轮流。状态ωi 是 Aldo 当天的位置。在状态ω1(ω2)，Aldo 在 A(B)。作为 Sorriso 特别邮件列表上的成员，收到了关于ωi 的通知。Lizzi 和 Joanna 的最佳结果是当她们在 Aldo 工作的地方相遇，这样她们就可以享受计划好的晚餐。如果她们相遇但错过了 Aldo，她们会感到失望，最终没有晚餐。如果任何一人去了 A 并发现自己独自一人，那么她会再次感到失望，没有晚餐。但她们真正想避免的是如果另一个人去了 A，她自己去了 B。如果她们中的任何一人独自到达 B，她不仅错过了晚餐，还必须支付 B 所在酒店的过高停车费，因为 B 的领班拒绝为要求两人桌然后独自就座的任何人验证停车券。这正是 Harsanyi（1967）所称的不完全信息博弈，因为游戏的回报取决于并非所有代理知道的状态。

A 是 Joanna 和 Lizzi 都采取的“玩得安全”的策略。\[33] 无论世界的状态如何，选择 A，代理都面临着可能无法获得与 Aldo 相遇的积极回报的风险，但每个人也肯定可以避免选择 B 而导致的真正糟糕后果，如果对方选择了 A。由于只有 Lizzi 知道世界的状态，因此两者都无法利用关于世界状态的信息来改善协调的前景。Joanna 没有这样的信息，而 Lizzi 知道这一点，她知道 Joanna 必须相应地选择，因此 Lizzi 必须根据她预期 Joanna 会做出的举动选择她的最佳响应，而不管 Lizzi 观察到的世界状态如何。显然，Lizzi 和 Joanna 无法实现比每个人期望的 1.02 更高的预期回报，如果他们在任何世界状态下选择 (A, A)。

如果状态ω是共同知识，那么在ω=ω1 时条件策略概要(A,A)，在ω=ω2 时条件策略概要(B,B)将是一个严格的纳什均衡，在这个均衡下每个人都将获得 2 的回报。因此，他们困境的明显解决方法是让丽兹（Lizzi）告诉乔安娜（Joanna）奥尔多（Aldo）的位置，通过面对面或电话交谈，并且他们同意去奥尔多所在的地方，这将使状态ω和他们在给定ω情况下协调的意图成为他们之间的共同知识。假设由于某种原因他们无法互相交谈，但他们事先安排好，如果丽兹发现ω2 发生，她将给乔安娜发送一封电子邮件。进一步假设乔安娜和丽兹的电子邮件系统设置为自动向接收并查看的消息发送方发送回复消息，并且由于技术问题，任何消息到达目的地的概率ε>0。然后，如果丽兹发送给乔安娜一条消息，并收到自动确认，那么丽兹知道乔安娜知道ω2 已发生。如果乔安娜收到丽兹的自动确认消息，那么乔安娜知道丽兹知道乔安娜知道ω2 已发生，依此类推。如果每个代理人收到无限多次的自动确认，那么ω2 发生将成为共同知识，假设所有确认可以在有限时间内发送和接收。然而，由于在每个通信阶段传输失败的概率ε，确认序列在有限的阶段后以概率 1 停止。因此，以概率 1，代理人们未能实现完全的共同知识。但他们至少实现了与共同知识“接近”的某种程度。这是否意味着他们有望达成(B,B)的协议？

Rubinstein 通过归纳证明，如果自动交换的确认消息数量是有限的，那么在考虑到每个代理人所知道的内容时，A 是唯一的选择，可以最大化预期效用。

> [鲁宾斯坦的证明](https://plato.stanford.edu/entries/common-knowledge/rubinsteinsproof.html)

因此，即使代理人具有“几乎”共同知识，即“琼娜知道丽兹知道……琼娜知道ω2 发生”的知识层次很多，他们的行为与在共同知识下ω2 发生时的行为有很大不同。事实上，正如鲁宾斯坦指出的那样，仅仅具有“几乎”共同知识，代理人选择的行为就好像根本没有发生任何沟通一样！鲁宾斯坦还指出，这一结果违反了我们对代理人在这种情况下会做什么的直觉。（见鲁宾斯坦 1992 年，第 324 页。）如果 Ti=17，我们难道不会期望代理人 i 选择 B 吗？事实上，在许多实际情况下，我们可能认为代理人会期望对方选择 B，即使 T1=T2=2，这就足以让丽兹知道琼娜已经收到她的原始消息，而琼娜知道丽兹知道这一点！Binmore 和 Samelson（2001）实际上表明，如果琼娜和丽兹在交换消息时需要付出代价，或者发送消息是有成本的，那么更长的消息流就不会被关注或发生。

Lederman (2018a)提出了对悖论的激进解决方案。在协调攻击的情况下，他认为，理性的将军们如果普遍知道他们是理性的，只有当他们普遍知道他们将要攻击时才会发动攻击；由于通过交换消息无法获得普遍知识，他们不会发动攻击。然而，如果承认将军们并不普遍相信他们是理性的，可以建立一个简单的模型，表明这样的将军们会在没有普遍知识的情况下发动攻击。类似地，在电子邮件游戏中，他指出，如果玩家可能是非理性类型（即使她选择游戏 B，即使她的预期收益低于选择游戏 A 的收益），并且一个玩家高概率地认为另一个玩家是非理性类型，那么玩家们可以在交换了有限数量的消息后协调选择游戏 B。因此，Lederman (2018a)认为，我们应该将理性的普遍知识视为一个简化假设，有助于产生可处理的数学模型，但在“野外”通常是错误的，普通理性观念让将军和普通人在少量消息交换后容易协调。Thomason (2021)对 Lederman 对常识理性概念的使用提出异议，并讨论了考虑导致个体和普遍持有态度出现的认知和审慎过程的重要性。尽管他们存在分歧，Lederman (2018a, 2018b)和 Thomason (2021)都强调（普遍）持有的信念或知识与实际推理之间的关系的重要性。Halpern 和 Pass (2017)提供了一个有趣的实际问题应用，涉及普遍知识的可获得性，其中分析了区块链协议（以及其中的共识和协调）与普遍知识概念的适当削弱之间的关系。

### 5.2 共同 p-信念

在第 5.1 节的例子暗示，相互知识并非是与协调相关的共同知识唯一削弱的方面。Brandenburger 和 Dekel（1987）以及 Monderer 和 Samet（1989）探讨了另一种选择，即削弱 K∗N 算子的属性。Monderer 和 Samet 通过指出，即使相互知识层次在某个水平停止，代理人仍可能对所讨论的命题有更高层次的相互信念，来激励这种方法。因此，他们用信念算子 Bpi 替换了知识算子 Ki：

\*\* 定义 5.1\*\* 如果μi(⋅)是代理 i 对Ω的概率分布, 那么

Bpi(A)={ω∣μi(A∣Hi(ω))≥p}

Bpi(A) 的含义是“i 在ω处以至少概率 p 相信 A（考虑到 i 的私人信息）”，或者称为“i p-相信 A”。信念运算符 Bpi 满足知识运算符的公理 K2、K3 和 K4。Bpi 不满足 K1，但满足更弱的性质。

μi(A∣Bpi(A))≥p

换句话说，如果一个人以至少 p 的概率相信 A，那么 A 的概率确实至少为 p。

可以类似于定义相互和共同知识的方式，递归地定义相互和共同 p-信念：

\*\* 定义 5.2\*\* 让给定一组可能世界Ω以及一组代理者 N。

(1) 提议 A 是 N 个代理人的（第一级或第一阶）相互 p-信念，即由 BpN1(A)定义的集合

BpN1(A)≡⋂i∈NBpi(A).

(2) A 是 N 个代理人之间的 m 级（或 m 阶）相互信念，即 BpNm(A)，被递归地定义为集合

BpNm(A)≡⋂i∈NBpi(BpNm−1(A))

(3) A 是 N 个代理人之间共同 p-信念的命题，即 BpN∗(A)，被定义为集合

BpN∗(A)≡∞⋂m=1BpNm(A).

如果 A 在世界ω上是共同（或 m 级相互）知识，则对于每个 p 的值，A 在ω上是共同（m 级）p-信念。因此，相互和共同 p-信念形式上概括了相互和共同知识的概念。然而，请注意 B1N∗(A)不一定与 K∗N(A)是相同的命题，也就是说，即使 A 是共同 1-信念，A 也可能不是共同知识。

共同 p-信念形成了类似于共同知识层次结构的层次结构：

\*\* 命题 5.3\*\* ω∈BpNm(A)当且仅当

对于所有代理人 i1，i2，…，im∈N，ω∈Bpi1Bpi2…Bpim(A) (∗)

因此，ω∈BpN∗(A) 当且仅当对于每个 m≥1，(\*)成立。

证明。类似于命题 2.5 的证明。

从示例 5.1 的电子邮件游戏中可以得出几个教训。Rubinstein（1987）认为，他的结论似乎具有悖论性，原因与 Alan 和 Fiona 完全信息博弈的逆向归纳解似乎具有悖论性相同：数学归纳似乎不是我们“日常”推理的一部分。这个游戏还表明，为了使 A 成为一组代理人的共同真理，他们通常必须感知一个事件，该事件同时暗示 A 在彼此面前。第三个教训是，在某些情况下，代理人可能会选择使用比 Nash 或相关均衡更弱的解决方案概念。在他们对电子邮件游戏的分析中，Monderer 和 Samet（1989）引入了 ex ante 和 ex post ε-均衡的概念。ex ante 均衡 h 是一组策略概况，使得没有代理人 i 期望从 h 偏离时获得超过ε-效用。ex post 均衡 h'是一组策略概况，使得没有代理人 i 在考虑 i 的私人信息的情况下，期望从 h'偏离时获得超过ε-效用。当ε=0 时，这些概念重合，h 是一个 Nash 均衡。Monderer 和 Samet 表明，虽然电子邮件游戏中的代理人永远无法实现对世界ω的共同知识，但如果他们对ω的共同 p-信念足够高，那么存在一个 ex ante 均衡，在该均衡下，如果ω=ω1，则他们选择（A，A），如果ω=ω2，则选择（B，B）。这个均衡结果实际上不是 ex post。然而，如果情况发生变化，没有回复，那么 Lizzi 和 Joanna 最多只能有关于ω=ω2 的一级相互知识。Monderer 和 Samet 表明，在这种情况下，如果对于ω=ω2 有足够高的共同 p-信念，那么存在一个 ex post 均衡，在该均衡下，Joanna 和 Lizzi 选择（B，B）如果ω=ω2！因此，人们可能会以另一种方式看待电子邮件游戏的第三个教训，即代理人协调的前景有时可能会显著改善，如果他们依赖于他们的共同信念以及他们的相互知识。最近，p-信念和 p-共同信念的概念被证明是有用的（Paternotte，2011），用于分析和形式化 Lewis 关于共同知识的论述，而 Paternotte（2017）建立了“普通”共同知识和 p-共同信念之间的联系，使用后者表明，在电子邮件游戏或协调攻击悖论中，只有有限数量的交换就足以确定协调。这一结果，基于 Leitgeb（2014）提供的基础，用于表明我们对共同知识的“普通”理解被概率共同信念所捕捉，尽管以降低相对于共同信念分享者数量和他们意识的鲁棒性为代价。

## Bibliography

### Annotations

Lewis (1969) is the classic pioneering study of common knowledge and its potential applications to conventions and game theory. As Lewis acknowledges, parts of his work are foreshadowed in Hume (1740) and Schelling (1960).

Aumann (1976) gives the first mathematically rigorous formulation of common knowledge using set theory. Schiffer (1972) uses the formal vocabulary of _epistemic logic_ (Hintikka 1962) to state his definition of common knowledge. Schiffer’s general approach is to augment a system of sentential logic with a set of knowledge operators corresponding to a set of agents, and then to define common knowledge as a hierarchy of propositions in the augmented system. Bacharach (1992), Bicchieri (1993) and Fagin, _et al_. (1995) adopt this approach, and develop logical theories of common knowledge which include soundness and completeness theorems. Fagin, et al. show that the syntactic and set-theoretic approaches to developing common knowledge are logically equivalent.

Aumann (1995) gives a recent defense of the classical view of backwards induction in games of imperfect information. For criticisms of the classical view, see Binmore (1987), Reny (1992), Bicchieri (1989) and especially Bicchieri (1993). Brandenburger (1992) surveys the known results connecting mutual and common knowledge to solution concepts in game theory. For more in-depth survey articles on common knowledge and its applications to game theory, see Binmore and Brandenburger (1989), Geanakoplos (1994) and Dekel and Gul (1997). For her alternate account of common knowledge along with an account of conventions which opposes Lewis’ account, see Gilbert (1989).

Monderer and Samet (1989) remains one of the best resources for the study of common p-belief.

### References

* Alberucci, Luca and Jaeger, Gerhard, 2005, “About cut elimination for logics of common knowledge”, _Annals of Pure and Applied Logic_, 133(1–3): 73–99.
* Aumann, Robert, 1974, “Subjectivity and Correlation in Randomized Strategies”, _Journal of Mathematical Economics_, 1: 67–96.
* –––, 1976, “Agreeing to Disagree”, _Annals of Statistics_, 4: 1236–9.
* –––, 1987, “Correlated Equilibrium as an Expression of Bayesian Rationality”, _Econometrica_, 55: 1–18.
* –––, 1995, “Backward Induction and Common Knowledge of Rationality”, _Games and Economic Behavior_ 8: 6–19.
* Bacharach, Michael, 1985 “Some Extensions of a Claim of Aumann in an Axiomatic Model of Knowledge”, _Journal of Economic Theory_, 37(1): 167–190.
* –––, 1992.“Backward Induction and Beliefs About Oneself”, _Synthese_, 91: 247–284.
* Barwise, Jon, 1988, “Three Views of Common Knowledge”, in _Proceedings of the Second Conference on Theoretical Aspects of Reasoning About Knowledge_, M.Y. Vardi (ed.), San Francisco: Morgan Kaufman, pp. 365–379.
* –––, 1989, _The Situation in Logic_, Stanford: Center for the Study of Language and Information.
* Bernheim, B. Douglas, 1984, “Rationalizable Strategic Behavior”, _Econometrica_, 52: 1007–1028.
* Bicchieri, Cristina, 1989, “Self Refuting Theories of Strategic Interaction: A Paradox of Common Knowledge”, _Erkenntnis_, 30: 69–85.
* –––, 1993, _Rationality and Coordination_, Cambridge: Cambridge University Press.
* –––, 2006, _The Grammar of Society_, Cambridge: Cambridge University Press.
* Binmore, Ken, 1987, “Modelling Rational Players I”, _Economics and Philosophy_, 3: 179–241.
* –––, 1992, _Fun and Games_, Lexington, MA: D. C. Heath.
* –––, 2008, “Do Conventions Need to be Common Knowledge?”, _Topoi_, 27: 17–27.
* Binmore, Ken and Brandenburger, Adam, 1988, “Common knowledge and Game theory” ST/ICERD Discussion Paper 88/167, London School of Economics.
* Binmore, Ken and Samuelson, Larry, 2001, “Coordinated Action in the Electronic Mail Game” _Games and Economic Behavior_, 35(1): 6–30.
* Bonanno, Giacomo and Battigalli, Pierpaolo, 1999, “Recent Results on Belief, Knowledge and the Epistemic Foundations of Game Theory”, _Research in Economics_, 53(2): 149–225.
* Bonnay, D. and Egré, Paul, 2009, “Inexact Knowledge with Introspection”, _Journal of Philosophical Logic_, 38: 179–227.
* Brandenburger, Adam, 1992, “Knowledge and Equilibrium in Games”, _Journal of Economic Perspectives_, 6: 83–101.
* Brandenburger, Adam, and Dekel, Eddie, 1987, “Common Knowledge with Probability 1”, _Journal of Mathematical Economics_, 16: 237–245.
* –––, 1988, “The Role of Common Knowledge Assumptions in Game Theory”, in _The Economics of Missing Markets, Information and Games_, Frank Hahn (ed.), Oxford: Clarendon Press, 46–61.
* Bruni, Riccardo and Giacomo Sillari, 2018, “A Rational Way of Playing: Revision Theory for Strategic Interaction”, _Journal of Philosophical Logic_, 47(3), 419–448.
* Carnap, Rudolf, 1947, _Meaning and Necessity: A Study in Semantics and Modal Logic_, Chicago, University of Chicago Press.
* Cave, Jonathan AK, 1983, “Learning to Agree”, _Economics Letters_, 12(2): 147–152.
* Chwe, Michael, 1999, “Structure and Strategy in Collective Action”, _American Journal of Sociology_ 105: 128–56.
* –––, 2000, “Communcation and Coordination in Social Networks”, _Review of Economic Studies_, 67: 1–16.
* –––, 2001, _Rational Ritual_, Princeton, NJ: Princeton University Press
* Cubitt, Robin and Sugden, Robert, 2003, “Common Knowledge, Salience and Convention: A Reconstruction of David Lewis’ Game Theory”, _Economics and Philosophy_, 19: 175–210.
* Dégremont, Cédric, and Oliver Roy, 2012, “Agreement Theorems in Dynamic-Epistemic Logic”, _Journal of Philosophical Logic_, 41(4): 735-764.
* Dekel, Eddie and Gul, Faruk, 1997, “Rationality and Knowledge in Game Theory”, in _Advances in Economic Theory: Seventh World Congress of the Econometric Society_, D. Kreps and K. Wallace eds., Cambridge: Cambridge University Press.
* Dekel, Eddie, Lipman, Bart and Rustichini, Aldo, 1998, “Standard State-Space Models Preclude Unawareness,” _Econometrica_, 66: 159–173.
* Devetag, Giovanna, Hosni, Hykel and Sillari, Giacomo, 2013, “Play 7: Mutual Versus Common Knowledge of Advice in a Weak-Link Game,” _Synthese_, 190(8): 1351–1381
* Fagin, Ronald and Halpern, Joseph Y., 1988, “Awareness and Limited Reasoning,” _Artificial Intelligence_, 34: 39–76.
* Fagin, Ronald, Halpern, Joseph Y., Moses, Yoram and Vardi, Moshe Y., 1995, _Reasoning About Knowledge_, Cambridge, MA: MIT Press.
* Friedell, Morris, 1967, “On the Structure of Shared Awareness,” _Working papers of the Center for Research on Social Organizations_ (Paper #27), Ann Arbor: University of Michigan.
* –––, 1969, “On the Structure of Shared Awareness,” _Behavioral Science_, 14(1): 28–39.
* Geanakoplos, John, 1989, “Games Theory without Partitions, and Applications to Speculation and Consensus,” Cowles Foundation Discussion Paper, No. 914.
* –––, 1994, “Common Knowledge”, in _Handbook of Game Theory_ (Volume 2), Robert Aumann and Sergiu Hart (eds.), Amsterdam: Elsevier Science B.V., 1438–1496.
* Geanakoplos, John and Heraklis M. Polemarchakis, 1982, “We Can’t Disagree Forever” _Journal of Economic theory_ 28(1): 192–200.
* Gilbert, Margaret, 1989, _On Social Facts_, Princeton: Princeton University Press.
* Halpern, Jospeh, 2001, “Alternative Semantics for Unawareness”, _Games and Economic Behavior_, 37(2): 321–339
* Halpern, J. Y., & Moses, Y. , 1990, “Knowledge and common Knowledge in a Distributed Environment”. _Journal of the Association for Computing Machinery_, 37(3): 549–587.
* Halpern, J. Y., & Pass, R., 2017, “A Knowledge-Based Analysis of the Blockchain Protocol”. _arXiv preprint_ arXiv:1707.08751.
* Harman, Gilbert, 1977, “Review of _Linguistic Behavior_ by Jonathan Bennett”, _Language_, 53: 417–424.
* Harsanyi, J., 1967, “Games with Incomplete Information Played by ”Bayesian“ Players, I: The basic model”, _Management Science_, 14: 159–82.
* –––, 1968a, “Games with Incomplete Information Played by ”Bayesian“ Players, II: Bayesian Equilibrium Points”, _Management Science_, 14: 320–324.
* –––, 1968b, “Games with Incomplete Information Played by ”Bayesian“ Players, III: The basic probability distribution of the game”, _Management Science_, 14: 486–502.
* Heifetz, Aviad, 1999, “Iterative and Fixed Point Common Belief”, _Journal of Philosophical Logic_, 28(1): 61–79.
* Heifetz, Aviad, Meier, Martin and Schipper, Burkhard, 2006, “Interactive Unawareness”, _Journal of Economic Theory_, 130: 78–94.
* Hintikka, Jaakko, 1962, _Knowledge and Belief_, Ithaca, NY: Cornell University Press.
* Hume, David, 1740 \[1888, 1976], _A Treatise of Human Nature_, L. A. Selby-Bigge (ed.), rev. 2nd. edition P. H. Nidditch (ed.), Oxford: Clarendon Press.
* Immerman, D., 2021, “How Common Knowledge Is Possible”. _Mind_, first online 17 January 2021. doi:10.1093/mind/fzaa090
* Jäger, Gerhard and Michel Marti, 2016, “Intuitionistic Common Knowledge or Belief”, _Journal of Applied Logic_, 18: 150–163
* Lederman, Harvey, 2018a, “Two Paradoxes of Common Knowledge: Coordinated Attack and Electronic Mail”, _Noûs_, 52: 921–945.
* –––, 2018b, “Uncommon Knowledge” _Mind_ 127, 1069–1105.
* Leitgeb, Hannes, 2014, “The Stability Theory of Belief”, _The Philosophical Review_, 123(2): 131–171.
* Lewis, C. I., 1943, “The Modes of Meaning”, _Philosophy and Phenomenological Research_, 4: 236–250.
* Lewis, David, 1969, _Convention: A Philosophical Study_, Cambridge, MA: Harvard University Press.
* –––, 1978, “Truth in Fiction”, _American Philosophical Quarterly_, 15: 37–46.
* Littlewood, J. E., 1953, _A Mathematical Miscellany_, London: Methuen; reprinted as _Littlewood’s Miscellany_, B. Bollobas (ed.), Cambridge: Cambridge University Press, 1986.
* McKelvey, Richard and Page, Talbot, 1986, “Common Knowledge, Consensus and Aggregate Information”, _Econometrica_, 54: 109–127.
* Meyer, J.-J.Ch. and van der Hoek, Wiebe, 1995, _Epistemic Logic for Computer Science and Artificial Intelligence_ (Cambridge Tracts in Theoretical Computer Science 41), Cambridge: Cambridge University Press.
* Milgrom, Paul, 1981, “An Axiomatic Characterization of Common Knowledge”, _Econometrica_, 49: 219–222.
* Milgrom, Paul, and Nancy Stokey, 1982, “Information, Trade and Common Knowledge”, _Journal of Economic Theory_, 26(1): 17–27.
* Monderer, Dov and Samet, Dov, 1989, “Approximating Common Knowledge with Common Beliefs”, _Games and Economic Behavior_, 1: 170–190.
* Nash, John, 1950, “Equilibrium Points in N-person Games”. _Proceedings of the National Academy of Sciences of the United States_, 36: 48–49.
* –––, 1951, “Non-Cooperative Games”. _Annals of Mathematics_, 54: 286–295.
* Nozick, Robert, 1963, _The Normative Theory of Individual Choice_, Ph.D. dissertation, Princeton University
* Paternotte, Cédric, 2011, “Being Realistic about Common Knowledge: a Lewisian Approach”, _Synthese_, 183(2): 249–276.
* –––, 2017, “The Fragility of Common Knowledge”, _Erkenntnis_, 82(3): 451–472.
* Pearce, David, 1984, “Rationalizable Strategic Behavior and the Problem of Perfection”, _Econometrica_, 52: 1029–1050.
* Reny, Philip J, 1988, “Common Knowledge and Games with Perfect Information.” In _PSA: Proceedings of the Biennial Meeting of the Philosophy of Science Association_, vol. 1988, no. 2, pp. 363–369. East Lansing: Philosophy of Science Association.
* –––, 1992, “Rationality in Extensive Form Games”, _Journal of Economic Perspectives_, 6: 103–118.
* Rubinstein, Ariel, 1987, “A Game with ”Almost Common Knowledge“: An Example”, in _Theoretical Economics_, D. P. 87/165. London School of Economics.
* Samet, Dov, 1990, “Ignoring Ignorance and Agreeing to Disagree”, _Journal of Economic Theory_, 52: 190–207.
* Schelling, Thomas, 1960, _The Strategy of Conflict_, Cambridge, MA: Harvard University Press.
* Schiffer, Stephen, 1972, _Meaning_, Oxford: Oxford University Press.
* Sillari, Giacomo, 2005, “A Logical Framework for Convention”, _Synthese_, 147(2): 379–400.
* –––, 2008, “Common Knowledge and Convention”, _Topoi_, 27(1): 29–39.
* –––, 2013, “Rule-Following as Coordination: a Game-Theoretic Approach”, _Synthese_, 190(5): 871–890.
* –––, 2019, “Logics of Belief”, _Rivista di Filosofia_, 110(2): 243–262.
* Skyrms, Brian, 1984, _Pragmatics and Empiricism_, New Haven: Yale University Press.
* –––, 1990, _The Dynamics of Rational Deliberation_, Cambridge, MA: Harvard University Press
* –––, 1991, “Inductive Deliberation, Admissible Acts, and Perfect Equilibrium”, in _Foundations of Decision Theory_, Michael Bacharach and Susan Hurley eds., Cambridge, MA: Blackwell, pp. 220–241.
* –––, 1998, “The Shadow of the Future”, in _Rational Commitment and Social Justice: Essays for Gregory Kavka_, Jules Coleman and Christopher Morris eds., Cambridge: Cambridge University Press, pp. 12–22.
* Sugden, Robert, 1986, _The Economics of Rights, Cooperation and Welfare_, New York: Basil Blackwell.
* Thomason, R. H., 2021, “Common Knowledge, Common Attitudes and Social Reasoning”, _Bulletin of the Section of Logic_, 50(2): 229–247.
* Vanderschraaf, Peter, 1995, “Endogenous Correlated Equilibria in Noncooperative Games”, _Theory and Decision_, 38: 61–84.
* Vanderschraaf, Peter, 1998, “Knowledge, Equilibrium and Convention”, _Erkenntnis_, 49: 337–369.
* –––, 2001. _A Study in Inductive Deliberation_, New York: Routledge.
* von Neumann, John and Morgenstern, Oskar, 1944, _Theory of Games and Economic Behavior_, Princeton: Princeton University Press.

## Academic Tools

| ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=common-knowledge).                                                                      |
| ------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/common-knowledge/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
| ![inpho icon](https://plato.stanford.edu/symbols/inpho.png)         | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=common-knowledge\&redirect=True) at the Internet Philosophy Ontology Project (InPhO).   |
| ![phil papers icon](https://plato.stanford.edu/symbols/pp.gif)      | [Enhanced bibliography for this entry](https://philpapers.org/sep/common-knowledge/) at [PhilPapers](https://philpapers.org/), with links to its database.                          |

## Other Internet Resources

* [Applications of Circumscription to Formalizing Common Sense Knowledge](http://www-formal.stanford.edu/jmc/applications/applications.html)
* [Burkhard C. Schipper’s Unawareness Bibliography](http://www.econ.ucdavis.edu/faculty/schipper/unaw.htm)

## Related Entries

[convention](https://plato.stanford.edu/entries/convention/) | [game theory](https://plato.stanford.edu/entries/game-theory/) | [logic: epistemic](https://plato.stanford.edu/entries/logic-epistemic/) | [prisoner’s dilemma](https://plato.stanford.edu/entries/prisoner-dilemma/) | [social norms](https://plato.stanford.edu/entries/social-norms/)

[Copyright © 2022](https://plato.stanford.edu/info.html#c) by\
[Peter Vanderschraaf](https://moralscience.arizona.edu/person/peter-vanderschraaf)\
[Giacomo Sillari](https://scienzepolitiche.luiss.it/en/docenti/cv/020229) <[_gsillari@luiss.it_](mailto:gsillari%40luiss%2eit)>
