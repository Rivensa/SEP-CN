# 因果模型 causal models (Christopher Hitchcock)

_首次发布于 2018 年 8 月 7 日星期二_

因果模型是代表个体系统或人口内因果关系的数学模型。它们有助于从统计数据中推断因果关系。它们可以教给我们很多关于因果关系认识论以及因果关系与概率之间关系的知识。它们也被应用于哲学家感兴趣的主题，比如反事实逻辑、决策理论以及实际因果分析。

* [1. 简介](https://plato.stanford.edu/entries/causal-models/#Intr)
* [2. 基本工具](https://plato.stanford.edu/entries/causal-models/#BasiTool)
* [2.1 变量、逻辑和语言](https://plato.stanford.edu/entries/causal-models/#VariLogiLang)
* [2.2 概率](https://plato.stanford.edu/entries/causal-models/#Prob)
* [2.3 图表](https://plato.stanford.edu/entries/causal-models/#Grap)
* [3. 确定性结构方程模型](https://plato.stanford.edu/entries/causal-models/#DeteStruEquaMode)
* [3.1 结构方程模型简介](https://plato.stanford.edu/entries/causal-models/#IntrSEMs)
* [3.2 结构反事实](https://plato.stanford.edu/entries/causal-models/#StruCoun)
* [3.3 实际因果](https://plato.stanford.edu/entries/causal-models/#ActuCaus)
* [4. 概率因果模型](https://plato.stanford.edu/entries/causal-models/#ProbCausMode)
* [4.1 具有随机误差的结构方程模型](https://plato.stanford.edu/entries/causal-models/#StruEquaModeRandErro)
* [4.2 马尔可夫条件](https://plato.stanford.edu/entries/causal-models/#MarkCond)
* [4.3 最小性和忠实性条件](https://plato.stanford.edu/entries/causal-models/#MiniFaitCond)
* [4.4 因果结构的可识别性](https://plato.stanford.edu/entries/causal-models/#IdenCausStru)
* [4.5 对功能形式假设的可识别性](https://plato.stanford.edu/entries/causal-models/#IdenAssuAbouFuncForm)
* [4.6 潜在共同原因](https://plato.stanford.edu/entries/causal-models/#LateCommCaus)
* [4.7 干预](https://plato.stanford.edu/entries/causal-models/#Inte)
* [4.8. 干预决策理论](https://plato.stanford.edu/entries/causal-models/#InteDeciTheo)
* [4.9 干预下的因果发现](https://plato.stanford.edu/entries/causal-models/#CausDiscInte)
* [4.10 反事实条件句](https://plato.stanford.edu/entries/causal-models/#Coun)
* [5. 进一步阅读](https://plato.stanford.edu/entries/causal-models/#FurtRead)
* [参考文献](https://plato.stanford.edu/entries/causal-models/#Bib)
* [学术工具](https://plato.stanford.edu/entries/causal-models/#Aca)
* [其他互联网资源](https://plato.stanford.edu/entries/causal-models/#Oth)
* [相关条目](https://plato.stanford.edu/entries/causal-models/#Rel)

***

## 1. 介绍

因果模型是一个跨学科领域，起源于 20 世纪 20 年代的统计革命，特别是美国生物学家和统计学家 Sewall Wright（1921 年）的工作。重要的贡献来自计算机科学、计量经济学、流行病学、哲学、统计学和其他学科。鉴于因果关系对许多哲学领域的重要性，人们对使用数学因果模型产生了越来越多的哲学兴趣。两部重要著作——Spirtes、Glymour 和 Scheines 2000 年（简称 SGS），以及 Pearl 2009 年——产生了特别大的影响。

一个因果模型对系统行为进行预测。特别是，因果模型涉及关于系统的反事实声明的真值或概率；它预测干预的效果；并涉及模型中包括的变量之间的概率依赖性或独立性。因果模型还促进了这些推断的逆过程：如果我们观察到变量之间的概率相关性，或者实验干预的结果，我们可以确定哪些因果模型与这些观察结果一致。讨论将集中在“原则上”可以做什么。例如，我们将考虑在完全了解系统中变量的概率分布的情况下，我们可以推断出系统的正确因果结构的程度。这忽略了从有限样本数据中推断真实概率的非常现实的问题。此外，本文还将讨论将因果模型应用于反事实逻辑、因果分析和决策理论。

## 2. 基本工具

本节介绍了因果建模中使用的一些基本形式工具，以及术语和符号约定。

### 2.1 变量、逻辑和语言

_变量_ 是因果模型的基本构建模块。它们将由斜体大写字母表示。变量是一个可以取各种值的函数。变量的值可以表示事件的发生或非发生，一系列不相容的事件，个体或个体群体的属性，或定量值。例如，我们可能想要建模苏茜扔石头并打破窗户的情况，并具有变量 _S_ 和 _W_，使得：

* S=1 表示苏茜扔石头； S=0 表示她没有扔

_W=1_代表窗户破碎；_W=0_代表窗户保持完好。

如果我们正在建模教育对美国收入的影响，我们可能会使用变量_E_和_I_，使得：

* 如果个体_i_没有高中学历，则 E(i)=0；如果个体完成了高中学业，则 E(i)=1；如果个体接受过一些大学教育，则 E(i)=2；如果个体拥有学士学位，则 E(i)=3；如果个体拥有硕士学位，则 E(i)=4；如果个体拥有博士学位（包括法律和医学领域的最高学位），则 E(i)=5。
* 如果个体_i_的税前年收入为$_x_，则 I(i)=x。

变量的可能值集合是该变量的_range_。我们通常会假设变量有有限多个可能的值，因为这样会使数学和表达更简单。然而，因果模型也可以包含连续变量，在某些情况下，这会产生重要的区别。

一个_world_是因果模型的完整规范；具体细节将取决于模型的类型。现在，我们注意到一个 world 将包括，_inter alia_，对模型中所有变量的值的分配。如果这些变量代表人群中个体的属性，一个 world 将包括对人群中每个个体的每个变量的值的分配。然后，变量可以被理解为其定义域是一组 worlds 或一组 worlds 和个体的函数。

如果_X_是因果模型中的一个变量，而_x_是_X_范围内的一个特定值，则_X=x_是一个_原子命题_。否定（“非”）、合取（“且”）、析取（“或”）、蕴含（“如果…那么…”）和双条件（“当且仅当”）的逻辑运算分别用“∼”、“&”、“∨”、“⊃”和“≡”表示。由原子命题和这些逻辑运算构建的任何命题都将被称为_布尔_命题。请注意，当变量定义在人口中的个体上时，对个体的引用_不_包含在命题中；相反，整个命题对人口中的各个个体为真或为假。

我们将使用集合论中的基本符号。集合将以粗体显示。

* ∅ 是空集（即没有成员或元素的集合）。
* x∈X 表示 _x_ 是集合 X 的成员或元素。
* X⊆Y 意味着 X 是 Y 的子集；即， X 的每个成员也是 Y 的成员。请注意， ∅ 和 Y 都是 Y 的子集。
* X∖Y 是从 X 中移除 Y 的成员后得到的集合。

_∀_ 和 _∃_ 分别是全称量词和存在量词。

如果_S={x1,…,xn}_ 是_X_范围内的一组值，则_X∈S_用作缩写，表示形式为_X=xi_的命题的析取，其中_i=1,…,n_。黑体表示_有序集_或_向量_。如果_X={X1,…,Xn}_ 是一组变量的向量，_x={x1,…,xn}_ 是一组值的向量，每个值_xi_在相应变量_Xi_的范围内，则_X=x_是形式为_Xi=xi_的命题的合取。

### 2.2 概率

在[第 4 节](https://plato.stanford.edu/entries/causal-models/#ProbCausMode)，我们将考虑包括概率的因果模型。概率是一个函数，P，它分配介于零和一之间（包括零和一）的值。概率函数的定义域是一组命题，其中将包括上述所有布尔命题，但也可能包括其他命题。

一些概率的标准属性如下：

* 如果 _A_ 是一个矛盾，则 P(A)=0。
* 如果_A_是一个重言式, 那么 P(A)=1。
* 如果 P(A\&B)=0, 那么 P(A∨B)=P(A)+P(B)。
* P(∼A)=1−P(A).

一些进一步的定义：

_条件概率_ _P(A∣B)_ _是标准定义如下：_

P(A∣B)=P(A\&B)P(B)。

我们将忽略可能出现的问题，即当 P(B)=0 时。

_A_ 和 _B_ 在概率上独立（相对于 P）的条件是 P(A\&B)=P(A)×P(B)。_A_ 和 _B_ 在概率上相关或相关的条件是其他情况。如果 P(B)>0，则当 P(A∣B)=P(A) 时，_A_ 和 _B_ 将是独立的。

_变量_X_和_Y_在所有形式为_X=x_和_Y=y\*的命题都是概率独立的情况下才是概率上独立的。

* _A_和_B_在给定_C_的条件下是_概率独立的_，只要 P(A\&B∣C)=P(A∣C)×P(B∣C)。如果 P(B\&C)>0，这等同于 P(A∣B\&C)=P(A∣C)。根据 Reichenbach（1956）的术语，我们也会说\*\*C_从_A_中_筛除_B_，当这些相等成立时。变量之间的条件独立类似地被定义。

作为一种方便的简写，一个只包含变量或一组变量但不包含值的概率陈述将被理解为对变量的所有可能值进行普遍量化。因此，如果 X={X1,…,Xm} 和 Y={Y1,…,Yn}，我们可以写成

P(X∣Y)=P(X)

作为的简写

∀x1…∀xm∀y1…∀yn\[P(X1=x1,…,Xm=xm∣Y1=y1,…,Yn=yn)=P(X1=x1,…,Xm=xm)]

在这里，每个变量的量化域将是相关变量的范围。

我们不会预设任何特定的概率解释（请参阅[概率解释](https://plato.stanford.edu/entries/probability-interpret/)条目），但我们将假设适当选择的样本中的频率提供了关于潜在概率的证据。例如，假设有一个包括上述变量_E_和_I_的因果模型，其中 P(E=3)=.25。那么我们期望，如果我们调查一个大的、随机选择的美国成年人样本，我们会发现大约四分之一的人拥有学士学位，但没有更高的学位。如果调查产生的样本频率与此有显著差异，我们有证据表明模型不准确。

### 2.3 图

如果 V 是因果模型中包含的变量集合，表示 V 中变量之间的因果关系的一种方式是通过_图_。虽然我们将在[第 3 节](https://plato.stanford.edu/entries/causal-models/#DeteStruEquaMode)中介绍和使用图，但它们将在[第 4 节](https://plato.stanford.edu/entries/causal-models/#ProbCausMode)中扮演更重要的角色。我们将讨论两种类型的图。第一种是_有向无环图_（DAG）。在变量集合 V 上的_有向图_ G 是 V 中变量的有序对的集合。我们通过从 _X_ 指向 _Y_ 的箭头来进行可视化表示，仅当 ⟨X,Y⟩ 在 G 中时。[图 1](https://plato.stanford.edu/entries/causal-models/#fig1) 展示了一个在变量集合 V={S,T,W,X,Y,Z} 上的有向图。

![一个图表，其中 S 有一个指向北方的箭头指向 T；T 有一个指向西北的箭头指向 X 和一个指向东北的箭头指向 Y；Y 有一个指向东北的箭头指向 Z；W 有一个指向北方的箭头指向 Z 和一个指向西北的箭头指向 Y](https://plato.stanford.edu/entries/causal-models/fig1.svg)

图 1

在一个有向图中，_路径_是一系列不重复的箭头，它们的端点相同。例如，在[图 1](https://plato.stanford.edu/entries/causal-models/#fig1)中，从_X_到_Z_有一条路径，我们可以写成 X←T→Y→Z。_有向路径_是所有箭头指向同一方向的路径；例如，有一条有向路径 S→T→Y→Z。如果没有从一个变量指向自身的有向路径，则有向图是_无环_的，因此是 DAG。这样的有向路径称为_循环_。图 1 中不包含循环，因此是 DAG。

图中的关系通常用家族关系的语言来描述。变量_X_是_Y_的_父母_，只要有一条从_X_到_Y_的箭头。PA(Y)表示_Y_的所有父母的集合。在[图 1](https://plato.stanford.edu/entries/causal-models/#fig1)中，PA(Y)={T,W}。_X_是_Y_的_祖先_（_Y_是_X_的_后代_），只要有一条从_X_到_Y_的有向路径。然而，为了方便起见，我们会略微偏离家族类比，并定义“后代”，使得每个变量都是其自身的后代。DE(X)表示_X_的所有后代的集合。在图 1 中，DE(T)={T,X,Y,Z}。

在因果模型中，有向无环图中从 _Y_ 指向 _Z_ 的箭头表示 _Y_ 是 _Z_ 的直接原因。大致上，这意味着 _Y_ 的值对 _Z_ 的值有一定的因果影响，并且 _Y_ 通过某个过程影响 _Z_，而这个过程不受 V 中任何其他变量的中介。直接性是相对于一个变量集的：相对于变量集 V，_Y_ 可能是 _Z_ 的直接原因，但相对于包括一些额外中介 _Y_ 对 _Z_ 影响的变量集 V'，_Y_ 就不是直接原因。随着我们更详细地发展我们对图形因果模型的描述，我们将能够更准确地说明一个变量是另一个变量的直接原因是什么意思。虽然我们不会定义“原因”，因果模型假定了广义的“造成差异”的因果概念，而不是因果过程概念（Salmon 1984，Dowe 2000）或机械主义概念（Machamer，Darden 和 Craver 2000；Glennan 2017）。我们将称在 DAG 中表示的直接因果关系系统（如 [图 1](https://plato.stanford.edu/entries/causal-models/#fig1)）为变量集 V 上的“因果结构”。

我们将考虑的第二种图形类型是“无环有向混合图”（ADMG）。ADMG 将包含双头箭头和单头箭头。双头箭头表示“潜在”的共同原因。变量 _X_ 和 _Y_ 的潜在共同原因是未包含在变量集 V 中的共同原因。例如，假设 _X_ 和 _Y_ 共享一个共同原因 _L_（[图 2(a)](https://plato.stanford.edu/entries/causal-models/#fig2a)）。在变量集 V={X,Y} 上的 ADMG 看起来像 [图 2(b)](https://plato.stanford.edu/entries/causal-models/#fig2b)。

![显示 L 有一个箭头向西北指向 X 和向东北指向 Y 的图表](https://plato.stanford.edu/entries/causal-models/fig2a.svg)

(a)

![X 在 Y 的右边，两者之间有一个双头曲箭头连接](https://plato.stanford.edu/entries/causal-models/fig2b.svg)

(因果模型)

图 2

我们可以更加精确。我们只需要在这种情况下以这种方式表示缺失的共同原因，即当它们是_最接近_的共同原因时。也就是说，当图中的 V 应该包含一个双向箭头，连接_X_和_Y_时，当存在一个变量_L_被省略在 V 中，如果_L_被添加到 V 中，它将是_X_和_Y_的_直接原因_。

在一个 ADMG 中，我们扩展了_路径_的定义，以包括双向箭头。因此，在[图 2(b)](https://plato.stanford.edu/entries/causal-models/#fig2b)中显示的 ADMG 中，X↔Y 是一条路径。_有向路径_保留相同的含义，有向路径不能包含双向箭头。

我们将采纳这样的约定，即 DAG 和 ADMG 都表示直接因果关系和潜在共同原因的_存在和不存在_。例如，[图 1](https://plato.stanford.edu/entries/causal-models/#fig1)中的 DAG 表示_W_是_Y_的直接原因，_X_不是_Y_的直接原因，并且_没有潜在共同原因_。从图 1 中没有双向箭头并不仅仅表明我们选择不在我们的表示中包括潜在共同原因；它表明没有潜在共同原因。

## 3. 确定性结构方程模型

在这一部分中，我们介绍确定性_结构方程模型_（SEMs），将概率的讨论推迟到[第 4 节](https://plato.stanford.edu/entries/causal-models/#ProbCausMode)。我们将考虑确定性 SEM 的两个应用：反事实逻辑和实际因果分析。

### 3.1 SEMs 简介

因果模型描述了一个具有一组变量的因果系统，并描述了每个变量如何依赖于其直接因果前因的一组方程。考虑一个用于烹饪肉类的燃气烧烤炉。我们可以使用以下变量描述烧烤炉的操作：

* _煤气连接_（如果是，则为 1，如果不是，则为 0）
* _煤气旋钮_（0 代表关闭，1 代表低，2 代表中，3 代表高）
* _气体水平_（0 代表关闭，1 代表低，2 代表中，3 代表高）
* _点火器_（1 代表按下，0 代表未按下）
* _火焰_（0 代表关闭，1 代表低，2 代表中，3 代表高）
* _肉类放置_（0 代表否，1 代表是）
* _熟肉_ (0 代表生的, 1 代表半生, 2 代表中等, 3 代表全熟)

因此，例如，_煤气旋钮_ = 1 意味着煤气旋钮设置为低；_点火器_ = 1 意味着点火器被按下，等等。然后方程可能是：

* _气体水平_ = _气体连接_ × _气体旋钮_
* _火焰_ = _气体水平_ × _点火器_
* _熟肉_ = _火焰_ × _肉放上_

例如，最后一个方程告诉我们，如果肉没有放在烤架上，它将保持生的（_熟肉_ = 0）。如果肉放在烤架上，那么它将根据火焰的强度而变熟：如果火焰低（_火焰_ = 1），肉会变生熟（_熟肉_ = 1），依此类推。

按照惯例，每个方程式左边有一个效应变量，右边有一个或多个原因变量。我们还会从每个方程式中排除任何对效应变量值没有影响的变量。例如，_Gas level_ 的方程式可以写成 _Gas level_ = (_Gas connected_ × _Gas knob_) + (0 × _Meat cooked_); 但由于在这个方程式中 _Meat cooked_ 的值对 _Gas level_ 的值没有影响，我们省略了变量 _Meat cooked_。如果变量可以被排序，使得在它们出现在右边之后永远不会出现在方程式左边，那么 SEM 是 _acyclic_ 的。如上所示，我们的示例是 _acyclic_ 的。在接下来的内容中，我们将假设 SEMs 是 _acyclic_ 的，除非另有说明。

我们可以将这些方程式表示为一个 DAG ([图 3](https://plato.stanford.edu/entries/causal-models/#fig3))：

![图表'Gas connected'有一箭头指向东北方向的'Gas level'; 'Gas knob'有一箭头指向西北方向的同一'Gas level'; 'Gas level'有一箭头指向东北方向的'Flame'; 'Igniter'有一箭头指向西北方向的同一'Flame'; 'Flame'有一箭头指向东北方向的'Meat cooked'; 'Meat on'有一箭头指向西北方向的同一'Meat cooked'](https://plato.stanford.edu/entries/causal-models/fig3.svg)

图 3

一个箭头从变量_X_指向变量_Y_，仅当_X_在_Y_的方程中作为参数。图表包含的信息严格少于方程组的信息；特别是，有向无环图给我们关于哪些变量取决于其他变量的定性信息，但它并不告诉我们关于依赖关系的功能形式的任何信息。

模型中的变量通常会依赖于未明确包含在模型中的其他变量。例如，火焰的强度也取决于氧气的存在。在模型中未明确表示的变量被假定为固定在使方程适当的值上。例如，在我们的燃气烧烤模型中，假定氧气以足够的数量存在，以维持火焰的强度从低到高不等。

在我们的例子中，变量_Gas level_、_Flame_和_Meat cooked_是_内生的_，这意味着它们的值由模型中的其他变量决定。_Gas connected, Gas knob, Igniter_和_Meat on_是_外生的_，这意味着它们的值是在系统外确定的。在我们将在[第 3 节](https://plato.stanford.edu/entries/causal-models/#DeteStruEquaMode)中考虑的所有模型中，外生变量的值是已知的或以其他方式已知的。

根据 Halpern（2016）的说法，我们将对外生变量的值分配称为_上下文_。在无环结构 SEM 中，上下文唯一确定模型中所有变量的值。无环结构 SEM 与上下文一起构成一个_世界_（Halpern 2016 称之为“因果设置”）。例如，如果我们添加设置

* _Gas connected_ = 1
* _Gas knob_ = 3
* _Igniter_ = 1
* _Meat on_ = 1

根据我们上面的三个方程式，我们得到一个世界，其中 _气体水平_ = 3，_火焰_ = 3，以及 _熟肉_ = 3。

结构方程模型的独特因果或“结构”内容源自对 _干预_ 的表示方式。对变量进行干预意味着通过一种覆盖通常因果结构的过程来设置该变量的值，而不干扰控制其他变量的因果过程。更确切地说，对变量 _X_ 进行干预会覆盖 _X_ 的正常方程式，同时保持其他方程式不变。例如，在我们的例子中对 _火焰_ 进行干预意味着将火焰设置为特定水平，而不管是否按下点火器或气体水平如何。（也许，例如，可以往烤架里倒入煤油并用火柴点燃。）Woodward（2003）提出，我们应该将干预视为在模型中独立于其他变量运作的因果过程。随机对照试验旨在以这种意义进行干预。例如，用于测试治疗高血压药物疗效的随机对照试验旨在确定每个受试者是否服用药物（而不是安慰剂），通过像抛硬币这样的随机过程。通常影响某人是否服用药物的因素，如教育和健康保险，对试验人群中的受试者不再起这种作用。或者，我们可以遵循 Lewis（1979）的方法，将干预视为通过小“奇迹”设置变量值。

为了表示对变量的干预，我们用一个新方程替换该变量的方程，陈述变量被设定为的值。例如，如果我们干预将火焰水平设定为低，我们会用_火焰_ = _气体水平_ × _点火器_ 替换这个方程，得到_火焰_ = 1。这样就创建了一个新的因果结构，其中_火焰_是一个外生变量；从图形上看，我们可以将干预看作是“打破箭头”指向_火焰_。然后可以解决新的方程组，以发现其他变量在干预结果下会取什么值。在上述描述的世界中，我们的干预将产生以下一组方程：

* _气体连接_ = 1
* _气阀_ = 3
* _点火器_ = 1
* _肉类在_ = 1
* _气体水平_ = _气体连接_ × _气体旋钮_

_火焰_ = _气体水平_ × _点火器_

_火焰_ = 1

* _熟肉_ = _火焰_ × _肉上_

我们划掉了原方程中的 _火焰_，表明它不再起作用。结果是一个具有修改因果结构的新世界，其中 _气体水平_ = 3，_火焰_ = 1，_熟肉_ = 1。由于连接 _火焰_ 与其原因的方程被移除，通过将 _火焰_ 设为 1 引入的任何变化只会向前传播到 _火焰_ 的后代。干预改变了 _火焰_ 和 _熟肉_ 的值，但不影响其他变量的值。我们可以以相同方式表示对多个变量的干预，替换所有受干预变量的方程。

干预有助于为对应的因果模型中的箭头提供内容。如果变量 Xi 是 Xj 的父节点，这意味着存在某种设置，使得在模型中将其他变量设置为这些值后，通过干预 Xi 仍然可以改变 Xj 的值。例如，在我们的原始模型中，_Gas level_ 是 _Flame_ 的父节点。如果我们通过干预将 _Igniter_ 的值设置为 1，并将 _Gas knob, Gas connected, Meat on,_ 和 _Meat cooked_ 设置为任何值，那么干预 _Gas level_ 对 _Flame_ 的值会产生影响。将 _Gas level_ 的值设为 1 会使 _Flame_ 的值为 1；将 _Gas level_ 设为 2 会得到 _Flame_ 为 2；依此类推。

### 3.2 结构反事实(Causal Models as 因果模型)

一个反事实是以虚拟条件句的形式提出的命题。前提假定了某种情况，通常是与事实相反的情况。例如，在我们的燃气烧烤世界中，火焰很高，肉烤得很熟。我们可能会推理：“如果火焰被调低了，肉就会是生的”。前提假设了一种假设的情况，而结果描述了在那种假设情况下会发生什么。

确定性结构方程模型自然地引发了反事实逻辑。这些反事实被称为_结构_反事实或_干预_反事实。结构反事实在某些方面类似于 Lewis（1979）所称的_非回溯_反事实。在非回溯反事实中，人们不会从反事实假设逆向推理出关于假设情况原因的结论。例如，人们不会推理“如果肉被煮成生的，那么火焰就会被调低”。Lewis（1979）提出，我们应该认为反事实的前提是通过一个小“奇迹”实现的。在前一节描述的表示干预的形式化过程中，防止了从效果到原因的回溯。

因果模型的逻辑是由 Galles 和 Pearl（1998 年）、Halpern（2000 年）、Briggs（2012 年）和 Zhang（2013a 年）发展起来的。本节将重点讨论 Briggs 的表述；它的语言最丰富，但与其他方法不同，它不能应用于具有循环的因果模型。尽管与非回溯性反事实有关，Briggs 的逻辑在许多方面与 Stalnaker（1968 年）和 Lewis（1973b 年）发展的更为熟悉的反事实逻辑有所不同。

我们将反事实条件_A_□→_B_解释为说如果通过干预使_A_成为真，则_B_将成为真。结构反事实的语言不允许连接词‘_A_□→_B_’出现在反事实的前提中。更准确地说，我们归纳地为该语言定义了良构公式（_wff_s）：

* 布尔命题是_wff_s
* 如果_A_是一个布尔命题，而_B_是一个_wff_，那么 A□→B 是一个_wff_

这意味着，例如，A□→(B□→(C□→D)) 是一个_wff_，但 A□→((B□→C)□→D) 不是，因为结果中嵌套的反事实并没有布尔命题作为前提。

考虑前一节中描述的燃气烧烤世界：

* _Gas connected_ = 1
* _Gas knob_ = 3
* _Igniter_ = 1
* _Meat on_ = 1
* _气体水平_ = _气体连接_ × _气阀_
* _火焰_ = _气体水平_ × _点火器_
* _熟肉_ = _火焰_ × _肉在上_

为了评估反事实情况下的 _火焰=1□→熟肉=1_（如果火焰被设置为 _低_，肉将被煮得很生），我们用 _火焰_ 的赋值 _火焰_ = 1 替换方程式。然后我们可以计算出 _熟肉_ = 1；反事实情况为真。如果前提是原子命题的合取，比如 _火焰_ = 1 和 _点火器_ = 0，我们会替换所有相关方程式。当前提连接分配不同值给同一变量的原子命题时，比如 _火焰_ = 1 和 _火焰_ = 2，就会出现特殊情况。在这种情况下，前提是一个矛盾，反事实被认为是显然为真的。

如果前因是原子命题的析取，或者是原子命题的合取的析取，那么当执行前因描述的每个可能干预或干预集时，结论必须为真。例如，

((火焰=1&气体水平=0)∨(火焰=2&肉类=0))□→(肉类煮熟=1∨肉类煮熟=2)。

如果我们执行第一个干预，我们计算得到_熟肉_= 1，因此结果为真。但是，如果我们执行第二个干预，我们计算得到_熟肉_= 0。因此，反事实变得不成立。一些否定被视为此目的的析取。例如，∼(火焰=1)将被视为与析取相同的方式处理

火焰=0∨火焰=2∨火焰=3。

如果结果包含一个反事实，我们会重复这个过程。考虑这个反事实：

火焰=1□→(气体水平=0□→(火焰=2□→肉类煮熟=1)).

要评估这个反事实，我们首先将_火焰_的方程式更改为_火焰_ = 1。然后我们将_气体水平_的方程式更改为_气体水平_ = 0。然后我们再次更改_火焰_的方程式，从_火焰_ = 1，变为_火焰_ = 2。最后，我们计算出_熟肉_ = 2，因此反事实为假。与_火焰_ = 1 和_火焰_ = 2 在前提中连接的情况不同，_火焰_的两种不同赋值并不会产生一个不可能的前提。在这种情况下，干预是按照指定的顺序进行的：_火焰_首先设为 1，_然后_设为 2。

结构反事实和斯坦纳克-刘易斯反事实之间的差异源自结构反事实的以下两个特点：

1. 反事实的前因始终被视为由干预实现，即使在特定世界中前因已经为真。例如，在我们的燃气烧烤世界中，_火焰_ = 3。然而，如果我们评估在这个世界中前因为_火焰_ = 3 的反事实，我们会用_火焰_ = 3 替换_火焰_的方程式。
2. 反事实的真值仅由世界的因果结构以及其前因中指定的干预决定。_相似性_的进一步考虑并不起作用。例如，反事实

火焰=1∨火焰=2□→火焰=2

在我们的燃气烧烤世界中（实际上在所有可能的世界中）将是错误的。我们不推断一个世界中火焰=2 比一个世界中火焰=1 更接近我们的世界（其中火焰=3）。

这些结构反事实的特征导致了 Briggs (2012) 发展的完整语言中的一些不寻常的属性：

1. _modus ponens_ 的类比在结构条件语句中失败；即，从 _A_ 和 A□→B 不能推断出 _B_。例如，在我们的烧烤世界中，_火焰_ = 3 和 火焰=3□→(气体水平=2□→熟肉=3) 都是真的，但气体水平=2□→熟肉=3 是假的。要评估最后一个反事实，我们用 _气体水平_ 的方程替换 _气体水平_ = 2。这导致 _火焰_ = 2 和 _熟肉_ = 2。要评估之前的反事实，我们首先代入 _火焰_ = 3 的方程。现在，_火焰_ 的值不再取决于 _气体水平_ 的值，因此当我们代入 _气体水平_ = 2 时，我们得到 _熟肉_ = 3。即使 _火焰_ 的实际值是 3，我们通过干预 _火焰_ 将其设置为 3 来评估反事实。有了这个干预，对 _气体水平_ 的进一步干预对 _火焰_ 或 _熟肉_ 没有影响。
2. 将逻辑上等价的命题替换为反事实的前提并不总是保留真值。例如，Gas level=2□→Meat cooked=2 是真的，但 Gas level=2&(Flame=2∨∼(Flame=2))□→Meat cooked=2 是假的。第一个反事实不需要我们干预_Flame_的值，但第二个反事实需要我们考虑将_Flame_设置为其所有可能值的干预。

为了处理第二种情况，Briggs（2012）使用 Fine（2012）的状态空间语义定义了布尔命题之间的_确切等价_关系。在一个世界中，使命题为真的状态是对导致命题为真的变量值的集合。在我们的示例世界中，使 Gas level=3 为真的状态是估值 Gas level=3。相比之下，使

气体水平=3&(火焰=2∨∼(火焰=2))

真包括_气体水平_=3 和_火焰_=3。 如果两个命题在所有可能的世界中由相同的状态变为真，则它们完全等价。 当完全等价的命题替换到前提中时，反事实的真值保持不变。

Briggs (2012) 提供了一个对非循环结构因果模型中的结构反事实提供了完整而严谨的公理化。该系统的公理和推理规则在[Briggs 公理化补充](https://plato.stanford.edu/entries/causal-models/axiomatization.html)中呈现。

### 3.3 实际因果

许多哲学家和法理论家对_实际因果_的关系感兴趣。这涉及根据事件的实际发展情况来确定某一事件的因果责任。例如，假设比利和苏茜都拿着石头。苏茜把她的石头扔向窗户，但比利没有。苏茜的石头击中了窗户，导致了窗户的破裂。那么苏茜的投掷是窗户破裂的实际原因。

我们可以用结构方程模型很容易地表示这个故事。对于变量，我们选择：

* 如果 Billy 投掷，则 B=1，如果他不投掷则为 0
* 如果 Suzy 投掷，则 S=1，如果她不投掷则为 0
* 如果窗户破碎，则 W=1，如果没有破碎则为 0

我们的背景和方程式将是：

* B=0
* S=1
* W=max(B,S)

_W_的方程告诉我们，如果 Billy 或 Suzy 扔掉他们的石头，窗户会破裂。相应的因果模型如[图 4](https://plato.stanford.edu/entries/causal-models/#fig4)所示。

![diagram B has an arrow pointing northeast to W and S has an arrow pointing northwest to the same W](https://plato.stanford.edu/entries/causal-models/fig4.svg)

图 4

但我们不能简单地从图表或方程式中直接推断出实际因果关系。例如，[图 4](https://plato.stanford.edu/entries/causal-models/#fig4)中从_B_指向_W_的箭头并不能被解释为说比利的(不)行动是窗户破裂的实际原因。请注意，虽然区分单一或特定因果关系，以及一般或类型级因果关系是常见的（参见，例如，Eells 1991，Introduction），但这并不是问题的关键。我们的因果模型不代表任何形式的因果概括：它代表了比利和苏茜在特定时间和地点的实际和可能的行动。实际因果关系不仅仅是单个案例的因果结构。需要进一步的实际因果标准，这些标准是根据因果结构以及变量的实际值来定义的。

根据 Lewis（1973a）的观点，自然而然地尝试用_反事实依赖_来分析实际因果关系。在我们的模型中，以下命题都是真实的：

* S=1
* W=1
* S=0□→W=0

用文字表达：苏茜扔了她的石头，窗户破碎了，如果苏茜没有扔石头，窗户就不会破碎。一般来说，我们可能会尝试将实际因果关系分析如下：

X=x 在世界 _w_ 中是 Y=y 的一个实际原因，只要：

* _X_ 和 _Y_ 是不同的变量
* X=x\* 和 _Y=y_ 在 _w_ 中
* 存在 _x′≠x_ 和 _y′≠y_ 使得在 _w_ 中 X=x′□→Y=y′ 成立

不幸的是，这种简单的分析不起作用，因为涉及到_优先_和_过度决定_的熟悉原因。以下是每种情况的说明：

_优先:_ 比利决定让苏茜有机会先投掷。如果苏茜投掷她的石头，他就不会投掷，但如果她不投掷，他会投掷，他的石头会打碎窗户。事实上，苏茜投掷了她的石头，打碎了窗户。比利没有投掷。

_过度决定：_ 比利和苏茜同时扔出他们的石头。他们的石头同时击中窗户，将其击碎。任何一块石头本身都足以击碎窗户。

在这两种情况下，苏茜的投掷是窗户破碎的实际原因，但窗户的破碎并不依赖于她的投掷：如果苏茜没有扔石头，比利的石头也会击碎窗户。自 1973 年以来，关于因果理论的反事实理论的大部分工作都致力于解决这些问题。

一些作者已经使用 SEM 来尝试以反事实的方式制定关于实际因果关系的充分分析，包括 Beckers＆Vennekens（2018），Glymour＆Wimberly（2007），Halpern（2016），Halpern＆Pearl（2001，2005），Hitchcock（2001），Pearl（2009：第 10 章），Weslake（即将出版），和 Woodward（2003：第 2 章）。作为一个例证，考虑一个基于 Halpern（2016）提出的提案的分析：

(**AC**) X=x 在世界_w_中是 Y=y 的实际原因，只有当：

1. _X_ 和 _Y_ 是不同的变量
2. X=x 和 Y=y 在 _w_ 中
3. 存在不相交的变量集 X 和 Z，其中 X∈X，具有值 X=x 和 Z=z 在_w_中，使得：
4. 存在 x′≠x，使得(X=x′\&Z=z)□→Y≠y 在_w_中为真
5. 没有 _X_ 的任何子集满足 (3a)

也就是说，_X_ 属于一个最小的变量集合 X，当我们进行干预以使变量 Z 保持在 _w_ 中实际取值时，_Y_ 在因果上依赖于 X 中变量的取值。我们将通过我们对先占和过决的例子来说明这一点。

在_Preemption_中，让变量_B_、_S_和_W_如上所定义。我们的上下文和方程式是：

* S=1
* B=1−S
* W=max(B,S)

那就是：苏茜扔她的石头；如果苏茜不扔，比利会扔他的石头；如果任何人扔石头，窗户就会破碎。DAG 显示在[图 5](https://plato.stanford.edu/entries/causal-models/#fig5)中。

![图 B 有一个箭头指向东北到 W，S 有一个箭头指向西北到相同的 W，S 还有一个箭头指向西到相同的 B](https://plato.stanford.edu/entries/causal-models/fig5.svg)

图 5

我们想要展示 S=1 是 W=1 的一个实际原因。条件 AC(1) 和 AC(2) 明显被满足。对于条件 AC(3)，我们选择 X={S} 和 Z={B}。由于在_Preemption_中 B=0，我们希望固定 B=0 同时改变 _S_。我们可以很容易地看到 S=0\&B=0□→W=0：用 B=0 和 S=0 替换 _B_ 和 _S_ 的两个方程，解得 W=0。换句话说，这个反事实说如果既没有比利也没有苏茜扔石头，窗户就不会破碎。因此条件 AC(3a) 被满足。AC(3b) 显然被满足，因为 X={S} 是一个单元素集。

这里是因果模型在这个例子中的工作方式。_S_ 影响 _W_ 通过两条不同的路径：直接路径 S→W 和间接路径 S→B→W。这两条路径以一种相互作用的方式相互抵消，_S_ 的值对 _W_ 的值没有净影响。然而，通过将 _B_ 固定在其实际值 0，我们消除了 _S_ 对 _W_ 的影响沿着那条路径。结果是我们隔离出 _S_ 对 _W_ 通过直接路径产生的贡献。AC 将实际因果定义为一种特定类型的_路径特定_效应。

要处理_过度决定_，让 _B_，_S_ 和 _W_ 保持相同的含义。我们的设置和方程将是：

* B=1
* S=1
* W=max(B,S)

图表与上文中显示的[图 4](https://plato.stanford.edu/entries/causal-models/#fig4)相同。我们再次想要展示 S=1 是 W=1 的一个实际原因。条件 AC(1)和 AC(2)显然被满足。对于 AC(3)，我们选择 X={B,S}和 Z=∅。对于条件 AC(3a)，我们选择我们的备选设置 X=x′，B=0 和 S=0。再次，反事实 S=0\&B=0□→W=0 成立。现在，对于 AC(3b)，我们必须展示 X={B,S}是最小的。很容易检查到仅{B}不会满足 AC(3a)。无论我们取 Z=∅还是 Z={S}，改变 B 为 0（也许同时将 S 设为 1）都不会改变 W 的值。类似的论证表明仅{S}也不会满足 AC(3a)。关键思想在于 S 是一个需要改变以改变 W 值的最小变量集的成员。

尽管取得了这些成功，迄今为止发展的实际因果分析并没有完美地捕捉到我们在每种情况下的先验直觉。一些作者追求的策略之一是在变量的_默认_和_异常_值之间，或者_正常_和_异常_条件之间引入一些区别。例如，参见 Hall (2007), Halpern (2008; 2016: 第 3 章), Halpern & Hitchcock (2015), Hitchcock (2007), 以及 Menzies (2004)。Blanchard & Schaffer (2017) 提出了反对这种方法的论点。Glymour 等人 (2010) 对试图分析实际因果的项目提出了许多问题。

## 4. 概率因果模型

在这一部分，我们将讨论在某种程度上融入概率的因果模型。概率可以用来表示我们对特定情况下未观察变量的值或者人群中变量值的分布的不确定性。我们经常关注的是从变量值的概率分布中（也许结合背景假设和其他观察）可以推断出系统因果结构的某些特征。例如，我们可能知道一组变量 V 上的概率分布，并想知道哪些关于 V 中变量的因果结构与该分布兼容。在现实科学案例中，我们从未直接观察到一组变量上的真实概率分布 P。相反，我们观察到的是有限数据，当样本量足够大且观测协议设计良好时，这些数据会近似于真实概率。我们将不在这里讨论这些重要的实际问题。相反，我们的重点将放在从概率中可能推断出什么，原则上而非实践上。我们还将考虑将概率因果模型应用于决策理论和反事实推理。

### 4.1 具有随机误差的结构方程模型

我们可以通过对外生变量进行概率分布来将概率引入 SEM 中。

设 V={X1,X2,…,Xn} 为一组内生变量，而 U={U1,U2,…,Un} 为相应的外生变量集合。假设每个内生变量 Xi 都是其在 V 中的父变量和 Ui 的函数，即：

因果模型：Xi=fi(PA(Xi),Ui)。

作为一个一般规则，我们对这个结构方程模型的图形表示只包括内生变量 V，并且我们使用 PA(Xi)来表示 Xi 的内生父节点的集合。Ui 有时被称为 Xi 的误差变量：它负责 Xi 的实际值与仅基于 PA(Xi)预测值之间的任何差异。我们可以将 Ui 看作是包含了 Xi 的所有未包含在 V 中的原因。假设每个内生变量都有一个误差变量是无害的。必要时，Ui 可以是一个变量向量。例如，如果 Y1、Y2 和 Y3 都是 Xi 的原因，但未包含在 V 中，我们可以让 Ui=⟨Y1,Y2,Y3⟩。此外，误差变量不必是不同的，也不必彼此独立。

假设方程系统是无环的，对外生变量 U1, U2,… ,Un 赋值将唯一确定模型中所有变量的值。然后，如果我们有一个概率分布 P′ 关于 U 中变量的值，这将导致在 V 上唯一的概率分布 P。

### 4.2 马尔可夫条件

假设我们有一个包含内生变量 V、外生变量 U、概率分布 P（如前一节所述）以及代表 V 上因果结构的 DAG G 的 SEM。Pearl 和 Verma（1991）证明，如果在 P 中误差变量 Ui 在概率上是独立的，那么 V 上的概率分布将满足_马尔可夫条件_（MC）关于 G。当 G 是一个 DAG 时，马尔可夫条件有几种等价的表述（Pearl 1988）：

|（MCScreening\_off）|对于 V 中的每个变量_X_，以及变量集合 Y⊆V∖DE(X)，P(X∣PA(X)\&Y)=P(X∣PA(X))。|

\| --- | --- |

\| (MCFactorization) | 让 V={X1,X2,…,Xn}。那么 P(X1,X2,…,Xn)=∏iP(Xi∣PA(Xi))。 |

\| (MC_d_-separation) | 让 X,Y∈V,Z⊆V∖{X,Y}。那么如果 Z _d_-分离 _X_ 和 _Y_ 在 G 中（下面解释），则 P(X,Y∣Z)=P(X∣Z)×P(Y∣Z)。|

让我们花点时间解释这些表述。

MCScreening\_off 表示，变量 _X_ 的父母从除了 _X_ 的后代之外的所有其他变量中筛选出来。在已知是 _X_ 的父母的变量的值的情况下，_Y_ 中的变量的值（其中不包括 _X_ 的后代）对 _X_ 取任何特定值的概率不会再产生影响。

MCFactorization 告诉我们，一旦我们知道每个变量在给定其父母的条件概率分布，即 P(Xi∣PA(Xi))，我们就可以计算所有变量的完整联合分布。相对容易看出，MCFactorization 是由 MCScreening\_off 推导出来的。由于 G 是无环的，我们可以重新标记变量的下标，使它们按照从“早”到“晚”的顺序排列，只有较早的变量是较晚变量的祖先。根据概率演算，得出 P(X1,X2,…,Xn)=P(X1)×P(X2∣X1)×…×P(Xn∣X1,X2,…,Xn−1)（这是全概率定理的一个版本）。对于每个项 P(Xi∣X1,X2,…,Xi−1)，我们的排序确保 Xi 的所有父母都将包含在右侧，而没有一个后代会包含在其中。MCScreening\_off 随后告诉我们，我们可以消除右侧的所有项，除了 Xi 的父母。

MC_d_-separation 引入了_d_-分离的图形概念。如上所述，从_X_到_Y_的路径是一系列变量⟨X=X1,…,Xk=Y⟩，对于每个 Xi，Xi+1，G 中要么从 Xi 到 Xi+1 有箭头，要么从 Xi+1 到 Xi 有箭头。变量 Xi，1\<i\<k，如果路径上从 Xi−1 到 Xi 和从 Xi+1 到 Xi 都有箭头，那么他是路径上的一个_碰撞器_。换句话说，如果箭头汇聚于路径中的 Xi，则 Xi 是一个碰撞器。设 X、Y 和 Z 是 V 的不相交子集。Z_d_-分离 X 和 Y，只要从 X 中的一个变量到 Y 中的一个变量的每条路径⟨X1,…,Xk⟩都包含至少一个变量 Xi，使得要么：(i) Xi 是一个碰撞器，并且 Xi 的后代（包括 Xi 本身）都不在 Z 中；或者(ii) Xi 不是一个碰撞器，并且 Xi 在 Z 中。满足此条件的任何路径被称为被 Z_阻塞_。如果 Z 不_d_-分离 X 和 Y，则 X 和 Y 被 Z_d-连接_。

请注意，MC 提供了变量在给定其他变量条件下概率独立的充分条件，但没有必要条件。

这里有一些插图：

![diagram T has an arrow pointing north to W; W has a long arrow pointing northeast to Z; W also has an arrow pointing northwest to X; X has an arrow pointing northwest to Y](https://plato.stanford.edu/entries/causal-models/fig6.svg)

图 6

在[图 6](https://plato.stanford.edu/entries/causal-models/#fig6)，MC 意味着_X_将_Y_与所有其他变量隔离开来，_W_将_Z_与所有其他变量隔离开来。这最容易从 MCScreening\off 中看出。_W_还将_T_与所有其他变量隔离开来，这最容易从 MC_d\-separation 中看出。_T_不一定将_Y_与_Z_隔离开来（或者实际上是任何东西与任何东西隔离开来）。

![图 X 有一个指向东北的箭头指向 Y，Z 有一个指向同一个 Y 的西北箭头](https://plato.stanford.edu/entries/causal-models/fig7.svg)

图 7

在[图 7](https://plato.stanford.edu/entries/causal-models/#fig7)中，MC 意味着_X_和_Z_将无条件独立，但不意味着它们在给定_Y_的条件下会独立。这最容易从 MC_d\-separation 中看出。

让_Vi_和_Vj_是 V 中的两个不同变量，对应的外生误差变量为_Ui_和_Uj_，代表了被排除在 V 之外的_Vi_和_Vj_的原因。假设_Vi_和_Vj_至少有一个被排除在 V 之外的共同原因。在这种情况下，我们不会期望_Ui_和_Uj_在概率上独立，Pearl 和 Verma（1991）的定理也不适用。在这种情况下，V 中变量之间的因果关系将不能适当地由 DAG 表示，而需要一个带有双向箭头连接_Vi_和_Vj_的无环有向混合图（ADMG）。我们将在下文的[4.6 节](https://plato.stanford.edu/entries/causal-models/#LateCommCaus)中更详细地讨论这种情况。

MC 不应该适用于任意变量集合 V，即使 DAG G 准确表示这些变量之间的因果关系。例如，(MC) 在以下情况通常会失败：

1. 在 EPR（爱因斯坦-波多尔斯基-罗森）设置中，我们有两个粒子处于纠缠态。如果 _X_ 表示对一个粒子的自旋测量，_Y_ 表示对另一个粒子（在同一方向上）的自旋测量，则 _X_ 和 _Y_ 是完全反相关的。（一个粒子的自旋向上，只有在另一个粒子的自旋向下时才会出现。）这些测量可以在彼此足够远的地方进行，以至于一个结果不可能因果影响另一个结果。然而，可以证明没有（局部的）共同原因 _Z_ 能够控制这两个测量结果。
2. 在 V 中的变量没有适当地区分。例如，假设 _X_、_Y_ 和 _Z_ 是概率上独立且因果无关的变量。现在定义 U=X+Y 和 W=Y+Z，并令 V={U,W}。那么 _U_ 和 _W_ 将在概率上存在依赖关系，即使它们之间没有因果关系。
3. 如果变量过于粗粒度，MC 可能会失败。假设 _X_、_Y_ 和 _Z_ 是定量变量。 _Z_ 是 _X_ 和 _Y_ 的共同原因，而 _X_ 和 _Y_ 都不会导致另一个。假设我们用一个更粗糙的变量 Z′ 替换 _Z_，只指示 _Z_ 是高还是低。那么我们不会期望 Z′ 会将 _X_ 从 _Y_ 中隔离开。 _X_ 的值很可能包含有关 _Z_ 值的信息，超出 Z′ 所提供的信息，这可能会影响 _Y_ 的概率。

Both SGS (2000) and Pearl (2009) contain statements of a principle called the _Causal Markov Condition_ (CMC). The statements are in fact quite different from one another. In Pearl’s formulation, (CMC) is just a statement of the mathematical theorem described above: If each variable in V is a deterministic product of its parents in V, together with an error term; and the errors are probabilistically independent of each other; then the probability distribution on V will satisfy (MC) with respect to the DAG G representing the functional dependence relations among the variables in V. Pearl interprets this result in the following way: Macroscopic systems, he believes, are deterministic. In practice, however, we never have access to all of the causally relevant variables affecting a macroscopic system. But if we include enough variables in our model so that the excluded variables are probabilistically independent of one another, then our model will satisfy the MC, and we will have a powerful set of analytic tools for studying the system. Thus MC characterizes a point at which we have constructed a useful approximation of the complete system.

In SGS (2000), the (CMC) has more the status of an empirical posit. If V is set of macroscopic variables that are well-chosen, meaning that they are free from the sorts of defects described above; G is a DAG representing the causal structure on V; and P is the empirical probability distribution resulting from this causal structure; then P can be expected to satisfy MC relative to G. They defend this assumption in (at least) two ways:

1. 从经验上看，似乎有很多系统实际上满足因果模型。
2. 实际上用于检测因果关系的许多方法都含蓄地假定了因果模型。特别是，随机试验的使用假定了因果模型的一个特例。假设一个实验者随机确定哪些受试者将接受药物治疗（D=1），哪些将接受安慰剂（D=0），并且在这种方案下，治疗与康复存在概率相关性（R）。随机化的效果是消除_D_的所有父节点，因此因果模型告诉我们，如果_R_不是_D_的后代，则_R_和_D_应该在概率上独立。如果我们不做出这个假设，那么我们如何能从实验中推断出_D_是_R_的原因呢？

Cartwright（1993 年，2007 年：第 8 章）认为 MC 不一定适用于真正不确定的系统。Hausman 和 Woodward（1999 年，2004 年）试图为不确定系统辩护。

一个包括 DAG 和满足 MC 的概率分布的因果模型被称为_因果贝叶斯网络_。

### 4.3 最小性和忠实性条件

MC 确定了条件概率独立的充分条件，但并非必要条件。因此，MC 本身永远不能蕴涵两个变量是有条件或无条件依赖的。最小性和忠实性条件是给出概率独立的必要条件的两个条件。（这是使用 Spirtes 等人的术语（SGS 2000）。Pearl（2009）包含了一个略有不同于此处描述的“最小性条件”）。

(i) _最小性条件_。假设变量集合 V 上的 DAG G 满足概率分布 P 的 MC。最小性条件断言，G 在 V 上的任何子图也不能满足 P 的马尔可夫条件。举例说明，考虑变量集合{X,Y}，假设从_X_到_Y_有一个箭头，并且_X_和_Y_在概率上是相互独立的。这个图会满足 P 的 MC：MC 规定的任何独立关系都不缺失（事实上，MC 不规定任何独立关系）。但这个图会违反 P 的最小性条件，因为去掉从_X_到_Y_的箭头的子图也会满足 MC。最小性条件暗示，如果从_X_到_Y_有一个箭头，那么_X_对_Y_造成概率上的差异，条件是_Y_的其他父节点。换句话说，如果 Z=PA(Y)∖{X}，存在 z，y，x，x'，使得 P(Y=y∣X=x\&Z=z)≠P(Y=y∣X=x'\&Z=z)。

(ii) _忠实性条件_。忠实性条件（FC）是马尔可夫条件的逆：它表示 V 中变量之间存在的所有（条件和无条件的）概率独立性都是 MC 所_要求_的。例如，假设 V={X,Y,Z}。还假设_X_和_Z_在无条件下是相互独立的，但在给定_Y_的条件下是相关的。（另外两对变量在有条件和无条件下都是相关的。）在[图 8](https://plato.stanford.edu/entries/causal-models/#fig8)中显示的图与该分布不满足 FC（口语上，该图对该分布不忠实）。当应用于图 8 的图时，MC 并不意味着_X_和_Z_的独立。这可以通过注意到_X_和_Z_是_d\-连接的（通过空集）来看出：路径 X→Z 和 X→Y→Z 都没有被（空集）阻断。相比之下，在[图 7](https://plato.stanford.edu/entries/causal-models/#fig7)中显示的图对所描述的分布是忠实的。请注意，图 8 满足了对该分布的最小性条件；没有子图满足对所描述分布的 MC。事实上，FC 比最小性条件严格。

![diagram X has an arrow pointing northeast to Y and another arrow pointing east to Z; Y has an arrow pointing southeast to Z](https://plato.stanford.edu/entries/causal-models/fig8.svg)

图 8

这里有一些其他例子：在上图 6 中，存在路径 W→X→Y；FC 意味着 _W_ 和 _Y_ 应该在概率上相关。在上图 7 中，FC 意味着 _X_ 和 _Z_ 应该在 _Y_ 的条件下相关。

如果因果模型中的概率参数恰到好处，FC 可能会失败。例如，在上图 8 中，_X_ 影响 _Z_ 通过两条不同的有向路径。如果一条路径的影响恰好抵消了另一条路径的影响，那么 _X_ 和 _Z_ 将在概率上独立。如果基础 SEM 是线性的，Spirtes 等人 (SGS 2000: 定理 3.2) 证明了违反忠诚性的参数集具有勒贝格测度为 0。尽管如此，导致违反 FC 的参数值是 _可能的_，因此 FC 似乎不太可能作为因果关系和概率之间连接的形而上或概念约束。相反，它是一个 _方法论_ 原则：在 {X,Y,Z} 上给定一个分布，其中 _X_ 和 _Z_ 是独立的，我们应该更倾向于上图 7 中描述的因果结构，而不是图 8 中的结构。这并不是因为图 8 被分布明确排除，而是因为假设一个 _暗示_ _X_ 和 _Z_ 独立的因果结构比假设一个仅仅与独立性 _一致_ 的因果结构更可取。有关 FC 角色的全面讨论，请参阅张和 Spirtes 2016。

FC 的违反原则通常在原则上是可以检测到的。例如，假设真实的因果结构如[图 7](https://plato.stanford.edu/entries/causal-models/#fig7)所示，并且在_X_、_Y_和_Z_上的概率分布展现出 MC 所需的所有条件独立关系。此外，假设在给定_Y_的条件下，_X_和_Z_是独立的。这种条件独立关系不是由 MC 蕴含的，因此构成了 FC 的违反。事实证明，没有一个有向无环图能够忠实地反映这个概率分布。这提示我们存在 FC 的违反。虽然我们无法推断出正确的因果结构，但至少在这种情况下我们会避免推断出错误的因果结构。有关详细信息，请参阅 Steel 2006，Zhang & Spirtes 2008 和 Zhang 2013b。

研究人员已经探讨了采用比 FC 更弱的各种假设的后果；例如 Ramsey 等人 2006 年，Spirtes & Zhang 2014 年和 Zhalama 等人 2016 年。

### 4.4 因果结构的可识别性

如果我们有一组变量 V，并且知道在 V 上的概率分布 P，我们可以推断出关于 V 上的因果结构吗？这个认识论问题与是否可能将因果关系归约为概率的形而上问题密切相关（例如，Reichenbach 1956 年和 Suppes 1970 年提出的）。

珍珠（1988 年：第 3 章）证明了以下定理：

（**时间顺序的可识别性**）

如果

1. V 中的变量是时间索引的，只有较早的变量才能导致较晚的变量;
2. 概率 P 为 V 中变量的每种可能取值分配了正概率；
3. 没有潜变量，因此正确的因果图 G 是一个有向无环图（DAG）；
4. 并且概率测度 P 满足对于 G 的马尔可夫和最小条件；

那么就有可能根据 P 唯一地确定 G。

这相对容易理解。对于每个变量 Xi，它的父节点必须来自于时间指数较低的变量中，称之为 X1,…,Xi−1。这个组中任何不是 Xi 的父节点的变量将是 Xi 的非后代；因此它们将被 Xi 的父节点（从 MCScreening\_off）屏蔽。因此，我们可以从分布 P(Xi∣X1,…,Xi−1) 开始，然后剔除右侧不影响 Xi 概率分布的任何变量。根据最小性条件，我们知道被剔除的变量不是 Xi 的父节点。剩下的变量是 G 中 Xi 的父节点。

如果我们没有关于时间顺序的信息，或者其他限制变量 V 中可能的因果结构的实质性假设，那么仅凭概率可能并不总是能够确定因果结构。一般来说，给定变量 V 上的概率分布 P，只能够确定一个_马尔可夫等价类_的因果结构。这将是所有在 V 上的 DAGs 的集合，这些 DAGs（与 MC 一起）暗示了 P 中包含的所有条件独立关系。换句话说，这将是所有 DAGs G 的集合，使得 P 对于 G 满足 MC 和 FC。SGS（2000: 84–85）描述的 PC 算法是一种算法，它为具有非空马尔可夫等价类的任何概率分布生成马尔可夫等价类。

考虑涉及三个变量 {X,Y,Z} 的两个简单示例。假设我们的概率分布具有以下特性：

* _X_ 和 _Y_ 在无条件下是相关的，在给定 _Z_ 的条件下

_Y_ 和 _Z_ 在 _X_ 的条件下是无条件依赖的

* _X_ 和 _Z_ 在 _Y_ 的条件下是无条件依赖的

然后，马尔可夫等价类为：

X→Y→ZX←Y←ZX←Y→Z

我们无法从概率分布中确定，连同 MC 和 FC，这些结构中哪个是正确的。

另一方面，假设概率分布如下：

* _X_ 和 _Y_ 在无条件下是相关的，并且在 _Z_ 的条件下是相关的
* _Y_ 和 _Z_ 在无条件下是相关的，并且在 _X_ 的条件下是相关的
* _X_ 和 _Z_ 在无条件下是独立的，但在条件 _Y_ 下是相关的

那么马尔可夫等价类是：

X→Y←Z

这是唯一的 DAG，相对于该 DAG，给定的概率分布满足 MC 和 FC。

### 4.5 通过对功能形式的假设进行可识别性

假设我们有一个具有内生变量 V 和外生变量 U 的 SEM，其中 V 中的每个变量都由以下形式的方程确定：

Xi=fi(PA(Xi),Ui)。

假设，此外，我们在 U 上有一个概率分布 P'，其中所有的 Uis 都是独立的。这将导致在 V 上满足相对于 V 上正确因果 DAG 的概率分布 P。换句话说，我们的概率 SEM 将生成一个唯一的因果贝叶斯网络。前一节描述的方法试图从概率依赖和独立关系中推断出潜在的图 G。这些方法最多只能识别马尔可夫等价类。通过利用有关概率分布 P 的额外信息，我们能做得更好吗？

有好消息也有坏消息。首先是坏消息。如果 V 中的变量是离散的，并且我们对 fi 函数的形式没有任何假设，那么我们对 SEM 推断的信息就不会超过图所属的 Markov 等价性（Meek 1995）。

更多坏消息：如果 V 中的变量是连续的，最简单的假设，也是研究得最详细的假设，是方程是_线性_的，带有_高斯_（正态，或钟形）误差。也就是：

* Xi=∑jcjXj+Ui，其中 _j_ 取值为 PA(Xi) 的索引，cjs 为常数
* Pr′ 为每个 Ui 分配一个高斯分布

事实证明，在这些假设下，我们无法比从概率依赖和独立性中推断出 V 上的因果图的马尔可夫等价类更好（Geiger＆Pearl 1988）。

现在是好消息。有相当一般的假设，使我们能够推断出更多信息。以下是一些相当简单的情况：

(**LiNGaM**) (Shimizu et al. 2006)

如果：

1. V 中的变量是连续的；
2. fi 函数是线性的；
3. 误差变量 Ui 上的概率分布不是高斯分布（或至多一个是高斯分布）；
4. 误差变量 Ui 在 P' 中是概率上独立的；

然后，对于 V 上的诱导概率分布 P，正确的 DAG 可以被唯一确定。

（**非线性可加**）（Hoyer 等人，2009）

几乎所有以下形式的函数都允许通过在 V 上诱导的概率分布 P 来唯一确定正确的 DAG：

1. 函数 fi 是非线性的，误差是可加的（因此 Xi=fi(PA(Xi))+Ui，其中 fi 是非线性的）;
2. 错误变量 Ui 在 P' 中是概率上独立的;

事实上, 这种情况可以被广泛推广:

(**后非线性**) (Zhang & Hyvärinen 2009)

除了可以完全指定的五种特定情况外，所有以下形式的函数都允许通过在 V 上诱导的概率分布 P 来唯一确定 V 上的正确 DAG。

1. 这些函数的形式为 Xi=gi(fi(PA(Xi))+Ui) ，其中 fi 和 gi 是非线性的，而 gi 是可逆的；
2. 误差变量 Ui 在 P′ 中是概率上独立的；

参见 Peters 等人（2017 年）的讨论。

虽然这些结果背后有特定的假设，但它们仍然是引人注目的。例如，它们意味着（根据定理的假设）仅仅知道两个变量_X_和_Y_上的概率分布，我们就可以推断_X_是引起_Y_还是_Y_引起_X_。

### 4.6 潜在共同原因

到目前为止，讨论集中在变量 V 没有潜在共同原因的情况，且误差变量 Ui 可以被期望为概率独立的情况。正如我们在[Section 2.3](https://plato.stanford.edu/entries/causal-models/#Grap)中所指出的，我们用双头箭头表示潜在共同原因。例如，无环有向混合图中的[Figure 9](https://plato.stanford.edu/entries/causal-models/#fig9)表示 _X_ 和 _Z_ 的潜在共同原因。更一般地，我们可以使用类似于图 9 的 ADMG 来表示 _X_ 和 _Z_ 的误差变量不是概率独立的。

![图表 X 有一个指向东方的箭头指向 Y，Y 又有一个指向东方的箭头指向 Z；X 和 Z 之间由一个弯曲的双头箭头连接](https://plato.stanford.edu/entries/causal-models/fig9.svg)

图 9

如果存在潜在的共同原因，我们期望如果我们以天真的方式应用它们，MCScreening\off 和 MCFactorization 将会失败。在 [图 9](https://plato.stanford.edu/entries/causal-models/#fig9) 中，_Y_ 是图中显示的 _Z_ 的唯一父节点，如果我们尝试应用 MCScreening\off，它告诉我们 _Y_ 应该将 _X_ 屏蔽掉 _Z_。然而，由于潜在的共同原因，即使在我们对 _Y_ 进行条件设定时，我们期望 _X_ 和 _Z_ 也会相关。问题在于图中缺少 _Z_ 的一个相关父节点，即被省略的共同原因。然而，假设在 {L,X,Y,Z} 上的概率分布满足包括 _L_ 作为 _X_ 和 _Z_ 的共同原因的 DAG 的 MC。那么结果表明，概率分布仍然会满足相对于图 9 的 ADMG 的 MC_d\-separation。包含 ADMG 和满足 MC_d\-separation 的概率分布的因果模型被称为_半马尔可夫因果模型_（SMCM）。

如果我们允许正确的因果图可能是 ADMG，我们仍然可以应用 MC_d_-separation，并询问哪些图暗示相同的条件独立关系集。马尔可夫等价类将比我们不考虑潜在变量时更大。例如，假设在 {X,Y,Z} 上的概率分布具有以下特征：

* _X_ 和 _Y_ 在无条件下是相关的，在给定 _Z_ 的条件下
* _Y_ 和 _Z_ 在无条件下是相关的，在给定 _X_ 的条件下

_X_ 和 _Z_ 在无条件下是独立的，但在条件 _Y_ 下是相关的

我们在[Section 4.4](https://plato.stanford.edu/entries/causal-models/#IdenCausStru)中看到，唯一暗示这些（非）依赖关系的有向无环图是：

X→Y←Z

但是，如果我们允许潜在的共同原因的可能性，将会有额外的 ADMGs 也暗示着这些（不）依赖关系。例如，这个结构

X↔Y↔Z

也属于马尔可夫等价类，还有其他一些。

潜变量带来了进一步的复杂性。与误差变量 Ui 在概率上独立的情况不同，具有相关误差项的 SEM 可能暗示概率约束，除了条件（独立）关系之外，即使在没有关于功能形式的进一步假设的情况下。这意味着我们可以通过不同类型的概率约束排除马尔可夫等价类中的一些 ADMG。

### 4.7 干预

一个条件概率，比如 P(Y=y∣X=x) 给出了当观察到 _X_ 取值为 _x_ 时，_Y_ 将取值 _y_ 的概率。然而，我们通常对于预测当我们进行干预设置 _X_ 的值为特定值 _x_ 时，_Y_ 的取值感兴趣。Pearl (2009) 使用 P(Y=y∣do(X=x)) 来描述这个概率。这种表示方法有误导性，因为 do(X=x) 不是原始概率空间中的一个事件。更准确的写法可能是 Pdo(X=x)(Y=y)，但在这里我们将使用 Pearl 的表示法。观察和干预之间有什么区别？当我们仅仅观察一个变量的取值时，我们是在了解这个变量在正常方式下被引起时的取值，就像我们因果模型中所表示的那样。关于这个变量取值的信息也会提供给我们关于它的原因以及这些原因的其他影响的信息。然而，当我们进行干预时，我们会覆盖正常的因果结构，强制一个变量取一个值，这个值可能在系统被放置不管的情况下不会取到。从图形上看，我们可以通过消除指向被干预变量的箭头来表示这种干预的效果。这样的干预有时被描述为“打破”那些箭头。正如我们在第 [3.1](https://plato.stanford.edu/entries/causal-models/#IntrSEMs) 节中看到的，在 SEM 的背景下，我们通过用一个新方程指定 X=x 来代替 _X_ 的方程来表示将 _X_ 设置为 _x_ 的干预。

正如我们在 [第 3.2](https://plato.stanford.edu/entries/causal-models/#StruCoun) 节中看到的，干预和反事实之间存在着密切的联系；特别是，结构反事实的前提被认为是通过干预实现的。然而，Pearl (2009) 区分了由 _do_ 运算符表示的干预与反事实。前者以陈述语气理解；它们涉及实际执行的干预。反事实则是以虚拟语气，涉及假设性的干预。这导致了普通干预和反事实之间的一个重要认识论差异：它们在与变量值的观察互动的方式上表现不同。在干预的情况下，我们关注评估诸如

P(Y=y∣X=x,do(Z=z))。

我们假设干预 do(Z=z) 正在实际世界中进行，并且我们观察到其他变量取值 (X=x) 在干预发生的同一个世界中。在反事实情况下，我们观察到实际世界中各种变量的值，在那里没有干预。然后我们问，如果干预 _已经_ 进行，会发生什么。我们观察到的变量值在干预发生的假设世界中可能会取 _不同_ 的值。这里是一个简单的例子来说明这种差异。假设我们有一个因果模型，其中用药物治疗导致疾病康复。可能还有其他变量和它们之间的因果关系。

干预：

* 对一名特定患者进行了药物治疗干预，观察到她没有恢复。
* 问题：给定干预和观察到的证据，她康复的概率是多少？
* 回答：零，显然。

反事实：

* 观察到一个患者没有从疾病中恢复。
* 问题：她如果接受药物治疗，她会康复的概率是多少？
* 回答：非平凡。答案不一定是零，也不一定是 P(_康复_ | _治疗_)。如果我们知道她实际上接受了治疗，那么我们可以推断如果接受治疗，她就不会康复。但我们不知道她是否接受了治疗。她没有康复这一事实给了我们部分信息：这使得她实际上接受治疗的可能性降低；这也使得她有免疫系统较弱的可能性增加，等等。我们必须利用所有这些信息来确定如果接受治疗，她会康复的概率。

我们将在本节讨论干预措施，并在下面的[4.10 节](https://plato.stanford.edu/entries/causal-models/#Coun)中讨论反事实。

假设我们有一个具有外生变量 U 和内生变量 V 的无环结构方程模型。我们有以下形式的方程式。

Xi=fi(PA(Xi),Ui),

和外生变量 U 上的概率分布 P′。然后在 V 上引起概率分布 P。为了表示将 Xk 设置为 xk 的干预，我们用 Xk=xk 替换 Xk 的方程。现在 P′在 V 上引起了一个新的概率分布 P _（因为外生变量 U 的设置在干预后导致 V 中变量的不同值）。P_是 Pearl 写成 P(∙∣do(Xk=xk))的新概率分布。

但即使我们没有完整的 SEM，我们通常也可以计算干预的效果。假设我们有一个因果模型，其中概率分布 P 满足因果 DAG G 上的变量集 V={X1,X2,…,Xn} 上的 MC。对于思考干预最有用的 MC 版本是 MCFactorization（参见[Section 4.2](https://plato.stanford.edu/entries/causal-models/#MarkCond)），它告诉我们：

P(X1,X2,…,Xn)=∏iP(Xi∣PA(Xi))。

现在假设我们通过将 Xk 的值设置为 xk 来进行干预。后干预概率 P\* 是通过以下方式改变因式分解的结果：

P∗(X1,X2,…,Xn)=P′(Xk)×∏i≠kP(Xi∣PA(Xi)),

在这里 P′(Xk=xk)=1。形式为 P(Xi∣PA(Xi)) 的条件概率对于 i≠k 保持不变。这与使用 SEM 计算干预结果得到相同结果，当后者可用时。这个结果可以推广到干预强加概率分布 P† 在 V 中某些变量的子集上的情况。为简单起见，让我们重新标记变量，使得 {X1,X2,…,Xk} 是我们进行干预的变量集。然后，后干预概率分布为：

P∗(X1,X2,…,Xn)=P†(X1,X2,…,Xk)×∏k\<i≤nP(Xi∣PA(Xi))。

SGS（2000 年：定理 3.6）的_操纵定理_将这个公式推广到涵盖更广泛类别的干预，包括那些不会打断所有指向被干预变量的箭头的干预。

Pearl（2009 年：第 3 章）发展了一个公理系统，他称之为_do-演算_，用于计算可以应用于具有潜变量的系统的干预后概率，其中 V 上的因果结构由 ADMG（包括双头箭头）而不是 DAG 表示。该系统的公理在\*[do](https://plato.stanford.edu/entries/causal-models/do-calculus.html)\*​[-演算的补充](https://plato.stanford.edu/entries/causal-models/do-calculus.html)中呈现。一个有用的特例是由

_后门准则_。设_X_和_Y_是 V 中的变量，_Z⊆V∖{X,Y}_ ，使得：

1. _Z_的任何成员都不是_X_的后代；
2. 每一条在 _X_ 和 _Y_ 之间以箭头指向 _X_ 结束的路径要么 (a) 包括在 _Z_ 中的一个非共轭节点，要么 (b) 包括在 _Z_ 中没有后代的共轭节点；

那么 P(Y∣do(X),Z)=P(Y∣X,Z)。

也就是说，如果我们能找到一个合适的条件集合 Z，对 _X_ 进行干预所得到的概率将与观察 _X_ 对应的条件概率相同。

### 4.8. 干预主义决策理论

Evidential Decision Theory of the sort developed by Jeffrey (1983), runs into well-known problems in variants of _Newcomb’s problem_ (Nozick 1969). For example, suppose Cheryl believes the following: She periodically suffers from a potassium deficiency. This state produces two effects with high probability: It causes her to eat bananas, which she enjoys; and it causes her to suffer debilitating migraines. On days when she suffers from the potassium deficiency, she has no introspective access to this state. In particular, she is not aware of any banana cravings. Perhaps she rushes to work every morning, grabbing whatever is at hand to eat on her commute. Cheryl’s causal model is represented by the DAG in [Figure 10](https://plato.stanford.edu/entries/causal-models/#fig10).

![diagram with K having an arrow pointing northwest to B and northeast to M](https://plato.stanford.edu/entries/causal-models/fig10.svg)

图 10

K=1 代表钾缺乏，B=1 吃香蕉，而 M=1 偏头痛。她的概率如下：

P(K=1)=.2,P(B=1∣K=1)=.9,P(B=1∣K=0)=.1,P(M=1∣K=1)=.9,P(M=1∣K=0)=.1

她对世界状态的效用定义为 w≡{K=k,B=b,M=m} 是 U(w)=b−20m。也就是说，她吃香蕉会获得一单位的效用，但遭受偏头痛会损失 20 单位。她对钾缺乏没有内在价值。

Cheryl 准备去上班。她应该吃香蕉吗？根据_Evidential Decision Theory_（EDT），Cheryl 应该最大化_Evidential Expected Utility_，其中

EEU(B=b)=∑wP(w∣B=b)U(w)

根据给定的概率，我们可以计算出：

P(M=1∣B=1)≈.65P(M=1∣B=0)≈.12

吃香蕉与偏头痛强相关，因为有共同原因。因此

EEU(B=1)≈−12EEU(B=0)≈−2.4

因此，至少在其最简单的形式下，EDT 建议避免食用香蕉。尽管 Cheryl 喜欢吃香蕉，但它们提供了强有力的证据表明她会患偏头痛。

许多人认为这是个坏建议。吃香蕉并不会_导致_Cheryl 患偏头痛；这只是一种无害的享受。许多作者已经制定了各种版本的_Causal Decision Theory_（CDT），旨在明确纳入因果考虑（例如，Gibbard＆Harper 1978；Joyce 1999；Lewis 1981；Skyrms 1980）。因果模型为 CDT 提供了一个自然的环境，这是 Meek 和 Glymour（1994）提出的一个想法，并由 Hitchcock（2016）、Pearl（2009：第 4 章）和 Stern（2017）发展而来。其核心思想是，代理人应将其行动视为一种_干预_。这意味着 Cheryl 应该最大化她的_Causal Expected Utility_：

CEU(B=b)=∑wP(w∣do(B=b))U(w)

现在我们可以计算

P(M=1∣do(B=1))=.26P(M=1∣do(B=0))=.26

因果模型

CEU(B=1)=−4.2CEU(B=0)=−5.2

这导致了一个合理的结果，即吃香蕉会给 Cheryl 提供一个免费的效用单位。通过干预，Cheryl 打破了从 _K_ 到 _B_ 的箭头，并破坏了吃香蕉和偏头痛之间的相关性。

更一般地，可以使用前一节中描述的计算干预效应的方法来计算计算因果期望效用所需的概率。Stern (2017)扩展了这种方法，允许将信任分配到多个因果模型的代理。Hitchcock (2016)展示了如何利用在下文[4.10 节](https://plato.stanford.edu/entries/causal-models/#Coun)中更详细讨论的干预和反事实之间的区别，可以用来回避一些声称违背 CDT 的反例。

关于 EDT 和 CDT 之间的辩论还有很多值得讨论的地方。例如，如果 Cheryl 知道自己正在进行干预，那么她不会认为自己被[图 10](https://plato.stanford.edu/entries/causal-models/#fig10)中的因果结构准确描述。相反，她会认为自己实现了一个从 _K_ 到 _B_ 的箭头被移除的因果结构。在这种因果结构中，如果 P 满足 MC，我们将有 P(w∣B=b)=P(w∣do(B=b))，而 EDT 和 CDT 之间的差异将消失。如果有一个有原则的理由，使得一个深思熟虑的代理人总是相信自己正在进行干预，那么 EDT 将产生与 CDT 相同的规范建议，并且将避免像上面描述的那种反例。Price 对 EDT 的辩护 (Price 1986) 可能可以沿着这些线重新构建。因此，结论不一定是 CDT 在规范上是正确的，而是因果模型可能有助于澄清与因果相关的决策理论问题。

### 4.9 通过干预进行因果发现

在前一节中，我们讨论了如何利用对因果图 G 结构的知识（或假设）来推断干预结果。在本节中，我们探讨了相反的问题。如果我们可以对变量进行干预并观察干预后的概率分布，那么我们可以推断出关于潜在因果结构的什么信息？这个主题在 Eberhardt 及其合作者的研究中得到了广泛探讨。（例如，参见 Eberhardt & Scheines 2007 和 Hyttinen 等人 2013a。）毫不奇怪，如果我们可以进行干预，我们就可以更多地了解因果结构，而不仅仅是进行被动观察。然而，我们能够推断出多少取决于我们可以进行何种干预，以及我们做出了什么样的背景假设。

如果没有潜在的共同原因，使得在 V 上的真实因果结构由一个 DAG G 表示，那么总是可以通过干预来发现完整的因果结构。如果我们一次只能对一个变量进行干预，那么在因果结构被唯一确定之前，我们可能需要分别对除一个变量之外的所有变量进行干预。如果我们可以同时对多个变量进行干预，我们可以更快地发现真实的因果结构。

如果存在潜在的共同原因，使得在 V 上的真实因果结构由一个 ADMG 表示，那么可能无法仅通过单变量干预来发现真实的因果结构。（尽管在基础结构方程模型中的函数全为线性时可以做到这一点。）然而，如果我们可以同时对多个变量进行干预，那么就有可能发现真实的因果图。

Eberhardt 和合作者还探讨了使用_软_干预进行因果发现。软干预会影响变量的值，而不会打破指向该变量的箭头。例如，假设我们想知道增加假释者收入是否会导致再犯率下降。我们随机将受试者分为治疗组和对照组，并向治疗组的人定期提供现金支付。这并不是对收入_本身_的干预，因为收入仍会受到通常因素的影响：储蓄和投资、职业培训、家庭成员的帮助等等。软干预有助于因果推断，因为它们会产生碰撞器，正如我们所见，碰撞器具有独特的概率特征。令人费解的是，这意味着如果我们想确定_X_是否导致_Y_，最好对_Y_进行软干预（而不是_X_），以查看是否可以创建一个碰撞器 I→Y←X（其中_I_是干预）。软干预与_工具变量_密切相关。如果没有潜在的共同原因，我们可以使用软干预推断出真实的因果结构。实际上，如果我们可以同时对每个变量进行干预，我们可以从这一个干预中确定正确的因果结构。但是，如果存在潜在的共同原因，通常无法使用软干预发现完整的因果结构。（尽管如果我们假设是线性的话是可以做到的。）

### 4.10 反事实的

[第 3.3 节](https://plato.stanford.edu/entries/causal-models/#ActuCaus)讨论了在确定性因果模型背景下的反事实。引入概率会增加许多复杂性。特别是，我们现在可以有意义地谈论一个反事实成立的概率。反事实在因果模型的_潜在结果_框架中发挥着核心作用，这一框架是由奈曼（1923 年）开创，并由鲁宾（1974 年）和罗宾斯（1986 年）等人发展而来。

潜在结果框架中的反事实与 Lewis（1973b）框架中的反事实以不同方式与概率相互作用。假设 Ted 接触了石棉并患上了肺癌。我们对这个反事实感兴趣：“如果 Ted 没有接触石棉，他就不会患上肺癌”。假设癌症发展的过程是真正不确定的。那么，如果说如果 Ted 没有接触石棉，他肯定会患上肺癌是错误的；同样，说他肯定不会患上肺癌也是错误的。在这种情况下，Lewis 会说反事实“如果 Ted 没有接触石棉，他就不会患上肺癌”是明确_错误_的。因此，这个反事实成立的客观概率为零。另一方面，一个具有客观概率_在结果中_的反事实可能是真实的：“如果 Ted 没有接触石棉，他患上肺癌的客观几率将为 0.06”。相比之下，在潜在结果框架中，概率可以从结果中抽取出来，并应用于整个反事实：反事实“如果 Ted 没有接触石棉，他会患上肺癌”的概率可以为 0.06。

如果我们有一个完整的结构方程模型，我们可以根据观察结果为反事实情况分配概率。让 V={X1,X2,…,Xn} 为一组内生变量， U={U1,U2,…,Un} 为一组外生变量。我们的结构方程具有以下形式：

Xi=fi(PA(Xi),Ui)

我们在 U 上有一个概率分布 P'，它在 U∪V 上引出一个概率分布 P。假设我们观察到一些变量的值：对于所有的 j∈S⊆{1,…,n}，Xj=xj。现在我们想评估反事实情况“如果 Xk 是 xk，那么 Xl 将是 xl”，其中_k_和_l_可能在 S 中但不一定。我们可以使用以下三个步骤来评估这种反事实的概率：

1. 通过对观察结果进行条件概率更新概率 P，得到一个新的概率分布 P(∙∣∩j∈SXj=xj)。将这个概率函数在 U 上的限制称为 P''。
2. 用 Xk=xk 替换 Xk 的方程。
3. 使用在 U 上的分布 P′′ 以及修改后的方程组来诱导出一个新的概率分布 P\* 在 V 上。 P∗(Xl=xl) 然后是反事实的概率。

这个程序与干预程序的程序不同（见[Section 4.7](https://plato.stanford.edu/entries/causal-models/#Inte)），因为步骤 1 和 2 已经颠倒。我们首先更新概率分布，然后执行干预。这反映了观察告诉我们有关实际世界的事实，即干预并没有（必然）发生。

如果我们没有完整的结构方程模型，通常无法确定反事实的概率，只能设定上限和下限。例如，假设我们相信石棉暴露会导致肺癌，因此我们提出一个简单的有向无环图：

A→L.

假设我们还有类似于 Ted 的人的数据，得出以下概率：

P(L=1∣A=1)=.11,P(L=1∣A=0)=.06.

(我们正在过分简化，并将石棉和肺癌视为二元变量。) 我们观察到 Ted 实际上接触过石棉，并且确实患有肺癌。如果 Ted 没有接触过石棉，他不会患肺癌的概率是多少？Pearl（2009）将这种形式的概率称为_必然性概率_。它通常被称为_因果概率_，尽管格陵兰和罗宾斯（1988）讨论了这种术语存在误导性的原因。这个数量在侵权法中通常很重要。假设 Ted 起诉他的雇主与他的肺癌有关的损害。他必须说服陪审团，他暴露于石棉导致了他的肺癌。美国民事法要求“比不可能性更大”的证明标准，并采用“如果不是这样”或反事实因果关系的定义。因此，Ted 必须说服陪审团，如果他没有接触过石棉，他患肺癌的可能性比不患肺癌的可能性更大。

我们可以将人口分为四类，具体取决于他们的哪些反事实是真实的：

* _doomed_ 个体无论如何都会患肺癌
* _immune_ 个体无论如何都会避免患肺癌
* _sensitive_ 个体只要接触石棉就会患肺癌
* _reverse sensitive_ 个体只有在没有接触石棉的情况下才会患肺癌

最容易将人口分为四类，每个人属于这四种类型之一。但我们不需要假设这个过程是确定性的；每个人可能只有一定的概率属于这四类中的一种。

数学上，这等同于以下内容。让 UL 成为 L 的误差变量。UL 取形如 (u1,u2) 的值，其中每个 ui 为 0 或 1。(1,1) 对应于 _doomed_，(0,0) 对应于 _immune_，(1,0) 对应于 _sensitive_，而 (0,1) 对应于 _reverse_。也就是说，第一个元素告诉我们，如果个体暴露于石棉， _L_ 将取什么值，而第二个元素告诉我们，如果个体没有暴露， _L_ 将取什么值。 _L_ 的方程将是 L=(A×u1)+((1−A)×u2)。

让我们假设误差变量 UL 的分布与石棉暴露 _A_ 是独立的。观察到的肺癌概率与我们的四个反事实类别上的以下概率分布都是兼容的：

P1(注定)=.06,P2(注定)=0,P1(免疫)=.89,P2(免疫)=.83,P1(敏感)=.05,P2(敏感)=.11,P1(相反)=0P2(相反)=.06

更一般地，观察到的概率与任何满足的概率 P'兼容：

P′(注定)+P′(敏感)=P(L∣A)=.11;P′(免疫)+P′(相反)=P(∼L∣A)=.89;P′(注定)+P′(相反)=P(L∣∼A)=.06;P′(免疫)+P′(敏感)=P(∼L∣∼A)=.94.

P1 和 P2 只是最极端的情况。从泰德接触石棉并患上肺癌的事实，我们知道他要么是_敏感_要么是_注定_。感兴趣的反事实只有在他是_敏感_的情况下才成立。因此，根据现有证据，反事实的概率是 P(_敏感_ | _敏感_或_注定_)。然而，使用 P1 得到的条件概率为.45（5/11），而 P2 得到的条件概率为 1。根据我们掌握的信息，我们只能得出必然性的概率在.45 和 1 之间。要更准确地确定概率，我们需要了解误差变量的概率分布。

一个与之密切相关的反事实数量是 Pearl（2009）所称的_充分性概率_。假设特丽莎与泰德不同，没有接触石棉，也没有患肺癌。充分性概率是她如果暴露于石棉会患肺癌的概率。也就是说，充分性概率是指如果原因添加到原本没有原因和结果的情况中，结果会发生的概率。充分性概率与 Sheps（1958）所称的_相对差异_以及 Cheng（1997）所称的_因果力_密切相关。Cheng 的术语反映了这样一个观念，即_C_对于_E_的充分性概率是_C_在_E_缺席的情况下导致_E_发生的能力。与必要性概率的情况类似，如果没有完整的结构方程模型，而只有因果贝叶斯网络或半马尔可夫因果模型，通常只能对充分性概率进行上下界的估计。使用前面例子中的概率，石棉对肺癌的充分性概率将介于 0.05（5/94）和 0.12（11/94）之间。

确定反事实概率，即使是上下界，也是需要大量计算的。Balke 和 Pearl 的双网络方法（Balke 和 Pearl（1994a），（1994b）；Pearl（2009，第 213-215 页））以及 Richardson 和 Robins 的分裂节点方法（Richardson 和 Robins（2016））是两种已提出用于解决这类问题的方法。

## 5. 进一步阅读

本条目中调查的最重要作品是 Pearl 2009 和 Spirtes, Glymour, & Scheines 2000。Pearl 2010，Pearl 等人 2016 年，以及 Pearl & Mackenzie 2018 是 Pearl 计划的三个概述。Pearl 2010 是最简短但技术含量最高的。Pearl & Mackenzie 2018 则是最不技术性的。Scheines 1997 和 Glymour & Cooper 1999 的“Introduction”是 SGS 计划的可访问介绍。Eberhardt 2009，Hausman 1999，Glymour 2009 和 Hitchcock 2009 是简短概述，涵盖了本条目中提到的一些主题。

在[因果关系和可操纵性](https://plato.stanford.edu/entries/causation-mani/)条目中包含了对干预的广泛讨论，以及对因果模型的一些讨论。

Halpern (2016)涉及了[第 3 节](https://plato.stanford.edu/entries/causal-models/#DeteStruEquaMode)中的许多主题。另请参阅[因果关系的反事实理论](https://plato.stanford.edu/entries/causation-counterfactual/)的条目。

[概率因果关系](https://plato.stanford.edu/entries/causation-probabilistic/)条目与本条目存在一些重叠。本条目的[第 4 节](https://plato.stanford.edu/entries/causal-models/#ProbCausMode)中的一些材料也出现在该条目的第 3 节中。该条目还包含了一些关于概率因果模型与早期概率因果理论之间关系的讨论。

Eberhardt 2017 是一份简短的调查报告，清晰介绍了[第 4.2 节](https://plato.stanford.edu/entries/causal-models/#MarkCond)到 4.6 节以及第[4.9 节](https://plato.stanford.edu/entries/causal-models/#CausDiscInte)涵盖的许多主题。Spirtes 和 Zhang 2016 是一份更长、更技术性的概述，涵盖了很多相同的内容。它特别详细地涵盖了[第 4.5 节](https://plato.stanford.edu/entries/causal-models/#IdenAssuAbouFuncForm)中提出的问题。

在[决策理论](https://plato.stanford.edu/entries/decision-theory/)和[因果决策理论](https://plato.stanford.edu/entries/decision-causal/)条目中提供了更详细的背景信息，涉及到[第 4.8 节](https://plato.stanford.edu/entries/causal-models/#InteDeciTheo)中提出的一些问题。

这个条目侧重于哲学家最感兴趣的主题。有许多重要的技术问题被大多数忽略了。其中许多问题涉及到在这里所做的各种简化假设（如无环性和对真实概率的了解）被拒绝时出现的问题。其中一些问题简要概述，并附有参考资料，详见[因果推断中进一步主题的补充](https://plato.stanford.edu/entries/causal-models/topics.html)。

## Bibliography

* Balke, Alexander and Judea Pearl, 1994a, “Probabilistic Evaluation of Counterfactual Queries”, in Barbara Hayes-Roth and Richard E Korf (eds.), _Proceedings of the Twelfth National Conference on Artificial Intelligence_, Volume I, Menlo Park CA: AAAI Press, pp. 230–237. \[[Balke & Pearl 1994a available online](https://www.aaai.org/Papers/AAAI/1994/AAAI94-035.pdf)]
* –––, 1994b, “Counterfactual Probabilities: Computational Methods, Bounds, and Applications”, in Ramon Lopez de Mantaras and David Poole (eds.), _Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence_, San Francisco: Morgan Kaufmann, pp. 46–54. \[[Balke & Pearl 1994b available online](https://arxiv.org/abs/1302.6784)]
* Bareinboim, Elias, and Judea Pearl, 2013, “A General Algorithm for Deciding Transportability of Experimental Results”, _Journal of Causal Inference_, 1(1): 107–134. doi:10.1515/jci-2012-0004
* –––, 2014, “Transportability from Multiple Environments with Limited Experiments: Completeness Results”, in Zoubin Ghahramani, Max Welling, Corinna Cortes, and Neil Lawrence and Kilian Weinberger (eds.), _Advances of Neural Information Processing 27 (NIPS Proceedings)_, 280–288. \[[Bareinboim & Pearl 2014 available online](http://papers.nips.cc/paper/5536-transportability-from-multiple-environments-with-limited-experiments-completeness-results.pdf)]
* –––, 2015, “Causal Inference and the Data-Fusion Problem”, _Proceedings of the National Academy of Sciences_, 113(27): 7345–7352. doi:10.1073/pnas.1510507113
* Beckers, Sander and Joost Vennekens, 2018, “A Principled Approach to Defining Actual Causation”, _Synthese_, 195(2): 835–862. doi:10.1007/s11229-016-1247-1
* Beebee, Helen, Christopher Hitchcock, and Peter Menzies (eds.), 2009, _The Oxford Handbook of Causation_, Oxford: Oxford University Press.
* Blanchard, Thomas, and Jonathan Schaffer, 2017,“Cause without Default”, in Helen Beebee, Christopher Hitchcock, and Huw Price (eds.). _Making a Difference_, Oxford: Oxford University Press, pp. 175–214.
* Briggs, Rachael, 2012, “Interventionist Counterfactuals”, _Philosophical Studies_160(1): 139–166. doi:10.1007/s11098-012-9908-5
* Cartwright, Nancy, 1993, “Marks and Probabilities: Two Ways to Find Causal Structure”, in Fritz Stadler (ed.), _Scientific Philosophy: Origins and Development_, Dordrecht: Kluwer, 113–119. doi:10.1007/978-94-017-2964-2\_7
* –––, 2007, _Hunting Causes and Using Them_, Cambridge: Cambridge University Press. doi:10.1017/CBO9780511618758
* Chalupka, Krzysztof, Frederick Eberhardt, and Pietro Perona, 2017, “Causal Feature Learning: an Overview”, _Behaviormetrika_, 44(1): 137–167. doi:10.1007/s41237-016-0008-2
* Cheng, Patricia, 1997, “From Covariation to Causation: A Causal Power Theory”, _Psychological Review_, 104(2): 367– 405. doi:10.1037/0033-295X.104.2.367
* Claassen, Tom and Tom Heskes, 2012, “A Bayesian Approach to Constraint Based Causal Inference”, in Nando de Freitas and Kevin Murphy (eds.) _Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence_, Corvallis, OR: AUAI Press, pp. 207–216. \[[Claassen & Heskes 2012 available online](http://arxiv.org/abs/1210.4866)]
* Cooper, G. F. and Herskovits, E. 1992, “A Bayesian Method for the Induction of Probabilistic Networks from Data”, _Machine Learning_, 9(4): 309–347. doi:10.1007/BF00994110
* Danks, David, and Sergey Plis, 2014, “Learning Causal Structure from Undersampled Time Series”, _JMLR Workshop and Conference Proceedings (NIPS Workshop on Causality)_. \[[Danks & Plis 2014 available online](https://doi.org/10.1184/R1/6492101.v1)]
* Dash, Denver and Marek Druzdzel, 2001, “Caveats For Causal Reasoning With Equilibrium Models”, in Salem Benferhat and Philippe Besnard (eds.) _Symbolic and Quantitative Approaches to Reasoning with Uncertainty, 6th European Conference, Proceedings. Lecture Notes in Computer Science 2143_, Berlin and Heidelberg: Springer, pp. 92–103. doi:10.1007/3-540-44652-4\_18
* Dechter, Rina and Thomas Richardson (eds.), 2006, _Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence_, Corvallis, OR: AUAI Press.
* Dowe, Phil, 2000, _Physical Causation_, Cambridge: University of Cambridge Press. doi:10.1017/CBO9780511570650
* Eberhardt, Frederick, 2009, “Introduction to the Epistemology of Causation”, _Philosophy Compass_, 4(6): 913–925. doi:10.1111/j.1747-9991.2009.00243.x
* –––, 2017, “Introduction to the Foundations of Causal Discovery”, _International Journal of Data Science and Analytics_, 3(2): 81–91. doi:10.1007/s41060-016-0038-6
* Eberhardt, Frederick and Richard Scheines, 2007, “Interventions and Causal Inference”, _Philosophy of Science_, 74(5): 981–995. doi:10.1086/525638
* Eells, Ellery, 1991, _Probabilistic Causality_, Cambridge: Cambridge University Press. doi:10.1017/CBO9780511570667
* Eichler, Michael, 2012, “Causal Inference in Time Series Analysis”, in Carlo Berzuini, Philip Dawid, and Luisa Bernardinelli (eds.), _Causality: Statistical Perspectives and Applications_, Chichester, UK: Wiley, pp. 327–354. doi:10.1002/9781119945710.ch22
* Fine, Kit, 2012, “Counterfactuals without Possible Worlds”, _Journal of Philosophy_, 109(3): 221–246. doi:10.5840/jphil201210938
* Galles, David, and Judea Pearl, 1998, “An Axiomatic Characterization of Causal Counterfactuals”, _Foundations of Science_, 3(1): 151–182. doi:10.1023/A:1009602825894
* Geiger, Dan and David Heckerman, 1994, “Learning Gaussian Networks”, Technical Report MSR-TR-94-10, Microsoft Research.
* Geiger, Dan and Judea Pearl, 1988, “On the Logic of Causal Models”, in Ross Shachter, Tod Levitt, Laveen Kanal, and John Lemmer (eds.), _Proceedings of the Fourth Conference on Uncertainty in Artificial Intelligence_, Corvallis, OR: AUAI Press, pp. 136–147.
* Gibbard, Alan, and William Harper, 1978, “Counterfactuals and Two Kinds of Expected Utility”, in Clifford Hooker, James Leach, and Edward McClennen (eds.), _Foundations and Applications of Decision Theory_, Dordrecht: Reidel, pp. 125–62.
* Glennan, Stuart, 2017, _The New Mechanical Philosophy_, Oxford: Oxford University Press.
* Glymour, Clark, 2009, “Causality and Statistics”, in Beebee, Hitchcock, and Menzies 2009: 498–522.
* Glymour, Clark and Gregory Cooper, 1999, _Computation, Causation, and Discovery_, Cambridge, MA: MIT Press.
* Glymour, Clark, David Danks, Bruce Glymour, Frederick Eberhardt, Joseph Ramsey, Richard Scheines, Peter Spirtes, Choh Man Teng, and Jiji Zhang, 2010, “Actual Causation: a Stone Soup Essay”, _Synthese_, 175(2): 169–192. doi:10.1007/s11229-009-9497-9
* Glymour, Clark and Frank Wimberly, 2007, “Actual Causes and Thought Experiments”, in Joseph Campbell, Michael O’Rourke, and Harry Silverstein (eds.), _Causation and Explanation_, Cambridge, MA: MIT Press, pp. 43–68.
* Gong, Mingming, Kun Zhang, Bernhard Schölkopf, Dacheng Tao, and Philipp Geiger, 2015, “Discovering Temporal Causal Relations from Subsampled Data”, in Francis Bach and David Blei (eds.), _Proceeding of the 32nd International Conference on Machine Learning_, 37: 1898–1906. \[[Gong et al. 2015 available online](http://proceedings.mlr.press/v37/gongb15.html)]
* Gong, Mingming, Kun Zhang, Bernhard Schölkopf, Clark Glymour, and Dacheng Tao, 2017, “Causal Discovery from Temporally Aggregated Time Series”, in Gal Elidan and Kristian Kersting (eds.), _Proceedings of the Thirty-Third Conference on Uncertainty in Artificial Intelligence_, Corvallis, OR: AUAI Press. \[[Gong et al. 2017 available online](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5995575/)]
* Greenland, Sander, and James Robins, 1988, “Conceptual Problems in the Definition and Interpretation of Attributable Fractions”, _American Journal of Epidemiology_, 128(6): 1185–1197. doi:10.1093/oxfordjournals.aje.a115073
* Hall, Ned, 2007, “Structural Equations and Causation”, _Philosophical Studies_, 132(1): 109–136. doi:10.1007/s11098-006-9057-9
* Halpern, Joseph Y., 2000, “Axiomatizing Causal Reasoning”, _Journal of Artificial Intelligence Research_, 12: 317–337. \[[Halpern 2000 available online](https://www.jair.org/index.php/jair/article/view/10257)]
* –––, 2008, “Defaults and Normality in Causal Structures”, in Gerhard Brewka and Jérôme Lang (eds.), _Principles of Knowledge Representation and Reasoning: Proceedings of the Eleventh International Conference_, Menlo Park, CA: AAAI Press, pp. 198–208.
* –––, 2016, _Actual Causality_, Cambridge, MA: MIT Press.
* Halpern, Joseph Y. and Christopher Hitchcock, 2015, “Graded Causation and Defaults”, _British Journal for Philosophy of Science_, 66(2): 413–57. doi:10.1093/bjps/axt050
* Halpern, Joseph and Judea Pearl, 2001, “Causes and Explanations: A Structural-Model Approach. Part I: Causes”, in John Breese and Daphne Koller (eds.), _Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence_, San Francisco: Morgan Kaufmann, pp. 194–202
* –––, 2005, “Causes and Explanations: A Structural-Model Approach. Part I: Causes”, _British Journal for the Philosophy of Science_, 56(4): 843–887. doi:10.1093/bjps/axi147
* Hausman, Daniel M., 1999, “The Mathematical Theory of Causation”, _British Journal for the Philosophy of Science_, 50(1): 151–162. doi:10.1093/bjps/50.1.151
* Hausman, Daniel M. and James Woodward, 1999, “Independence, Invariance, and the Causal Markov Condition”, _British Journal for the Philosophy of Science_, 50(4): 521–583. doi:10.1093/bjps/50.4.521
* –––, 2004, “Modularity and the Causal Markov Condition: a Restatement”, _British Journal for the Philosophy of Science_, 55(1): 147–161. doi:10.1093/bjps/55.1.147
* Hitchcock, Christopher, 2001, “The Intransitivity of Causation Revealed in Equations and Graphs”, _Journal of Philosophy_, 98(6): 273–299. doi:10.2307/2678432
* –––, 2007, “Prevention, Preemption, and the Principle of Sufficient Reason”, _Philosophical Review_, 116(4): 495–532. doi:10.1215/00318108-2007-012
* –––, 2009, “Causal Models”, in Beebee, Hitchcock, and Menzies 2009: 299–314.
* –––, 2016, “Conditioning, Intervening, and Decision”, _Synthese_, 193(4): 1157–1176. doi:10.1007/s11229-015-0710-8
* Hoyer, Patrik O., Dominik Janzing, Joris Mooij, Jonas Peters, and Bernhard Schölkopf, 2009, “Nonlinear Causal Discovery with Additive Noise Models”, _Advances in Neural Information Processing Systems_, 21: 689–696. \[[Hoyer et al. 2009 available online](https://papers.nips.cc/paper/3548-nonlinear-causal-discovery-with-additive-noise-models)]
* Huang, Yimin and Marco Valtorta, 2006, “Pearl’s Calculus of Intervention Is Complete”, in Dechter and Richardson 2006: 217–224. \[[Huang & Valtorta 2006 available online](http://arxiv.org/abs/1206.6831)]
* Hyttinen, Antti, Frederick Eberhardt, and Patrik O. Hoyer, 2013a, “Experiment Selection for Causal Discovery”, _Journal of Machine Learning Research_, 14: 3041–3071. \[[Hyttinen, Eberhardt, & Hoyer 2013a available online](http://www.jmlr.org/papers/v14/hyttinen13a.html)]
* Hyttinen, Antti, Frederick Eberhardt, and Matti Järvisalo, 2014, “Constraint-based Causal Discovery: Conflict Resolution with Answer Set Programming”, in Nevin Zhang and Jin Tian (eds.), _Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence_, Corvallis, OR: AUAI Press, pp. 340–349.
* –––, 2015, “Do-calculus When the True Graph is Unknown”, in Marina Meila and Tom Heskes (eds.), _Uncertainty in Artificial Intelligence: Proceedings of the Thirty-First Conference_, Corvallis, OR: AUAI Press, pp. 395–404.
* Hyttinen, Antti, Patrik O. Hoyer, Frederick Eberhardt, and Matti Järvisalo, 2013b, “Discovering Cyclic Causal Models with Latent Variables: A General SAT-Based Procedure”, in Nichols and Smyth 2013: 301–310.
* Hyttinen, Antti, Sergey Plis, Matti Järvisalo, Frederick Eberhardt, and David Danks, 2016, “Causal Discovery from Subsampled Time Series Data by Constraint Optimization”, in Alessandro Antonucci, Giorgio Corani, Cassio Polpo Campos (eds.) _Proceedings of the Eighth International Conference on Probabilistic Graphical Models_, pp. 216–227.
* Jeffrey, Richard, 1983, _The Logic of Decision_, Second Edition, Chicago: University of Chicago Press.
* Joyce, James M., 1999, _The Foundations of Causal Decision Theory_, Cambridge: Cambridge University Press. doi:10.1017/CBO9780511498497
* Lewis, David, 1973a, “Causation”, _Journal of Philosophy_, 70(17): 556–567. doi:10.2307/2025310
* –––, 1973b, _Counterfactuals_, Oxford: Blackwell.
* –––, 1979, “Counterfactual Dependence and Time’s Arrow”, _Noûs_, 13(4): 455–476. doi:10.2307/2215339
* –––, 1981, “Causal Decision Theory”, _Australasian Journal of Philosophy_, 59(1): 5–30. doi:10.1080/00048408112340011
* Machamer, Peter, Lindley Darden, and Carl Craver, 2000, “Thinking about Mechanisms”, _Philosophy of Science_, 67(1): 1–25. doi:10.1086/392759
* Maier, Marc, Katerina Marazopoulou, David Arbour, and David Jensen, 2013, “A Sound and Complete Algorithm for Learning Causal Models from Relational Data”, in Nichols and Smyth 2013: 371–380. \[[Maier et al. 2013 available online](http://arxiv.org/abs/1309.6843)]
* Maier, Marc, Brian Taylor, Hüseyin Oktay, and David Jensen, 2010, “Learning Causal Models of Relational Domains”, in Maria Fox and David Poole (eds.), _Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence_, (Menlo Park CA: AAAI Press), pp. 531–538. \[[Maier et al. 2010 available online](https://www.aaai.org/ocs/index.php/AAAI/AAAI10/paper/view/1919)]
* Meek, Christopher, 1995, “Strong Completeness and Faithfulness in Bayesian Networks”, in Philippe Besnard and Steve Hanks (eds.) _Proceedings of the Eleventh Conference Conference on Uncertainty in Artificial Intelligence_, San Francisco: Morgan Kaufmann, pp. 411–418.
* Meek, Christopher and Clark Glymour, 1994, “Conditioning and Intervening”, _British Journal for Philosophy of Science,_, 45(4): 1001–1024. doi:10.1093/bjps/45.4.1001
* Menzies, Peter, 2004, “Causal Models, Token Causation, and Processes”, _Philosophy of Science_, 71(5): 820–832. doi:10.1086/425057
* Mooij, Joris, Dominik Janzing, and Bernhard Schölkopf, 2013, “From Ordinary Differential Equations to Structural Causal Models: the Deterministic Case”, in Nichols and Smyth 2013: 440–448.
* Neal, Radford M., 2000, “On Deducing Conditional Independence from d-separation in Causal Graphs with Feedback”, _Journal of Artificial Intelligence Research_, 12: 87–91. \[[Neal 2000 available online](https://www.jair.org/index.php/jair/article/view/10250)]
* Neapolitan, Richard, 2004, _Learning Bayesian Networks_, Upper Saddle River, NJ: Prentice Hall.
* Neapolitan, Richard and Xia Jiang, 2016, “The Bayesian Network Story”, in Alan Hájek and Christopher Hitchcock (eds.), _The Oxford Handbook of Probability and Philosophy_, Oxford: Oxford University Press, pp. 183–99.
* Neyman, Jerzy, 1923 \[1990], “Sur les Applications de la Théorie des Probabilités aux Experiences Agricoles: Essai des Principes”) _Roczniki Nauk Rolniczych, Tom_, X: 1–51. Excerpts translated into English by D. M. Dabrowska and Terrence Speed, 1990, “On the Application of Probability Theory to Agricultural Experiments. Essay on Principles”, _Statistical Science_, 5(4): 465–80. doi:10.1214/ss/1177012031
* Ann Nichols and Padhraic Smyth (eds), 2013, _Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence_, Corvallis, OR: AUAI Press.
* Nozick, Robert, 1969, “Newcomb’s Problem and Two Principles of Choice”, in Nicholas Rescher (ed.), _Essays in Honor of Carl G. Hempel_, Dordrecht: Reidel, pp. 114–146. doi:10.1007/978-94-017-1466-2\_7
* Pearl, Judea, 1988, _Probabilistic Reasoning in Intelligent Systems_, San Francisco: Morgan Kaufmann.
* –––, 1995, “Causal Diagrams for Empirical Research”, _Biometrika_, 82(4): 669–688. doi:10.1093/biomet/82.4.669
* –––, 2009, _Causality: Models, Reasoning, and Inference_, Second Edition, Cambridge: Cambridge University Press.
* –––, 2010, “An Introduction to Causal Inference”, _The International Journal of Biostatistics_, 6(2): article 7, pp. 1–59. doi:10.2202/1557-4679.1203
* Pearl, Judea and Rina Dechter, 1996, “Identifying Independencies in Causal Graphs with Feedback”, in Eric Horvitz and Finn Jensen (eds.) _Proceedings of the Twelfth Conference on Uncertainty in Artificial Intelligence_, San Francisco: Morgan Kaufmann, pages 420–426.
* Pearl, Judea, Madelyn Glymour, and Nicholas P. Jewell, 2016, _Causal Inference in Statistics: A Primer_, Chichester, UK: Wiley.
* Pearl, Judea and Mackenzie, Dana, 2018, _The Book of Why: The New Science of Cause and Effect._, New York: Basic Books.
* Pearl, Judea and Verma, Thomas, 1991, “A Theory of Inferred Causation”, in James Allen, Richard Fiskes, and Erik Sandewall (eds.), _Principles of Knowledge Representation and Reasoning: Proceedings of the Second International Conference_, San Mateo, CA: Morgan Kaufmann, pp. 441–52.
* Peters, Jonas, Dominik Janzing, and Bernhard Schölkopf, 2017, _Elements of Causal Inference: Foundations and Learning Algorithms._, Cambridge, MA: MIT Press.
* Price, Huw, 1986, “Against Causal Decision Theory”, _Synthese_, 67(2): 195–212. doi:10.1007/BF00540068
* Ramsey, Joseph, Peter Spirtes, and Jiji Zhang, 2006, “Adjacency Faithfulness and Conservative Causal Inference”, in Dechter and Richardson 2006: 401–408. \[[Ramsey, Spirtes, & Zhang 2006 available online](http://arxiv.org/abs/1206.6843)]
* Reichenbach, Hans, 1956, _The Direction of Time_, Berkeley and Los Angeles: University of California Press.
* Richardson, Thomas, and James Robins, 2016, _Single World Intervention Graphs (SWIGs): A Unification of the Counterfactual and Graphical Approaches to Causality_, Hanover, MA: Now Publishers.
* Robins, James, 1986, “A New Approach to Causal Inference in Mortality Studies with a Sustained Exposure Period: Applications to Control of the Healthy Workers Survivor Effect”, _Mathematical Modeling_, 7(9–12): 1393–1512. doi:10.1016/0270-0255(86)90088-6
* Rubin, Donald, 1974, “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies”, _Journal of Educational Psychology_, 66(5): 688–701. doi:10.1037/h0037350
* Salmon, Wesley, 1984, _Scientific Explanation and the Causal Structure of the World_, Princeton: Princeton University Press.
* Scheines, Richard, 1997, “An Introduction to Causal Inference” in V. McKim and S. Turner (eds.), _Causality in Crisis?_, Notre Dame: University of Notre Dame Press, pp. 185–199.
* Schulte, Oliver and Hassan Khosravi, 2012, “Learning Graphical Models for Relational Data via Lattice Search”, _Machine Learning_, 88(3): 331–368. doi:10.1007/s10994-012-5289-4
* Schulte, Oliver, Wei Luo, and Russell Greiner, 2010, “Mind Change Optimal Learning of Bayes Net Structure from Dependency and Independency Data”, _Information and Computation_, 208(1): 63–82. doi:10.1016/j.ic.2009.03.009
* Shalizi, Cosma Rohilla, and Andrew C. Thomas, 2011, “Homophily and Contagion are Generically Confounded in Observational Social Studies”, _Sociological Methods and Research_, 40(2): 211–239. doi:10.1177/0049124111404820
* Sheps, Mindel C., 1958, “Shall We Count the Living or the Dead?” _New England Journal of Medicine_, 259(12): 210–4. doi:10.1056/NEJM195812182592505
* Shimizu, Shohei, Patrik O. Hoyer, Aapo Hyvärinen, and Antti Kermine, 2006, “A Linear Non-Gaussian Acyclic Model for Causal Discovery”, _Journal of Machine Learning Research_, 7: 2003–2030. \[[Shimizu et al. 2006 available online](http://www.jmlr.org/papers/v7/shimizu06a.html)]
* Shpitser, Ilya and Judea Pearl, 2006, “Identification of Conditional Interventional Distributions”, in Dechter and Richardson 2006: 437–444. \[[Shpister & Pearl 2006 available online](http://arxiv.org/abs/1206.6876)]
* Skyrms, Brian, 1980, _Causal Necessity_, New Haven and London: Yale University Press.
* Spirtes, Peter, 1995, “Directed Cyclic Graphical Representation of Feedback Models”, in Philippe Besnard and Steve Hanks (eds.), _Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence_, San Francisco: Morgan Kaufmann, pp. 491–498.
* Spirtes, Peter, Clark Glymour, and Richard Scheines, \[SGS] 2000, _Causation, Prediction and Search_, Second Edition, Cambridge, MA: MIT Press.
* Spirtes, Peter and Jiji Zhang, 2014, “A Uniformly Consistent Estimator of Causal Effects under the _k_-Triangle-Faithfulness Assumption”, _Statistical Science_, 29(4): 662–678. doi:10.1214/13-STS429
* Spirtes, Peter and Kun Zhang, 2016, “Causal Discovery and Inference: Concepts and Recent Methodological Advances”, _Applied Informatics_, 3: 3. doi:10.1186/s40535-016-0018-x
* Stalnaker, Robert, 1968, “A Theory of Conditionals”, in Nicholas Rescher (ed.) _Studies in Logical Theory_, Blackwell: Oxford, pp. 98–112.
* Steel, Daniel, 2006, “Homogeneity, Selection, and the Faithfulness Condition”. _Minds and Machines_, 16(3): 303–317. doi:10.1007/s11023-006-9032-4
* Stern, Reuben, 2017, “Interventionist Decision Theory”, _Synthese_, 194(10): 4133–4153. doi:10.1007/s11229-016-1133-x
* Suppes, Patrick, 1970, _A Probabilistic Theory of Causality_, Amsterdam: North-Holland Publishing Company.
* Tillman, Robert E., and Frederick Eberhardt, 2014, “Learning Causal Structure from Multiple Datasets with Similar Variable Sets”, _Behaviormetrika_, 41(1): 41–64. doi:10.2333/bhmk.41.41
* Triantafillou, Sofia, and Ioannis Tsamardinos, 2015, “Constraint-based Causal Discovery from Multiple Interventions over Overlapping Variable Sets”, _Journal of Machine Learning Research_, 16: 2147–2205. \[[Triantafillou & Tsamardinos 2015 available online](http://www.jmlr.org/papers/v16/triantafillou15a.html)]
* Weslake, Brad, forthcoming, “A Partial Theory of Actual Causation”, _British Journal for the Philosophy of Science._
* Woodward, James, 2003, _Making Things Happen: A Theory of Causal Explanation_, Oxford: Oxford University Press. doi:10.1093/0195155270.001.0001
* Wright, Sewall, 1921, “Correlation and Causation”, _Journal of Agricultural Research_, 20: 557–85.
* Zhalama, Jiji Zhang, and Wolfgang Mayer, 2016, “Weakening Faithfulness: Some Heuristic Causal Discovery Algorithms”, _International Journal of Data Science and Analytics_, 3(2): 93–104. doi:10.1007/s41060-016-0033-y
* Zhang, Jiji, 2008, “Causal Reasoning with Ancestral Graphs”, _Journal of Machine Learning Research_, 9: 1437–1474. \[[Zhang 2008 available online](http://www.jmlr.org/papers/v9/zhang08a.html)]
* –––, 2013a, “A Lewisian Logic of Counterfactuals”, _Minds and Machines_, 23(1): 77–93. doi:10.1007/s11023-011-9261-z
* –––, 2013b, “A Comparison of Three Occam’s Razors for Markovian Causal Models”, _British Journal for Philosophy of Science_, 64(2): 423–448. doi:10.1093/bjps/axs005
* Zhang, Jiji and Peter Spirtes 2008, “Detection of Unfaithfulness and Robust Causal Inference”, _Minds and Machines_, 18(2): 239–271. doi:10.1007/s11023-008-9096-4
* –––, 2016, “The Three Faces of Faithfulness”, _Synthese_, 193(4): 1011–1027. doi:10.1007/s11229-015-0673-9
* Zhang, Kun, and Aapo Hyvärinen, 2009, “On the Identifiability of the Post-nonlinear Causal Model”, in Jeff Bilmes and Andrew Ng (eds.), _Proceeding of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence_, (Corvallis, OR: AUAI Press), pp. 647–655.

## Academic Tools

| ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=causal-models).                                                                      |
| ------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/causal-models/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
| ![inpho icon](https://plato.stanford.edu/symbols/inpho.png)         | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=causal-models\&redirect=True) at the Internet Philosophy Ontology Project (InPhO).   |
| ![phil papers icon](https://plato.stanford.edu/symbols/pp.gif)      | [Enhanced bibliography for this entry](http://philpapers.org/sep/causal-models/) at [PhilPapers](http://philpapers.org/), with links to its database.                            |

## Other Internet Resources

* [Causal Analysis and Theory in Practice](http://causality.cs.ucla.edu/blog/)
* [_Causality_, 2nd Edition, 2009](http://bayes.cs.ucla.edu/BOOK-2K/), Judea Pearl's web page on his book.
* [The Tetrad Project](http://www.phil.cmu.edu/tetrad/).
* [Causal and Statistical Reasoning](http://www.phil.cmu.edu/projects/csr/), The Carnegie Mellon Curriculum, Core Site Materials.

## Related Entries

[causation: and manipulability](https://plato.stanford.edu/entries/causation-mani/) | [causation: counterfactual theories of](https://plato.stanford.edu/entries/causation-counterfactual/) | [causation: probabilistic](https://plato.stanford.edu/entries/causation-probabilistic/) | [causation: the metaphysics of](https://plato.stanford.edu/entries/causation-metaphysics/) | [conditionals: counterfactual](https://plato.stanford.edu/entries/counterfactuals/) | [decision theory](https://plato.stanford.edu/entries/decision-theory/) | [decision theory: causal](https://plato.stanford.edu/entries/decision-causal/) | [logic: conditionals](https://plato.stanford.edu/entries/logic-conditionals/) | [probability, interpretations of](https://plato.stanford.edu/entries/probability-interpret/) | [quantum theory: the Einstein-Podolsky-Rosen argument in](https://plato.stanford.edu/entries/qt-epr/) | [rational choice, normative: expected utility](https://plato.stanford.edu/entries/rationality-normative-utility/) | [Reichenbach, Hans: common cause principle](https://plato.stanford.edu/entries/physics-Rpcc/)

### Acknowledgments

Thanks to Frederick Eberhardt, Clark Glymour, Joseph Halpern, Judea Pearl, Peter Spirtes, Reuben Stern, Jiji Zhang, and Kun Zhang for detailed comments, corrections, and discussion.

Portions of this entry are taken, with minimal adaptation, from the author’s separate entry on [probabilistic causation](https://plato.stanford.edu/entries/causation-probabilistic/) so that readers do not need to consult that entry for background material before reading this entry.

[Copyright © 2018](https://plato.stanford.edu/info.html#c) by\
[Christopher Hitchcock](http://hss.divisions.caltech.edu/people/christopher-r-hitchcock) <[_cricky@caltech.edu_](mailto:cricky%40caltech%2eedu)>
