# 风险 risk (Sven Ove Hansson)

*首次发表于 2007 年 3 月 13 日；实质性修订于 2022 年 12 月 8 日*

自 1970 年代以来，风险研究已经发展成为一个重要的跨学科研究领域。虽然相对较少的哲学家专注于风险研究，但风险研究与几个哲学子学科之间存在重要联系。本文总结了这些联系中最为成熟的，并介绍了风险哲学中的一些主要主题。它包括七个部分，涉及风险的定义以及与认识论、科学哲学、技术哲学、伦理学、决策理论和经济哲学相关的风险处理。

---

## 1. 风险的定义

在非技术背景下，“风险”一词通常指的是可能但不确定会发生某种不良事件的情况，而且常常含糊不清。在技术背景下，这个词有几个更专门的用法和含义。其中有五个特别重要，因为它们在各个学科中被广泛使用：

1. 风险 = 可能发生或可能不发生的不希望事件。

这种用法的一个例子是：“肺癌是影响吸烟者的主要风险之一。”

2. 风险 = 可能发生或可能不发生的不希望事件的原因。

这种用法的一个例子是：“吸烟是工业化国家中最重要的健康风险。”（这里隐含指的是吸烟引起的疾病。）（1）和（2）都是风险的定性意义。这个词也有定量意义，其中最早的一个是：

3. 风险 = 可能发生或可能不发生的不受欢迎事件的概率。

这种用法的例子是：“吸烟导致吸烟相关疾病缩短吸烟者寿命的风险约为 50%。”

4. 风险 = 可能发生或可能不发生的不良事件的统计期望值。

可能负面事件的期望值是其概率和其严重程度的某种度量的乘积。通常使用死亡人数作为事故严重程度的度量。根据这种严重程度的度量，与潜在事故相关的“风险”（在第 4 个意义上）等于统计预期的死亡人数。其他严重程度的度量会导致其他风险度量。

尽管期望值自 17 世纪以来就被计算出来，但在这个意义上使用“风险”一词是相对较新的。它是在有影响力的反应堆安全研究 WASH-1400（Rasmussen 等，1975 年，Rechard 1999 年）中引入风险分析的。如今，在许多学科中，“风险”一词的标准技术含义。一些风险分析师认为这是该术语唯一正确的用法。

5. 风险 = 在已知概率条件下做出决策的事实（与“不确定性下的决策”相对）

除了这五个常见的“风险”含义外，还有一些更专业的含义，在专门的研究领域中得到了很好的确立。下面将介绍在经济分析中使用的一些主要风险定义（第 7.1 节）。

虽然上述大部分“风险”的含义已被哲学家所提及，但哲学文献中关于风险的很大一部分是指本节开头提到的更非正式的含义，即一种不希望发生的事件可能发生也可能不发生的状态。一些哲学家批评了风险的技术定义过于有限，未涵盖应包括在风险评估中的所有方面（Buchak 2014; Pritchard 2015; Shrader-Frechette 1991）。语言证据表明，风险的技术定义几乎对非技术用法没有影响（Boholm et al. 2016）。

术语说明：一些哲学家区分“主观”和“客观”概率。其他人将术语“概率”保留给主观概念。在这里，使用前一种术语，即“概率”可以指主观概率或客观机会。

## 2. 认识论

当存在风险时，必定存在某种未知或具有未知结果的事物。因此，对风险的了解就是对缺乏知识的了解。这种知识与无知的结合使得从认识论的角度来看，风险问题变得复杂。

在非规范化的用法中，“风险”和“不确定性”在主观-客观维度上有所不同。虽然“不确定性”似乎属于主观领域，“风险”具有强烈的客观成分。如果一个人不知道草蛇是否有毒，那么她在与其毒性有关的能力方面处于不确定状态。然而，由于这个物种没有毒性，所以没有被它毒害的风险。两个概念“风险”和“不确定性”之间的关系似乎在某种程度上类似于“真理”和“信念”之间的关系。

规范化的决策理论用法与此不同。在决策理论中，如果相关的概率可用，则称决策是“在风险下”做出的；如果概率不可用或只有部分可用，则称决策是“在不确定性下”做出的。部分确定的概率有时用概率区间表示，例如，“明天下雨的概率在 0.1 到 0.4 之间”。（当根本没有可用的概率信息时，有时会使用“无知下的决策”这个术语。）

尽管风险和不确定性之间的区别在决策理论上是有用的，但从认识论的角度来看，它需要进一步澄清。很少有概率是确定的。严格来说，“风险”（已知概率）的明确案例似乎只存在于理想化的教科书案例中，这些案例涉及到被认为是确定公平的骰子或硬币等设备。在现实生活中，即使我们根据一个确定的概率估计来行动，我们也不能完全确定这个估计是否完全正确，因此存在不确定性。因此，几乎所有的决策都是在“不确定性”下做出的。如果将一个决策问题视为“风险决策”，这并不意味着所讨论的决策是在完全已知概率的条件下做出的。相反，这意味着选择了简化该决策问题的描述，将其视为已知概率的情况。这在决策理论中通常是一个非常有用的理想化。然而，在实际应用中，重要的是区分那些可以视为已知的概率和那些不确定的概率，因此更需要不断更新。前者的典型例子是从广泛而有记录的使用经验中推断出的技术组件的故障频率。后者的例子是专家对一种新型组件预期故障频率的估计。

风险认识论中的一个重要问题是如何处理我们对于关键风险估计所必需的独特复杂系统行为的认识的局限性，例如气候系统、生态系统、世界经济等。这些系统中包含了如此多的组成部分和潜在的相互作用，以至于其中的重要方面是不可预测的。然而，尽管存在这种不确定性，我们仍然可以对这些系统的许多方面做出相对可靠的陈述。人为气候变化就是一个例子。尽管许多细节尚不清楚，但总体情况是明确的，对于人为气候变化的存在、主要原因和机制，以及它对我们社会产生的风险的总体性质，没有合理的怀疑（Mayer 等，2017 年；Lewandowsky 等，2018 年）。关于复杂系统的这种部分知识的认识论地位以及涉及的不确定性的性质仍然需要进一步澄清（McKinney，1996 年；Shrader-Frechette，1997 年）。

在风险科学中，通常区分“客观风险”和“主观风险”。前者的概念原则上是相当无问题的，因为它涉及到概率的频率解释。后者的概念更加模糊。在 20 世纪 70 年代的风险心理测量文献中，主观风险通常被看作是对客观风险的主观估计。在更近期的文献中，出现了一个更复杂的情况。对（风险的严重性）的主观评估在很大程度上取决于传统的客观风险度量所未涵盖的因素，如控制和对自然的干预。如果按照这个意义来理解这些术语，主观风险受到对客观风险的主观估计的影响，但不能与之等同。在心理学文献中，主观风险通常被看作是个体对危险或所谓危险的严重性的整体评估。这样的个体评估通常被称为“风险感知”，但严格来说，这个术语是误导性的。这不是一个感知问题，而是一种态度和期望问题。主观风险可以用态度测量和心理标度的方法进行研究（Sjöberg 2004）。

在哲学以及其他学科中，概率方法主导了对风险的研究，但一些哲学家研究了一种替代的、模态的风险解释。根据这种解释，"[说一个目标事件是有风险的]是指（在保持该事件的相关初始条件不变的情况下）它在接近的可能世界中发生"（Pritchard 2016, 562）。风险越小，目标事件发生的最近可能世界越远。这种方法与心理学对风险的解释有有趣的联系，但如何定义和确定可能世界之间的距离还远未明确。

## 3. 科学哲学

在风险问题上，科学中价值观的作用一直备受争议。风险评估经常受到批评，认为其中包含“隐藏”的价值观，导致对风险的过高接受度（Cranor 2016；2017；Intemann 2016；Heinzerling 2000）。还有关于在风险评估中加强某些价值观影响的讨论，例如公正考虑（Shrader-Frechette 2005a）、人权（Shrader-Frechette 2005b）以及未来人的权利和福祉（Caney 2009；Ng 2005）。风险问题也引发了关于政策决策所需的科学证据水平的激烈辩论。科学的证明标准往往在将科学应用于需要与科学不同的证明或证据标准的实际问题时会引起困难。

在实践中，接受或拒绝科学陈述（例如假设）的决策总是存在错误的可能性。这种错误的机会通常被称为归纳风险（Hempel 1965, 92）。存在两种主要类型的错误。第一种是在实际上不存在现象或效应时得出存在现象或效应的结论。这被称为 I 型错误（假阳性）。第二种是错过了现有的现象或效应。这被称为 II 型错误（假阴性）。在科学的内部交往中，I 型错误通常被认为比 II 型错误更为棘手。常见的科学统计显著性标准大大降低了 I 型错误的风险，但不能防止 II 型错误的发生（Shrader-Frechette 2008；John 2017）。

许多关于风险评估的争议涉及到类型 I 和类型 II 错误之间的平衡。虽然科学更重视避免类型 I 错误而不是避免类型 II 错误，但当错误具有实际后果时，平衡可能会发生变化。这可以从一个案例中看出，在这个案例中，人们不确定飞机发动机是否存在严重缺陷。在这种情况下，类型 II 错误，即假设没有这样的缺陷，而实际上存在缺陷，将被认为比类型 I 错误更严重，即假设存在缺陷，而实际上没有缺陷。（类型 I 和类型 II 错误的区别取决于所研究效应的界定。在风险讨论中，这种界定大多数情况下是无争议的。Lemons 等，1997 年；van den Belt 和 Gremmen，2002 年。）

在这个特定案例中，避免类型 II 错误优先于避免类型 I 错误是相当无争议的。换句话说，最好推迟飞行，然后发现发动机状态良好，而不是飞行时发现发动机出现故障。然而，在其他情况下，两种错误类型之间的平衡更具争议性。例如，关于化学物质对人类健康和环境可能产生的负面影响采取行动所需的证据程度常常引起争议。

![figure 1](https://plato.stanford.edu/entries/risk/figure1.png)

图 1. 用于政策目的的科学数据的使用。

这些争议可以通过一个简单但富有说明性的模型来澄清，该模型说明了科学数据如何影响科学判断和实际决策（Hansson 2008）。科学知识始于实验和其他观察所产生的数据（见图 1）。通过批判性评估的过程，这些数据形成了科学文献（箭头 1）。粗略地说，科学文献包括那些在（足够详细的）教科书中可以合理地无保留地提出的陈述。在确定是否应该将科学假设暂时接受为科学文献的一部分时，证明的责任落在其支持者身上。同样，那些声称存在尚未被证明的现象的人有证明的责任。这些证明标准对科学的完整性至关重要。

在政策制定中使用科学信息的最明显方法是利用科学文献中的信息（箭头 2）。对于许多目的来说，这是唯一明智的做法。然而，在风险管理决策中，仅依赖于科学文献可能会产生不希望的后果。假设对一种以前从毒理学角度研究过的物质进行毒理学调查，结果是不确定的。这些调查引发了基于科学的怀疑，认为该物质对人类健康有危险，但并不能构成该问题的完全科学证明。由于证据不足以使其成为科学文献的一部分，这些信息无法以标准方式（通过箭头 1 和 2）影响政策。在箭头 1 所代表的过程中，有严格的要求避免 I 型错误，这个过程会过滤掉在这种情况下可能具有实际相关性并且可以证明某些保护措施的信息。

在这种情况下，通常会采取从数据到政策的直接路径（箭头 3）。这意味着在特定情况下，基于实际考虑而不是依赖于强调避免第一类错误的标准科学程序，确定了第一类和第二类错误之间的平衡。

在这里，有必要区分两种与风险相关的决策过程。一种是确定哪些关于风险的陈述应该包含在科学文集中。另一种是确定风险相关信息如何影响保护健康和环境的实际措施。如果这两种决策的证据标准总是相同，那将是一个奇怪的巧合。在科学中，可以提出严格的证明标准，即对文集的高入口要求有充分的理由。同时，有合理的政策理由允许风险管理决策受到科学上可行的危险迹象的影响，这些迹象尚未得到足够的确认以符合纳入科学文集的条件。

归纳风险一词通常用于指直接由假设的接受或拒绝而产生的（第一类和第二类）风险。认识风险一词用于指信念形成过程中更广泛的风险类别，例如在选择方法论、接受背景假设或决定如何解释数据时所采取的风险（Biddle 2016）。

风险相关的政策问题经常成为科学否认和其他伪科学形式的广泛虚假信息宣传活动的目标（Oreskes 2010）。几位哲学家一直在否定无效主张和捍卫与风险相关问题的科学方面发挥作用（Cranor 2005; 2016; 2017; Goodwin 2009; Prothero 2013; Shrader-Frechette 2014; Hansson 2017）。

## 4. 技术哲学

安全和避免风险是实际工程中的重要关注点。安全工程也越来越成为学术研究的主题。然而，这些讨论在不同技术领域之间往往是零散的。例如，在化学、核能和电气工程中，相同的基本思想或“安全哲学”以不同的名称进行讨论。然而，许多基本思维在不同的安全工程领域似乎是相同的（Möller and Hansson 2008）。

简单的安全原则通常可以表达为经验法则，在安全工程中起着核心作用。其中最重要的三个原则是固有安全性、安全系数和多重屏障。

固有安全性，也称为一级预防，是指消除危险源。它与二级预防相对，二级预防是指减少与危险源相关的风险。举个简单的例子，考虑一个使用易燃材料的工艺过程。固有安全性将包括将易燃材料替换为不易燃材料。二级预防将包括消除或隔离点火源和/或安装灭火设备。正如这个例子所示，二级预防通常涉及附加的安全设备。相比于二级预防，更倾向于固有安全性的主要原因是只要危险源仍然存在，它可以被一些意外的触发事件实现。即使采取了最佳的控制措施，如果存在易燃材料，一些意想不到的事件链也可能引发火灾。

安全系数是在设计过程中用于我们的房屋、桥梁、车辆、工具等的数值因子，以确保我们的建筑物比其功能所需的最低要求更加坚固。详细的安全系数体系已在规范和标准中规定。安全系数通常指的是不导致特定类型失效的最大载荷与相应的最大预期载荷之间的比率。通常会使桥梁和其他建筑物足够强大，能够承受两倍或三倍于预测最大载荷的负荷。这意味着采用了 2 或 3 的安全系数。

安全因素也被用于监管毒理学和生态毒理学。例如，在食品毒理学中，人体接触的最高剂量通常被计算为在实验动物中没有观察到任何负面效应的最高剂量（每千克体重）。如今，比 100 更高的安全因素已经很常见（Dourson 和 Stara 1983; Pressman 等，2017）。

安全屏障通常被排列成链条。理想情况下，每个屏障都独立于其前任，以便如果第一个屏障失效，第二个仍然完好无损，依此类推。例如，在古代堡垒中，如果敌人设法通过第一道墙壁，那么额外的层次将保护防守部队。一些工程安全屏障遵循同心物理屏障的原则。其他安全屏障按照时间或功能而不是空间的意义上串行排列。工程师从泰坦尼克号灾难中学到的一个教训是，如果改进早期屏障的构造导致忽视后期屏障（在那种情况下是救生艇），那么这种改进并没有太大帮助。

安全屏障建设的主要问题是如何使它们尽可能独立。如果两个或更多的屏障对同一类型的冲击敏感，那么同一破坏性力量可以一举摧毁它们所有。例如，如果在同一个工厂大厅中安装了三个安全阀，每个阀门故障的概率为 1/1,000，那么并不意味着三个阀门全部失效的概率是 1×10−9。这三个阀门可能都在同一场火灾中被摧毁，或者在维护操作中由同一错误损坏。这是许多类型设备的常见情况。

固有安全性、安全因素和多重屏障具有一个重要的共同特点：它们都旨在保护我们不仅免受可以分配有意义的概率估计的风险，而且还免受无法概率化的危险，例如某些意外类型的事件可能导致事故的可能性。然而，技术哲学家仍然需要进一步研究安全工程的基本原理，并澄清它们与其他工程设计原理的关系（Doorn 和 Hansson 2015）。

已经进行了许多尝试来预测与新兴和未来技术相关的风险。哲学家在这些努力中的角色通常是指出这些预测中涉及的困难和不确定性（Allhoff 2009; Gordijn 2005）。经验表明，即使在大力努力使新产品安全之后，仍然需要进行市场后监测（PMS）以发现意外问题。例如，在 1990 年左右大规模引入汽车安全气囊之前，安全工程师对不同的碰撞场景进行了实验室测试，使用代表各种体重和配置（包括婴儿和孕妇）的假人。但是，尽管这些测试导致了构造的调整，充气的安全气囊仍然造成了相当数量的（主要是轻微的）伤害。通过仔细分析实际事故的经验，工程师能够大大减少此类伤害的频率和严重程度（Wetmore 2008）。对于药物和一些医疗器械，许多司法管辖区法律要求进行市场后监测。

## 5. 伦理学

### 5.1 道德理论的困难之处

直到最近，道德哲学中的风险问题还没有得到系统地处理。对于这种限制的可能辩护是，道德哲学可以将其留给决策理论来分析不确定性和缺乏知识在现实生活中引发的复杂性。根据这两个学科之间的传统分工，道德哲学提供了在确定情况下对人类行为的评估。决策理论将这些情况的评估视为给定的，并添加可用的概率信息，从而推导出在不确定和不确定的世界中的理性行为的评估。根据这种观点，处理不确定性或缺乏知识不需要额外的道德价值输入，因为决策理论仅使用理性的标准。

举例来说，很容易找到一些例子来展示这两个学科之间的问题性质。比较从高楼上往一个人身上扔砖和在没有先确认下面没有人的情况下从高楼上扔砖的行为。这两个行为之间的道德差异在概率计算中并不明显。对于这种差异的伦理分析必须参考风险强加的道德方面与故意恶行相比。更一般地说，对于风险伦理的相对完整的解释必须区分故意和非故意的风险暴露，以及自愿接受风险、强加给接受者的风险和强加给不接受者的风险。这在将风险视为概率混合结果的框架中无法实现。原则上，这些结果可以被广泛定义，包括所有相关的道德方面，包括权利侵犯以及意图和其他相关的心理状态。然而，这仍然无法涵盖风险承担本身的道德含义，因为这些不是任何潜在结果的固有属性。

需要一种能够指导风险承担和风险强加决策的道德分析方法。第一步是研究标准道德理论如何处理与决策理论中相同的风险问题，即作为（道德）评估的概率混合（确定性）场景。

### 5.2 功利主义

在功利主义理论中，对这类问题有两种明显的方法。一种是实际主义解决方案。它的做法是将潜在结果的（概率性）混合物的效用赋予与实际发生的结果相等的效用。为了说明这种方法，考虑一个决策，即是否在使用一次非常重的运输之前加固一座桥。如果不加固，桥有 50%的风险会倒塌。假设决策是不加固桥梁，并且一切顺利；桥梁没有受损。根据实际主义的观点，这个决策是正确的。当然，这与常见的道德直觉相反。

另一种已确立的功利主义方法是最大化预期效用。这意味着潜在结果的效用被定义为这些结果的效用的概率加权平均值。

预期效用准则受到了多方面的批评。其中一种批评是它不允许一种常见的谨慎形式，即对大灾难的不成比例的回避。例如，假设人的死亡被平等地且可加地评估，正如大多数功利主义者倾向于做的那样，这个框架不允许一个人更喜欢一个人死亡的概率为 1/1000，而不是五十个人死亡的概率为 1/100000。预期效用框架还可以因为不允许对特定个体的高概率风险进行不成比例的回避而受到批评，这是一种对公平努力的常见表达。因此，在选择让一个人面临 0.9 的被杀概率和让一百个人中的每个人面临 0.01 的被杀概率之间，它要求选择前者。总之，预期效用最大化禁止了在冒险和风险强加方面看似合理的道德立场。

然而，值得注意的是，预期效用准则并不一定源自功利主义。广义上的功利主义（Scanlon 1982）与其他评估不确定结果的方式兼容（尤其是与实际后果功利主义兼容，但原则上也可以与最小最大化准则兼容）。因此，针对预期效用最大化的批评并不一定显示出功利主义思维的缺陷。

### 5.3 基于权利的道德理论

处理基于权利的道德理论中的风险问题是由罗伯特·诺齐克提出的：“强加给违反某人权利的伤害的概率有多小也会侵犯他的权利？”（Nozick 1974, 74）。

将基于权利的道德理论扩展到不确定性案例中，可以通过规定如果 A 有一个权利，即 B 不会导致某种结果，那么 A 也有一个权利，即 B 不会执行任何增加该结果概率的行动。不幸的是，这种严格的权利扩展在社会实践中是站不住脚的。可以推测，A 有权利不被 B 杀害，但将这种权利扩展到 B 的所有行为，这些行为会导致 A 死亡的风险非常小，比如在 A 居住的城镇开车。这种严格解释将使人类社会不可能存在。

因此，不被风险暴露的权利将是可推翻的，以便在某些情况下（但不一定是所有情况下）可以被推翻，当概率增加很小的时候。然而，仍然需要找到一个可信的标准来确定何时应该被推翻。正如诺齐克观察到的那样，在“一个认为从某人那里偷走一分钱或一根别针或任何东西都侵犯了他的权利的传统中，这个传统并没有选择一个伤害的阈值作为下限，在伤害肯定会发生的情况下”（诺齐克 1974 年，75 页）。

### 5.4 应义务论道德理论

处理义务论理中的风险问题与基于权利的理论中的相应问题类似。不伤害他人的义务可以延伸为不执行增加他们受伤风险的行为的义务。然而，我们所知的社会在没有对此规则的例外的情况下是不可能存在的。确定此类例外的标准是问题所在，就像基于权利的理论一样。所有合理的道德义务系统都将包含一般禁止杀害他人的行为。这种禁止可以（也应该）扩展到涉及大风险杀害他人的行为。然而，它不能扩展到导致微小增加杀害他人风险的所有行为，因为那将排除许多我们中的少数人愿意放弃的行为和行为方式。必须在合理和不合理的风险强加之间划定界限。似乎这样的界定将不得不诉诸于概率和/或通过冒险获得的利益的大小等概念，这些概念不是义务论理内部资源的一部分。

### 5.5 合同理论

合同理论可能比上述理论更有前景。它们提供的确定性情况的标准，即所有相关人员的同意，也可以应用于风险选项。可以声称，只有在得到共识的情况下，风险强加才是可接受的。在合同理论中构想的这种共识可以是实际的或假设的。

在一个复杂的社会中，每个人的行为对许多人的生活产生微小但累加的影响，实际共识是不现实的。根据实际共识的标准，任何当地居民都可以否决其他任何想在她所居住的城镇驾车的人。这样，公民可以相互阻止，形成僵局的社会。

在契约理论中，假设共识已经发展成为处理个体间问题的标准。我们被邀请考虑一个假设的初始情况，在这种情况下，未来社会的社会秩序尚未确定。当未来的公民们聚集在一起选择社会秩序时，他们中的每个人都对自己在可选择的社会安排中的位置一无所知。根据约翰·罗尔斯的正义理论，他们将选择最大化最小值的解决方案，即一个社会秩序，其中任何人在该社会中可能拥有的最差位置尽可能好。在为这个解决方案辩护时，罗尔斯在很大程度上依赖于这样一个假设，即参与者中没有人对自己最终会处于未来社会秩序中的哪个位置有任何了解（罗尔斯，1957 年；1971 年；1974 年）。约翰·哈萨尼在罗尔斯之前讨论了这个问题，他假设自己处于特定社会位置的概率等于将拥有该位置的人口份额，并且所有参与者都知道这一点。因此，如果某种类型的社会中有五分之一的人口是移民工人，那么哈萨尼初始情况下的每个参与者都会假设自己有百分之二十的概率成为移民工人，而罗尔斯初始情况下的参与者则不知道这个概率是多少。在哈萨尼的初始情况下，参与者将选择具有最高期望效用（概率加权效用）的社会秩序，从而考虑到所有潜在的未来位置，而不仅仅是最不利的位置（哈萨尼，1953 年；1955 年；1975 年）。

然而，在我们现有社会中讨论各种风险时，我们对契约理论的假设初始情况并没有太多用处。现实生活中的风险和不确定性与假设的不确定性（或无知）完全不同，后者是初始情况中的一个关键要求，即对自己的社会地位和条件的不确定性。初始情况的思想实验似乎并没有为我们提供任何用于道德评估风险的智力工具，除了那些即使不试图摆脱我们自己身份也可以获得的工具。

### 5.6 总结和展望

总之，从道德角度评估风险的问题在上述常见类型的道德理论中似乎没有令人满意的解决方案。以下是解决方案的三个可能要素：

1. 将注意力从以概率和严重性（或以这两者的乘积）描述的风险转移到风险承担和风险施加的行为可能是有用的。这些行为除了上述两个维度之外，还具有许多道德相关的属性，例如谁在因果上对风险做出贡献，以及以何种方式、何种意图对风险做出贡献，以及风险及其相关利益如何分配。
2. 通过假设每个人都有一种原则上的道德权利，即不受他人行为对其健康或财产造成负面影响的风险，可以解释重要的道德直觉。然而，这是一种原则上的权利，在许多情况下必须被覆盖，以使社会生活成为可能。因此，对这种权利的承认引发了一个可以称之为豁免问题的问题，即确定何时合理地覆盖它。
3. 解决豁免问题的一部分可能是通过允许风险和利益的相互交换来获得的。因此，如果允许 A 开车，使 B 面临一定的风险，那么作为交换，B 也被允许开车，使 A 面临相应的风险。为了应对现代社会的复杂性，这个原则还必须应用于不同类型的风险和利益的交换。如果将一个人暴露于风险中是公平的社会风险承担系统的一部分，并且对她有利，那么这种暴露可以被视为可以接受的。这样的系统可以要求包含消除或补偿由疾病和残疾引起的社会不平等的机制。（Hansson 2003; 2013）

风险接受的整体问题讨论可在 Macpherson（2008），Hansson（2013）和 Oberdiek（2014）中找到。风险强加的公正性在 Ferretti 2010 和 Heyward＆Roser 2016 中进行了讨论。权利和风险问题在 Thomson 1986 中进行了讨论，并在 Kermisch 2012 和 van de Poel 等人的 2012 年研究中特别强调责任。

## 6. 决策理论

决策理论关注确定以尽可能有价值的结果的最佳方式，考虑到我们拥有的价值观。在决策理论中，我们的价值观和目标被视为已知，分析关注如何以尽可能高的程度实现它们。决策理论中的一个主要主题是在风险和不确定性下进行决策。通常假设如果一组潜在结果的价值已知（例如来自道德哲学），那么纯粹的工具性考虑就足以确定在风险或不确定性下如何行动以实现最佳结果。（有关该假设的批判性讨论，请参见 Hansson 2013，49-51。）在决策理论分析中，所假定的价值可以是道德哲学中发展和分析的那种类型的道德价值观，但不一定是。

### 6.1 决策权重

决策理论传统上倾向于后果主义，其结构适用于大多数决策制定的形式模型。对于风险的标准决策理论方法是最大化预期效用，可以看作是（行为）功利主义的平滑扩展。在预期效用理论中，与不确定情况相关联的价值等于其所有可能结果的概率加权值的总和。设 p 为将概率分配给结果的函数，u 为将值分配给结果的函数。那么具有三个可能结果 x1、x2 和 x3 的情况的价值等于

p(x1)⋅u(x1)+p(x2)⋅u(x2)+p(x3)⋅u(x3)。

然而，已经提出了一些有影响力的替代决策规则。对于这种努力，有两种主要的证明方式。首先，已经提出了一些例子，其中声称期望效用最大化是唯一符合规范的决策规则似乎是不合理的（Allais 1953; Ellsberg 1961）。其次，许多心理实验表明，人类决策者往往会大大偏离期望效用最大化。第一种证明方式对期望效用的规范合理性提出了质疑，而第二种证明方式则揭示了其作为描述模型的不足之处。

在一类重要的替代决策规则中，期望效用计算中使用的概率被一些其他数字（"决策权重"）所取代。这种方法是由 William Fellner（1961）提出的。在这些构造中，所有的概率都通过某个转换函数 r 进行转换。代理人将最大化(p(x))⋅u(x)而不是最大化标准期望效用 p(x)⋅u(x)。

已经提出了几种具有这种结构的决策规则。最早的一种是 Handa（1977）。目前，这一传统中最著名的提案是前景理论（Kahneman 和 Tversky 1979; Tversky 和 Kahneman 1986），该理论的发展旨在比期望效用理论更准确地描述心理决策实验的观察结果。前景理论是一个相当复杂的理论，它在其他方面也与期望效用理论有所偏离。传统的关注点从结果转变为对损失和收益的关注，并且对待它们是不对称的。（另见第 7.3 节。）

如上所定义的函数 r 存在一个问题，即它产生的转换概率之和不会等于 1，除非 r 是恒等函数的平凡情况（Fishburn 1978）。为了解决这个问题，Quiggin（1982）引入了最大化预期效用的规则（也称为具有等级依赖概率的效用）。他没有将 p(x)替换为个体概率的函数 r(p(x))，而是将其替换为一个还取决于问题中涉及的其他概率和效用的函数。首先将结果从最差到最好进行排序，得到一个结果向量⟨x1,x2,…,xn⟩，使得 u(x1)≤u(x2)≤…≤u(xn)。然后可以为每个结果分配一个决策权重，考虑到其概率和在结果排序序列中的位置。由于具有相同概率的结果的决策权重可以不同，Fishburn 的平凡化结果在这里不适用。有证据表明，等级依赖效用模型可能比前景理论更符合实证（Harrison 和 Ross 2017）。

还有其他模型提出了用其他类型的决策权重替代期望效用最大化中的概率（Gilboa 和 Schmeidler 1994；Buchak 2014）。

### 6.2 悲观主义、谨慎主义和预防原则

在风险的决策理论分析中，区分两对与风险相关的概念非常重要：悲观主义与乐观主义，以及谨慎与冒险。

悲观主义和乐观主义涉及一个人对未来事件的价值相关信念模式。一个人对某种未来发展持悲观态度，是因为她给不希望的结果分配了比最可信分配更高的概率，并给希望的结果分配了比最可信分配更低的概率。她对某种未来发展持乐观态度，是因为她给希望的结果分配了比最可信分配更高的概率，并给不希望的结果分配了比最可信分配更低的概率。

谨慎（风险规避）和冒险（风险亲和）涉及一个人的决策和行动，而不是她的信念。在选择不同行动方案时，谨慎（风险规避）的人倾向于选择具有最小概率的最糟糕结果的方案。即使这样做会阻止她最大化选择的预期效用。相反，冒险的人寻找具有最佳结果高概率的选项，即使这样做会牺牲最大化选择的预期效用。（另见第 7.2 节。）

预防原则通常被认为是一种谨慎行事的一般指导。然而，这并不是通常所指的“预防原则”。这是一个在国际条约和欧洲立法中定义的原则。根据这些定义，预防原则涉及到当科学上合理怀疑对健康或环境存在风险，但证据不足以确凿地证明风险存在时，我们应该如何行动。预防原则指出，在这种情况下，我们可以，并且通常应该采取措施来防范潜在的危险。这个定义至少自 1992 年以来一直是标准，当时预防原则被包括在联合国的里约宣言和欧洲联盟的罗马条约中，现在被称为欧洲联盟的功能条约（Pyhälä等，2010）。其实际应用取决于对科学证据的解释，这些证据表明存在危险，但对科学家来说还不足以将该危险的存在视为已知。对这种证据的评估引发了需要进一步澄清的方法论和认识论问题，尤其是需要借助在科学哲学中发展起来的概念工具。

还有一个关于预防原则其他定义的哲学讨论仍在进行中。其中许多提议更接近于一般（决策理论）的谨慎性，而不是更狭义定义的法律概念（Munthe 2011）。

## 7. 风险在经济分析中

风险在经济活动中起着核心作用。在资本主义市场经济中，承担经济风险是企业家角色的重要组成部分。对于投资和金融市场活动的决策只能在涉及的风险背景下理解。因此，现代经济理论强调经济活动的数学模型，已经发展了几个形式化的风险模型，这并不令人意外。

### 7.1 经济风险的度量

投资组合分析是在 20 世纪 50 年代由哈里·马科维茨（Harry Markowitz，1952 年）、詹姆斯·托宾（James Tobin，1958 年）等人开发的，是风险经济分析的重要进展。这些作者采用了一个简单的统计度量，即标准差（或者是标准差的平方，即方差）作为风险的度量。因此，在两种投资选择之间的比较中，经济结果计算出具有最大标准差的那个被认为是最具风险的。在不同投资选择之间的比较中，每个选择都可以用两个数字来描述，即其期望值和标准差或风险度。投资者通常更喜欢期望值较高、风险度较低的投资。然而，投资者在对期望和风险规避的相对权重上存在差异。在给定这些决策权重的情况下，可以确定个人的最佳投资组合。

自 20 世纪 60 年代末以来，已经发展出了对风险的替代度量方法。其中最有影响力的可能是由迈克尔·罗斯柴尔德和约瑟夫·斯蒂格利茨（1970 年）提供的方法：如果我们将概率分布的质量从中心移到尾部，同时保持其均值不变，那么我们增加了与该分布相关的风险。可以构建基于这一原理的度量方法（保持均值的扩展），其数学性质比旧的标准差度量方法更具吸引力。

### 7.2 风险态度的度量方法

我们在对风险的态度上存在差异。我们中的一些人愿意承担其他人认为过大的风险。确定等价结果的概念可用于指定这种差异。考虑一个风险结果 X。如果且仅如果（1）Y 不涉及不确定性且（2）代理人认为 X 和 Y 同样好，那么另一个结果 Y 是 X 的确定等价结果。例如，假设 X 是一张彩票，有 50%的机会赢得你分配了 10 个效用单位（utiles）的东西，有 50%的机会一无所获。这张彩票的预期效用是 5 个 utiles。现在假设你对确定获得 3 个 utiles 和获得 X 之间持中立态度。那么你的态度是风险规避的。风险规避（风险回避，谨慎）的一般标准是 CE(X)<EU(X)。同样，如果 CE(X)=EU(X)，你对 X 持风险中立态度，如果 EU(X)<CE(X)，你对 X 持风险亲和态度（风险寻求，风险喜爱）。

在经济学中，风险规避通常与金钱有关。让 X 代表一张中奖几率为 50%、奖金为 100 欧元的彩票，假设你认为这张彩票价值 30 欧元。我们有 EU(X)=u(100)/2，CE(X)=u(30)。这意味着 u(30)=u(100)/2。如果这是一个一致的模式，那么在一个以金钱金额 x 为 x 轴、其效用 u(x)为 y 轴的图表中，金钱的效用将由一个凹（山形）曲线表示。同样，如果存在风险亲和行为，将由一个凸（谷形）曲线表示。假设效用函数 u 具有二阶连续可微性，这可以更精确地表示为风险规避/亲和的 Arrow-Pratt 风险度量，其中代理人在任意点 x 的风险规避程度等于−u′′(x)/u′(x)。因此，如果一个具有效用函数 u1 的人在某一点 x 上比一个具有效用函数 u2 的人更加风险规避，那么当且仅当−u1′′(x)/u1′(x)>−u2′′(x)/u2′(x)（Arrow 1965; Pratt 1964）。Arrow-Pratt 度量具有一个优点，即它在保持所代表的偏好关系的效用函数变换下是不变的（即在效用与正常数的乘法和任意常数的加法下是不变的）。另一方面，可以从哲学的角度质疑风险态度是否可以充分地通过金钱效用的变化来表示。可以认为谨慎和金钱效用是两个独立的问题，因此它们应该有独立的表示方式。

### 7.3 实验经济学

实验经济学研究表明，实际代理人通常不符合理论推导的理性标准。一种最受欢迎的描述性理论试图捕捉风险下的实际行为，即前景理论，该理论由丹尼尔·卡尼曼和阿莫斯·特沃斯基于 1980 年左右开发（卡尼曼和特沃斯基，1979 年；特沃斯基和卡尼曼，1986 年）。它区分决策过程中的两个阶段。在第一阶段，即编辑阶段，确定了不同选项中的收益和损失。它们相对于某个中性参考点进行定义，通常是当前资产位置。在第二阶段，即评估阶段，以类似于预期效用分析的方式评估选项，但效用和概率都被其他类似的度量替代。效用被一种在收益和损失之间不对称的度量所取代。客观概率通过一个函数进行转换，该函数在分布的两端附近给予概率差异更大的权重，而不是在分布的中心附近。因此，将负面结果的概率从 2%降低到 1%比将其从 51%降低到 50%产生更大的差异。

前景理论可以解释实际行为与标准经济模型下的理性行为在风险下的偏离方式。因此，接近零或接近一的概率变化被过度加权，可以解释为什么人们既购买保险又购买彩票。然而，前景理论不太可能作为风险下理性行为的规范理论。可能，风险的规范理论和描述性理论将不得不朝不同的方向发展。

### 7.4 风险-效益分析

风险效益分析（RBA），也称为成本效益分析（CBA），是一种将优势与劣势以数值方式进行权衡的决策辅助技术集合。在典型的风险效益分析中，多维问题被简化为单一维度。这是通过为所有潜在结果分配货币价值来实现的。通常，不确定的结果根据预期效用模型进行评估。这意味着通过将不希望事件发生的概率乘以代表其严重程度的货币价值来获得风险的负价值（Sen 2000; Sunstein 2005）。

为了使整体替代方案能够以简单的数值方式进行比较，包括人员生命损失在内的所有后果都必须被赋予货币价值。关于为人的生命赋予货币价值的讨论似乎起源于美国空军对兰德公司 1950 年的一份报告的批评。该报告推荐了一种军事战略，其结果是机组成员的死亡率被军方认为是无法接受的高。这是因为在计算中没有包括机组成员的损失。这个遗漏产生了将士兵的生命价值设定为零的效果。作为对批评的回应，兰德公司开始在他们的分析中包括生命价值，但是他们在推导这个价值时遇到了相当大的困难（Banzhof 2014）。他们的员工托马斯·谢林提出，生命价值应该从个体对死亡风险的边际分析中得出（Schelling 1968）。如果一个人愿意接受 1/10,000 的死亡风险，以换取 400 或 4,000,000 美元的补偿。

风险效益分析的大部分哲学讨论都集中在将人类生命的损失赋予货币价值上（MacLean 1994; Heinzerling 2000; 2002）。有人声称生命和金钱是无法比较的，并且确定和使用这种“生命价值”表达了对人类生命的不尊重。风险效益分析的支持者反驳说，这些价值只是代表社会倾向于支付（或应该支付）以拯救人类生命的技术构建物。风险效益分析可以帮助决策者在他们可以分配给拯救生命政策的固定资源下尽可能拯救更多的生命（Sunstein 2005）。

成本效益分析中使用的许多价值赋值都是基于（假设的）支付意愿的估计或测量。这样的估计将更多地影响富裕人群，因为他们可以支付比其他人更多的费用来按照自己的方式行事。可以通过根据收入进行调整来纠正这一点，以报告的支付意愿。然而，在支付意愿研究的执行和解释中存在相当大的问题（Grüne-Yanoff 2009）。

风险效益分析引发了一些其他具有相当哲学兴趣的哲学问题（Hansson 2007）。由于其定量性质，它往往忽略了难以量化的问题，例如文化贫困、社会孤立和社会阶层之间的紧张关系。此外，由于其聚合结构，风险效益分析通常忽略了社会公正和其他分配方面的问题，尽管这些问题实际上可以进行定量处理。

<!--md-padding-ignore-begin-->
## Bibliography

* Allais, M., 1953, “Le comportement de l’homme rationnel devant le risque: critique des postulats et axiomes de l’école Américaine”, *Econometrica*, 21: 503–546.
* Allhoff, F., 2009, “Risk, Precaution, and Emerging Technologies”, *Studies in Ethics, Law, and Technology*, 3(2), published online 25 June, 2009. doi:10.2202/1941-6008.1078
* Arrow, K.J., 1965, *Aspects of the Theory of Risk-Bearing. Yrjö Jahnsson Lectures*. Helsinki: Yrjö Jahnssonin Säätiö.
* Banzhaf, H.S., 2014, “Retrospectives: the Cold-War origins of the value of statistical life”, *Journal of Economic Perspectives* 28(4): 213–26.
* Biddle, J.B., 2016, “Inductive risk, epistemic risk, and overdiagnosis of disease”, *Perspectives on Science* 24(2): 192–205.
* Boholm, M. et al., 2016, “The Concepts of Risk, Safety, and Security: Applications in Everyday Language.”, *Risk Analysis* 36 (2): 320–338.
* Buchak, L., 2014, *Risk and Rationality*, Oxford: Oxford University Press.
* Caney, S., 2009, “Climate Change and the Future: Discounting for Time, Wealth, and Risk”, *Journal of Social Philosophy*, 40(2): 163–186.
* Cranor C., 1997, “The Normative Nature of Risk Assessment: Features and Possibilities”, *Risk: Health, Safety & Environment*, 8: 123–36.
* –––, 2005. “The Science Veil Over Tort Law Policy: How Should Scientific Evidence Be Utilized in Toxic Tort Law?”, *Law and Philosophy*, 24(2): 139–210.
* –––, 2016, *Toxic Torts: Science, Law and the Possibility of Justice* (second edition), Cambridge: Cambridge University Press.
* –––, 2017, *Tragic Failures: How and Why We Are Harmed by Toxic Chemicals*, Oxford: Oxford University Press, 2017.
* Doorn, N., and S.O. Hansson, 2015, “Design for the value of safety”, in J. van den Hoven, I. van de Poel, and P. Vermaas (eds), *Handbook of Ethics, Values and Technological Design*, Dordrecht: Springer, 491–511.
* Dourson, M.L., & Stara, J.F., 1983, “Regulatory history and experimental support of uncertainty (safety) factors”, *Regulatory Toxicology and Pharmacology* 3(3): 224–238.
* Ellsberg, D., 1961, “Risk, Ambiguity, and the Savage Axioms”, *Quarterly Journal of Economics*, 75: 643–669.
* Fellner, W. 1961, “Distortion of subjective probabilities as a reaction to uncertainty”, *Quarterly Journal of Economics*, 75: 670–689.
* Ferretti, M.P., 2010, “Risk and Distributive Justice: The Case of Regulating New Technologies”, *Science and Engineering Ethics*, 16(3): 501–515.
* Fishburn, P.C., 1978, “On Handa’s ‘New theory of cardinal utility’ and the maximization of expected return”, *Journal of Political Economy*, 86: 321–324.
* Gigerenzer, G., 2002, *Calculated Risks: How to Know When Numbers Deceive You*, New York: Simon and Schuster.
* Gilboa, I. and D. Schmeidler, 1994, “Additive representations of non-additive measures and the Choquet integral”, *Annals of Operations Research*, 52: 43–65.
* Goodwin, W., 2009, “How Does the Theologizing of Physics Contribute to Global Warming?”, *Environmental Philosophy*, 6(2): 21–42.
* Gordijn, B., 2005, “Nanoethics: From Utopian Dreams and Apocalyptic Nightmares Towards a More Balanced View”, *Science and Engineering Ethics*, 11(4): 521–533.
* Grüne-Yanoff, T., 2009, “Mismeasuring the Value of Statistical Life”, *Journal of Economic Methodology*, 16 (2): 109–123.
* Handa, J., 1977, “Risk, probabilities, and a new theory of cardinal utility”, *Journal of Political Economy*, 85: 97–122.
* Hansson, S. O., 2003, “Ethical criteria of risk acceptance”, *Erkenntnis*, 59: 291–309.
* –––, 2004, “Weighing Risks and Benefits”, *Topoi*, 23: 145–152.
* –––, 2006, “Economic (ir)rationality in risk analysis”, *Economics and Philosophy*, 22: 231–241.
* –––, 2007, “Philosophical Problems in Cost-Benefit Analysis”, *Economics and Philosophy* 23: 163–183.
* –––, 2013, *The Ethics of Risk: Ethical analysis in an uncertain world*, New York: Palgrave MacMillan.
* –––, 2017, “Science denial as a form of pseudoscience”, *Studies in History and Philosophy of Science*, 63:39–47.
* Harrison, G.W. and D. Ross, 2017, “The empirical adequacy of cumulative prospect theory and its implications for normative assessment”, *Journal of Economic Methodology*, 24: 150–165.
* Harsanyi, J.C., 1953, “Cardinal utility in welfare economics and in the theory of risk-taking”, *Journal of Political Economy*, 61: 434–435.
* Harsanyi, J.C., 1955, “Cardinal welfare, individualistic ethics, and interpersonal comparisons of utility”, *Journal of Political Economy*, 63: 309–321.
* Harsanyi, J.C., 1975, “Can the maximin principle serve as a basis for morality? A critique of John Rawls’s theory”, *American Political Science Review*, 69: 594–606.
* Heinzerling, L., 2000, “The rights of statistical people.”, *Harvard Environmental Law Review* 24: 189–207.
* –––, 2002, “Markets for arsenic”, *Georgetown Law Journal*, 90: 2311–2339.
* Hempel, C.G., 1965, *Aspects of scientific explanation, and other essays in the philosophy of science*, New York: Free Press.
* Heyward, C., and D. Roser (eds.), 2016, *Climate Justice in a Non-Ideal World*, Oxford: Oxford University Press.
* Intemann, K., 2015, “Distinguishing Between Legitimate and Illegitimate Values in Climate Modeling.”, *European Journal for Philosophy of Science*, 5(2): 217–232.
* Jellinek, S. D., 1981, “On The Inevitability Of Being Wrong”, *Annals of the New York Academy of Science*, 363: 43–47.
* John, S., 2017, “From Social Values to P-Values: The Social Epistemology of the Intergovernmental Panel on Climate Change”, *Journal of Applied Philosophy*, 34 (2): 157–171.
* Kahneman, D. and A. Tversky 1979, “Prospect theory: An analysis of decision under risk”, *Econometrica*, 47: 263–293.
* Kermisch, C., 2012, “Risk and Responsibility: A Complex and Evolving Relationship”, *Science and Engineering Ethics*, 18(1): 91–102.
* Lemons, J., et al., 1997, “The Precautionary Principle: Scientific Uncertainty and Type I and Type II Errors”, *Foundations of Science*, 2(2): 207–236.
* Lewandowsky, S., J. Cook & E. Lloyd, 2018, “The ‘Alice in Wonderland’ Mechanics of the Rejection of (Climate) Science: Simulating Coherence by Conspiracism”, *Synthese* 195 (1):175–196.
* MacLean, D. (ed.), 1986, *Values at Risk* (Maryland Studies in Public Philosophy), Totowa, NJ: Rowman and Littlefield.
* –––, 1994, “Cost-benefit analysis and procedural values”, *Analyse & Kritik*, 16(2): 166–180.
* Machina, M.D. and M. Rothschild, 1987, “Risk”, in J. Eatwell, M. Milgate, and P. Newman (eds.), *The New Palgrave: A Dictionary of Economic Theory and Doctrine* (Volume 4), London and New York: Macmillan and Stockton, pp. 201–205.
* Macpherson, J.A.E., 2008, “Safety, Risk Acceptability, and Morality”, *Science and Engineering Ethics*, 14(3): 377–390.
* Markowitz, H.M., 1952, “Portfolio Selection”, *Journal of Finance*, 7(1): 77–91.
* Mayer, L. et al., 2017, “Understanding Scientists’ Computational Modeling Decisions About Climate Risk Management Strategies Using Values-Informed Mental Models”, *Global Environmental Change* 42:107–116.
* McKerlie, D., 1986, “Rights and Risk”, *Canadian Journal of Philosophy*, 16: 239–52.
* McKinney, W.J., 1996, “Prediction and Rolston’s Environmental Ethics: Lessons From the Philosophy of Science”, *Science and Engineering Ethics*, 2(4): 429–440.
* Möller, N. and S.O. Hansson, 2008, “Principles of engineering safety: risk and uncertainty reduction”, *Reliability Engineering and System Safety*, 93: 776–783.
* Munthe, Christian, 2011, *The Price of Precaution and the Ethics of Risk*, Dordrecht: Springer.
* Ng, Y.-K., 2005, “Intergenerational Impartiality: Replacing Discounting by Probability Weighting”, *Journal of Agricultural and Environmental Ethics*, 18(3): 237–257.
* Nozick, Robert, 1974, *Anarchy, State, and Utopia*, New York: Basic Books.
* Oberdiek, J., 2014, *Imposing Risk: A Normative Framework*, Oxford: Oxford University Press.
* Pratt, J. W., 1964, “Risk Aversion in the Small and in the Large”, *Econometrica*, 32: 122–136.
* Pressman, P., R. Clemens, W. Hayes, & C. Reddy, 2017, “Food additive safety: A review of toxicologic and regulatory issues”, *Toxicology Research and Application* 1:1–22.
* Pritchard, D., 2015, “Risk”, *Metaphilosophy*, 46(3): 436–461.
* –––, 2016, “Epistemic risk”, *Journal of Philosophy* 113(11): 550–571.
* Prothero, D., 2013, “The Holocaust Denier’s Playbook and the Tobacco Smokescreen: Common Threads in the Thinking and Tactics of Denialists and Pseudoscientists”, pp. 341–358 in M. Pigliucci and M. Boudry (eds), *Philosophy of Pseudoscience. Reconsidering the demarcation problem*, Chicago: University of Chicago Press.
* Pyhälä, M., A.C. Brusendorff & H. Paulomäki, 2010, “The precautionary principle”, pp. 203–226 in M. Fitzmaurice, D. M. Ong & P. Merkouris (eds.), *Research Handbook on International Environmental Law*. Cheltenham: Edward Elgar.
* Quiggin, J., 1982, “A theory of anticipated utility”, *Journal of Economic Behavior & Organization*, 3: 323–343.
* Rasmussen, Norman, *et al*., 1975, “Reactory Safety Study”, *WASH-1400*, Washington, DC: US NRC.
* Rawls, J., 1957, “Justice as Fairness”, *Journal of Philosophy*, 54: 653–662.
* –––, 1971, *A Theory of Justice*, Cambridge, Mass.: Harvard University Press.
* –––, 1974, “Some Reasons for the Maximin Criterion”, *American Economic Review*, 64: 141–146.
* Rechard, R.P., 1999, “Historical relationship between performance assessment for radioactive waste disposal and other types of risk assessment”, *Risk Analysis*, 19(5): 763–807.
* Rothschild, M. and J. Stiglitz, 1970, “Increasing risk: 1. A definition”, *Journal of Economic Theory*, 2: 225–243.
* Scanlon, T.M., 1982, “Contractualism and Utilitarianism,” in A. Sen and B. Williams, *Utilitarianism and Beyond*, Cambridge: Cambridge University Press.
* Schelling, T.C., 1968, “The Life You Save May Be Your Own”, in *Problems in Public Expenditure Analysis*, S.B. Chase, Jr. (ed.), 127–162. Washington, DC: Brookings Institution.
* –––, 1996, “Research By Accident”, *Technological Forecasting And Social Change*, 53: 15–20.
* Sen, A., 2000, “The discipline of cost-benefit analysis”, *Journal of Legal Studies*, 29: 931–952.
* Shrader-Frechette, K., 1991, *Risk and Rationality. Philosophical Foundations for Populist Reforms*, Berkeley: University of California Press.
* –––, 1997, “Hydrogeology and Framing Questions Having Policy Consequences”, *Philosophy of Science* (Supplement), 64: S149–S160.
* –––, 2005, “Flawed Attacks on Contemporary Human Rights: Laudan, Sunstein, and the Cost-Benefit State”, *Human Rights Review*, 7(1): 92–110.
* –––, 2005, *Environmental Justice: Creating Equality, Reclaiming Democracy*, New York: Oxford University Press.
* Sjöberg, L., 2004, “The Methodology of Risk Perception Research”, *Quality and Quantity*, 34: 407–418.
* Sunstein, C.R., 2005, “Cost-Benefit Analysis and the Environment”, *Ethics*, 115: 351–385.
* Thompson, P. B., 1985, “Risking or Being Willing: Hamlet and the DC-10”, *Journal of Value Inquiry*, 19: 301–310.
* Thomson, J.J., 1985, “Imposing Risks”, in *To Breathe Freely*, Mary Gibson (ed.), Totowa, NJ: Rowman and Allanheld, 124–140.
* –––, 1986, *Rights, Restitution and Risk: Essays in Moral Philosophy*, Cambridge, Mass.: Harvard University Press.
* Tobin, J., 1958, “Liquidity preference as behavior towards risk”, *Review of Economic Studies* 25(2): 65–86.
* Tversky, A. and D. Kahneman, 1986, “Rational Choice and the Framing of Decisions”, *Journal of Business*, 59: 251–278.
* van den Belt, H. and B. Gremmen., 2002, “Between Precautionary Principle and ‘Sound Science’: Distributing the Burdens of Proof.”, *Journal of Agricultural and Environmental Ethics*, 15(1): 103–122.
* van de Poel, I., et al., 2012, “The Problem of Many Hands: Climate Change as an Example”, *Science and Engineering Ethics*, 18(1): 49–67.
* Wagner, W. E., 1995, “The Science Charade In Toxic Risk Regulation”, *Columbia Law Review*, 95: 1613–1723.
* Weinberg, A. M., 1972, “Science and Trans-Science”, *Minerva*, 10: 209–222.
* Wetmore, J.M., 2008, “Engineering with Uncertainty: Monitoring Air Bag Performance”, *Science and Engineering Ethics*, 14(2): 201–218.

## Academic Tools

> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=risk). |
> | --- | --- |
> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/risk/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
> | ![inpho icon](https://plato.stanford.edu/symbols/inpho.png) | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=risk&redirect=True) at the Internet Philosophy Ontology Project (InPhO). |
> | ![phil papers icon](https://plato.stanford.edu/symbols/pp.gif) | [Enhanced bibliography for this entry](https://philpapers.org/sep/risk/) at [PhilPapers](https://philpapers.org/), with links to its database. |

## Other Internet Resources

[Please contact the author with suggestions.]

## Related Entries

[causation: in the law](https://plato.stanford.edu/entries/causation-law/) | [causation: probabilistic](https://plato.stanford.edu/entries/causation-probabilistic/) | [consequentialism](https://plato.stanford.edu/entries/consequentialism/) | [contractarianism](https://plato.stanford.edu/entries/contractarianism/) | [economics: philosophy of](https://plato.stanford.edu/entries/economics/) | [game theory](https://plato.stanford.edu/entries/game-theory/) | [luck: justice and bad luck](https://plato.stanford.edu/entries/justice-bad-luck/) | [scientific knowledge: social dimensions of](https://plato.stanford.edu/entries/scientific-knowledge-social/) | [technology, philosophy of](https://plato.stanford.edu/entries/technology/)

[Copyright © 2022](https://plato.stanford.edu/info.html#c) by  
[Sven Ove Hansson](http://people.kth.se/~soh/) <[*soh@kth.se*](mailto:soh%40kth%2ese)>
<!--md-padding-ignore-end-->
