# 基于逻辑的人工智能 logic-based (Richmond Thomason)
*首次发表于 2003 年 8 月 27 日；实质性修订于 2024 年 2 月 27 日*

人工智能（以下简称“AI”）是计算机科学的一个子领域，致力于开发能够展示智能行为的程序。[1]

在 AI 的早期阶段，许多具有影响力的人物都有雄心勃勃的目标和观点。约翰·麦卡锡的计划是利用哲学逻辑的思想来形式化常识推理。在他的一生中，他和他的学生和合作者进行了一些具有明显哲学特色的项目。这个主题一直存在，但大部分已经融入到知识表示的工作中。它变得更加直接与应用相关；与哲学和哲学逻辑的联系仍然存在，但更加脆弱。

从 AI 中产生的新的见解和理论在任何涉及推理的哲学研究领域都具有巨大的潜在价值，例如关于该做什么的推理，或者关于我们自己的态度或他人的态度的推理。虽然 AI 中的逻辑起源于哲学逻辑，但在这个新的环境中，它产生了新的理论和雄心勃勃的计划，这些计划只有在致力于构建工作的大规模计算模型的社区中才能得到培育。

这个条目假设主要是哲学家的受众，他们对人工智能几乎没有了解。它集中讨论了在机械推理系统中使用逻辑来理解智能推理时出现的问题。它提供了一个选择性的概述，而不试图实现完全覆盖。第 3 和第 4 节描述了早期出现并持续至今的两个重要主题：非单调逻辑和关于行为和变化的推理。其余部分概述了选定的主题，并参考了主要文献。

---

## 1. 人工智能中的逻辑

### 1.1 逻辑在人工智能中的作用

理论计算机科学起源于逻辑学、计算理论（如果将其视为与逻辑学不同的学科）以及相关的数学领域。因此，大多数计算机科学家对逻辑学有很好的了解，即使他们不是逻辑学家。他们熟悉逻辑提供的分析语言推理属性的技术，并了解高层次逻辑分析推理问题及其实现之间的区别。例如，逻辑可以通过将程序映射到应该许可的计算并启用证明这些计算符合某些标准来为编程语言提供规范。

然而，逻辑与计算机程序之间的联系通常没有这么紧密。当一个软件应用程序在可证明的情况下是完备且正确的时，可以说它实现了逻辑形式化，但也可以说当逻辑思想影响了软件开发过程的某些部分时。一个被认为实现了逻辑模型的程序可能是不完整的，甚至是不正确的。

有时，工作系统的某些部分受到逻辑思想的启发，而其他部分似乎存在逻辑问题。这些具有挑战性的特征可能会提出对逻辑理论的改进建议。因此，逻辑理论为应用提供了指导，而应用则挑战逻辑理论并可能导致理论创新。逻辑编程提供了许多此类互动的示例。

即使是有限目标的推理系统也可能需要大量复杂的陈述性信息。在人工智能领域，普遍认识到将陈述性表示与其检索、维护以及为其服务的推理系统作为独立的项目进行处理是很重要的，每个项目都有自己的研究问题。专家系统的发展说明了这一点。最早的专家系统完全基于大型的过程规则系统，没有对背景知识进行单独的表示。但是后一代的专家系统在设计上显示出更高的模块化。一个独立的知识表示组件对于软件工程目的非常有用——拥有一个通用事实的单一表示形式，能够有多种不同的用途，并且使系统更易于开发和修改。这种模块化对于使这些系统能够提供解释而不仅仅是结论是至关重要的。[3]

为了设计这个陈述性组件，人工智能的一个子领域——知识表示在 20 世纪 80 年代出现了。自 1989 年以来，专门讨论这个主题的会议已经举行了，这些会议提供了该领域研究的深入记录。请参阅第 12 节，了解会议记录的列表。

KR 和推理会议上的典型演讲涉及以下主题。

1. 基于逻辑的理论和计算理论中的主题，包括
2. 非单调逻辑
3. 复杂性理论
4. 应用领域的研究，包括
5. 时间推理
6. 用于规划、行动和变化以及因果推理的形式化方法
7. 元推理
8. 对上下文的推理
9. 对价值和欲望的推理
10. 对其他行为体的心理状态进行推理，尤其是对知识和信念的推理
11. 空间推理
12. 对模糊性进行推理
13. 论证和论证理论
14. 各种聚合问题，例如对冲突知识来源的整合
15. 应用技术研究，包括基于逻辑的技术
16. 基于逻辑的编程
17. 描述逻辑
18. 定理证明
19. 模型构建
20. 大规模应用研究，包括
21. 认知机器人学
22. 创建、合并、更新和纠正知识库
23. 查询知识库

这些主题与《符号逻辑杂志》的内容几乎没有共同之处，该杂志是数理逻辑的主要记录期刊。但是与《哲学逻辑杂志》存在很大的重叠，特别是在时态逻辑、认知逻辑、逻辑方法与实际推理以及信念变化等主题上。当然，也存在一些差异；《哲学逻辑杂志》的出版物很少涉及复杂性理论或潜在的自动推理应用。

### 1.2 哲学逻辑

成立于 1936 年，JSL 旨在将数学家和哲学家在逻辑领域的研究汇集在一起。第一卷中的文章在专业数学家和哲学家之间几乎平均分配，并且早期的卷册在主题上没有显示出两个群体之间的明显差异。

这种情况在 1960 年代发生了变化。1969 年的 JSL 卷册中有 39 篇数学家的文章，只有 9 篇哲学家的文章。到了 1970 年代初，许多哲学家认为 JSL 不太可能接受关于逻辑的哲学论文，并且被接受的论文也不太可能被哲学家阅读。此时，这两个群体已经明显分道扬镳。数学家追求越来越技术化和复杂化的方法和定理体系的发展，而许多哲学家认为这种趋势对哲学没有启示意义，也与哲学无关。这些分歧导致了 1972 年《哲学逻辑学杂志》的创刊。第一期中的样本主题包括：

1. 直接与哲学问题相关的逻辑理论分支的贡献，例如归纳逻辑、模态逻辑、义务逻辑、量子逻辑、时态逻辑、自由逻辑、问题逻辑、命令逻辑、偏好逻辑、条件逻辑、多值逻辑、相关逻辑；
2. 利用形式逻辑工具进行哲学讨论的贡献...；
3. 关于逻辑和语言的逻辑结构的哲学问题的讨论...；
4. 与特殊科学相关的哲学作品，....

这里的共同线索是希望将数学逻辑的方法应用于非数学领域。例如，量子逻辑和归纳逻辑将逻辑应用于物理学和经验科学。JPL 列表中的其他主题涉及逻辑发展，可能有助于解决非科学推理问题。

### 1.3 AI 中的逻辑和哲学逻辑

1959 年的麦卡锡（McCarthy）是逻辑人工智能的早期贡献，讨论了如何到达机场的问题。在这里，麦卡锡提出了一个现实的推理问题。它的解决方案可能涉及许多相关的推理，尽管最终它可能看起来像一个证明——证明执行某些动作将产生一个某人位于机场的结果——但它与数学练习不同，因为它利用了更广泛且不易处理的资源。这些资源包括因果知识以及目标和偏好。相比之下，哲学逻辑的研究论文使用推理示例来说明，而不是激发逻辑理论和他们引用的推理示例是简单的、孤立的推理。

将早期的逻辑人工智能工作描述为致力于一个新的、雄心勃勃的应用领域的哲学逻辑是不太准确的。事实上，AI 逻辑学家的第一代[4]阅读了哲学逻辑的文献并受其影响。然而，随后这两个专业分道扬镳。在逻辑人工智能领域出现了新的逻辑理论（非单调逻辑是最重要的例子），这些理论并未出现在哲学家的思考中。AI 社区对算法的理论分析以及有用技术的兴趣是其他差异的原因。AI 研究人员经常关注使用前所未有的大量数据和推理规则的雄心勃勃的应用。它们的规模之大产生了新的问题和新的方法论。另一方面，哲学逻辑学家是哲学家，因此他们通常对计算机科学家不感兴趣的主题（例如形而上学主题）感兴趣。

如果哲学逻辑和人工智能中的逻辑继续分道扬镳，可能是出于这样的方法论原因。但尽管如此，基础研究目标是相同的——逻辑人工智能是受到大规模形式化和可行性、可实现性推理的兴趣限制的哲学逻辑。

哲学逻辑对人工智能中的逻辑产生了深远影响。麦卡锡和海耶斯在 1969 年发表的《逻辑人工智能》一文的参考文献清单很好地说明了这一点。参考文献中有 58 个引用，其中 35 个引用了哲学逻辑文献。（其中有 17 个计算机科学引用，一个数学逻辑引用，一个经济学引用和一个心理学引用。）这篇论文是在几乎没有计算机科学文献中提到逻辑人工智能的时候写的。当然，随着逻辑人工智能作为计算机科学的一个分支成熟和发展，跨学科引用的比例已经减少。从 1989 年举办的第一届知识表示会议（Brachman 等人，1989）的文章样本中，只有 12 个哲学逻辑引用，总共有 522 个样本引用。从 Cohn 等人的 1998 年文章样本中，有 23 个哲学逻辑引用，总共有 468 个样本引用。[5]

尽管明确引用数量大幅减少，但逻辑人工智能后期文献反映了对哲学逻辑的间接了解，通过引用直接受哲学工作影响的计算机科学会议论文。当然，随着时间的推移，这种影响变得越来越微弱，而且这一趋势加速了新的理论主题在逻辑人工智能中的发展，这些主题在哲学文献中只能模糊地预示。在欧洲，很难在逻辑学家之间划定专业分工的界限。一些欧洲期刊，尤其是《逻辑、语言和信息学杂志》和《逻辑研究》杂志，在保持逻辑焦点的同时，吸引了来自逻辑所涉及的各个学科的作者。

归根结底，逻辑处理的是推理问题，而我们所做的推理中数学内容相对较少，而非数学专业人士所做的几乎所有数学推理都只是计算而已。为了具有范围和严谨性，逻辑需要作为一个单一学科维持下去，将其数学和哲学两个方面统一起来。但计算机科学的需求为这种统一增添了强大的动力，提供了一种新的方法论和与新的有益应用相关的关系。

## 2. 约翰·麦卡锡和常识逻辑主义

### 2.1 基于逻辑的人工智能

约翰·麦卡锡是逻辑人工智能领域最有影响力的人物，至今仍然如此。麦卡锡是人工智能的创始人之一，并一直主张逻辑形式化是实现人类水平人工智能的途径。麦卡锡研究计划中的几乎所有工作都可以在 Lifschitz 1990a 中找到，该书还包含 Lifschitz 1990b，对麦卡锡的工作进行了介绍。有关更多历史背景，请参阅 Israel 1991。

麦卡锡的观点首次在麦卡锡 1959 年的论文中得到阐述，并在麦卡锡和海耶斯 1969 年的论文中进行了详细阐述和修正。他认为，即使人工智能的实现不直接使用像定理证明这样的逻辑推理技术，逻辑形式化也有助于理解推理问题本身。该观点是，如果没有对推理领域进行逻辑解释，将无法实现推理本身。这实际上是有争议的。许多人工智能研究人员认为在他们的工作中不需要逻辑形式化。例如，机器学习的产品通常与逻辑没有明显的关系，而是依赖于训练语料库和累积学习经验的组合。在声明性、概念层面上，没有明显的方式来描述或理解它们，它们与逻辑的关系也是有问题的。

McCarthy＆Hayes 1969 年的建议在很大程度上与分析哲学的建议重叠，但其目标不同：可编程的通用智能而不是概念分析。一些哲学家也有类似的目标；例如，参见 Carnap 1956 年（第 244-247 页）和 Pollock 1995 年。

假设本文的大多数读者对逻辑人工智能与哲学逻辑之间的关系感兴趣，本文的其余部分将忽略与哲学总论以及开发人类级智能系统的可行性的关系。

### 2.2 常识的形式化

麦卡锡的长期目标是形式化常识推理，即人类在日常问题上进行思考的非科学推理。我们已经提到了一个规划问题：如何去机场。其他例子包括：

1. 叙事理解。从叙述中重建隐含信息的推理，例如事件的顺序和推断的因果关系。
2. 诊断。例如，根据观察解释物理设备的故障。
3. 空间推理。例如，推理刚体的部分及其形状，以及它们与整体形状的关系。
4. 推理其他行为体的态度。例如，根据“窥视观察”或短暂互动访谈中的对话线索，对其他行为体的信念和欲望进行知情猜测。

麦卡锡的目标对大多数哲学家来说可能看起来是荒谬的，因为他们接受的训练使他们认为常识是难以捉摸和不连贯的。但哲学家在哲学争议中引用常识，其中常识的运用是有问题的。麦卡锡考虑的是日常实际的常识。如果在这些情境中常识不可靠，我们将无法应对简单的日常任务。形式化支持这些任务的推理可能是不切实际的，但这个项目本身既不是误导的，也不是狂想的。

无论形式化是否是实现人级 AI 的秘密，它在较小规模上已经取得了成功——不仅在非实体环境中[6]，而且在在线机器人规划和执行中也是如此。它被用于一些完全自主的代理方法[7]。它在多智能体系统中起着重要作用，其中沟通和推理知识至关重要[8]。它还阐明了对物理设备行为的定性推理[9]。

## 3. 非单调推理和非单调逻辑

### 3.1 非单调性

虽然数学证明必须涵盖每一种可能性，但实际推理常常忽视一些可能性。考虑到达机场的计划。它可能会受到地震、陨石撞击或高速公路事故的阻碍。但忽略前两个因素是完全合理的，甚至第三个因素通常也可以安全地忽略。接受一个计划，与接受一个证明不同，是有风险的。事实上，风险和可能出现不愉快的意外是合乎常识推理的特点。这意味着推理是非单调的。

古典逻辑是以数学为目标设计的，它们的推理关系是单调的。也就是说，如果一组公式蕴含一个结果，那么一个更大的集合也将蕴含这个结果。如果一个逻辑的推理关系缺乏这个属性，那么它就是非单调的。首选模型提供了一种引导非单调推理关系的一般方法。调用一个函数，对于每个 ，产生的模型的子集；一般来说，我们期望是这些模型的一个真子集。然后我们说如果每个模型都满足 。只要我们不假设如果 ，那么蕴含关系就是非单调的。

不确定性不是忽视某种可能性的唯一原因。其他原因包括：（1）对正常和通常情况的感觉；（2）认识上的可原谅性——免于忽视可能性所带来的任何责备；（3）进一步思考的估计成本；以及（4）不注意和纯粹的认知懒惰。其中一些可能比其他因素更“理性”，但事实上很难确定理性和非理性因素之间的界限。可能没有人成功地阐明和梳理这些激发考虑的因素。

在其发展的早期阶段，许多研究人员希望非单调逻辑能够提供一种关于不确定性的高效推理的通用方法。但到了 20 世纪 80 年代末，完全定量的概率推理不仅可以实施，而且在许多应用中明显优于涉及非单调逻辑的方法。非单调性并不是高效推理的魔法路径。它在推理不确定性方面可能有用。但概率也可以。

### 3.2 开始

1980 年出现了三篇有影响力的非单调逻辑论文：McDermott＆Doyle 1980 年，Reiter 1980 年和 McCarthy 1980 年。在每种情况下，这些论文中提出的形式主义都经过了数年或更长时间的孕育期。要准确地阐述历史影响，需要对作者进行采访，但这尚未完成。然而，似乎存在两个激励因素：与人工智能的长期目标有关的战略考虑，以及从 20 世纪 70 年代部署的推理系统的分析中产生的更具体的战术考虑。

第 3.1 节解释了为什么人们普遍认为单调性使得经典逻辑不适合作为形式化常识推理的工具。Minsky 1974 年的论文在发表时广泛阅读，帮助形成了这种态度。Minsky 的论文提出了一系列人工智能的挑战，首先关注自然语言理解的问题。[10]他提倡“基于框架”的知识表示技术[11]，并将其视为逻辑的替代方案，他提出了一些与逻辑方法 loosley 相关的挑战，包括以下问题：构建大规模表示、高效推理、表示控制知识以及提供灵活的可废除信念的修订。回顾起来，大多数人工智能研究人员可能会同意这些问题是任何研究计划（包括当时 Minsky 本人提倡的计划）所面临的普遍挑战，并且会补充说逻辑技术是解决某些甚至所有问题的重要因素。例如，良好结构化的逻辑设计可以在扩展任何计算上有用的知识体系方面提供很大帮助。

或许无意中，Minsky 的论文通过将单调性视为逻辑的所谓缺点的源头，激励了非单调逻辑学家。尽管 Minsky 显然意图贬低人工智能中的逻辑方法，但 McDermott＆Doyle 1980 年和 McCarthy 1980 年将他的批评解释为一种挑战，即通过开发不具备单调性属性的逻辑来应对。

非单调逻辑的发展也在很大程度上归功于人工智能应用的需求。实际上，这种影响力至少与麦卡锡的战略考虑一样有说服力，并且在形成出现的形式主义方面更具影响力。在这里，我们提到了三个似乎对早期非单调逻辑学家至关重要的应用：信念修正、封闭世界推理和规划。

#### 3.2.1 信念修正

1979 年，多伊尔提出了一种“真值维护系统”。多伊尔的真值维护算法满足了一种普遍需求，为知识库的“信念”更新提供了一种机制。其思想是跟踪信念的支持，并在需要修正信念时使用这些支持依赖的记录。

在 TMS 中，支持一个信念的一部分可以是其他信念的缺席。这引入了非单调性。例如，它提供了默认值：由相反信念的缺席引发的信念。

TMS 算法及其改进对 AI 应用产生了重大影响，这就需要进行逻辑分析。（即使在相当简单的情况下，如果没有分析工具，很难看出 TMS 应该产生什么后果。）这为那些试图发展非单调逻辑的人提供了一个自然而高度具体的挑战。TMS 还提出了非单调性与基于不可证明性的推理有关的观点；这一洞察对于模态方法和默认逻辑非常重要。而 TMS 对论证之间相互作用的强调则引发了非单调逻辑中一个至今仍然重要的主题。抽象论证是一个与逻辑编程有关的默认推理框架，一直受到广泛关注。例如，参见 Besnard＆Hunter 2008 和 Rahwan＆Simari 2009。

#### 3.2.2 闭世界推理

计算机科学中的数据库研究有一个基于逻辑的一面；参见 Minker 1997 进行调查。这个领域与逻辑人工智能有交互作用。在非单调逻辑问题的思考过程中，演绎数据库范式正在形成，提供了几个需要分析的非单调推理的具体例子。其中，也许最重要的是封闭世界假设。根据这个假设，至少就简单的主张（即正面或负面文字）而言，系统假设它知道所有应该知道的事情。当系统在其数据中找不到这样的航班时，封闭世界假设使得对查询“从底特律到博洛尼亚是否有直达航班？”的否定回答成立。这是从证明的缺失中推理出的另一个情况。通过系统性地尝试证明肯定的事情的失败，实际上证明了否定的事情。这个想法在 Reiter 1978 和 Clark 1978 等论文中进行了研究，为非单调逻辑学家提供了一个明确定义的挑战，以及如何应对这个挑战的建议。

#### 3.2.3 规划

没有能够推理一系列考虑行动结果的能力，理性规划是不可能的。这种预测性推理是局部的；在一个具有许多动态变量的复杂世界中，我们假设大多数变量在执行一个动作后不会改变。如何形式化这种“因果惯性”的问题被称为框架问题。

基于逻辑的推理通常假设惯性默认保持不变，即变量在执行操作时不会改变，除非有特殊原因认为它们会改变。这表明非单调时间形式主义在推理行为和变化方面可能有用，并且特别可能解决框架问题。Sandewall 1972 年是这方面的早期尝试。后续工作在这个方向上提供了一个特别重要和有启示性的案例研究，展示了逻辑在人工智能中的应用；详见第 4.4 节，进行进一步讨论。

### 3.3 最早的形式主义

第 3.2 节提到了三种有影响力的非单调逻辑方法：圆周法（McCarthy），模态方法（Doyle＆McDermott）和默认逻辑（Reiter）。

在 McCarthy 1993a 中，McCarthy 敦促我们在考虑环绕论的早期历史时，要考虑一组三篇论文：McCarthy 1986、1980 和 1987。第一篇论文将 McCarthy＆Hayes 1969 的战略思想与非单调逻辑的需求联系起来，并概述了域环绕论的逻辑思想，这是环绕论的最简单情况。第二篇论文提供了更全面的逻辑基础，并引入了更一般和强大的谓词环绕论方法。第三篇论文讨论了具有挑战性的常识例子和形式化技术。

所有形式的环绕论都涉及将注意力限制在某些集合最小化的模型上；因此，环绕论可以与非单调性的首选模型处理方法分组。McCarthy 的方法是保守的：它使用经典的二阶逻辑。因此，环绕论文献可以避免逻辑基础，并集中于形式化。其他类型的非单调逻辑，包括默认逻辑和模态非单调逻辑，引发了对哲学逻辑学家来说似曾相识的问题。这些问题涉及到设计新逻辑、系统研究关于有效性的问题以及管理替代逻辑的增加。

将非单调推理视为有保留的是很自然的。也就是说，非单调推理可能不仅需要已证明的结论的存在，还需要其他结论的缺失。这种默认规则的一般形式是：

:

在存在和不存在的情况下，得出结论。
我们将这样的规则写为；。

是一个重要的特例，即一个正常的默认规则，一条简单的规则，条件是默认情况下成立，条件是假设。这可以通过将结论的否定本身作为必须不存在的内容来形式化。

:

在存在和不存在的情况下，推断为 ，写作 。
规定结论默认成立的特殊情况是或简称为 。

默认理论由两个组成部分组成：一组作为公理的公式和一组默认规则。

乍一看，如何对默认逻辑中的证明进行表征是令人困惑的，因为可证性的默认解释是循环的：证明是根据正确推理链定义的，但正确推理是根据（不）可证性定义的。因此，可证性不能像单调情况那样归纳地进行表征。Sandewall 1972 年的早期理论未能成功解决这个困难。McDermott＆Doyle 1980 年和 Reiter 1980 年提出了解决这个问题的方法。在这两种情况下，逻辑任务是（1）开发一种可以表达类似的规则的形式化方法，以及（2）定义非单调公理和规则的组合与可能被视为合理的后果的理论之间的关系。在后来成为标准的术语中，我们需要定义默认理论与其扩展之间的关系。

这与经典逻辑有着根本的不同，经典逻辑将公理基础与一组后果关联起来。默认理论可以确定许多替代的后果集，而逻辑本身没有提供选择它们之间的方法。

回顾过去，我们可以确定非单调逻辑有两种方法：基于偏好和基于冲突的方法。第一种方法的理论（如缩小范围）涉及对逻辑推论的普通模型论定义的相对简单的修改，利用模型之间的偏好关系。第二种方法的理论（如默认逻辑）需要对逻辑思想进行更彻底的改造。多个扩展的可能性——从一组前提中可以得出不同的可能的连贯、推理完备的结论集——意味着我们必须将逻辑推论视为一个关系，而不是将一组公理映射到其逻辑闭包的函数。由于逻辑推论如此基础，这代表了一个重大的理论转变。通过多个扩展，我们仍然可以以各种方式检索理论与公式之间的推论关系，最简单的方式是说如果是每个扩展的成员，则非单调地蕴含。然而，基于冲突的推论解释提供了比偏好解释更丰富的基础结构。

Reiter 以保守的方式处理形式化问题。默认逻辑的语言与一阶逻辑的语言相同，其公式无法表达默认值。但是一个理论可以涉及一组默认规则——形式为的规则。因此，一个默认理论是由一组（单调的）公理和一组默认规则组成的一对。Reiter 1980 提供了这种理论扩展的不动点定义，并为该方法开发了理论基础，证明了一些基本定理。

在这些定理中，我们特别提到一个定理，它将在第 4.5 节中与耶鲁射击异常相关联。这个想法是采用一个猜测的扩展（将是一个集合）并将该集合用于一种类似证明的过程中的一致性检查，该过程依次应用默认规则，从开始的阶段开始。

我们定义了一个相对于的默认证明过程  ，如下所示。

* 让 。
* 如果在基于逻辑的中没有适用于相对于的非空默认规则，则在中逻辑闭包为。
  。
* 否则，选择一些适用于相对于的非空默认规则；并让
  .

换句话说，只要我们能够在适用的默认情况下非空地关闭我们正在工作的阶段，我们就这样做；否则，我们什么也不做。 Reiter 的一个定理表明，在这些情况下：

> 是 的扩展，当且仅当存在一个相对于 的证明过程 ，使得 。

因此，我们可以通过以下步骤来证明 是一个扩展：(1) 从 构建一个默认推理过程 ，使用 进行一致性检查，(2) 取这个过程的极限 ，并且 (3) 验证实际上 。

模态方法调用一个模态运算符，非正式地解释为“可证明的”[12]。麦克德莫特和多伊尔的方法的本质，像瑞特的方法一样，是非单调逻辑扩展的一个不动点定义。将非单调性纳入客体语言会产生一些额外的复杂性，在早期的模态方法中主要体现在逻辑的增多和评估替代方案的困难上。随着模态解释的基础变得更加完善，可以证明模态逻辑和默认逻辑方法的等价性[13]。

与其他早期的非单调逻辑呈现不同，瑞特的方法显示出对逻辑编程中非单调性的早期和独立工作的具体影响 - 这项工作似乎在很大程度上受到了为演绎数据库中的非单调推理提供逻辑基础的需求的启发。非单调逻辑的后续历史与逻辑编程语义的文献密切相关。

多伊尔和麦克德莫特的论文引用了逻辑主义人工智能的早期文献，将非单调逻辑作为形式化常识合理性计划的一部分。但这项工作显然也受到了提供真值维护的形式化解释的需求的影响。

### 3.4 非单调逻辑的后续工作

非单调逻辑是一个复杂而强大的研究领域。由于存在许多不同的基础范式来形式化非单调推理，并且这些范式之间的关系并不简单，因此对该主题进行概述是困难的。即使对该领域的一个重要部分进行充分的解释也需要类似于一本书的篇幅。有许多书籍和手册文章可供参考，包括Łukaszewicz 1990、Brewka 1991、Besnard 1992、Marek＆Truszczynski 1994、Gabbay 等人 1994、Antoniou 1997、Brewka 等人 1997、Schlechta 1997、Makinson 2005、Antoniou＆Wang 2007、Bochman 2007、Horty 2012、Straßer 2014 和 Straßer＆Antonelli 2019。Ginsberg 1987 是对该主题早期历史感兴趣的读者的一个有用的来源，并且有一个优秀的引言。

#### 3.4.1 偏好语义

第 3.1 节解释了如何使用首选模型来描述非单调的推理关系。这种对非单调性模型理论的方法在 Shoham 1988 年得到了澄清，比第 3.2 节讨论的工作晚了五年。Shoham 的工作提供了一种更一般和抽象的方法。

优先语义依赖于一个将模型集合映射到的函数。优先蕴涵的关键定义规定，如果是的每个模型都蕴涵，则是（非单调的）结果。Shoham 用模型之间的偏序来描述：是在中是-最小的模型集合。为了确保除非经典地蕴涵矛盾，否则不能优先地蕴涵矛盾，必须禁止无限下降链。

这种对非单调性的处理类似于早期的条件模态语义理论，特别是使用将一组世界与前提相关联的条件语义的演示，如 Chellas 1975。当然，经典条件逻辑的结果关系是单调的，条件语义使用可能世界，而不是模型。但条件的左非单调性（事实上不蕴涵）引发了与非单调结果关系相似的问题。条件和非单调逻辑之间的相互关系成为非单调逻辑中后续工作的重要主题。例如，参见 Gärdenfors＆Makinson 1994，Boutilier 1992，Pearl 1994，Gabbay 1995，Delgrande 1998，Arlo-Costa＆Shapiro 1992，Alcourrón 1995，Asher 1995，Kern-Isberner 2001，Giordano＆Schwind 2004，Lent＆Thomason 2015 和 Casini＆Straccia 2022。

偏好语义为制定和证明关于偏好关系条件与抽象结果关系属性的表示定理提供了机会。这一研究方向始于 Lehmann＆Magidor 1992 年。

#### 3.4.2 模态和认知理论

无论是 Doyle 还是 McDermott 都没有在初始阶段之外深入研究模态方法。然而，在 Robert Stalnaker 的建议下（参见 Stalnaker 1993），Robert C. Moore 提出了一种模态理论，该理论在许多方面改进了早期的想法。 Moore 根据默认规则的概念，将其系统的模态运算符赋予认知解释，即除非有知识阻止结论，否则默认规则允许推出一个结论。在 Moore 的自我认知逻辑中，理论的扩展是一个稳定的超集，即是演绎闭合的，并满足以下两个规则：

1. 如果  那么 .
2. 如果  那么 .

对于基于逻辑的自我认知扩展，通常还会对其施加一个基于根据的条件，确保扩展的每个成员都有一些追溯到的理由。已经考虑了各种这样的条件；最简单的条件限制扩展为满足该条件的扩展。

3. 是非模态后果的集合。

自知逻辑仍然是非单调逻辑的一种流行方法，部分原因是它在为逻辑编程提供理论基础方面的实用性。参见 Marek＆Truszczynski 1991，Marek＆Truszczynski 1989，Konolige 1994，Antoniou 1997，Moore 1993 和 Deneker 等人 2003。

认知逻辑启发了其他非单调逻辑方法。与其他非单调性的模态理论一样，这些理论使用模态来反映对象语言中的一致性，因此允许表达类似于的默认规则。但是，这些理论使用的是无知而不是一致性。有关这个想法的变体，请参见 Halpern＆Moses 1985 和 Levesque 1987。这些理论在 Meyer＆van der Hoek 1995 中得到了解释，并与其他非单调逻辑进行了比较。在最近的工作中，Levesque 的想法在 Levesque＆Lakemeyer 2000 中得到了系统地介绍和应用于知识库理论。

## 4. 推理关于行动和变化

### 4.1 先验时态逻辑

现代时间逻辑的轮廓在 1950 年代和 1960 年代由亚瑟·普赖尔（Arthur Prior）标准化：参见 Prior 1956、1967、1968。[14] 由于它在哲学逻辑中的发展，时态逻辑被证明是模态逻辑的一种。因此，它将公式的真值相对化为世界状态或世界的时间阶段；这些是普通模态逻辑的无时无刻的可能世界的时态理论类比。然后可以从模态逻辑中借用一个研究计划，例如，研究公理系统与时间排序的相应模型理论约束之间的关系。例如，参见 Burgess 1984 和 van Benthem 1983。

先验时态逻辑与模态逻辑共同关注使用关系的一阶理论来解释逻辑现象，期望重要的时间运算符将是对世界状态的量词，并与现实的、实际的时间推理的联系相对薄弱。当然，这些时间逻辑确实产生了有效性，比如（如果，那么过去将会是这种情况），这显然是直观上有效的。但最多，它们只能在解释关于时间的常识推理中起到广泛的基础性作用。很难想象它们在实际推理中起到主导作用的现实例子。

4.2 计划问题和情景演算

### 4.2 Planning Problems and the Situation Calculus

规划问题为将逻辑分析与人工智能应用相结合提供了最有成果的展示之一。一方面，自动规划具有许多实际价值的应用，另一方面，规划的逻辑形式化在理解规划问题和设计算法方面确实是有帮助的。

人工智能规划问题的经典表示，如 Amarel 1968 所述，显然源自 Herbert Simon 早期的工作，发表在 1966 年的 CMU 技术报告中，Simon 1966。在这样的问题中，一个处于初始世界状态的行为体配备了一组被视为将世界状态转化为世界状态的部分函数的行为。行为仅在满足适当约束的世界状态中可行。（这些约束现在被称为行为的“前提条件”）。然后，规划问题变成了寻找一系列可行行动的搜索，这些行动逐步将初始世界状态转化为所需的世界状态。

由 John McCarthy 开发的情境演算是后来大部分关于行动和变化推理形式化工作的起源。它首次在 1969 年被描述，关于该主题的最早普遍可访问的出版物是 McCarthy＆Hayes 1969。

显然，Priorian 时态逻辑对 Amarel 没有影响。但是 Amarel 的世界状态与 Priorian 时态逻辑的世界状态之间没有重要的区别。Situation Calculus 中的“情境”就是这些相同的世界状态，只是换了个名字。[15]它们类似于模态逻辑中的可能世界，提供支持一致且完备的真理集合的抽象位置。与时态逻辑类似，这些位置是有序的，变化通过从一个位置到另一个位置的真值条件的变化来表示。当然，这些差异受到了 Situation Calculus 的预期用途的启发：它旨在形式化 Simon 对规划问题的表示，其中单个代理人推理关于顺序执行动作的情景。[16]情境演变在情境演算中是动态的，由动作的执行驱动。因此，基本的模型论组成部分是

一个动作 a、一个在其中执行 a 的输入情境 s 以及在动作执行后立即发生的输出情境之间的关系。通常（尽管这并非绝对必要），假设是唯一确定的。

当然，所有这些都假设了一个离散的时间观。与其他以行动为驱动的框架（如博弈论和数字计算理论）一样，这样的观点似乎是不可或缺的。

一般来说，行动只能在特定的有限情况下成功执行。这可以通过允许存在这样的情况来建模，即不存在这样的情况。然而，通常假设是实际上是一个总函数，但在 s 不满足 a 的“前提条件”的情况下，对满足的 s 没有任何限制。这意味着在这种情况下，a 的因果效应将完全没有限制，在惯性定律的存在下，“执行”a 将使事物保持不变。

规划问题始于一组有限的行动（每个行动都与前提条件和效果相关），一个初始情况和一个目标（可以视为一个公式）。规划问题是找到一系列行动的问题，这些行动将在给定初始情况的情况下实现目标。也就是说，给定目标和初始情况 s，问题将包括找到一系列行动的序列，这些行动将把 s 转化为满足的最终情况。规划问题实际上是在寻找这样一系列行动的过程中进行搜索。搜索的成功条件可以用类似情境演算的形式化方法来描述，该方法允许表达关于行动结果的信息。

到目前为止，还没有讨论过情境演算的实际语言。关键是如何表达变化。考虑到时态逻辑，自然会引入类似的模态，如，其真值条件为

这种基于逻辑的形式化实际上是对麦卡锡的一种有吸引力的替代方式。

但是麦卡锡和海耶斯在 1969 年使用了一种更接近一阶逻辑的语言。（这种形式化风格是麦卡锡工作的特点；参见麦卡锡 1979 年。）行为被视为个体。而可以随时间改变真值的命题（命题流变量）也被视为个体。其中表示一个情境和一个流变量，表示在中为真。

### 4.3 对微观世界进行形式化

自从 19 世纪和 20 世纪初逻辑学家的开创性工作以来，形式化数学领域的过程已经变得常规化。尽管（与集合论一样），关于哪些公理和逻辑基础最适合形式化数学领域可能存在争议，但形式化的方法和评估标准是自动的（大部分）且未经审查的。这种方法论的清晰性尚未成功地扩展到其他领域；即使是经验科学的形式化也存在难题，尚未解决。[17]

时间推理的形式化，特别是关于行为和计划的推理，是现代形式化技术在数学理论以外领域最成功的扩展。这一转变需要创造新的方法论。方法论创新将在第 4.5 节中介绍：开发一套场景库以测试各种形式主义的适用性，并创建专门的领域，如块世界领域（在第 4.2 节中提到），用于测试想法。有关块世界的更多信息，请参见 Genesereth＆Nilsson 1987; Davis 1991。麦卡锡关于扩展容忍度的想法（McCarthy 1999）提供了一个有趣的尝试，以提供形式化的适用性标准。在形式化常识领域的过程中出现的另一个想法是明确本体论的重要性；例如，请参见 Fikes 1996 和 Lenat＆Guha 1989。另一个是明确表示上下文的潜在有用性；请参见 Guha，1991。另一个是使用模拟技术：例如，请参见 Johnstone＆Williamson 2007。

### 4.4 预测和框架问题

要判断一个计划是否实现了其目标，你需要看这个目标在计划的最终状态中是否成立。这需要预测推理，一种时态逻辑文献中忽视的推理类型。与力学类似，预测涉及从早期状态推断出后期状态。但是（至少在简单的规划问题中），变化是由行动驱动的，而不是由微分方程驱动的。对这种定性形式的时间推理以及相关推理形式（例如，计划识别，试图从观察到的行动推断目标，以及叙事解释，试图填补时间叙述中的隐含信息）的研究是常识逻辑学短暂历史中最令人印象深刻的章节之一。

预测的本质是推断在执行一个动作后所发生的情况中成立的内容，给定关于初始情况的信息。如果代理人对初始情况有完全的了解，这个问题就容易得多——这个假设通常是不现实的，但在经典规划形式主义中很常见。

行动驱动的动力学的很大一部分与不变的事物有关。以使用文字处理器键入“cat”为例的一个简单计划：自然的计划是先输入“c”，然后输入“a”，然后输入“t”。对这个计划的信心的一部分是行动是独立的：例如，输入“a”不会同时抹去“c”。所需的推理可以被看作是一种惯性的形式。框架问题是如何形式化所需的惯性推理的问题。

帧问题是在 1969 年由麦卡锡和海耶斯命名和引入的。与大多数在人工智能领域出现的哲学上有趣的技术问题不同，它引起了哲学家们的兴趣；大部分相关论文和背景信息可以在福特和皮利辛的 1996 年以及皮利辛的 1987 年的著作中找到。这两卷书都记录了人工智能和哲学之间的互动。

这些互动的质量令人沮丧。像任何现实的常识推理问题一样，帧问题是开放性的，并且可以依赖于各种各样的情况。如果你把  20 放在钱包里，它将保留下来。但是如果你在购物时把 20 美元留在柜台上，你不能安全地期望它以后还在那里。这可能解释了为什么一些哲学家希望非常广泛地解释帧问题，以至于很快它变得难以区分于在任意领域中形式化常识的问题。这样广泛的解释可能会引发关于人工智能性质的推测性讨论，但它失去了与人工智能社区发现的真正的、新的逻辑问题的联系。

纯粹的逻辑帧问题可以使用单调逻辑来解决，只需编写明确的公理来说明在执行动作时不会发生变化的内容。这种技术可以成功地应用于相当复杂的形式化问题。但是非单调解决方案已经得到了广泛的研究和应用；这些解决方案引发了新的有趣的逻辑发展方向。

一些哲学家（Fodor 1987，Lormand 1996）认为，人为构造的命题在与框架问题相关时会带来特殊困难。正如 Shanahan 指出的（Shanahan 1997 [p. 24]），Fodor 的“冰箱”例子在情境演算中很容易形式化，并且不会带来特殊问题。然而，正如 Lormand 所建议的那样，Goodman 的例子（Goodman, 1946）如果被视为流变量，将会产生问题；在其中，为了保持它们的绿色，物体会从绿色变为蓝色。

这是哲学家对于框架问题提出的少数几个真正对 AI 形式化构成困难的观点之一。但这个困难是次要的，因为这个例子是不现实的。流变量并不假设具有闭包性质（如布尔运算的闭包性）。事实上，通常认为在规划领域形式化时选择的流变量将代表状态相关函数的非常有限的子集；通常，它将是一个相对较小的有限变量集，代表领域中被认为重要的特征。在特定情况下，这些变量的选择方式与统计建模中选择变量的方式非常相似。

我不知道 AI 文献中是否有关于形式化方法论的系统性解释，或者特别是如何选择适当的流变量。但肯定会在这样的解释中提到，所有流变量都应该对应于 Goodman 所说的可投射谓词。

### 4.5 惯性的非单调处理和一系列问题的解决方案

对于框架问题的非单调解决方案使惯性成为默认情况；只有在某些特殊原因的情况下才会假设发生变化。在以行动为中心的变化解释中，这些特殊原因可以在规定行动的直接影响的公理中找到。

我们可以用 Reiter 的默认逻辑来说明形式化过程。回想一下，在 Reiter 的理论中，默认情况被表示为规则，而不是公理；这意味着我们需要使用默认规则模式来形式化惯性。对于每个流畅、行动和情境，惯性模式将包括以下规则：

这种做事方式使得流畅的真值发生任何变化都成为一种表面上的异常。但根据 Reiter 对扩展的解释，当这些默认值与给出状态动态的（单调）公理发生冲突时，这些默认值将被覆盖。例如，如果有一个单调的因果公理，确保将某个棋子移动到 Q4 将使棋子位于 Q4，那么实例将被覆盖，并且在执行移动-P4-to-Q4 操作后，不会有一个扩展使得棋子保持在原位。惯性将确保其他棋子保持不动。

捕捉到更广泛关注的框架问题是被孤立地从上下文中拿出来的。如果有人有兴趣了解在使用情境演算等形式主义时出现的哲学上有趣的问题，最好考虑更广泛的问题范围。这些问题不仅包括框架问题本身，还包括资格问题、分歧问题以及一系列特定挑战，例如本节后面提到的场景。而且还必须考虑如何进行概括：例如，如何处理不完全信息、多个代理同时行动以及环境中的持续变化。

The frame problem that captured wider attention was taken out of context and in isolation. If one is interested in understanding the philosophically interesting problems that arise in deploying formalisms like the Situation Calculus, it is best to consider a larger range of problems. These include not only the Frame Problem itself, but also the Qualification Problem, the Ramification Problem, and an assortment of specific challenges such as the scenarios mentioned later in this section. And one has to think about how to generalize: for instance, how to deal with incomplete information, multiple agents acting concurrently, and continuous change in the environment.

合乎常识的普遍化概括的形式化会引发资格问题。通常，这些问题会涉及到一系列开放且似乎难以管理的例外情况。同样的现象，在分析哲学中被称为“ceteris paribus 概括问题”，也出现在自然语言中的泛指结构的语义中。

非单调逻辑通过实现增量形式化为这个问题做出了贡献。如果将合乎常识的概括形式化为默认规则，那么可以非破坏性地添加进一步的限定条件。默认公理被保留，然后添加一个例外情况（它本身可能是一个默认规则）。即使它不能解决更深层次的哲学问题，这也是有帮助的。

资格问题最早在 1986 年由麦卡锡提出，主要是针对行为后果的概括；麦卡锡详细考虑了打开汽车点火开关会启动汽车的概括。实际上，几乎任何行为都可以提出同样的观点，包括将一个积木叠在另一个上面——这是情境演算法早期阶段使用的标准示例。利夫希茨在 1987 年提出了一种资格问题的限定方法；该方法明确地将行为与其前提条件之间的关系引入形式化，并通过限定最小化前提条件，从首选模型中消除可能使行为无效的“未知前提条件”。

并非每种非单调逻辑都提供了优雅的资格机制。例如，普通的默认逻辑并不能产生直观上期望的结论，因为它没有提供默认规则覆盖其他默认规则的方式。为了实现这种效果，需要一种高级版本的逻辑，其中默认规则具有优先级。这可能会大大复杂化理论；例如，参见 Asher＆Morreau 1991 和 Horty 1994。正如 Elkan 1995 指出的那样，资格问题引发了计算问题。

相对于时间推理中的其他问题，对于表征行动的资格问题并没有受到太多关注。特别是，对于不成功行动的标准解释有些不直观。例如，在 Lifschitz 1987 的形式化中，只有在满足前提条件时，行动的常规效果才能得到保证，这与未满足前提条件的行动之间的区别仅在于当满足前提条件时才能确保行动的常规效果。就好像在任何时刻都可以进行一笔 100 万美元的交易，尽管如果你没有钱，特定的效果将无法保证。[23]而且，对于那些甚至无法尝试的行动（比如当你在悉尼时试图登上伦敦的飞机），可以尝试但预计会失败的行动（比如在资金不足时尝试取款），可以尝试并有合理成功希望的行动，以及可以尝试并保证成功的行动之间没有区别。正如奥斯汀在 Austin 1961 中明确指出的那样，行动的尝试方式以及尝试行动的失败方式是常识推理中一个发展完善的部分。显然，在考虑包含可能失败的行动的计划时，人们可能需要推理失败的后果。对行动的病理进行形式化，提供关于行动及其包含的计划可能出错的系统理论，将是规划形式化的有益补充，并且将阐明哲学中的重要主题。

Ramification Problem（首次由 Finger 1987 提出）所提出的挑战是对行为的间接后果进行形式化，其中“间接”效果是同步的[24]但是因果派生的。如果一个人走进一个房间，直接效果是他现在在房间里。还有许多间接效果：例如，他的衬衫现在也在房间里。

从这个表述中可以看出，行为的直接后果（与行为本身内在相关并由其成功执行保证的后果）与其他后果之间存在着一个区别。这个假设在行为形式化的人工智能文献中被普遍接受而没有被质疑。你可以为它的常识合理性提出充分的理由 - 例如，我们许多与行为相关的词汇（“变暖”，“变长”，“填充”）都是从与它们惯常相关的效果中派生出来的。在这些情况下，成功是必然的：如果有人把某物变暖了，那就意味着它变暖了。但是也存在一些复杂情况。Lin 1995 讨论了一个简单的例子：一个特定的手提箱有两个锁，只有当两个锁都打开时，它才是打开的。然后（假设动作不是同时进行的）如果打开一个锁只有在另一个锁打开的情况下才会打开手提箱。Lin 的形式化处理将打开每个锁都视为一个行为，具有直接后果。但是打开手提箱不是一个行为，而是一个间接效果。

显然，Ramification Problem 与框架问题密切相关。在采用非单调解决方案来解决框架问题的方法中，惯性默认值需要被后果覆盖以获得正确的结果。在 Lin 的例子中，假设手提箱的左锁是打开的，并执行打开右锁的动作。那么，需要以某种方式抑制默认结论，即手提箱仍然关闭。

一些解决分歧问题的方法依赖于常识因果理论的发展，因此与第 4.6 节中提到的关于时间和行动推理的因果方法密切相关。例如，参见 Giunchiglia 等人 1997 年，Thielscher 1989 年，Lin 1995 年。

哲学逻辑学家一直满足于用相对小规模的例子来说明他们的观点。即使是大规模数学理论的形式化也相对不成问题。逻辑主义人工智能是逻辑的第一个分支，它承担了形式化现实且非平凡的常识推理的任务。在这样做的过程中，该领域不得不发明新的方法。在形式化行动和变化的过程中，方法学的一个重要部分是以场景的形式提出的挑战。这些场景代表了通常涉及相对简单、现实的例子的形式化问题，旨在以特定的方式挑战逻辑理论。通常，对于这些情况应该进行的推理有明确的常识直觉。挑战在于设计一个逻辑形式化方法，能够为这些基准问题提供一般的、有充分动机的解决方案。

在文献中讨论过许多场景，包括婴儿场景、公交车乘坐场景、国际象棋棋盘场景、渡船连接场景、家具组装场景、藏火鸡场景、厨房水槽场景、俄罗斯火鸡场景、斯坦福谋杀之谜、斯德哥尔摩交付场景、被盗汽车场景、闷热的房间场景、被罚款的汽车场景、走路的火鸡场景和耶鲁枪击异常。这些的解释可以在 Shanahan 1997 年和 Sandewall 1994 年找到；特别是 Sandewall 1994 年[第 2 章和第 7 章]。

这些场景中的许多是为了测试高级问题而设计的，这些问题在这里不会讨论，例如处理多个行为体或连续变化的挑战。在这里，我们集中讨论最早的、可能也是最微妙的场景之一：耶鲁射击异常，最早由 Hanks＆McDermott 1985 年报道，并在 Hanks＆McDermott 1986 年和 Hanks＆McDermott 1987 年发表。

耶鲁射击异常涉及三个行为：装弹、射击和等待。一个命题性的流畅性 Loaded 跟踪某个手枪是否装弹；另一个流畅性 Alive 跟踪某只火鸡 Fred 是否活着。装弹行为没有前提条件；它的唯一效果是 Loaded。射击行为的唯一前提条件是 Loaded，唯一效果是 Not-Alive；等待行为没有前提条件和效果。

关于公理的因果信息被形式化如下。

| ** 载入：**   |  |
| --------------- | -- |
| ** 射击 1：** |  |
| ** 射击 2：** |  |

没有等待公理。

我们将使用 Reiter 的默认逻辑来形式化这种情景中的惯性推理。该理论的默认集包括惯性模式的所有实例。在初始情况下，Fred 是活着的，手枪未装弹。

| **IC1:** |  |
| -- | -- |
| **IC2:** |  |

场景的单调理论由以下组成：(1) 行为公理 Load, Shoot 1 和 Shoot 2，以及 (2) 初始条件和。

 让 ，和 。

耶鲁枪击异常涉及从 到 的动作序列加载;等待;射击，如下所示。

|  |  |  |  |  |  |  |
| -- | -- | -- | -- | -- | -- | -- |

这是一个异常情况-对于惯性的天真理论的挑战-因为默认逻辑允许根据这样一个扩展，即手枪未装弹且弗雷德在最终情况下仍然活着。这个异常的扩展如下所示。

|  |  |  |  |  |  |  |
| -- | -- | -- | -- | -- | -- | -- |

以叙述形式，这个扩展中发生的是这样的。起初，弗雷德还活着，手枪未装弹。装弹后，手枪装弹且弗雷德仍然活着。等待后，手枪变为未装弹且弗雷德仍然活着。射击因为手枪未装弹而无效。因此，最后，在射击之后，弗雷德仍然活着且手枪仍然未装弹。

看到这是一个扩展的最好方法是通过证明来进行。虽然不太正式，但你可以看到，弗雷德最终死亡的预期扩展违反了一个默认：当弗雷德在最后一步改变状态时，违反了“活着”的框架默认值。但是，异常的扩展也只违反了一个默认：当枪在等待时突然变得未装弹时，违反了“装弹”的框架默认值。如果只根据违反的默认值数量来判断，两个扩展都是同样好的。

基于直接的基于默认逻辑的因果惯性形式化的规划算法将无法按预期执行。它将无法验证一个完全合理的常识计划来杀死弗雷德，并且在除了最简单的规划场景之外也会失败。因此，耶鲁射击异常代表了发展基于惯性的预测推理理论的一个重大障碍。一个合理、有动机的逻辑解决方案已经在一个简单、明确的例子中遭遇到错误的结果。

当然，关于耶鲁射击异常的文献非常广泛。关于其中一些工作的调查，包括参考文献，可以在 Shanahan 1997 和 Morgenstern 1996 中找到。

### 4.6 一些新兴框架

人们普遍认为，好的解决方案需要在大量的场景中表现出色，并且具有泛化能力：特别是，它们应该能够在引入连续时间、并发行为和各种形式的无知的情况下进行部署。并且人们一致认为，它们应该支持多种推理任务，包括不仅仅是预测和计划验证，还包括根据执行的动作和代理目标解释历史信息或叙述。

在这里，我们提到了四种方法：（1）特征和流畅（Sandewall），（2）动机行为理论（Morgenstern 和 Stein），（3）事件演算中的状态最小化（Shanahan）和（4）因果理论（Lifschitz 和其他人）。第四种方法最有可能引起哲学家的兴趣，并包含一些无论未来发展如何都具有持久重要性的元素，并且将进行更详细的讨论。

#### 4.6.1 特点和流畅性

这种基于偏好语义的方法，如 Sandewall 1994 所述，用于组织关于行为和变化推理的非单调解决方案。Sandewall 并没有引入一个单一的逻辑框架，而是考虑了许多时间逻辑，包括使用离散、连续和分支时间的逻辑。这些逻辑的属性经过系统地测试，与大量的测试场景进行对比。

#### 4.6.2 动机行为理论

这个理论是基于对上述第 4.5 节中描述的时间推理问题的直接考虑而发展起来的，尤其是耶鲁枪击案场景。Morgenstern＆Stein 1994 试图找到一个通用的、直观动机的逻辑框架来解决这些困难。Morgenstern 和 Stein 认为，无动机的行为应该被最小化，其中一个行为可以直接通过公理或间接通过因果链来获得动机。关键的技术思想是基于区间的时间逻辑中动机的（相当复杂的）定义。

Morgenstern 1996 提出了该理论的概述，并提出了拒绝其因果竞争对手的理由。其中最重要的是，基于 Situation Calculus 的解释似乎不能推广到允许并发和无知的情况。她还引用了早期因果理论无法处理逆推的失败案例。

#### 4.6.3 基于事件演算的状态最小化

1989 年，贝克（Baker）使用基于逻辑的耶鲁射击异常的限定版本进行研究。回想一下，限定使用首选模型，其中异常谓词的扩展被最小化。在这个最小化过程中，某些参数（包括要最小化的谓词）被允许变化；其余参数保持不变。哪些参数变化，哪些参数保持不变由应用程序决定。

在最早的解决框架问题的限定解中，惯性规则使用了一个异常谓词来陈述。

这个公理使用了一个双条件语句，以便可以用于逆向推理；这是最近的常识惯性的典型表述。对框架问题的一个不成熟的解决方案是最小化异常谓词，同时允许"Holds"谓词变化，并保持所有其他参数固定。这种方法与默认逻辑类似，容易受到耶鲁射击异常的影响。限定不涉及多个扩展，因此在射击后无法得出 Fred 已经死亡的结论，这就是异常的表现。

在贝克尔对问题的重新表述中，分离的公理确保了与每个布尔组合的情态对应的情境的存在，并且允许结果函数变化，而保持 Holds 谓词不变。在这种设置中，需要为“反事实”行为（尤其是射击和耶鲁射击异常中的等待）指定结果函数。正是这个特点消除了该场景的错误模型；有关详细信息，请参见贝克尔 1989 年和 Shanahan 1997 年第 6 章。

Shanahan 称之为“基于状态的最小化”的这个想法在 Shanahan 1997 年中得到了发展和扩展，它是从 Kowalski＆Sergot 1986 年的事件演算中推导出来的时间逻辑的上下文中。Shanahan 的版本具有与逻辑编程密切相关的优势。

#### 4.6.4 因果理论

回想一下，在耶鲁枪击场景的异常模型中，枪在执行等待动作后变为空弹夹，这个动作没有常规效果。然后，卸弹是无因果的。这表明了一种最小化没有原因的结果的解决方案。

这种策略在 Geffner 1990 和 1992 年进行了追求。从 Lifschitz 1987 年开始的类似方法沿着这些思路发展了一系列的研究，不仅由 Lifschitz 及其在德克萨斯行动小组的学生和同事进行，还有其他一些人。有关这项工作和进一步的参考资料，请参阅 Thielscher 1989，Gustaffson＆Doherty 1996，Baral 1995，Nakashima 等人。1997 年，Lifschitz 1997 年，Giunchiglia＆Lifschitz 1998 年，Lin 1995 年，Haugh 1987 年，Lifschitz 1998b 年，Turner 1999 年，McCain＆Turner 1995 年，Elkan 1991 年，McCain＆Turner 1997 年，Thielscher 1996 年和 Gelfond＆Lifschitz 1998 年。

在这里，我们描述了 Turner 1999 年提出的因果解决方案。Turner 回到了 Geffner 1992 年的思想，但将它们放在一个更简单的逻辑环境中，并将它们应用于更复杂的场景的形式化，以说明因果惯性与其他考虑因素（尤其是分叉问题）的相互作用。

分歧是由存在静态法则引起的，这些法则将行为的直接后果与其他变化联系起来。汽车启动场景说明了困难。有一个动作，即打开，它打开点火开关；假设这个动作没有前提条件。有一个流畅的跟踪，用于跟踪点火是否打开，一个流畅的跟踪，用于跟踪电池是否没电，以及一个流畅的跟踪，用于跟踪发动机是否运行。一个静态法则说，如果点火打开且电池没电，发动机就会运行。（假设在这种情况下，已经排除了其他故障的可能原因；无法启动的唯一可能原因是电池没电。）我们想考虑的是，在点火未打开、电池未没电且汽车未运行的情况下执行打开动作的转变。

当然，我们希望在这种情况下推断出打开动作的执行将导致点火打开、电池未没电且发动机运行的情况。但是，逆因果法则使这个结论受挫。困难在于：我们可以通过逆推我们唯一的静态法则得出结论，即如果点火打开且发动机未运行，则电池没电。这个法则不仅在我们的场景中是正确的，而且会被用来解释启动汽车失败的尝试。但是，如果它被用于预测，那么执行打开动作将产生一个“墨菲定律”的结果，即点火打开、电池没电且发动机未运行。在这个不希望的结果中，一切都有原因：电池没电是因为因果惯性，发动机不运行是因为逆因果法则。

想要详细探讨在相对表达力强的行动语言中嵌入非单调解决方案到框架问题的读者可以参考 Gelfond＆Lifschitz 1998。本文介绍了一系列越来越强大和复杂的行动语言，其中包含了对分叉问题的一种有些特殊的解决方案。Turner 1999 是在这些方面的一种改进。

Turner 的想法是将  视为一个带有非单调优先模型解释的模态运算符 。在优先模型中普遍的因果关系成立：引起的命题和真命题必须一致。此外，该模型必须是唯一的；它必须是与语言的外延部分一致的唯一可能性。

要理解这个想法，有助于回忆一下在可能世界解释中，世界可以被认为是状态描述，即完整一致的文字集合（原子公式及其否定）。这使我们可以将模型视为一对 ，其中是包括的解释集合。模态运算符具有标准语义。其中是解释集合，当且仅当对于所有 ，满足一组公式，当且仅当对于所有 。

Turner 的首选模型是满足以下条件的一对：(1)满足，(2)，和(3)是满足条件(1)和(2)的唯一解释 I，S。条件(2)保证了“因果关系的普遍性”；它验证了。条件(3)以最强的意义上的非因果信息（在我们感兴趣的模型中，这将是哪些情况下的流变量保持）“基于”因果关系：它是由此信息唯一确定的。

尽管不明显，但 Turner 对首选模型的解释与更一般的非单调逻辑（如默认逻辑）有关。有关详细信息，请参阅 Turner 1999。

指定行为效果的公理将这些效果视为被引起的；例如，装载的公理模式将如下所示：

> | ** 因果负载：** | [[25](https://plato.stanford.edu/entries/logic-ai/notes.html#note-25)] |
> | ----------------- | ---- |

行为的直接效果的后果也被视为是由其引起的。并且存在两个非单调的惯性公理模式：

 和

因此，一个真命题可以是因为它是一个行为的直接或间接效果，或者因为它涉及到一个被引起的命题的持续存在。根据规定，初始条件也被认为是被引起的。

为了说明这种方法的工作原理，考虑最简单的情况：一个只有一个表示流畅的常量 f 和一个表示行动的常量 wait 的语言。与耶鲁枪击问题一样，wait 没有公理；该行动总是可以执行且没有相关的效果。设 s 是在 s 中执行等待行动的结果。

这个理论包含一个初始条件

和一个初始条件是由引起的陈述，

两个模型满足条件（1）和（2）：

 在哪里

是指什么不变的模型。它满足条件（3），因为如果满足，则满足惰性公理。

 因此，。

是一个异常的模型，在这个模型中，流畅的停止是自发的。这个模型不满足条件（3），因为也满足；特别地，它满足了对于 f 的惯性公理，因为它不满足。因此，虽然是一个首选模型，但不是。

特纳的方法通过给予因果关系形式来避免对偶问题

当对偶时，这变成了

不具有因果定律形式的。

“普遍因果性原则”在解释定性常识推理中的一系列问题时的表面上的有用性应该引起哲学家的兴趣。而由 Geffner 发起并由 Turner 发展起来的因果理论具有许多有趣的详细特征。例如，虽然关于因果关系的哲学研究集中在因果关系上，但 Taylor 的方法表明，仅使用非关系性的因果谓词也可以做很多工作。

行为驱动动力学可以用于构建条件逻辑模型。Lent 和 Thomason 2015 年使用 Turner 的因果方法在前提是行为表达式和简单非模态条件的合取的受限情况下提供这样的模型。对于框架问题的明确解决提供了反事实的预测并自动提供了条件语义。

Morgenstern 1996 对于关于行动推理的因果方法提出了两个主要批评：它不能给出充分的解释[26]，而且情境演算本身的范围有限。这两个批评都不是致命的；都可以被视为未来研究的挑战。

关于非单调因果推理的另一种方法，基于输入-输出逻辑（Makinson＆van der Torre 2000），请参见 Bochman 2004。

## 5. 因果推理

当然，因果推理是一个重要的研究课题。例如，它在关于设备的定性推理中起到了作用。赫伯特·西蒙（Herbert Simon）在这个领域的工作可以追溯到 20 世纪 50 年代：参见西蒙（Simon）1952 年、1977 年；岩崎和西蒙（Iwasaki & Simon）1986 年。朱迪亚·珀尔（Judea Pearl）及其学生和合作者负责对因果模型和因果推理进行了最持久和成功的研究。珀尔和他的许多合著者是计算机科学家，但统计学家和哲学家也为这个研究项目做出了贡献。我们在这里不再进一步讨论因果网络。请参见哈尔彭（Halpern）2016 年和希奇科克（Hitchcock）2022 年。

## 6. 空间推理

在与空间推理相关的哲学逻辑的预计算文献中，相对较少。但是，在应用领域（如运动规划和物理空间中的操作，图像的索引和检索，地理信息系统，图解推理以及高级图形程序的设计）中支持计算推理的需求，引起了对空间表示和空间推理的新兴兴趣。当然，几何传统为这一领域提供了非常强大的数学资源。但是，与许多其他与人工智能相关的领域一样，这些理论是否适用于这些应用并不清楚，许多计算机科学家认为值得开发新的基础。这项工作中的一些内容与上述第 2.2 节中提到的定性推理研究密切相关，并且在某些情况下由同一人员进行。当然，这也与哲学逻辑中的部分论文有关。

空间推理的人工智能文献非常广泛；有关这里未讨论的一些领域的参考文献，请参阅 Stock 1997，Kapur＆Mundy 1988，Hammer 1995，Wilson 1998，Osherson＆Lasnik 1990，Renz＆Nebel 1999，Yeap＆Jeffries 1999，Chen 1990，Burger＆Bhanu 1992，Allwein＆Barwise 1996，Glasgow 等人 1995 年和 Kosslyn 1990。在这里，我们只讨论了一个趋势，这与哲学逻辑中的并行工作密切相关。

空间的定性方法早在 20 世纪初就被引入到逻辑文献中，由 Stanisław Leśniewski 提出；请参阅 Leśniewski 1916，其中提出了关于物理个体之间的部分-整体关系的整体论或定性理论的思想。这种关于区域之间关系的逻辑理论的思想在哲学逻辑中仍然活跃，尽管吸引了相对较少的研究者。哲学文献中的更近期的工作，特别是 Casati＆Varzi 1999，Simons 1987，Casati＆Varzi 1996，Clarke 1981 和 Clarke 1985，对当前的计算工作产生了影响。

利兹大学的计算机科学家开发的区域连接演算（RCC）是基于空间区域的原始关系：其预期解释是和的值的闭包的交集非空。有关详细信息和参考文献，请参阅 Cohn 等人 1997 年，Cohn 1996 年。使用这个简单的原始关系可以定义的范围令人惊讶，但技术细节很快变得复杂；例如，请参阅 Gotts 1994 年，Gotts 1996 年。Cohn 等人 1997 年引用的工作描述了基于 RCC 及其扩展的实现推理的约束传播技术和直觉命题逻辑编码。基于 RCC 的最新工作涉及表示和推理运动，当然结合了空间和时间问题；请参阅 Wolter＆Zakharyaschev 2000 年。有关运动的定性理论的更多信息以及其他方法的参考，请参阅 Galton 1997 年。

## 7. 关于知识的推理

Hintikka 1962 年，作为认识逻辑的经典来源，从模态逻辑中汲取灵感。因此，该工作集中于如何使用模态运算符对单个代理的态度进行建模。由于可能世界语义适用于替代模态运算符，Hintikka 详细讨论了哪些替代方案适用于知识和信念的问题，并选择了模态逻辑。有关后续发展的背景和信息，请参阅 Rendsvig＆Symons 2022 年。Laux＆Wansing 1995 年讨论了截至 1994 年的哲学和计算传统。

认识态度在博弈论中起着作用，同时也在逻辑人工智能中起作用，并且在这两个应用领域中的工作要么与 Hintikka 的模态方法相平行，要么受其影响。在几篇论文中（包括 McCarthy 1979），John McCarthy 推荐了一种使用一阶逻辑来形式化知识的方法，但是明确量化了诸如个体概念之类的事物。然而，在这里，我们讨论的是大多数计算机科学家采取的方法，他们与 McCarthy 不同，使用模态逻辑，但与 Hintikka 不同，专注于多主体情况。

Fagin 等人在 1995 年简化了底层的模态性，使用知识（或信念的义务），但专注于代理人对彼此态度的态度。这样的逻辑在分布式系统的分析中具有直接应用，动态系统通过消息操作来实现变化，这些操作根据通信协议确定的规则修改代理人的知识。多主体认识逻辑是应用需求为逻辑做出重要贡献的另一个例子。Fagin 等人在 1995 年的论文对于那些真正对这个主题感兴趣的人来说是必读的。认识逻辑的其他应用工作记录在从 1986 年开始的一系列会议的论文集中，其中包括 Halpern 1986。尽管涉及的哲学家群体相对较小，但这些会议记录了哲学家与计算机科学家在计算机科学中的最成功的合作之一。这些会议的重点逐渐从计算机科学转向经济学。

计算机科学家习惯将推理视为符号表示的操作。而正是由于人工智能的发展，有限理性成为一个引起严肃兴趣的话题，为哲学和经济学的理想化提供了一种平衡。[27] 你可能会认为，在人工智能领域，认知态度在逻辑推论下的封闭性会非常不受欢迎。但事实并非如此；在 Fagin 等人 1995 年讨论的领域中，可能世界方法不仅是主导理论，甚至在机器人应用中也得到了提倡；参见 Rosenschein＆Kaelbling 1995; Rosenschein 1989。然而，超内涵性问题在人工智能文献中得到了研究；参见 Perlis 1985; Konolige 1986; Lakemeyer 1997; Levesque 1984）。尽管人工智能领域对这个问题的研究提供了新的理论和一些新的结果，但尚未出现主导方法。

## 8. 迈向常识的形式化

约翰·麦卡锡明确的长期目标——对常识知识的形式化——被相对较小的人工智能研究人员群体所采纳和追求。更大的群体（涉及知识表示、认知机器人和定性物理学的人员）的工作为支持更大目标的专门项目做出了贡献。远离实现常识形式化的目标，以至于——如果有可能的话——猜测何时能够完成这个任务是没有希望的。但至少这一努力已经使我们更好地了解如何开发一种可行的常识形式化方法，并将更大的问题分解为更可管理的部分。

这个主题的首部专著，Davis 1991，将总体问题分为以下子主题。

1. 数量和测量
2. 时间
3. 空间
4. 物理学
5. 心智
6. 计划和目标
7. 社会

这些主题中的前四个与定性物理学重叠。有关这个相关子领域的更多信息，请参考 Weld 和 de Kleer 1990 年，Davis 2008 年和 Forbus 2008 年。

项目 6 是戴维斯七项中研究最广泛的。第 4 节讨论了这项工作的早期阶段。关于规划和目标形成的研究有着丰富的后续历史，后来的工作融入了对自主代理规划架构的研究。项目 5 和项目 7 的研究较少。虽然人工社会和人工智能架构得到了广泛研究，但对常识心理学和常识人际推理的形式化研究相对较少。然而，可以参考戴维斯 1991 年和霍布斯和戈登 2005 年的研究。

关于常识挑战的书籍，请参阅穆勒，2006 年。该书的一半以上内容是关于行动和变化的推理。书中还有关于空间和心理状态的简短章节，以及更长的非单调推理的论述。

计算机科学的研究几乎完全受到资金的驱动。常识推理的形式化从未得到过大量的资金支持，但在约翰·麦卡锡于 2011 年去世之前，还是有一些少量的资金可用。常识兴趣小组在 1998 年、2001 年、2003 年、2005 年、2007 年和 2009 年定期举行会议。2003 年会议上提交的许多论文在 2004 年以扩展形式收集在《人工智能》第 153 卷中。戴维斯和莫根斯坦 2004 年的介绍提供了对常识形式化和常识推理机械化研究的有用调查和评价。常识问题页面仍在维护，但从 2010 年至今，该领域的活动一直较为缓慢，除了相关的知识表示研究。

借鉴计算机科学的其他领域的思想，常识社区试图开发一套“基准问题”：公开一些困难但不是不可能解决的问题，并鼓励解决方案的创造和比较。到目前为止，可能有最详细记录的问题是 Ernest Davis 的“打蛋问题”。在常识问题页面中，它被表述如下。

> 一个厨师正在将生鸡蛋敲在玻璃碗上。如果操作正确，鸡蛋撞击碗边的冲击力会将蛋壳劈成两半。厨师将鸡蛋悬在碗上方，用手指分开蛋壳的两半，扩大裂缝，鸡蛋的内容物会轻轻地掉进碗里。最终结果是整个鸡蛋的内容物都在碗里，鸡蛋没有破裂，蛋壳的两半在厨师的手指间。

> 变体：如果发生以下情况会怎样：厨师将鸡蛋迅速撞击？非常缓慢地撞击？厨师将鸡蛋放在碗里并用手稳定施加压力？厨师在打破鸡蛋后试图像剥煮熟鸡蛋一样将其与蛋壳分离？碗是由活页纸制成的？由软黏土制成的？碗比鸡蛋小？碗倒置了？厨师尝试用煮熟的鸡蛋进行此过程？用椰子？用 M&M 巧克力？

随着问题本身，三个解决方案被发布：Shanahan 2004，Lifschitz 1998a 和 Morgenstern 2001 的一个版本。比较这些解决方案是有益的-相似之处超过了差异。所有的作者都认为这是一个规划问题，并在形式化中使用了 Situation Calculus 或 Event Calculus 的版本。每个公理化都是模块化的，例如，有专门用于相关几何和材料属性的模块。每个作者通过展示公理支持在简单情况下破解鸡蛋计划的正确性来提供形式化的“概念证明”。没有一个作者考虑到 Davis 对问题的所有阐述，但公理是以阐述为目标并考虑了一些阐述。目前尚不清楚任何作者是否实际实施了他们的形式化（例如，使用定理证明器，动画或机器人控制器）。

破蛋的例子引出了如何评估常识问题的中等规模形式化的问题。Morgenstern 和 Shanahan 明确表达了这个问题。Morgenstern 建议重要的标准是（1）认识论的充分性（与直觉推理相一致，由从事其中的人体验到），（2）对真实世界的忠实性，（3）可重用性和（4）阐述容忍度。前两个标准可能过于主观，不太有用。Shanahan 还增加了（5）可用性。然而，从长远来看，更重要的是通过生成场景并使用真实世界或模拟机器人代理进行测试和评估的自动化。

任何一种即使是稍微成功的形式化常识的尝试，很快就会遇到前所未有的规模问题，这会带来与软件工程试图解决的类似挑战。即使是相当小的程序和公理系统也很难理解，并且可能产生意想不到的结果。创建和维护它们可能需要开发团队，引发组织问题，以及与模块集成、大型系统的维护和测试以及从不同知识来源生成公理的问题。尽管对大规模软件系统的需求为这类企业提供了最佳实践，但即使有充足的资金，人类专业知识可能也无法胜任这项任务。

可以想象有两种自动化创建形式化的方法。(1)由知识表示社区创建的大规模本体可以被挖掘出公理，或者(2)可以使用机器学习技术直接从语料库中创建公理。第一种方法将涉及与知识整合有关的前所未有的困难。机器学习解释其产品的技术[28]为第二种方法提供了一些希望，但这些技术的输出与逻辑公理完全不同，将它们转换的任务似乎是具有挑战性的，至少可以这样说。

所有这些与哲学分析的方法论形成鲜明对比。分析的规模要小得多，不以实现为目标进行形式化，并且几乎不关注它们的整合。哲学家从未选择一个与规划领域相当的特定领域，并进行持续的形式化尝试，同时伴随着开发适当的逻辑的努力。

很容易怀疑许多一直困扰分析哲学的主题表现出了一种复杂性，例如，从人工智能研究人员试图形式化关于行为及其影响的推理的尝试中出现的复杂性。如果人工智能研究人员能够为常识问题页面中列出的那些问题开发并部分自动化一个形式化方法论，那么这无疑将是对分析哲学家所能取得的成就的巨大进步。但也许哲学家们可以庆幸这被证明是一个如此困难的挑战。

## 9. 分类学表示和推理

### 9.1 基于概念的分类

传统上，代表大量领域信息进行通用推理的任务一直是知识表示中最重要的领域之一。利用领域的直观分类组织对于这个目的非常有用；分类层次不仅有助于组织知识获取的过程，还提供了与基于规则推理的有用连接。[29]

对于那些复杂定义是组织信息的自然方式的领域，基于概念定义的知识工程服务非常成功。像无变量版本的一阶逻辑（例如，Quine 1960）一样，这些系统以概念或一阶谓词为中心，并提供了一些机制来定义它们。与这些分类逻辑相关的基本算法是一个分类器，它输入一组定义并输出定义和原始概念之间的蕴涵关系。有关这些系统的背景，请参阅 Woods＆Schmolze 1992 和 Brachman 等人 1991 年的文献。

最简单的分类逻辑可以被看作是具有复杂谓词的一阶逻辑的子系统。但它们已经以许多方式进行了扩展，并且许多这些扩展引发的问题在许多情况下与哲学逻辑中的主题重叠。

### 9.2 非单调继承

当允许将一个领域组织成层次结构并允许存在例外时，会出现更复杂的逻辑问题。一种处理这个主题的方法是探索如何使分类逻辑非单调；但非单调继承是一个独立的主题。尽管与非单调逻辑存在密切关联，非单调继承更多地依赖于基于图形的表示而不是传统的逻辑思想，并且似乎提供了一种更精细的非单调推理方法，引发了全新的问题，并且很快变得棘手。因此，非单调继承系统往往表达能力较弱，并且它们与更强大的非单调逻辑之间的关系从未完全澄清。有关此主题的背景，请参阅 Thomason 1992 和 Horty 1994。

## 10. 上下文推理

在处理语境对表达式解释的哲学逻辑传统中，以及在动态逻辑的最新传统中，语境主要被形式化为对变量赋值，并且语言的设计旨在使对语境的推理要么非常有限，要么根本不可能。

AI 领域对表示大型和明显异构领域以及整合不同知识源的关注，以及对在 2.2 节中讨论的形式化常识的兴趣，导致 AI 社区对更明确考虑语境的形式化语言产生了兴趣。

在麦卡锡 1993b 中，麦卡锡推荐研究包含一种构造的语言

在这里，“is-true”被解释为“是真实的”。这类似于情境演算的构造方式，但现在“stands for”表示一个上下文，而“is”是一个可能复杂的命题表示，许多人（包括麦卡锡）认为它指的是一个句子。

这里既有模态逻辑的类比，也有带有显式真值谓词的语言的类比。但是，对于上下文逻辑的应用所设想的机会和问题在许多方面都是新的。麦卡锡原始建议之后关于上下文逻辑的研究包括麦卡锡和布瓦克（1998）、古哈（1991）以及 Akman 等人（2001）和 Bouquet 等人（1999）的会议论文集中的一些论文。受麦卡锡建议启发的 Richard Montague 的意向逻辑的扩展，请参见 Thomason（2003）和（2005）。

由于某种原因，计算机界在显式上下文形式化的研究方面没有进一步深入，但是关于信息整合的应用，请参见 Snidaro（2019）。

对上下文的哲学兴趣，尤其是对上下文与命题态度和情态的相互作用的兴趣，仍然很强烈；但是麦卡锡设想的非常普遍的上下文逻辑框架尚未被哲学家们采纳。

## 11. 实践理性的逻辑理论前景

有理由希望，在人工智能中将逻辑方法与规划应用相结合，可以实现比以往更全面和更充分的实践推理理论的发展。与许多与常识推理有关的问题一样，所需的形式化的规模和复杂性超出了传统的哲学逻辑技术的范围。然而，通过实施和测试这些形式化的计算方法，并且借助认知机器人等领域提供的实验室来开发和测试想法，我们可以希望在这个问题上取得根本性的进展，这个问题自亚里士多德首次提出以来几乎没有取得任何进展：如何设计一个真正适用于现实问题的实践推理的形式化。

由冯·赖特（见冯·赖特 1983）开始的基于逻辑的道义逻辑的经典作品是一种思想的来源；参见（Horty 2001 和 van der Torre 1997）。事实上，正如基于逻辑的道义逻辑的最新研究所显示的那样，非单调逻辑为经典道义逻辑提供了一种自然且有用的补充。一项最近的研究（Horty 2012）试图基于 Reiter 的默认逻辑的优先版本来建立道义逻辑。

当这些思想与在上文第 4 节中讨论的关于规划和行动推理基础的工作相结合时，实践推理的更强大的解释开始出现。但是，通过将形式化扩展到包括偏好和意图，这一发展可以进一步推进。[30]

最终，需要一个智能推理和行动代理模型。开发这样的模型不一定完全是逻辑的问题，但根据一种思想流派，逻辑在其中起着核心作用；例如，参见 Baral＆Gelfond 2000，Wobcke 等人 1998，Burkhard 等人 1998），Wooldridge 2000，Thielscher 2005 和 Levesque＆Lakemeyer 2008。

## 12. 阅读材料

《Minker 2000b》是一本关于基于逻辑的人工智能领域的综合性论文集和原创贡献，其中详细引用了相关文献。杰克·明克尔（Jack Minker）的引言《Minker 2000a》是对该领域的有用导引。对于希望进一步研究这个主题的读者来说，这本书是一个很好的起点。《Brachman & Levesque 2004》以教科书形式介绍了知识表示领域。《Davis 1991》和《Mueller 2006》是关于形式化常识推理这一具有挑战性问题的专著。《Straßer & Antonelli 2012》是对非单调逻辑感兴趣的读者的良好入门点，《Shanahan 2009》则是对框架问题的有用讨论。《Wooldridge 2000》涉及到理性代理的逻辑形式化。

知识表示与推理会议的论文集提供了从 1989 年至今人工智能领域逻辑研究的最详细记录：《Brachman et al. 1989》、《Allen et al. 1991》、《Nebel et al. 1992》、《Doyle et al. 1994》、《Aiello et al. 1996》、《Cohn et al. 1998》、《Cohn et al. 2000》、《Fensel et al. 2002》、《Dubois et al. 2004》、《Doherty et al. 2006》、《Brewka & Lang 2008》、《Lin et al. 2010》、《Eiter et al. 2012》、《Baral et al. 2014》、《Baral et al. 2016》、《Thielscher et al. 2018》、《Calvanese et al. 2020》、《Bienvenu et al. 2021》和《Kern-Isberner et al. 2022》。

## Bibliography

* Aiello, Luigia Carlucci, Doyle, Jon, and Shapiro, Stuart (eds.), 1996, *KR’96: Principles of Knowledge Representation and Reasoning*, San Francisco: Morgan Kaufmann.
* Akman, Varol, Bouquet, Paolo, Thomason, Richmond, and Young, Roger A. (eds.), 2001, *Modeling and Using Context*, Berlin: Springer-Verlag.
* Alcourrón, Carlos E., 1995, “Defeasible logics: Demarcation and affinities”, in *Conditionals: From Philosophy to Computer Science*, Gabriella Crocco, Luis Fariñas del Cerro, and A. Herzig (eds.), Oxford: Oxford University Press, 67–102.
* Allen, James F., Fikes, Richard, and Sandewall, Erik (eds.), 1989, *KR’89: Principles of Knowledge Representation and Reasoning*, San Francisco: Morgan Kaufmann.
* Allen, James F., Fikes, Richard, and Sandewall, Erik (eds.), 1991, *KR’91: Principles of Knowledge Representation and Reasoning*, San Mateo, California: Morgan Kaufmann.
* Allwein, Gerard and Barwise, Jon (eds.), 1996, *Logical Reasoning with Diagrams*, Oxford: Oxford University Press.
* Amarel, Saul, 1968, “On representations of problems of reasoning about actions”, in *Machine Intelligence 3*, Donald Mitchie (ed.), Chichester, England: Ellis Horwood, 131–171.
* Antoniou, Grigoris, 1997, *Nonmonotonic Reasoning*, Cambridge, Massachusetts: The MIT Press.
* Antoniou, Grigoris and Wang, Kewen, 2007, “Default logic”, in *Handbook of the History of Logic, Volume 8: The Many-Valued and Nonmonotonic Turn in Logic*, Dov Gabbay and John Woods (eds.), Amsterdam: Elsevier Science Publishers, 517–555.
* Arlo-Costa, Horacio and Shapiro, Scott, 1992, “Maps between nonmonotonic logic and conditional logic”, in *KR’92. Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference*, Bernhard Nebel, Charles Rich, and William Swartout (eds.), San Mateo, California: Morgan Kaufmann, 553–564.
* Asher, Nicholas, 1995, “Commonsense entailment: A conditional logic for some generics”, in *Conditionals: From Philosophy to Computer Science*, Gabriella Crocco, Luis Fariñas del Cerro, and A. Herzig (eds.), Oxford: Oxford University Press, 103–145.
* Asher, Nicholas and Morreau, Michael, 1991, “Commonsense entailment: a modal theory of nonmonotonic reasoning”, in *Proceedings of the Twelfth International Joint Conference on Artificial Intelligence*, J. Mylopoulos and R. Reiter (eds.), Los Altos, California: Morgan Kaufmann, 387–392.
* Austin, John L., 1961, “A plea for excuses”, in *Philosophical Papers*, J.O. Urmson and G.J. Warnock (eds.), Oxford: Oxford University Press.
* Bacchus, Fahiem, Halpern, Joseph Y., and Levesque, Hector J., 1999, “Reasoning about noisy sensors and effectors in the situation calculus”, *Artificial Intelligence*, 111(1–2): 171–208.
* Baker, Andrew B., 1989, “A simple solution to the Yale shooting problem”, in *KR’89: Principles of Knowledge Representation and Reasoning*, Ronald J. Brachman, Hector J. Levesque, and Raymond Reiter (eds.), San Mateo, California: Morgan Kaufmann, 11–20.
* Baral, Chitta, 1995, “Reasoning about actions: Non-deterministic effects, constraints, and qualification”, in *Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence*, Chris Mellish (ed.), San Francisco: Morgan Kaufmann, 2017–2023.
* Baral, Chita, De Giacomo, Giuseppe, and Eiter, Thomas (eds.), 2014, *KR2014: Principles of Knowledge Representation and Reasoning*, Menlo Park, California: AAAI Press.
* Baral, Chita, Delgrande, James, and Wolter, Frank (eds.), 2016, *KR2016: Principles of Knowledge Representation and Reasoning*, Menlo Park, California: AAAI Press.
* Baral, Chitta and Gelfond, Michael, 2000, “Reasoning agents in dynamic domains”, in *Logic-Based Artificial Intelligence*, Jack Minker (ed.), Dordrecht: Kluwer Academic Publishers, 257–279.
* Besnard, Philippe, 1992, *Default Logic*, Berlin: Springer-Verlag.
* Besnard, Philippe and Hunter, Anthony, 2008, *Elements of Argumentation*, Cambridge, Massachusetts: The MIT Press.
* Bienvenu, Meghyn, Lakemeyer, Gerhard, and Erdem, Esra (eds.), 2021, *KR2021: Principles of Knowledge Representation and Reasoning*, Menlo Park, California: AAAI Press.
* Bochman, Alexander, 2004, “A causal approach to nonmonotonic reasoning”, *Artificial Intelligence*, 160(1–2): 105–143.
* Bochman, Alexander, 2007, “Nonmonotonic reasoning”, in *Handbook of the History of Logic. Volume 8: The Many Valued and Nonmonotonic Turn in Logic*, Dov M. Gabbay and John Woods (eds.), Amsterdam: Elsevier Publishing Co., 557–622.
* Boolos, George, 1993, *The Logic of Provability*, Cambridge, England: Cambridge Universoti Press.
* Bouquet, Paolo, Serafini, Luigi, Brézillon, Patrick, Benerecetti, Massimo, and Castellani, Francesca (eds.), 1999, *Modeling and Using Contexts: Proceedings of the Second International and Interdisciplinary Conference, CONTEXT’99*, Berlin: Springer-Verlag.
* Boutilier, Craig, 1992, “Conditional logics for default reasoning and belief revision”, Tech. Rep. KRR-TR-92-1, Computer Science Department, University of Toronto, Toronto, Ontario.
* Boutilier, Craig, 1996, “Iterated revision and minimal change of conditional beliefs”, *Journal of Philosophical Logic*, 25(3): 263–305.
* Boutilier, Craig, Dean, Thomas, and Hanks, Steve, 1996, “Planning under uncertainty: Structural assumptions and computational leverage”, in *New Directions in AI Planning*, Malik Ghallab and Alfredo Milani (eds.), Amsterdam: IOS Press, 157–171.
* Brachman, Ronald J., Levesque, Hector J., and Reiter,, Raymond, 1989, *KR’89: Principles of Knowledge Representation and Reasoning*, San Mateo, Morgan Kaufmann.
* Brachman, Ronald J., McGuinness, Deborah L., Patel-Schneider, Peter F., and Resnik, Lori A., 1991, “Living with CLASSIC: When and how to use a KL-ONE-like language”, in *Principles of Semantic Networks*, John F. Sowa (ed.), San Mateo, California: Morgan Kaufmann, 401–456.
* Brachman, Ronald J. and Levesque, Hector J., 2004, *Knowledge Representation and Reasoning*, Amsterdam: Elsevier.
* Brewka, Gerhard, 1991, *Nonmonotonic Reasoning: Logical Foundations of Commonsense*, Cambridge, England: Cambridge University Press.
* Brewka, Gerhard, Dix, Jürgen, and Konolige, Kurt, 1997, *Nonmonotonic Reasoning: An Overview*, Stanford: CSLI Publications.
* Brewka, Gerhard and Lang, Jérôme (eds.), 2008, *KR2008: Proceedings of the Eleventh National Conference*, Menlo Park, California: AAAI Press.
* Burger, Wilhelm and Bhanu, Bir, 1992, *Qualitative Motion Planning*, Dordrecht: Kluwer Academic Publishers.
* Burkhard, Hans-Dieter, Hannebauer, Markus, and Wendler, Jan, 1998, “Belief-desire-intention deliberation in artificial soccer”, *The AI Magazine*, 1998(3): 87–93.
* Burgess, John P., 1984, “Basic tense logic”, in *Handbook of Philosophical Logic, Volume II: Extensions of Classical Logic*, Dov Gabbay and Franz Guenther (eds.), Dordrecht: D. Reidel Publishing Co., 89–133.
* Calvanese, Diego, Erdem, Esra, and Thielscher, Michael (eds.), 2020, *KR2020: Principles of Knowledge Representation and Reasoning*, Menlo Park, California: AAAI Press.
* Carlson, Greg N. and Pelletier, Francis Jeffry (eds.), 1995, *The Generic Book*, Chicago, IL: Chicago University Press.
* Carnap, Rudolph, 1955, “Meaning and synonymy in natural languages”, *Philosophical Studies*, 7: 33–47. Reprinted in [Carnap 1956](https://plato.stanford.edu/entries/logic-ai/#carnap:1956a), pp. 233–247.
* Carnap, Rudolph, 1956, *Meaning and Necessity*, Chicago: Chicago University Press, second edition (First edition published in 1947.).
* Casati, Roberto and Varzi, Achille C., 1996, *Holes and Other Superficialities*, Cambridge, Massachusetts: The MIT Press.
* Casati, Roberto and Varzi, Achille C., 1999, *Parts and Places: The Structures of Spatial Representation*, Cambridge, Massachusetts: The MIT Press.
* Casini, Giovanni and Straccia, Umberto, 2022, “A general framework for modelling conditional reasoning—Preliminary Report”, in *KR2022: Principles of Knowledge Representation and Reasoning, Proceedings of the Nineteenth International Conference*, Gabriele Kern-Isberner and Gerhard Lakemeyer and Thomas Meyer (eds.), Menlo Park, California, 575–595.
* Chellas, Brian, 1975, “Basic conditional logic”, *Journal of Philosophical Logic*, 4(2): 133–154.
* Chen, Su-Shing (ed.), 1990, *Advances in Spatial Reasoning, Volume 1*, Norwood, New Jersey: Ablex.
* Chopra, Amit, van der Torre, Leon, Verhagen, Harko, and Villata, Serena 1997, *Handbook of Normative Multiagent Systems*, London: College Publications.
* Clancey, William J., 1983, “The epistemology of a rule-based expert system: a framework for explanation”, *Artificial Intelligence*, 20: 215–251.
* Clark, Keith L., 1978, “Negation as failure”, in *Logic and Data Bases*, H. Gallaire and Jack Minker (eds.), New York: Plenum Press, 293–322.
* Clarke, Bowman L., 1981, “A calculus of individuals based on ‘connection’”, *Notre Dame Journal of Formal Logic*, 22(3): 204–218.
* Clarke, Bowman L., 1985, “Individuals and points”, *Notre Dame Journal of Formal Logic*, 26(1): 61–75.
* Cohen, Philip R. and Levesque, Hector J., 1990, “Intention is choice with commitment”, *Artificial Intelligence*, 42(3): 213–261.
* Cohn, Anthony G., 1996, “Qualitative spatial representation and reasoning techniques”, in *KI-97, Advances in Artificial Intelligence*, Gerhard Brewka, Christopher Habel, and Bernhard Nebel (eds.), Berlin: Springer-Verlag, 1-30.
* Cohn, Anthony G., Bennett, Brandon, Gooday, John, and Gotts, Nicholas M., 1997, “Representing and reasoning with qualitative spatial relations”, in *Spatial and Temporal Reasoning*, Oliviero Stock (ed.), Dordrecht: Kluwer Academic Publishers, 97–134.
* Cohn, Anthony G., Schubert, Lenhart, and Shapiro, Stuart C. (eds.), 1998, *KR’98: Principles of Knowledge Representation and Reasoning*, San Francisco: Morgan Kaufmann.
* Cohn, Anthony G., Giunchiglia, Fausto, and Selman, Bart (eds.), 2000, *KR2000: Principles of Knowledge Representation and Reasoning*, San Francisco: Morgan Kaufmann.
* Copeland, B. Jack, 1996, “Arthur Prior’s life and legacy”, in *Logic and Reality: Essays on the Legacy of Arthur Prior*, Jack Copeland (ed.), Oxford: Oxford University Press, 1–40.
* Davis, Ernest, 1991, *Common Sense Reasoning*, San Francisco: Morgan Kaufmann.
* Davis, Ernest and Morgenstern, Leora, 2004, “Introduction: Progress in formal commonsense reasoning”, *Artificial Intelligence*, 153(1–2): 1–12.
* Davis, Martin, 1988, “Mathematical Logic and the Origin of Modern Computers”, in *The Universal Turing Machine: A Half-Century Survey*, Jack Copeland (ed.), Oxford: Oxford University Press, 149–174.
* Davis, Ernest, 2008, “Physical reasoning”, in *Handbook of Knowledge Representation*, van Harmelen, Frank, Lifschitz, Vladimir and Porter, Bruce (eds.), : Elsevier, 597–620.
* DeJong, Gerald D. and Bennett, Scott W., 1989, “Permissive planning: Extending classical planning to uncertain task domains”, *Artificial Intelligence*, 89(1–2): 173–217.
* Delgrande, James P., 1998, “Conditional logics for defeasible logics”, in *Handbook of Defeasible Reasoning and Uncertainty Management Systems, Volume 2*, Dov M. Gabbay and Philippe Smets (eds.), Dordrecht: Kluwer Academic Publishers, 135–174.
* Deneker, Marc, Marek, Victor W., and Truszczyński, Miroslaw 1998, “Uniform semantic treatment of default and autoepistemic logics”, *Artificial Intelligence*, 143(1): 79–122.
* Dennett, Daniel, 1987, “Cognitive wheels: The frame problem of AI”, in *The Robot’s Dilemma: The Frame Problem in Artificial Intelligence*, Zenon Pylyshyn (ed.), Norwood, New Jersey: Ablex Publishing Co., 41–64.
* Doherty, Patrick, Fikes, Richard, and Sandewall, Erik (eds.), 2006, *KR’2006: Proceedings, Tenth International Conference on Principles of Knowledge Representation and Reasoning*, Palo Alto: AAAI Press.
* Doyle, Jon, 1995, “A truth maintenance system”, *Artificial Intelligence*, 12(1): 231–272.
* Doyle, Jon, Sandewall, Erik, and Torasso, Pietro (eds.), 1994, *KR’94: Principles of Knowledge Representation and Reasoning*, San Francisco: Morgan Kaufmann.
* Doyle, Jon and Thomason, Richmond H., 1999, “Background to qualitative decision theory”, *AI Magazine*, 20(2): 55–68.
* Dubois, Didier, Welty, Christopher, and Williams, Mary-Anne (eds.), 2004,*KR2004: Principles of Knowledge Representation and Reasoning*, Palo Alto: AAAI Press.
* Eiter, Tomas, McIlraith, Sheila A., and Brewka, Gerald (eds.), 1992, *KR2012: Proceedings of the Thirteenth International Conference*, Menlo Park, California: AAAI Press.
* Elkan, Charles, 1991, “Reasoning about action in first-order logic”, in *Proceedings of the Conference of the Canadian Society for Computational Studies of Intelligence (CSCSI)*, Canadian Society for Computational Studies of Intelligence, San Francisco: Morgan Kaufman, 221–227.
* Elkan, Charles, 1995, “On solving the qualification problem”, in *Working Notes of the AAAI Spring Symposium on Extending Theories of Action: Formal Theories and Applications*, Menlo Park, California: American Association for Artificial Intelligence.
* Fagin, Ronald, Halpern, Joseph Y., Moses, Yoram, and Vardi, Moshe Y., 1995, *Reasoning about Knowledge*, Cambridge, Massachusetts: The MIT Press.
* Fensel, Dieter, Giunchiglia, Fausto, McGuinness, Deborah, and Williams, Mary-Anne (eds.), 2002, *KR2002: Principles of Knowledge Representation and Reasoning*, San Francisco, California: Morgan Kaufmann.
* Fikes, Richard, 1996, “Ontologies: What are they, and where’s the research?”, in *KR’96: Principles of Knowledge Representation and Reasoning*, Luigia Carlucci Aiello, Jon Doyle, and Stuart Shapiro (eds.), San Francisco, California: Morgan Kaufmann, 652–654.
* Finger, Jeffrey J., 1987, *Exploiting Constraints in Design Synthesis*, Ph.D. dissertation, Department of Computer Science, Stanford University, Stanford, California.
* Fodor, Jerry A., 1987, “Modules, frames, fridgeons, sleeping dogs, and the music of the spheres”, in *The Robot’s Dilemma: The Frame Problem in Artificial Intelligence*, Zenon Pylyshyn (ed.), Norwood, New Jersey: Ablex Publishing Co., 139–149.
* Forbus, Kenneth 2008, “Qualitative Modeling”, in *Handbook of Knowledge Representation*, van Harmelen, Frank, Lifschitz, Vladimir and Porter, Bruce (eds.), : Elsevier, 361–393.
* Ford, Kenneth M. and Pylyshyn, Zenon (eds.), 1996, *The Robot’s Dilemma Revisited: The Frame Problem in Artificial Intelligence*, Norwood, New Jersey: Ablex Publishing Co.
* Gabbay, Dov, Hogger, Christopher J., and Robinson, J. A. (eds.), 1994, *Handbook of Logic in Artificial Intelligence and Logic Programming, Volume 3: Nonmonotonic Reasoning and Uncertain Reasoning*, Oxford: Oxford University Press.
* Gabbay, Dov M., 1995, “Conditional implications and non-monotonic consequence”, in *Conditionals: From Philosophy to Computer Science*, Gabriella Crocco, Luis Fariñas del Cerro, and A. Herzig (eds.), Oxford: Oxford University Press, 337–359.
* Galton, Anthony, 1997, “Space, time, and movement”, in *Spatial and Temporal Reasoning*, Oliviero Stock (ed.), Dordrecht: Kluwer Academic Publishers, 321–352.
* Gärdenfors, Peter and Makinson, David, 1994, “Nonmonotonic inferences based on expectations”, *Artificial Intelligence*, 65(2): 197–245.
* Geffner, Hector, 1990, “Causal theories of nonmonotonic reasoning”, in *Proceedings of the Eighth National Conference on Artificial Intelligence*, Thomas Dietterich and William Swartout (eds.), American Association for Artificial Intelligence, Menlo Park, CA: AAAI Press, 524–530.
* Geffner, Hector, 1992, *Default Reasoning: Causal and Conditional Theories*, Cambridge, Massachusetts: MIT Press.
* Gelfond, Michael and Lifschitz, Vladimir, 1998, [“Action languages”](https://www.diva-portal.org/smash/get/diva2:1716299/FULLTEXT02.pdf), *Electronic Transactions on AI*, 3.
* Genesereth, Michael and Nilsson, Nils J., 1987, *Logical Foundations of Artificial Intelligence*, San Mateo, California: Morgan Kaufmann.
* Ghallab, Malik, Nau, Dana, and Traverso, Paolo, 2014, “The actor’s view of automated planning and acting: A position paper”, *Artificial Intelligence*, 208: 1–17.
* Ginsberg, Matthew L. (ed.), 1987, *Readings in Nonmonotonic Reasoning*, Los Altos, California: Morgan Kaufmann. (Out of print.).
* Giordano, Laura and Schwind, Camilla, 2004, “Conditional logic of actions and causation”, *Artificial Intelligence*, 157(1–2): 239–279.
* Giunchiglia, Enrico, Kartha, G. Neelakantan, and Lifschitz, Vladimir, 1997, “Representing action: Indeterminacy and ramifications”, *Artificial Intelligence*, 95(2): 409–438.
* Giunchiglia, Enrico and Lifschitz, Vladimir, 1998, “An action language based on causal explanation”, in *Proceedings of the Fourteenth National Conference on Artificial Intelligence and the Ninth Innovative Applications of Artificial Intelligence Conference*, Ted Senator and Bruce Buchanan (eds.), American Association for Artificial Intelligence, Menlo Park, California: AAAI Press, 623–628.
* Glasgow, Janice, Narayanan, N. Hari, and Chandrasekaran, B. (eds.), 1995, *Diagrammatic Reasoning*, Cambridge, Massachusetts: The MIT Press.
* Goodman, Nelson, 1946, *Fact, Fiction and Forecast*, Cambridge, Massachusetts: Harvard University Press, fourth edition.
* Gotts, N.M., 1994, “How far can we ‘C’? defining a doughnut using connection alone”, in *KR’94: Principles of Knowledge Representation and Reasoning*, Jon Doyle, Erik Sandewall, and Pietro Torasso (eds.), San Francisco, California: Morgan Kaufmann, 246–257.
* Gotts, N.M., 1996, “Topology from a single primitive relation: Defining topological properties and relations in terms of connection”, Tech. Rep. 96.24, School of Computer Studies, University of Leeds, Leeds.
* Guha, Ramanathan V., 1991, “Contexts: a formalization and some applications”, Tech. Rep. STAN-CS-91-1399, Stanford Computer Science Department, Stanford, California.
* Guidotti, Riccardo, Monreale, Anna, Ruggieri, Salvatore, Turini, Franco, Giannotti, Fosca, and Pedreschi, Dino, 2018, “A survey of methods for explaining black box models”, *ACM Computing Surveys*, 51(5): 1–42.
* Gustaffson, Joakim and Doherty, Patrick, 1996, “Embracing occlusion in specifying the indirect effects of actions”, in *KR’96: Principles of Knowledge Representation and Reasoning*, Luigia Carlucci Aiello, Jon Doyle, and Stuart Shapiro (eds.), San Francisco, California: Morgan Kaufmann, 87–98.
* Halpern, Joseph Y. (ed.), 1986, *Theoretical Aspects of Reasoning about Knowledge: Proceedings of the First Conference (TARK 1986)*, Los Altos, California: Morgan Kaufmann Publishers, Inc.
* Halpern, Joseph L., 2016, *Actual Causality*, Cambridge, Massachusetts: The MIT Press.
* Halpern, Joseph Y. and Moses, Yoram, 1985, “Towards a theory of knowledge and ignorance”, in *Logics and Models of Concurrent Systems*, Krzysztof R. Apt (ed.), Berlin: Springer-Verlag, 459–476.
* Halpern, Joseph, and Pearl, Judea, 2001, “Causes and explanations: a Structural-model approach”, in *Uncertainty in Artificial Intelligence. Proceedings of the Seventeenth Conference*, San Francisco: Morgan Kaufmann, 194–202.
* Hammer, Eric M., 1995, *Logic and Visual Information*, Stanford, California: CSLI Publications.
* Hanks, Steven and McDermott, Drew, 1985, “Temporal reasoning and default logics”, Tech. Rep. YALEU/CSD/RR#430, Department of Computer Science, Yale University, New Haven, Connecticut.
* Hanks, Steven and McDermott, Drew, 1986, “Default reasoning, nonmonotonic logics and the frame problem”, in *Proceedings of the Fifth National Conference on Artificial Intelligence*, Tom Kehler and Stan Rosenschein (eds.), American Association for Artificial Intelligence, Los Altos, California: Morgan Kaufmann, 328–333.
* Hanks, Steven and McDermott, Drew, 1987, “Non-monotonic logics and temporal projection”, *Artificial Intelligence*, 33(3): 379–412.
* Haugeland, John, 1981, “Semantic engines: An introduction to mind design”, in *Mind Design*, John Haugeland (ed.), Cambridge, Massachusetts: The MIT Press, 1–34.
* Haugh, Brian, 1987, “Simple causal minimization for temporal persistence and projection”, in *Proceedings of the Seventh National Conference on Artificial Intelligence*, Kenneth Forbus and Howard Shrobe (eds.), American Association for Artificial Intelligence, Menlo Park, California: AAAI Press, 218–223.
* Hintikka, Jaakko, 1962, *Knowledge and Belief*, Ithaca, New York: Cornell University Press.
* Hitchcock, Christopher, 2022, “Causal models”, in *The Stanford Encyclopedia of Philosophy*, Edward N. Zalta (ed.), URL https://plato.stanford.edu/archives/spr2022/entries/causal-models/.
* Hobbs, Jerry and Gordon, Andrew, 2005, “Encoding knowledge of commonsense psychology”, *7th International Symposium on Logical Formalizations of Commonsense Reasoning.* May 22–24, 2005, Corfu, Greece.
* Horty, John F., 1994, “Some direct theories of nonmonotonic inheritance”, in *Handbook of Logic in Artificial Intelligence and Logic Programming, Volume 3: Nonmonotonic Reasoning and Uncertain Reasoning*, Dov Gabbay, Christopher J. Hogger, and J. A. Robinson (eds.), Oxford University Press, 111–187.
* Horty, John F., 2001, *Agency and Deontic Logic*, Oxford: Oxford University Press.
* Horty, John, 2012, *Reasons as Defaults*, Oxford: Oxford University Press.
* Israel, David J., 1991, “A short sketch of the life and career of John McCarthy”, in *Artificial Intelligence and Mathematical Theory of Computation: Papers in Honor of John McCarthy*, Vladimir Lifschitz (ed.), San Diego, California: Academic Press.
* Iwasaki, Yumi and Simon, Herbert, 1986, “Causality in device behavior”, *Artificial Intelligence*, 29(1): 3–32.
* Johnston, Benjamin and Williams, Mary-Anne, “A generic framework for approximate simulation in commonsense reasoning systems”, AAAI 2007 Spring Symposium on Commonsense Reasoning, American Association for Artificial Intelligence, Menlo Park, 2007.
* Kapur, Deepak and Mundy, Joseph L., 1988, “Geometric reasoning and artificial intelligence: Introduction to the special volume”, *Artificial Intelligence*, 37(1–3): 1–11.
* Kern-Isberner, Gabriele, 2001, *Conditionals in Nonmonotonic Reasoning and Belief Revision: Considering Conditionals as Agents*, Berlin: Springer-Verlag.
* Kern-Isberner, Gabriele, Lakemeyer, Gerhard, and Meyer, Thomas (eds.), 2022, *KR2022: Principles of Knowledge Representation and Reasoning*, Menlo Park, California: AAAI Press.
* Konolige, Kurt, 1986, “What awareness isn’t: A sentential view of implicit and explicit belief”, in *Theoretical Aspects of Reasoning about Knowledge: Proceedings of the First Conference*, Joseph Y. Halpern (ed.), Los Altos, California: Morgan Kaufmann Publishers, Inc., 241–250.
* Konolige, Kurt, 1988, “On the relation between default and autoepistemic logic”, *Artificial Intelligence*, 35(3): 343–382. (See also errata, Artificial Intelligence (1): 115.).
* Konolige, Kurt, 1994, “Autoepistemic logic”, in *Handbook of Logic in Artificial Intelligence and Logic Programming, Volume 3: Nonmonotonic Reasoning and Uncertain Reasoning*, Dov Gabbay, Christopher J. Hogger, and J. A. Robinson (eds.), Oxford: Oxford University Press, 217–295.
* Konolige, Kurt and Pollack, Martha, 1993, “A representationalist theory of intention”, in *Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence*, Ruzena Bajcsy (ed.), San Mateo, California: Morgan Kaufmann.
* Kosslyn, Stephen Michael, 1990, “Visual cognition: Introduction”, in *An Invitation to Cognitive Science. Volume 2: Visual Cognition and Action*, Daniel N. Osherson and Howard Lasnik (eds.), Cambridge, Massachusetts: The MIT Press, 3–4.
* Kowalski, Robert A. and Sergot, Marek J., 1986, “A logic-based calculus of events”, *New Generation Computing*, 4: 67–95.
* Lakemeyer, Gerhard, 1997, “Limited reasoning in first-order knowledge bases”, *Artificial Intelligence*, 71(2): 213–255.
* Laux, Armin and Wansing, Heinrich (eds.), 1995, *Knowledge and Belief in Philosophy and Artificial Intelligence*, Berlin: Akedemie Verlag.
* Lehmann, Daniel and Magidor, Menachem, 1992, “What does a conditional knowledge base entail?”, *Artificial Intelligence*, 55(1): 1–60.
* Lenat, Douglas B. and Guha, R.V., 1989, *Building Large Knowledge-Based Systems: Representation and Inference in the CYC Project.*, Reading, Massachusetts: Addison-Wesley Publishing Company.
* Lent, Jeremy and Thomason, Richmond, 2015, “Action models for conditionals”, *Journal of Logic, Language, and Information*, 24(2): 211–231.
* Leśniewski, Stanisław, 1916, “Podstawy ogólnej teorii mnogosci I”, English Title: “Foundations of a general set theory I.”, Moscow: Popławski.
* Levesque, Hector and Lakemeyer, Gerhard, 2000, *The Logic of Knowledge Bases*, Cambridge, Massachusetts: The MIT Press.
* Levesque, Hector J., 1984, “A logic of implicit and explicit belief”, in *Proceedings of the Fourth National Conference on Artificial Intelligence*, American Association for Artificial Intelligence, 198–202.
* Levesque, Hector J., 1987, “Taking issue: Guest editor’s introduction”, *Computational Intelligence*, 3(3): 149–150.
* Levesque, Hector and Lakemeyer, Gerhard, 2008, “Cognitive robotics”, in *Handbook of Knowledge Representation*, Harmelen, Frank van, Lifschitz, Vladimir, and Porter, Bruce (eds.), Amsterdam: Elsevier, 969–886.
* Levy, Alon Y., 2000, “Logic-based techniques in data integration”, in *Logic-Based Artificial Intelligence*, Jack Minker (ed.), Dordrecht: Kluwer Academic Publishers, 575–595.
* Lin, Fangshen, Sattler, Ulrike, and Truszczyński, Miroslaw (eds.), 2010, *KR2010: Principles of Knowledge Representation and Reasoning*, Menlo Park, California: AAAI Press.
* Lifschitz, Vladimir, 1987, “Formal theories of action: Preliminary report”, in *Proceedings of the Tenth International Joint Conference on Artificial Intelligence*, John McDermott (ed.), Los Altos, California: Morgan Kaufmann.
* Lifschitz, Vladimir (ed.), 1990a, *Formalizing Common Sense: Papers by John McCarthy*, Norwood, New Jersey: Ablex Publishing Corporation.
* Lifschitz, Vladimir, 1990b, “Understanding common sense: McCarthy’s research in artificial intelligence”, in *Formalizing Common Sense: Papers by John McCarthy*, Vladimir Lifschitz (ed.), Norwood, New Jersey: Ablex Publishing Corporation, 1–8.
* Lifschitz, Vladimir, 1997, “On the logic of causal explanation”, *Artificial Intelligence*, 96(2): 451–465.
* Lifschitz, Vladimir, 1998a, “Cracking an Egg: An Exercise in Commonsense Reasoning”, presented at the Fourth Symposium on Logical Formalizations of Commonsense Reasoning, London, January 1998. [Lifschitz 1998a available online in PostScript](https://www.cs.utexas.edu/~vl/papers/egg.ps).
* Lifschitz, Vladimir, 1998b, “Situation calculus and causal logic”, in *KR’98: Principles of Knowledge Representation and Reasoning*, Anthony G. Cohn, Lenhart Schubert, and Stuart C. Shapiro (eds.), San Francisco, California: Morgan Kaufmann, 536–546.
* Lin, Fangzhen, 1995, “Embracing causality in specifying the indirect effects of actions”, in *Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence*, Chris Mellish (ed.), San Francisco: Morgan Kaufmann, 1985–1991.
* Lin, Fangzhen, Sattler, Ulrike, and Truszczynski, Miroslaw (eds.), 2010, *KR2010: Proceedings of the Twelfth International Conference*, Palo Alto: AAAI Press.
* Lormand, Eric, 1996, “The holorobophobe’s dilemma”, in *The Robot’s Dilemma Revisited: The Frame Problem in Artificial Intelligence*, Kenneth M. Ford and Zenon Pylyshyn (eds.), Norwood, New Jersey: Ablex Publishing Co., 61–88.
* Łukaszewicz, Witold, 1990, *Non-Monotonic Reasoning: Formalization of Commonsense Reasoning*, New York: Ellis Horwood.
* Makinson, David, 2005a, “How to go non-monotonic”, in *Handbook of Philosophical Logic* (Volume 12, Second edition), Dov Gabbay and Franz Guenthner (eds.), Berlin: Springer-Verlag, 175–278.
* Makinson, David, 2005b, *Bridges from Classical to Nonmonotonic Logic*, London: King’s College Publications.
* Makinson, David C. and Leendert van der Torre “Input/output logics”, *Journal of Philosophical Logic*, 29(4): 383–408.
* Marek, Victor and Truszczynski, Mirosaw, 1991, “Autoepistemic logic”, *Journal of the Association for Computing Machinery*, 38(3): 588–619.
* Marek, Wictor and Truszczynski, Mirosaw, 1989, “Relating autoepistemic and default logics”, in *KR’89: Principles of Knowledge Representation and Reasoning*, Ronald J. Brachman, Hector J. Levesque, and Raymond Reiter (eds.), San Mateo, California: Morgan Kaufmann, 276–288.
* Marek, Wictor and Truszczynski, Mirosaw, 1994, *Nonmonotonic Logic: Context-Dependent Reasoning*, Berlin: Springer-Verlag.
* McCain, Norman and Turner, Hudson, 1995, “A causal theory of ramifications and qualifications”, in *Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence*, Chris Mellish (ed.), San Francisco: Morgan Kaufmann, 1978–1984.
* McCain, Norman and Turner, Hudson, 1997, “Causal theories of action and change”, in *Proceedings of the Thirteenth National Conference on Artificial Intelligence and the Eighth Innovative Applications of Artificial Intelligence Conference*, Howard Shrobe and Ted Senator (eds.), American Association for Artificial Intelligence, Menlo Park, California: AAAI Press, 460–465.
* McCarthy, John, 1959, “Programs with common sense”, in *Proceedings of the Teddington Conference on the Mechanization of Thought Processes*, London: Her Majesty’s Stationary Office, 75–91.
* McCarthy, John, 1979, “First order theories of individual concepts and propositions”, in *Machine Intelligence 9*, J.E. Hayes, D. Mitchie, and L.I. Mikulich (eds.), Chichester, England: Ellis Horwood, 129–148.
* McCarthy, John, 1980, “Circumscription: A form of non-monotonic reasoning”, *Artificial Intelligence*, 13: 27–39.
* McCarthy, John, 1983, “Situations, actions, and causal laws”, Tech. Rep. Memo 2, Stanford Artificial Intelligence Project, Stanford University.
* McCarthy, John, 1986, “Applications of circumscription to formalizing common sense knowledge”, *Artificial Intelligence*, 13: 27–39.
* McCarthy, John, 1987, “Epistemological problems of artificial intelligence”, in *Readings in Nonmonotonic Reasoning*, Matthew L. Ginsberg (ed.), Los Altos, California: Morgan Kaufmann, 46–55.
* McCarthy, John, 1993a, “History of circumscription”, *Artificial Intelligence*, 59: 23–26.
* McCarthy, John, 1993b, “Notes on formalizing contexts”, in *Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence*, Ruzena Bajcsy (ed.), San Mateo, California: Morgan Kaufmann, 555–560.
* McCarthy, John, 1999, [“Elaboration tolerance”](http://www-formal.stanford.edu/jmc/elaboration.html) .
* McCarthy, John and Buvac, Saša, 1998, “Formalizing context (expanded notes)”, in *Computing Natural Language*, Atocha Aliseda, Rob van Glabbeek, and Dag Westerståhl (eds.), Stanford, California: CSLI Publications, 13–50.
* McCarthy, John and Hayes, Patrick J., 1969, “Some philosophical problems from the standpoint of artificial intelligence”, in *Machine Intelligence 4*, B. Meltzer and D. Michie (eds.), Edinburgh: Edinburgh University Press, 463–502.
* McDermott, Drew, 1982, “Nonmonotonic logic II: Nonmonotonic modal theories”, *Journal of the Association for Computing Machinery*, 29(1): 33–57.
* McDermott, Drew and Doyle, Jon, 1980, “Non-monotonic logic I”, *Artificial Intelligence*, 13: 41–72.
* Meyer, John-Jules Ch. and van der Hoek, Wiebe, 1995, *Epistemic Logic for AI and Computer Science*, Cambridge: Cambridge University Press.
* Minker, Jack, 1997, “Logic and databases: Past, present and future”, *AI Magazine*, 18(3): 21–47.
* Minker, Jack, 2000a, “Introduction to logic-based artificial intelligence”, in *Logic-Based Artificial Intelligence*, Jack Minker (ed.), Dordrecht: Kluwer Academic Publishers, 3–33.
* Minker, Jack (ed.), 2000, *Logic-Based Artificial Intelligence*, Dordrecht: Kluwer Academic Publishers.
* Minsky, Marvin, 1974, “A framework for representing knowledge”, Tech. Rep. 306, Artificial Intelligence Laboratory, MIT. Republished in several places, including [Haugeland 1981](https://plato.stanford.edu/entries/logic-ai/#haugeland:1981b).
* Moore, Johanna, 1995, *Participating in Explanatory Dialogues*, The MIT Press.
* Moore, Robert C., 1993, “Autoepistemic logic revisited”, *Artificial Intelligence*, 59(1–2): 27–30.
* Moore, Robert C., 1995, *Logic and Representation*, Cambridge, England: Cambridge University Press.
* Morgenstern, Leora, 1996, “The problem with solutions to the frame problem”, in *The Robot’s Dilemma Revisited: The Frame Problem in Artificial Intelligence*, Kenneth M. Ford and Zenon Pylyshyn (eds.), Norwood, New Jersey: Ablex Publishing Co., 99–133.
* Morgenstern, Leora, 2001, “Mid-Sized Axiomatizations of Commonsense Problems: A Case Study in Egg Cracking”, *Studia Logica*, 67(3):333–384.
* Morgenstern, Leora and Stein, Lynn, 1994, “Motivated action theory: a formal theory of causal reasoning”, *Artificial Intelligence*, 71(1): 1–42.
* Mueller, Erik T., 2006, *Common Sense Reasoning*, Elsevier.
* Nakashima, Hideyuki, Matsubara, Hitoshi, and Osawa, Ichiro, 1997, “Causality as a key to the frame problem”, *Artificial Intelligence*, 91(1): 37–50.
* Nebel, Bernhard, Rich, Charles, and Swartout, William (eds.), 1992, *KR’: Principles of Knowledge Representation and Reasoning*, San Francisco: Morgan Kaufmann.
* Nilsson, Nils J., 1991, “Logic and artificial intelligence”, *Artificial Intelligence*, 47(1–3): 31–56.
* Ohrstrom, Peter and Hasle, Per F.V., 1995, *Temporal Logic from Ancient Ideas to Artificial Intelligence*, Dordrecht: Kluwer Academic Publishers.
* Osherson, Daniel N. and Lasnik, Howard (eds.), 1990, *An Invitation to Cognitive Science. Volume 2: Visual Cognition and Action*, Cambridge, Massachusetts: The MIT Press.
* Pearl, Judea, 1994, “From Adams’ conditionals to default expressions, causal conditionals, and counterfactuals”, in *Probability and Conditionals: Belief Revision and Rational Decision*, Ellery Eells and Brian Skyrms (eds.), Cambridge, England: Cambridge University Press, 47–74.
* Pearl, Judea, 2000, *Causality: Models, Reasoning, and Inference*, Cambridge, England: Cambridge University Press.
* Perlis, Donald, 1985, “Languages with self-reference I: Foundations”, *Artificial Intelligence*, 25: 301–322.
* Pollack, Martha, 1992, “The uses of plans”, *Artificial Intelligence*, 57(1): 43–68.
* Pollock, John L., 1995, *Cognitive Carpentry: A Manual for How to Build a Person*, Cambridge, Massachusetts: The MIT Press.
* Prior, Arthur, 1956, *Time and Modality*, Oxford: Oxford University Press.
* Prior, Arthur, 1967, *Past, Present and Future*, Oxford: Oxford University Press.
* Prior, Arthur, 1968, *Papers on Time and Tense*, Oxford: Oxford University Press.
* Pylyshyn, Zenon (ed.), 1987, *The Robot’s Dilemma: The Frame Problem in Artificial Intelligence*, Norwood, New Jersey: Ablex Publishing Co.
* Quine, Willard V.O, 1960, “Variables explained away”, in *Selected Logic Papers*, Willard V. Quine (ed.), Cambridge, Massachusetts: Harvard University Press, 227–235.
* Rahwan, Iyad and Simari, Guillermo R., 2009, *Argumentation in Artificial Intelligence*, Berlin: Springer-Verlag.
* Reiter, Raymond, 1978, “On closed world data bases”, in *Logic and Data Bases*, H. Gallaire and J. Minker (eds.), New York: Plenum Press, 55–76.
* Reiter, Raymond, 1980, “A logic for default reasoning”, *Artificial Intelligence*, 13: 81–32.
* Reiter, Raymond, 1993, “Proving properties of states in the situation calculus”, *Artificial Intelligence*, 64: 337–351.
* Reiter, Raymond, 2001, *Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems*, Cambridge, Massachusetts: The MIT Press.
* Rendsvig, Rasmus and Symons,John 2022, “Epistemic logic”, in *The Stanford Encyclopedia of Philosophy* (Spring 2022 Edition), Edward M. Zalta (ed.), URL =[https://plato.stanford.edu/archives/spr2022/entries/logic-epistemic/“](https://plato.stanford.edu/archives/spr2022/entries/logic-epistemic/).
* Renz, Jochen and Nebel, Bernhard, 1999, ”On the complexity of qualitative spatial reasoning: A maximal tractable fragment of the region connection calculus“, *Artificial Intelligence*, 108(1–2): 69–123.
* Rosenschein, Stanley J., 1989, ”Synthesizing information-tracking automata from environment descriptions“, in *KR’89: Principles of Knowledge Representation and Reasoning*, Ronald J. Brachman, Hector J. Levesque, and Raymond Reiter (eds.), San Mateo, California: Morgan Kaufmann, 386–393.
* Rosenschein, Stanley J. and Kaelbling, Leslie Pack, 1995, ”A situated view of representation and control“, *Artificial Intelligence*, 73(1–2): 149–173.
* Russell, Stuart and Norvig, Peter, 2020, *Artificial Intelligence: A Modern Approach*, Englewood Cliffs, New Jersey: Prentice Hall, fourth edition.
* Russell, Stuart J. and Wefald, Eric, 1991, *Do the Right Thing*, Cambridge, Massachusetts: The MIT Press.
* Sadek, M.D., 1992, ”A study in the logic of intention“, in *KR’92. Principles of Knowledge Representation and Reasoning: Proceedings of the Third International Conference*, Bernhard Nebel, Charles Rich, and William Swartout (eds.), San Mateo, California: Morgan Kaufmann, 462–473.
* Sandewall, Eric, 1972, ”An approach to the frame problem, and its implementation“, in *Machine Intelligence 7*, D. Michie and B. Meltzer (eds.), Edinburgh University Press, 195–204.
* Sandewall, Erik, 1994, *Features and Fluents: A Systematic Approach to the Representation of Knowledge About Dynamical Systems*, Oxford: Oxford University Press.
* Schlechta, Karl, 1997, *Nonmonotonic Logics*, Berlin: Springer-Verlag.
* Schlechta, Karl, 2007, ”Non-monotonic logics: A preferential approach“, in *Handbook of the History of Logic, Volume 8: The Many-Valued and Nonmonotonic Turn in Logic*, Dov Gabbay and John Woods (eds.), Amsterdam: Elsevier Science Publishers, 451–516.
* Schubert, Lenhart, 1990, ”Monotonic solution of the frame problem in the situation calculus; an efficient method for worlds with fully specified actions“, in *Knowledge Representation and Defeasible Reasoning*, Henry Kyburg, Ronald Loui, and Greg Carlson (eds.), Dordrecht: Kluwer Academic Publishers, 23–67.
* Seligman, Jerry and Moss, Lawrence S., 1996, ”Situation theory“, in *Handbook of Logic and Language*, Johan van Benthem and Alice ter Meulen (eds.), Amsterdam: Elsevier, 239–307.
* Shanahan, Murray, 1997, *Solving the Frame Problem*, Cambridge, Massachusetts: The MIT Press.
* Shanahan, Murray, 2004, ”An attempt to formalise a non-trivial benchmark problem in common sense reasoning“, *Artificial Intelligence*, 153(1–2): 141–165.
* Shanahan, Murray, 2009, ”The Frame Problem“, *The Stanford Encyclopedia of Philosophy* (Winter 2009 Edition), Edward N. Zalta (ed.), URL [The Frame Problem (Stanford Encyclopedia of Philosophy/Winter 2009 Edition)](https://plato.stanford.edu/archives/win2009/entries/frame-problem/).
* Shoham, Yoav, 1988, *Reasoning About Change: Time and Causation From the Standpoint of Artificial Intelligence*, Cambridge, Massachusetts: The MIT Press.
* Simon, Herbert, 1952, ”On the definition of the causal relation“, *The Journal of Philosophy*, 49: 517–528.
* Simon, Herbert, 1966, ”On reasoning about action“, Tech. Rep. Complex Information Processing Paper #87, Carnegie Institute of Technology, Pittsburgh, Pennsylvania.
* Simon, Herbert A., 1977, *Models of Discovery*, Dordrecht: D. Reidel Publishing Co.
* Simon, Herbert A., 1982a, *Models of Bounded Rationality, Volume 1*, Cambridge, Massachusetts: The MIT Press.
* Simon, Herbert A., 1982b, *Models of Bounded Rationality, Volume 2*, Cambridge, Massachusetts: The MIT Press.
* Simons, Peter, 1987, *Parts: A Study in Ontology*, Oxford: Oxford University Press.
* Snidaro, Lauro, Herrero Jesús Garcíia, Llinas, James, and Blash, Erik, 2019, ”Recent trends in context exploitation for information fusion and AI“, *The AI Magazine*, 40(3): 14–27.
* Stalnaker, Robert C., 1993, ”A note on non-monotonic modal logic“, *Artificial Intelligence*, 64(2): 183–196. Widely circulated in manuscript form, 1980 to 1992.
* Stefik, Mark J., 1995, *An Introduction to Knowledge Systems*, San Francisco: Morgan Kaufmann.
* Stock, Oliviero (ed.), 1997, *Spatial and Temporal Reasoning*, Dordrecht: Kluwer Academic Publishers.
* Stone, Matthew, 1998, *Modality in Dialogue: Planning, Pragmatics and Computation*, Ph.D. dissertation, Computer Science Department, University of Pennsylvania, Philadelphia, Pennsylvania.
* Straßer, Christian, 2014, *Adaptive Logic and Defeasible Reasoning: Applications in Argumentation, Normative Reasoning and Default Reasoning*, Berlin: Springer Verlag.
* Straßer, Christian, and Antonelli, G. Aldo, 2019, ”Non-Monotonic Logic“, *The Stanford Encyclopedia of Philosophy* (Winter 2012 Edition), Edward N. Zalta (ed.), URL [Non-monotonic Logic (Stanford Encyclopedia of Philosophy/Winter 2012 Edition)](https://plato.stanford.edu/archives/win2012/entries/logic-nonmonotonic/).
* Thielscher, Michael, 1989, ”Ramification and causality“, *Artificial Intelligence*, 89(1–2): 317–364.
* Thielscher, Michael, 1996, ”Causality and the qualification problem“, in *KR’96: Principles of Knowledge Representation and Reasoning*, Luigia Carlucci Aiello, Jon Doyle, and Stuart Shapiro (eds.), San Francisco, California: Morgan Kaufmann, 51–62.
* Thielscher, Michael, 2005, *Reasoning Robots: The Art and Science of Programming Robotic Agents*, Dordrecht: Kluwer Academic Publishers.
* Thielscher, Michael, Toni, Francesco, and Wolter, Frank (eds.), 2018, *KR2018: Principles of Knowledge Representation and Reasoning*, Menlo Park, California: AAAI Press.
* Thomason, Richmond H., 1992, ”NETL and subsequent path-based inheritance theories“, in *Semantic Networks in Artificial Intelligence*, Fritz Lehmann (ed.), Oxford: Pergamon Press, 179–204.
* Thomason, Richmond, 2003, ”Dynamic contextual intensional logic: logical foundations and an application“, in *Modeling and Using Context: Fourth International and Interdisciplinary Conference*, Patrick Blackburn, Chiara Ghidini, and Roy Turner (eds.), Berlin: Springer-Verlag, 328-341.
* Thomason, Richmond, 2005, ”Making contextual intensional logic nonmonotonic“, in *Modeling and Using Context: Fifth International and Interdisciplinary Conference*, Anind Dey, Boicho Kokinov, David Leake, and Roy Turner (eds.), Berlin: Springer-Verlag, 502–514.
* Turner, Hudson, 1999, ”A logic of universal causation“, *Artificial Intelligence*, 113(1–2): 87–123.
* van Benthem, Johan, 1983, *The Logic of Time*, Dordrecht: D. Reidel Publishing Company.
* van der Torre, Leendert W.N., 1997, *Reasoning about Obligations: Defeasibility in Preference-Based Deontic Logic*, Amsterdam: Thesis Publishers.
* van Harmelen, Frank, Lifschitz, Vladimir, and Porter, Bruce (eds.) 2008,*Handbook of Knowledge Representation*, Amsterdam: Elsevier.
* von Wright, Georg Henrik, 1983, *Practical Reason: Philosophical Papers, Volume 1*, Ithaca: Cornell University Press.
* Weld, Daniel S. and de Kleer, Johan (eds.), 1990, *Qualitative Reasoning about Physical Systems*, San Mateo, California: Morgan Kaufmann.
* Wilson, Randall H., 1998, ”Geometric reasoning about assembly tools“, *Artificial Intelligence*, 98(1–2): 237–279.
* Wobcke, Wayne, Pagnucco, Maurice, and Zhang, C. (eds.), 1998, *Agents and Multi-Agent Systems—Formalisms, Methodologies, and Applications*, Berlin: Springer-Verlag.
* Wolter, Frank and Zakharyaschev, Michael, 2000, ”Spatio-temporal representation and reasoning based on RCC-8“, in *KR2000: Principles of Knowledge Representation and Reasoning*, Anthony G. Cohn, Fausto Giunchiglia, and Bart Selman (eds.), San Francisco: Morgan Kaufmann, 3–14.
* Woods, William A. and Schmolze, James G., 1992, ”The KL-ONE family“, in *Semantic Networks in Artificial Intelligence*, Fritz Lehmann (ed.), Oxford: Pergamon Press, 133–177.
* Wooldridge, Michael J., 2000, *Reasoning about Rational Agents*, Cambridge, England: Cambridge University Press.
* Yeap, Wai K. and Jeffries, Margaret E., 1999, ”Computing a representation of the local environment“, *Artificial Intelligence*, 107(2): 265–301.

## Academic Tools

> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=logic-ai). |
> | --- | --- |
> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/logic-ai/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
> | ![inpho icon](https://plato.stanford.edu/symbols/inpho.png) | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=logic-ai&redirect=True) at the Internet Philosophy Ontology Project (InPhO). |
> | ![phil papers icon](https://plato.stanford.edu/symbols/pp.gif) | [Enhanced bibliography for this entry](https://philpapers.org/sep/logic-ai/) at [PhilPapers](https://philpapers.org/), with links to its database. |

## Other Internet Resources

* Stanford Formal Reasoning Group, [Formal Reasoning Group Web Pages](http://www-formal.stanford.edu/).
* John McCarthy, [John McCarthy’s Web Pages](http://www-formal.stanford.edu/jmc/).
* Stanford Computer Science, [John McCarthy’s Posthumous Stanford Pages](http://jmc.stanford.edu/).
* Leora Morgenstern, [Common Sense Problem Page](http://www-formal.stanford.edu/leora/commonsense/).
* Toronto Cognitive Robotics Group, [Toronto Cognitive Robotics Pages](http://www.cs.toronto.edu/cogrobo/main/).

## Related Entries

[conditionals](https://plato.stanford.edu/entries/conditionals/) | [frame problem](https://plato.stanford.edu/entries/frame-problem/) | [logic: non-monotonic](https://plato.stanford.edu/entries/logic-nonmonotonic/) | [reasoning: automated](https://plato.stanford.edu/entries/reasoning-automated/)

### Acknowledgments

I am grateful to John McCarthy, who read an early draft of this article and provided extensive and helpful comments.

[Copyright © 2024](https://plato.stanford.edu/info.html#c) by  
Richmond Thomason <[*rthomaso@umich.edu*](mailto:rthomaso%40umich%2eedu)>
