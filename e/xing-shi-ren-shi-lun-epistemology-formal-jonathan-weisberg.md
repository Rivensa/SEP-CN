# 形式认识论 epistemology, formal (Jonathan Weisberg)

*首次发表于 2015 年 3 月 2 日星期一；实质性修订于 2021 年 3 月 15 日星期一*

形式认识论探讨知识和推理，使用“形式”工具，即数学和逻辑工具。例如，形式认识论者可能使用概率论来解释科学推理的运作方式。或者她可能使用模态逻辑来捍卫某种特定的知识理论。

形式认识论所关注的问题通常与“非正式”认识论所关注的问题相同。知识是什么，它与仅仅是观点的区别是什么？科学与伪科学之间有何不同？信念何时是合理的？是什么让我相信太阳明天会升起，或者外部世界是真实的，而不是笛卡尔恶魔诱导的幻觉？

然而，形式认识论者应用于这些问题的工具与其他领域有着许多历史和兴趣相同。因此，形式认识论者经常提出一些不属于通常认识论核心的问题，例如关于决策（§5.1）或假设语言意义的问题（§5.3）。

也许了解形式认识论的最佳方式是看具体的例子。我们将探讨一些经典的认识论问题，并看看对它们的流行形式方法，以了解形式工具带来了什么。我们还将研究这些形式方法在认识论之外的一些应用。

---

## 第一案例研究：确认科学理论

在 20 世纪初，大片数学成功地使用一阶逻辑进行重建。许多哲学家寻求类似的系统化，来描述生物学、心理学和物理学等经验科学中的推理。尽管经验科学在很大程度上依赖非演绎推理，但演绎逻辑的工具仍然提供了一个有前途的起点。

### 1.1 推理方法

考虑一个假设，比如所有的电子都带负电荷，这在一阶逻辑中被表达为∀x(Ex⊃Nx)。在将某个对象 a 确定为电子后，这个假设推导性地导致一个预测，即 Na，即 a 带有负电荷。

∀x(Ex⊃Nx)EaNa

如果我们测试这个预测并观察到，确实，Na，这似乎支持这一假设。

科学假设检验似乎类似于“反向演绎”（Goodman 1954）。如果我们在上述演绎中交换假设和预测数据，我们得到一个确认的例子。

EaNa¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯∀x(Ex⊃Nx)

在这里，双线代表非演绎推理。在这种情况下，推理非常薄弱，因为假设只在一个实例中得到验证。但随着我们添加更多实例 b、c 等，它变得更加有力（当然，前提是我们没有发现任何反例）。

这些观察表明了尼科德（1930）提出的一个建议，并由亨普尔（1945）进行了著名的研究

**尼科德准则**
普遍概括通过其积极实例得到确认（只要没有发现反例）：∀x(Fx⊃Gx)通过 Fa∧Ga，通过 Fb∧Gb 等得到确认。

假设得到验证的一般观念是，当它们的预测得到验证时。为了在演绎逻辑中正式捕捉这个观念，我们将预测等同于逻辑蕴涵。当一个对象是 F 时，假设∀x(Fx⊃Gx)蕴涵/预测这个对象是 G。因此，任何发现一个既是 F 又是 G 的对象的情况都会验证这个假设。

尼科德准则面临的一个经典挑战是臭名昭著的乌鸦悖论。假设我们想要测试所有乌鸦都是黑色的假设，我们将其形式化为∀x(Rx⊃Bx)。从逻辑上讲，这等同于∀x(¬Bx⊃¬Rx)，通过逆否命题。尼科德准则表明，发现任何一个不是黑色且不是乌鸦的对象——比如一件红色衬衫，或一条蓝色内裤（Hempel 1937, 1945）会证实这后一个假设。但是，在系里走廊上记录非黑色非乌鸦似乎并不是验证所有乌鸦都是黑色的合理方式。 “室内鸟类学”（Goodman 1954）怎么能成为良好的科学呢？

对于预测即演绎方法的第二个更一般的挑战是由统计假设提出的。假设我们想要测试只有 50%的乌鸦是黑色的理论。这个假设对于单个乌鸦的颜色并没有什么具体要求；它可能是其中的一只黑色的，也可能不是。事实上，即使对所有乌鸦进行了非常大规模的调查，结果都是黑色的，也不会与这个假设相矛盾。总是有可能那些不是黑色的乌鸦没有被调查到。（也许非黑色的乌鸦在躲避方面特别擅长。）

这个挑战提供了一些重要的教训。首先，我们需要比演绎蕴涵更宽松的预测概念。50%的假设可能不蕴涵一项大规模的乌鸦调查会有一些非黑色的乌鸦，但它确实相当强烈地暗示了这一预测。其次，作为一种推论，证实是定量的：它有不同程度。一只单独的黑色乌鸦对支持 50%的乌鸦是黑色的假设并没有太大帮助，但一大批大约一半是黑色一半是白色的乌鸦样本会有所帮助。第三，最后，证实的程度应该以概率来理解。50%的假设并不使一只乌鸦是黑色的概率很高，但它确实使一个更大的集合大约一半是黑色一半是非黑色的概率很高。而全黑的假设预测任何一批乌鸦样本都将完全是黑色，概率为 100%。

定量方法也有望帮助解决乌鸦悖论。最流行的解决方案认为，观察到一件红衬衫确实证实了所有乌鸦都是黑色的，只是数量极少。乌鸦悖论因此是一种错觉：我们将微小的证实量误认为根本没有（Hosiasson-Lindenbaum 1940）。但要使这种回应令人信服，我们需要一个恰当的、定量的证实理论，解释红衬衫如何与关于乌鸦的假设相关，但只是略微相关。

### 1.2 概率方法

让我们从这样一个观念开始，即确认一个假设就是使其更有可能性。证据越能增加一个假设的概率，就越能确认这个假设。

我们需要的是概率理论。标准理论始于一个函数 p，它接受一个命题并返回一个数字 x，即该命题的概率：p(A)=x。要被视为概率函数，p 必须满足三个公理。

1. 对于任何命题 A，0≤p(A)≤1。[1]
2. 对于任何重言式 A，p(A)=1。
3. 对于任何在逻辑上不相容的命题 A 和 B，p(A∨B)=p(A)+p(B)。

第一个公理设定了概率的范围，从 0 到 1，我们可以将其视为从 0%的概率到 100%的概率。[2]第二个公理将重言式置于这个范围的顶端：没有比重言式更可能的事情。[3]最后，第三个公理告诉我们如何通过将假设分解为部分来计算假设的概率。例如，一个美洲国家将首先开发治疗阿尔茨海默病的概率可以通过将一个北美国家首先的概率加上一个南美国家首先的概率来计算。[4]

什么是条件概率，比如在你之前的哲学课上表现良好的情况下，在下一门哲学课上表现良好的概率是多少？到目前为止，我们只形式化了绝对概率的概念，p(A)=x。让我们通过定义引入条件概率：

定义。给定 A 的条件概率写作 p(B∣A)，并定义为：p(B∣A)=p(B∧A)p(A)。

为什么这个定义？一个有用的启发法则是将给定 A 的情况下 B 的概率看作是 A 可能性中也是 B 可能性的部分。例如，在一个六面骰子上掷出一个高点数（4、5 或 6）的概率，假设掷出的是偶数，为 2/3。为什么？有 3 种偶数可能性（2、4、6），所以 p(A)=3/6。在这 3 种可能性中，有 2 种也是高点数（4、6），所以 p(B∧A)=2/6。因此 p(B∣A)=p(B∧A)p(A)=2/63/6=2/3。概括这个想法，我们从 A 可能性的数量作为一种基线开始，将 p(A)放在分母中。然后我们考虑有多少个也是 B 可能性的，将 p(B∧A)放在分子中。

请注意，当 p(A)=0 时，p(B∣A)是未定义的。这一点乍看起来似乎没什么问题。如果 A 为真的机会为零，为什么要担心 B 的概率呢？实际上，这里隐藏着深层问题（Hájek m.s.，其他互联网资源），尽管我们不会停下来探讨它们。

相反，让我们利用我们已经奠定的基础来阐述我们对数量确认的形式定义。我们的指导思想是，证据确认假设的程度取决于它增加其概率的程度。因此，我们通过比较 p(H∣E) 和 p(H) 来看它们之间的差异：

定义。E 证实 H 的程度，称为确认度，记为 c(H,E)，定义为：c(H,E)=p(H∣E)−p(H)。

当 c(H,E) 为负时，E 实际上降低了 H 的概率，我们说 E 反驳了 H。当 c(H,E) 为 0 时，我们说 E 对 H 是中立的。

这些简单的公理和定义虽然很简洁，却足以推导出许多有趣的关于概率和证实的结论。接下来的两个小节介绍了一些基础但有前景的结果。有关证明，请参阅技术补充部分。

#### 1.2.1 Basic Building Blocks1.2.1 基本构件

让我们从一些基本定理开始，说明概率如何与演绎逻辑相互作用：

定理（无矛盾的机会）。当 A 是一个矛盾时，p(A)=0。

定理（矛盾的互补性）。对于任何 A，p(A)=1−p(¬A)。

定理（等价物的相等性）。当 A 和 B 在逻辑上等价时，p(A)=p(B)。

定理（逻辑推论的条件确定性）当 A 在逻辑上蕴含 B 时，p(B∣A)=1。

下面的三个定理深入探讨，有助于得出更有趣的结果

定理（合取成本概率）。对于任意 A 和 B，p(A)>p(A∧B)，除非 p(A∧¬B)=0，在这种情况下，p(A)=p(A∧B)。

一种思考“合取成本概率”所表达的含义的方式是，陈述越强，虚假的风险就越大。如果我们通过添加 B 来加强 A，那么得到的更强的陈述就更不可能发生。除非，也就是说，本来 A 没有 B 的情况下就不可能为真。在这种情况下，将 B 添加到 A 并不会改变虚假的风险，因为本来 A 没有 B 的情况下也不可能为真。

定理（合取规则）。对于任意 A 和 B，使得 p(B)≠0，p(A∧B)=p(A∣B)p(B)。

这意味着我们可以通过暂时将 B 视为真实，评估在这种情况下 A 的概率，然后将结果与 B 本身的概率一样重要地考虑在内。

定理（总概率法则）。对于任何 A 和任何概率既非 0 又非 1 的 B：p(A)=p(A∣B)p(B)+p(A∣¬B)p(¬B)。

总概率法则基本上表明，我们可以通过将其分解为两种可能情况：B 和¬B 来计算 A 的概率。我们考虑如果 B 为真时 A 的可能性以及如果 B 为假时它的可能性。然后，我们通过将其乘以它发生的概率来为每种情况赋予适当的“权重”，然后将结果相加。为了使这个方法有效，p(A∣B)和 p(A∣¬B)必须被明确定义，因此 p(B)不能为 0 或 1。

#### 贝叶斯定理

这个经典定理将条件概率 p(H∣E)与无条件概率 p(H)联系起来：p(H∣E)=p(H)p(E∣H)p(E)

该定理在哲学上具有重要意义，我们马上就会看到。但它也可以作为计算 p(H∣E) 的工具，因为右侧的三个术语通常可以从可用统计数据中推断出来。

考虑，例如，X 大学的一名成绩优秀的学生（E）是否对她是否选修哲学课（H）有任何暗示。注册员告诉我们，有 35%的学生在某个时候选修了哲学课，因此 p(H)=35/100。他们还告诉我们，全校只有 20%的学生成绩优秀（定义为 GPA 为 3.5 或以上），因此 p(E)=20/100。但他们没有跟踪任何更详细的信息。幸运的是，哲学系可以告诉我们，选修他们课程的学生中有 25%成绩优秀，因此 p(E∣H)=25/100。这就是我们应用贝叶斯定理所需的一切：p(H∣E)=p(H)p(E∣H)p(E)=35/100×25/10020/100=7/16

这比 p(H)=20/100 更高，因此我们也可以看到学生的高分证实了她将要上哲学课的假设。

贝叶斯定理的哲学意义是什么？它统一了关于证实和科学方法论的许多有影响力的观念，将它们结合在一个单一、简单的方程中。让我们看看它是如何做到的。

1. 理论契合性。一个真理是，一个理论与证据的契合程度越高，证据就越支持它。但是，一个理论与证据契合意味着什么呢？

当 H 蕴含 E 时，理论表明证据必须是真实的，因此发现证据与理论完全吻合。我们的形式主义在这种特殊情况下证实了这个真理。当 H 蕴含 E 时，逻辑后果的条件确定性告诉我们 p(E∣H)=1，因此贝叶斯定理变为：p(H∣E)=p(H)1p(E)

如果提供的 p(E)小于 1，这相当于将 p(H)乘以一个大于 1 的比率，这意味着 p(H∣E)大于 p(H)。此外，由于 1 是分子中可能出现的最大数量，当 H 蕴含 E 且因此 p(E∣H)=1 时，对 H 的概率给予了最大可能的提升。换句话说，当理论与证据最为契合时，确认是最大的。

如果 p(E)=1，那又怎么样呢？那么 H 可能符合 E，但¬H 也可能符合 E。如果 p(E)=1，我们可以证明 p(E∣H)=1 和 p(E∣¬H)=1（提示：将全概率法则与互补性结合起来处理矛盾）。换句话说，E 既符合 H 又完全符合其否定。因此，它不应该能够区分这两个假设。实际上，在这种情况下，p(H∣E)与 p(H)相同，所以 c(H,E)=0。

当理论与证据的契合度不完美时怎么办？如果我们将契合度视为 H 预测 E 的确定性，即 p(E∣H)，那么先前的分析可以很好地推广。假设 H 强烈预测 E，但并非绝对确定：p(E∣H)=1−ε，其中ε是一个很小的数。再次应用贝叶斯定理，我们有：p(H∣E)=p(H)1−εp(E)

这再次意味着将 p(H) 乘以一个大于 1 的比率，前提是 p(E) 不接近 1。因此，p(H∣E) 将大于 p(H)。当然，ε 越大，确认就越弱，符合 H 预测 E 的弱度。

2. 新颖预测。另一个真理是，新颖的预测更重要。当一个理论预测了我们本来不会期待的事情时，如果这个预测被证实，那么它的确认尤为强烈。例如，泊松嘲笑认为光是一种波动的理论，因为它预测在某些阴影的中心应该出现一个明亮的斑点。之前没有人观察到这样的明亮斑点，这使得它成为一个新颖的预测。当这些明亮斑点的存在得到验证时，这对波动理论来说是一大好处。

再次，我们的形式化证实了真理。假设像以前一样，H 预测 E，因此 p(E∣H)=1，或者接近于 1。新颖的预测是指 p(E)较低，或者至少不是很高的情况。这是一个人们不会预期的预测。我们先前的分析揭示，在这种情况下，我们在贝叶斯定理中将 p(H)乘以一个较大的比率。因此 p(H∣E)远远大于 p(H)，使得 c(H,E)变大。因此，新颖的预测特别具有证实性。

3. 先验可信性。最后的真理：对于一个理论的新证据必须与该理论的先验可信性相权衡。也许这个理论本质上是不可信的，因为它复杂或在形而上学上充满困难。或者这个理论之前因为与早期证据相冲突而变得不可信。或者这个理论本来就相当可信，因为它优雅并且与先前的证据很好地契合。无论如何，新证据必须根据这些先前的考虑来评估。

贝叶斯定理再次证实了这个真理。p(H∣E)的计算是通过将 p(H)乘以因子 p(E∣H)/p(E)来实现的。我们可以将因子 p(E∣H)/p(E)看作捕捉证据对 H 的支持程度（如果 p(E∣H)/p(E)小于 1，则是反对 H），然后将其乘以 H 的先前概率 p(H)，以获得 H 的新的、全方位的可信度。如果 H 已经不太可能发生，p(H)将很低，这种乘法的结果将比如果 H 本来是可能的，p(H)因此很高时要小。

让我们暂停总结一下。贝叶斯定理不仅是一个有用的计算工具，它还证实了关于证实的三个真理，并将它们统一在一个方程中。每个真理对应于贝叶斯定理中的一个术语。

1. p(E∣H)对应于理论拟合度。假设与证据拟合得越好，这个量就会越大。由于这个术语出现在贝叶斯定理的分子中，更好的拟合意味着 p(H∣E)的值更大。
2. p(E)对应于预测的新颖性，或者说缺乏新颖性。预测越新颖，我们就越不期望 E 为真，因此 p(E)就越小。由于这个术语出现在贝叶斯定理的分母中，更多的新颖性意味着 p(H∣E)的值更大。
3. p(H)对应于先验可信度。在发现 E 之前，H 越可信，这个数量就越大，因此 p(H∣E)也会越大。

但乌鸦悖论呢？

### 1.3 定量确认与乌鸦悖论

回想乌鸦悖论：所有乌鸦都是黑色的假设在逻辑上等同于所有非黑色的事物都不是乌鸦的假设。然而，每次发现一个非黑色、非乌鸦的事物，比如红衬衫、蓝内裤等，似乎都会证实后者。然而，检查邻居晾衣绳上的衣物内容似乎不是研究鸟类学假设的好方法。（也不是对待邻居的好方法。）

经典的、定量的解决方案源自 Hosiasson-Lindenbaum（1940）。它认为，发现蓝色内裤确实证实了所有乌鸦都是黑色的假设，只是我们忽略了这一点。蓝色内裤如何与所有乌鸦都是黑色的假设相关呢？非正式地说，这个想法是，原来是一条蓝色内裤的物体本来可能是一只白色的乌鸦。当它事实证明不是这样的反例时，我们的假设经受了一种弱测试。我们的形式认识论是否证实了这种非正式的思维方式？答案是，“是的，但是…”。

“但是…”将证明尼科德准则的命运至关重要（剧透：前景不乐观）。但让我们从“是”的角度开始。

我们用一个定理来证明“是”的：发现一个不是黑色的非乌鸦对象，¬R∧¬B，在我们做出一些假设的情况下，只是略微增加了所有乌鸦都是黑色这一假设的概率，H。以下是该定理（有关证明，请参阅技术补充说明）：

定理（乌鸦定理）。如果（i）p(¬R∣¬B)非常高，且（ii）p(¬B∣H)=p(¬B)，那么 p(H∣¬R∧¬B)仅略大于 p(H)。

第一个假设，即 p(¬R∣¬B) 非常高，似乎相当合理。在世界上所有的非乌鸦中，一个给定对象不是乌鸦的概率相当高，尤其是如果它不是黑色的话。第二个假设是 p(¬B∣H)=p(¬B)。换句话说，假设所有的乌鸦都是黑色，并不会改变一个给定对象不是黑色的概率。这个假设更有争议（Vranas 2004）。如果所有的乌鸦都是黑色，那么一些本来可能是黑色的东西却不是，即乌鸦。在这种情况下，应该是 p(¬B∣H)<p(¬B) 才对吗？另一方面，也许所有的乌鸦都是黑色并不会减少宇宙中黑色物体的数量。也许这只是意味着其他类型的东西更常见地是黑色。幸运的是，结果表明我们可以用不那么可疑的假设（Fitelson 2006; Fitelson and Hawthorne 2010; Rinard 2014）替换（ii）。但我们不能没有任何假设，这让我们进入了关于证实和概率的两个关键点。

尼科德准则失败的第一点。乌鸦定理的假设（i）和（ii）并非总是成立。事实上，在某些情况下，发现一只黑乌鸦实际上会降低所有乌鸦都是黑色的概率。这怎么可能呢？关键在于想象一种情况，即发现一只乌鸦对所有乌鸦都是黑色的假设来说是个坏消息。如果所有乌鸦都是黑色的唯一方式是它们数量很少，那么偶然发现一只乌鸦会暗示乌鸦实际上很常见，这样它们就不都是黑色的。Good（1967）提供了以下具体的例证。假设只有两种可能性：

* 所有的乌鸦都是黑色的，尽管只有 100 只乌鸦和一百万其他东西。所有的乌鸦都是黑色的，尽管只有 100 只乌鸦和一百万其他东西。
* 有一只非黑乌鸦在 1,000 只乌鸦中，还有一百万其他事物。

在这种情况下，偶然遇到乌鸦有利于¬H，因为¬H 使乌鸦的外观少了十倍的奇异性。乌鸦是黑色的与 H 更相符，但不足以抵消第一个效应：在¬H 上，黑色乌鸦几乎不算稀有。这是与我们之前的“是的”相呼应的“但是……”。

第二点是一个深远的道德：关于证实的主张的命运往往取决于我们对 p 值的假设。尼科德的标准在像 Good 的情况下失败，其中 p 将较低的值分配给 p(R∧B∣H) 而不是 p(R∧B∣¬H)。但在另一种情况下，情况相反，尼科德的标准确实适用。同样，对于乌鸦悖论的诊断，像标准的诊断只有在对 p 的某些假设（如乌鸦定理的假设(i)和(ii)）成立时才适用。概率公理本身通常不足以告诉我们尼科德的标准何时适用，或者证实是小还是大，是正还是负。

### 1.4 The Problem of the Priors

这最后一点是一个非常普遍、非常重要的现象。就像一阶逻辑的公理一样，概率的公理也是相当弱的（Howson and Urbach 1993; Christensen 2004）。除非 H 是一个重言或矛盾，这些公理只告诉我们它的概率在 0 和 1 之间。如果我们可以将 H 表达为两个逻辑上不相容的子假设 H1 和 H2 的析取，并且我们知道这些子假设的概率，那么第三个公理让我们计算 p(H)=p(H1)+p(H2)。但这只是将事情推回一步，因为这些公理本身只告诉我们 p(H1)和 p(H2)必须位于 0 和 1 之间。

概率公理的这种弱点引发了先验问题，即关于先验概率的来源的问题。它们是否总是基于先前收集的证据？如果是这样，科学研究是如何开始的？如果它们不是基于先前证据而是先验的，那么什么原则支配这种先验推理？形式认识论者在这个问题上存在分歧。所谓的客观主义者认为概率公理是不完整的，需要通过额外的公设来确定研究应该从哪些概率开始。（这里的“无差别原则”是主要候选者。请参阅概率解释条目。）而所谓的主观主义者认为，不存在单一正确的概率函数 p，可以作为研究的起点。不同的研究者可能从不同的 p 值开始，因此其中没有一个比其他人更具科学性或理性。

在后面的部分，先验问题将多次出现，说明其重要性和普遍性。

### 1.5 总结

我们已经看到，使用概率论对确认进行形式化可以成功地实现几个重要方面：它证实了有关确认的几个真理，将这些真理统一在一个方程中，并解决了一个经典悖论（更不用说我们没有讨论的其他悖论了（Crupi and Tentori 2010））。

我们还看到它提出了一个问题，即先验的问题，形式认识论者在如何解决这个问题上存在分歧。还有其他问题我们没有探讨，尤其是逻辑全知和旧证据的问题（见贝叶斯认识论条目的子部分）。

这些问题和其他问题已经导致对科学推理和一般推理的探索和发展。有些人坚持概率框架，但在其中发展了不同的方法论（Fisher 1925; Neyman and Pearson 1928a,b; Royall 1997; Mayo 1996; Mayo and Spanos 2011; 参见哲学统计学条目）。其他人则偏离标准概率理论，如 Dempster-Shafer 理论（Shafer 1976; 参见信念的形式表示条目），这是概率理论的一种变体，旨在解决先验问题并进行其他改进。排名理论（Spohn 1988, 2012; 同样参见信念的形式表示条目）也与概率理论有些相似，但在条件句的可能世界语义中汲取了很多灵感（参见陈述条件句条目）。自举理论（Glymour 1980; Douven and Meijs 2006）完全摆脱了概率框架，而是从我们开始的基于演绎的方法中汲取灵感。还有其他方法发展了非单调逻辑（参见条目），用于进行不仅是演绎推理，而且是可废除的、归纳推理的逻辑（Pollock 1995, 2008; Horty 2012）。形式学习理论提供了研究各种方法的长期后果的框架。

对于接下来的两个部分，我们将基于这里介绍的概率方法进行构建，因为它目前是形式认识论中最流行和有影响力的方法。但重要的是要记住，存在丰富多样的替代方法，并且这种方法存在问题，其中一些后果我们很快就会遇到。

## 第二个案例研究：归纳问题

我们的很多推理似乎涉及将观察到的模式投射到未观察到的实例上。例如，假设我不知道我手中的硬币是有偏倚还是公平的。如果我抛掷它 9 次，每次都是正面朝下，我会期待第 10 次也是正面朝下。这种推理的理据是什么？休谟曾经著名地认为没有什么可以证明它。在现代形式中，休谟的挑战基本上是这样的：这种推理的理由必须要么依赖归纳论证，要么依赖演绎论证。依赖归纳论证将是不可接受的循环论证。而依赖演绎论证则必须表明未观察到的实例将类似于观察到的实例，这不是一个必然真理，因此也不能通过任何有效的论证来证明。因此，没有论证可以证明将观察到的模式投射到未观察到的情况中。(Russell and Restall (2010) 提供了一个形式化的发展。Haack (1976) 讨论了归纳和演绎之间的所谓不对称性。)

概率能在这里挽救吗？如果我们不是推断未观察到的实例将类似于观察到的实例，而是推断它们可能类似于观察到的实例呢？如果我们能够从概率公理中推断出，鉴于前 9 次掷硬币都是正面朝上，那么下一次掷硬币很可能会是反面朝上，这似乎可以解决休谟的问题。

很遗憾，无法进行这样的推断：概率公理根本就不会导致我们想要的结论。这是怎么回事呢？考虑在进行 10 次抛硬币的过程中，我们可能得到的所有不同的正面（H）和反面（T）序列：

HHHHHHHHHHHHHHHHHHHTHHHHHHHHTH⋮HHHHHHHHTTHHHHHHHTHT⋮TTTTTTTTTHTTTTTTTTTT

有 1024 种可能的序列，因此每个可能序列的概率似乎是 1/1024。当然，只有两个序列以连续 9 个尾巴开始，即最后两个序列。因此，一旦我们将事情缩小到以 9 个尾巴开始的序列，第 10 次投掷出现尾巴的概率是 1/2，与出现正面的概率相同。更正式地，应用条件概率的定义给出：

p(T10∣T1…9)=p(T10∧T1…9)p(T1…9)=1/10242/1024=12

因此，概率公理似乎意味着前 9 次抛掷对第 10 次抛掷没有任何影响。

实际上，概率公理甚至不要求这一点——它们实际上并未说明 p(T10∣T1…9)。在前一段中，我们假设每个可能的抛硬币序列是等可能的，对于每个序列，p(…)=1/1024。但概率公理并不要求这种“均匀”分配。正如我们在遇到先验问题时所看到的那样（1.4），概率公理只告诉我们永真式的概率为 1（矛盾的概率为 0）。偶然命题的概率可以在 0 到 1 之间的任何概率，这包括抛硬币序列将是 HHHHHHTHT，或任何其他 H 和 T 序列的命题。

我们可以利用这种自由，通过使用卡尔纳普（1950）提倡的不同方案来分配先验概率，从而获得更明智、更适合归纳的结果。假设我们不是为每个可能的序列分配相同的概率，而是为每个可能的 T 的数量分配相同的概率。我们可以得到从 0 到 10 个 T，因此每个可能的 T 的数量都有 1/11 的概率。现在，得到 0 个 T 的方法只有一种：

HHHHHHHHHH

因此，p(H1…10)=1/11。但有 10 种方法可以得到 1 T：

HHHHHHHHHTHHHHHHHHTHHHHHHHHTHH⋮THHHHHHHHH

因此，这种可能性的概率为 1/11，分为 10 种方式，每种子可能性的概率为 1/110，例如 p(HHHHHHHTHH)=1/110。然后有 45 种获得 2 个 T 的方式：

HHHHHHHHTTHHHHHHHTHTHHHHHHTHHT⋮TTHHHHHHHH

因此，1/11 的概率被分成 45 份，每个子可能性的概率为 1/495，例如 p(HTHHHHHTHH)=1/495。依此类推。

那么，p(T10∣T1…9)的命运是什么？

p(T10∣T1…9)=p(T10∧T1…9)p(T1…9)=p(T1…10)p(T1…10∨[T1…9∧H10])=p(T1…10)p(T1…10)+p(T1…9∧H10)=1/111/11+1/110=1011

因此，当我们根据卡尔纳普的两阶段方案分配先验概率时，我们会得到一个更合理的结果。然而，这个方案并不是由概率的公理所要求的。

这件事教导我们的一点是概率公理对休谟问题保持沉默。归纳推理与这些公理是相容的，因为卡尔纳普构建先验概率的方式使得在初始的 9 个 T 后出现第 10 个 T 的可能性非常高。但这些公理也与对归纳的怀疑相容。在构建先验概率的第一种方式中，一串 T 永远不会使得下一次抛硬币更有可能是 T，无论这串 T 有多长！事实上，还有其他构建先验概率的方式产生了“反归纳”，即我们观察到的 T 越多，下一次抛硬币出现 T 的可能性就越小。

我们还学到了另一件更有建设性的事情：休谟问题是先验问题的近亲。如果我们能够证明卡纳普分配先验概率的方式是合理的，我们将在解决休谟问题的道路上取得很大进展。（为什么仅仅是在道路上？稍后再详细讨论，但简单来说：因为我们仍然需要证明使用条件概率作为我们指导新的无条件概率的方法是合理的。）我们能够证明卡纳普的两阶段方案吗？这将引出形式认识论中的一个经典辩论。

### 2.1 The Principle of Indifference2.1 中立原则

如果你必须在不了解任何一匹马的情况下下注一场赛马比赛，你会下注哪匹马？对你来说可能无关紧要：每匹马获胜的可能性都是一样的，所以你会对可用的赌注无所谓。如果比赛中有 3 匹马，每匹马获胜的机会是 1/3；如果有 5 匹，每匹马获胜的机会是 1/5；等等。这种推理方式很常见，通常被归因于“无差别原则”：[5]

**The Principle of Indifference (PoI)**
在存在 n 个互斥且互相排斥的可能性的情况下，这些可能性中没有一个受到可用证据的偏爱，每个可能性的概率为 1/n。

PoI 乍看起来似乎很合理，并且甚至具有概念真理的味道。如果证据不支持，那么一个可能性怎么会比另一个更有可能呢？然而，PoI 面临着一个经典且顽固的挑战。

考虑赛马比赛中列出的第一匹马，雅典娜。有两种可能性，她会赢，或者她会输。我们的证据（或缺乏证据）不偏向任何一种可能性，因此 PoI 说她会赢的概率是 1/2。但假设赛马比赛中有三匹马：雅典娜，比阿特丽斯和塞西尔。由于我们的证据不偏向任何一匹马，PoI 要求我们将概率 1/3 分配给每匹马，这与我们之前得出的结论相矛盾，即雅典娜获胜的概率为 1/2。

麻烦的根源在于可能性可以进一步细分为更多的子可能性。雅典娜输的可能性可以细分为两种子可能性，一种是比阿特丽斯赢，另一种是塞西尔赢。由于我们缺乏任何相关证据，可用的证据似乎不倾向于更粗略的可能性而不是更精细的子可能性，导致概率分配出现矛盾。看起来我们需要的是一种选择一种单一、特权的方式来划分可能性空间，以便我们可以一致地应用归因原则。

我们自然会认为我们应该使用更精细的可能性划分，比如在雅典娜、贝阿特丽切和塞西尔的情况下的三分法。但实际上我们可以进一步划分事物——事实上可以无限划分。例如，雅典娜可能以一个全长、半个全长、四分之一全长等方式获胜。因此，她获胜的可能性实际上是无限可分的。我们可以扩展概率的解释来处理这种无限可能性划分，通过说，如果雅典娜获胜，她以 1 到 2 个全长之间获胜的概率是她以 1/2 到 1 个全长之间获胜的概率的两倍。但我们试图解决的同样问题仍然存在，以臭名昭著的 Bertrand 悖论的形式存在（Bertrand 2007 [1888]）。

悖论可以通过 van Fraassen（1989）的以下示例很好地说明。假设一家工厂切割边长从 0 厘米到 2 厘米的铁立方体。下一个要下线的立方体的边长在 0 厘米到 1 厘米之间的概率是多少？在没有关于工厂如何生产立方体的进一步信息的情况下，PoI 似乎会说概率是 1/2。从 0 到 1 的范围覆盖了从 0 到 2 的可能性的 1/2。但现在考虑这个问题：下一个要下线的立方体的体积在 0 立方厘米到 1 立方厘米之间的概率是多少？在这里，PoI 似乎会说概率是 1/8。因为从 0 到 1 的范围仅覆盖了从 0 到 8 立方厘米的所有可能体积的 1/8。因此，对于等价命题，我们有两个不同的概率：如果一个立方体的边长在 0 到 1 厘米之间，那么它的体积在 0 立方厘米到 1 立方厘米之间。再次，PoI 给出的概率似乎取决于我们如何描述可能结果的范围。用长度来描述，我们得到一个答案；用体积来描述，我们得到另一个。

伯特兰悖论具有相当普遍的适用性。无论我们对一个立方体的大小、一匹马将获胜的距离，或者任何以实数表示的参数感兴趣，我们总是可以重新描述可能结果的空间，以便由概率论推理所分配的概率值不同。即使对可能性空间进行无限细的划分也无法解决问题：由概率论推理所分配的概率仍然取决于我们如何描述可能性空间。

我们在用概率术语来构建归纳问题时，基本上面临这个问题。之前我们看到了两种竞争的方式来为硬币抛掷序列分配先验概率。一种方式根据 H 和 T 出现的确切顺序来划分可能的结果。PoI 为每个可能的序列分配了概率 1/1024，结果是前 9 次抛掷对第 10 次抛掷毫无意义。第二种，卡纳普式的方式则根据 T 的数量来划分可能的结果，而不管它们在序列中出现的位置。PoI 然后为每个可能的 T 数量分配相同的概率，1/11。结果是前 9 次抛掷告诉我们很多关于第 10 次抛掷：如果前 9 次抛掷是尾巴，第 10 次抛掷也有 10/11 的机会再次出现尾巴。

因此，应用 PoI 的一种方式导致归纳怀疑主义，另一种方式则导致归纳乐观主义，后者似乎对科学和日常生活至关重要。如果我们能够澄清 PoI 应该如何应用，并证明其使用，我们将得到对休谟问题的答案（或至少是第一部分——我们仍然需要解决将条件概率用作指导新的无条件概率的问题）。它能被澄清和证明吗？

在这里，我们再次遇到形式认识论中最深刻和最古老的分歧之一，即主观主义者和客观主义者之间的分歧。主观主义者认为，任何概率分配都是开始调查的一种合法、合理的方式。只需遵守三个概率公理就可以被认为是合理的。他们持这种观点主要是因为他们对澄清 PoI 感到绝望。例如，他们认为我们没有理由首先按照 T 的数量进行划分，然后再根据这些 T 在序列中的位置进行细分，为什么要遵循卡尔纳普的观点。与此怀疑密切相关的是对澄清 PoI 后，以一种能够使其与概率的三个公理相媲美的方式来证明的前景的怀疑。我们还没有涉及三个公理应该如何被证明。但经典故事是这样的：一系列定理——荷兰博弈定理（见条目）和表示定理（见条目）——被认为表明任何偏离概率的三个公理都会导致非理性的决策。例如，如果你偏离这些公理，你将接受一组注定会亏钱的赌注，尽管你可以看到亏钱是不可避免的。然而，这些定理并不适用于 PoI 的违反，无论它如何被澄清。因此，主观主义者得出结论，违反 PoI 并不是非理性的。

主观主义者在面对归纳问题时并非完全无助。根据他们的观点，任何概率的初始分配都是合理的，包括卡尔纳普的。因此，如果您确实从卡尔纳普式的分配开始，您将成为归纳乐观主义者，这是合理的。只是您不必从这种方式开始。您也可以选择将每个可能的 H 和 T 序列视为同等可能，这样您最终会成为归纳怀疑论者。这也是合理的。根据主观主义，归纳是完全合理的，只是不是推理的唯一合理方式。

客观主义者认为，有一种方法来分配初始概率（尽管一些人允许有一点灵活性（Maher 1996））。根据正统客观主义，这些初始概率由 PoI 给出。至于 PoI 根据可能性如何划分而产生冲突的概率分配，一些客观主义者提议限制它以避免这些不一致性（Castell 1998）。另一些人认为，概率分配依赖于可能性如何划分实际上是合适的，因为这反映了我们构想情况的语言，我们的语言反映了我们对事情的了解（Williamson 2007）。还有一些人认为，PoI 的分配实际上并不取决于可能性如何划分——有时很难判断证据何时支持一种可能性而不是另一种可能性（White 2009）。

对于如何证明 PoI 呢？主观主义者传统上通过上述定理之一来证明概率的三个公理：荷兰书定理或某种形式的表示定理。但正如我们之前指出的那样，这些定理并不适用于 PoI。

最近，一种不同类型的理据开始受到青睐，这种理据可能延伸到 PoI。依赖荷兰博弈或表示定理的论证长期以来一直受到怀疑，因为它们具有实用主义的特征。它们旨在表明偏离概率公理会导致非理性选择，这似乎充其量表明遵守概率公理是实用主义理性的一部分，而不是认识论非理性。（但请参阅 Christensen（1996, 2001）和 Vineberg（1997, 2001）的回应。）Joyce（1998, 2009）更倾向于采用更加恰当的认识论方法，他认为偏离概率公理会使人远离真理，无论真理最终是什么。Pettigrew（2016）将这种方法应用于 PoI，表明违反 PoI 会增加一个人远离真理的风险。（但请参阅 Carr（2017）对这种一般方法的批判性观点。）

### 2.2 更新与推理

无论我们更喜欢主观主义者对休谟问题的回应还是客观主义者的回应，一个关键要素仍然缺失。我们早些时候指出，仅仅证明对先验概率的卡纳皮安分配只能让我们走到解决问题的一半。我们仍然需要将这些先验概率转化为后验概率：最初，第十次抛掷出现尾巴的概率是 1/2，但在观察到前 9 次抛掷都出现尾巴后，这个概率应该是 10/11。在证明了我们对概率的初始分配的合理性之后——无论是主观主义的方式还是客观主义的方式——我们可以证明 p(T10∣T1…9)=10/11，相比之下 p(T10)=1/2。但这并不意味着新的 T10 的概率是 10/11。请记住，符号 p(T10∣T1…9)只是 p(T10∧T1…9)/p(T1…9)这个比例的简写。因此，p(T10∣T1…9)=10/11 只是意味着这个比例是 10/11，这仍然只是关于最初的先验概率的事实。

为了理解这个问题，暂时忘记概率，用简单、通俗的方式思考会有所帮助。假设你不确定 A 是否为真，但你相信如果 A 为真，那么 B 也是真的。如果你随后得知 A 事实上是真的，那么你有两个选择。你可能得出结论 B 是真的，但你也可能决定你最初认为如果 A 为真，那么 B 也是真的这个想法是错误的。面对接受 B 的可能性，你可能觉得太不可信，因此放弃了最初的条件信念，即如果 A 为真，则 B 也为真（Harman 1986）。

同样，我们可能一开始不确定前 9 次抛硬币是否会出现正面，但相信如果出现正面，那么第 10 次抛硬币出现正面的概率为 10/11。然后，当我们看到前 9 次抛硬币都出现正面时，我们可能会得出结论，第 10 次抛硬币出现正面的概率为 10/11，或者，我们可能会认为我们一开始认为第 10 次抛硬币出现正面的概率为 10/11 是错误的，如果前 9 次抛硬币都出现正面。

任务是证明选择第一条路而不是第二条路的理由：坚持我们的条件信念，即如果 T1…9，则 T10 的概率为 10/11，即使我们已经了解到确实 T1…9。以这种方式坚持自己的条件概率被称为“条件化”，因为这样一来，人们就将旧的条件概率转变为新的无条件概率。为了看到坚持旧的条件概率等同于将它们转变为无条件概率的原因，让我们继续使用 p 来表示先验概率，并引入 p'来表示在我们了解到 T1…9 之后的新的后验概率。如果我们坚持我们的先验条件概率，那么 p'(T10∣T1…9)=p(T10∣T1…9)=10/11。由于我们现在知道 T1…9，所以 p'(T1…9)=1。然后可以得出 p'(T10)=10/11。

p′(T10∣T1…9)=p′(T10∧T1…9)p′(T1…9)=p′(T10∧T1…9)=p′(T10)=10/11

第一行是根据条件概率的定义得出的。第二行是因为我们已经看到了前 9 次抛掷的结果，所以 p′(T1…9)=1。第三行是根据概率公理的一个基本定理得出的：将 A 与另一个概率为 1 的命题 B 连接起来会得到相同的概率，即 p(A∧B)=p(A)，当 p(B)=1 时。（读者可以自行推导这个定理。）最后，最后一行仅仅是根据我们的假设得出的，即 p′(T10∣T1…9)=p(T10∣T1…9)=10/11。我们通常应该以这种方式更新概率的论点被称为条件化。

**条件化**
根据先验概率分配 p(H∣E)，在学习 E 后，对 H 的新的无条件概率分配应为 p′(H)=p(H∣E)。

许多论证都支持这一原则，其中许多与先前提到的概率公理的论证相似。有些人提到荷兰书（Teller 1973; Lewis 1999），还有些人提到追求认知价值（Greaves and Wallace 2006），尤其是接近真理（Leitgeb and Pettigrew 2010a,b），还有一些人认为，当接受新信息时，一般应尽量少地修正自己的信念（Williams 1980）。

这些论点的细节可能非常技术化，因此我们不会在这里进行详细讨论。目前重要的是要意识到，归纳推理是一个动态过程，因为它涉及随时间改变我们的信念，但是概率公理和像卡尔纳普的先验概率分配这样的特定分配是静态的，仅涉及初始概率。因此，回答休谟的挑战的完整推理理论必须诉诸额外的动态原则，如条件化。因此，我们需要证明这些额外的动态原则，以证明一个恰当的推理理论并回答休谟的挑战。

重要的是，(i)–(iv) 中总结的道德原则非常普遍。它们不仅适用于基于概率论的形式认识论，还适用于基于其他形式主义的广泛理论，如登普斯特-沙弗理论、排名理论、信念修正理论和非单调逻辑。因此，这里的一个看法是。

形式认识论为我们提供了确切的陈述归纳如何运作的方式。但这些确切的表述本身并不能解决类似于休谟的问题，因为它们依赖于概率公理、卡尔纳普对先验概率的赋值以及条件化等假设。然而，它们确实帮助我们分离和澄清这些假设，然后制定各种辩护论据。形式认识论是否因此有助于解决休谟的问题取决于这些表述和理由是否可信，这是有争议的。

## 第三个案例研究：回归问题

归纳问题挑战了我们从观察到未观察到的推论。回归问题在更基本的层面上挑战了我们的知识，质疑我们首先通过观察来认识任何事物的能力（见 Weintraub 1995 年对这一区别的批判性分析）。

似乎要了解某事，你必须有一些理由来相信它。例如，你知道苏格拉底教导柏拉图是基于传承多年的证词和文本来源。但你如何知道这些证词和文本是可靠的来源呢？据推测，这种知识本身也是基于进一步的理由——与这些来源的各种经验，它们之间的一致性，以及与你独立观察到的其他事物的一致性等。但这种知识的基础也可能受到质疑。你如何知道这些来源甚至说的是你认为它们说的内容，或者它们是否存在——也许你阅读《辩护篇》的每一次经历都是一种幻觉或错觉。

著名的阿格里帕三难问题确定了这种理由回归最终可能展开的三种可能方式。首先，它可能永远持续下去，A 由 B 证明，B 由 C 证明，依此类推，无限循环。其次，它可能在某个时刻自我循环，例如 A 由 B 证明，B 由 C 证明，依此类推，最终由 B 证明。第三，最后，这种回归可能在某个时刻停止，A 由 B 证明，B 由 C 证明，依此类推，最终由 N 证明，而 N 不再由任何进一步的信念证明。

这三种可能性对应于对这种合理化回归的三种经典回应。无限主义者认为回归永无止境，一致主义者认为回归会循环回到自身，而基础主义者认为回归最终会终止。每种观点的支持者都拒绝将其他选择视为可接受。无限主义看起来在心理上不现实，需要一个无限的信念树，我们这样有限的心智无法容纳。一致主义似乎使合理化变得不可接受地循环，因此太容易实现。而基础主义似乎使合理化变得任意，因为回归末端的信念显然没有合理化。

支持每种观点的人长期以来一直努力回答有关自己观点的问题，并展示对于其他选择的担忧无法得到充分回答。最近，形式认识论的方法开始被招募来检验这些回答的充分性。我们将看一些关于连贯主义和基础主义的研究，因为这些一直是非正式和正式工作的重点。（有关无限主义的研究，请参见 Turri 和 Klein 2014 年。有关混合选项“foundherentism”，请参见 Haack（1993 年）。）

### 3.1 Kohärenzismus

关于连贯主义的直接关注是它使得理由论成为循环的。一个信念如何能够被其他信念所证明，而这些信念最终是由问题中的第一个信念所证明的呢？如果允许理由的循环，那么有什么能够阻止一个人相信任何他喜欢的东西，并将其作为自身的理由呢？

连贯主义者通常回应说，理由并不实际上是循环的。事实上，它甚至不是个别信念之间的关系。相反，一个信念之所以被证明是因为它是一个较大的信念体系的一部分，这些信念相互契合。因此，理由是全局的，或者说是整体的。它首先是整个信念体系的特征，仅其次才是个别信念的特征，因为它们是整体的一部分。当我们追溯一个信念的理由直至最初，我们并没有揭示它被证明的路径。相反，我们揭示了使整个网络作为一个单位被证明的各种相互连接。这些连接可以追溯到一个循环中，仅仅揭示了网络是多么相互连接，从 A 到 B 再到 N，然后从 N 一直回到 A。连贯主义者通常回应说，理由并不实际上是循环的。事实上，它甚至不是个别信念之间的关系。相反，一个信念之所以被证明是因为它是一个较大的信念体系的一部分，这些信念相互契合。因此，理由是全局的，或者说是整体的。它首先是整个信念体系的特征，仅其次才是个别信念的特征，因为它们是整体的一部分。当我们追溯一个信念的理由直至最初，我们并没有揭示它被证明的路径。相反，我们揭示了使整个网络作为一个单位被证明的各种相互连接。这些连接可以追溯到一个循环中，仅仅揭示了网络是多么相互连接，从 A 到 B 再到 N，然后从 N 一直回到 A。

然而，任意性仍然是一个令人担忧的问题：您仍然可以相信几乎任何事情，只要您还相信许多其他与之相吻合的事情。如果我想相信鬼魂，我是否可以采纳一个更广阔的世界观，其中超自然和超常现象很普遍？这种担忧导致了另一个担忧，对真理的担忧：鉴于几乎任何信念都可以嵌入一个更大的故事中，使其变得合理，为什么期望一个连贯的信念体系是真实的呢？人们可以讲述许多连贯的故事，其中绝大多数将是极其错误的。如果连贯性并不是真理的指示，那么它如何提供理由呢？

这就是形式方法的用武之地：概率论告诉我们关于一致性与真理之间的联系是什么？一致性更强的信念体系更可能是真实的吗？更不可能是真实的吗？

Klein 和 Warfield（1994）认为，一致性通常会降低概率。为什么？一致性的增加通常来自于能解释我们现有信念的新信念。一名调查犯罪的侦探可能会被相互矛盾的证词困扰，直到她得知嫌疑人有一个同卵双生兄弟，这解释了为什么一些证人声称在犯罪当天看到嫌疑人在另一个城市。然而，将关于同卵双生兄弟的事实添加到她的信念体系中实际上降低了其概率。这源自我们之前提到的概率公理定理（§ 1.2），即连接成本概率，它表明将 A 与 B 连接通常会产生比仅 A 更低的概率（除非 p（A∧¬B）=0）。直觉上，你相信的事情越多，你就越冒真相的风险。但理解事物通常需要更多的信念。

Merricks (1995)回应说，只有在添加信念时整个信念体系的概率才会下降。但其中包含的信念的个体概率才是问题所在。从侦探的角度来看，当她的个体信念通过额外信息（嫌疑人有一个同卵双生）得到解释时，这些信念确实变得更有可能。Shogenji (1999)持不同看法：整体的连贯性不能影响部分的概率。连贯性是为了让部分一起成立或失败，因此正如连贯性使所有成员更有可能一起为真，它也使它们更有可能全部为假（以牺牲一些可能为真而另一些为假的可能性）。

相反，Shogenji 更倾向于在集体层面上回答 Klein＆Warfield，即整个信念体系的层面。他认为，Klein＆Warfield 比较的信念体系之间的概率不同，因为它们具有不同的强度。一个信念体系包含的信念越多，或者其信念越具体，它就越强大。在侦探的案例中，添加关于双胞胎的信息会增强她的信念的强度。而且，一般来说，增强强度会降低概率，因为正如我们所见，p(A∧B)≤p(A)。因此，侦探信念的一致性增加伴随着强度的增加。Shogenji 认为，净效应是负面的：信念体系的概率下降，因为强度的增加超过了一致性的增加。

为了证明这一诊断，Shogenji 援引了一个用概率术语衡量信念集合一致性的公式，我们将其标记为 coh

coh(A1,…,An)=p(A1∧…∧An)p(A1)×…×p(An)

为了看到这个公式背后的原理，考虑一下只有两个信念的简单情况：

coh(A,B)=p(A∧B)p(A)×p(B)=p(A∣B)p(A)

当 B 对 A 没有影响时，p(A∣B)=p(A)，这个比率就是 1，这是我们的中立点。如果 B 提高了 A 的概率，这个比率大于 1；如果 B 降低了 A 的概率，这个比率小于 1。因此，coh(A,B)衡量了 A 和 B 之间的关联程度。Shogenji 的公式 coh(A1,…,An)将这个想法推广到更大的命题集合。

这种方式如何证明 Shogenji 对 Klein & Warfield 的回应，即侦探的连贯性增加被她信念的强度增加所抵消？公式中的分母跟踪强度：命题越多，越具体，分母就越小。因此，如果我们比较两个具有相同强度的信念集，它们的分母将是相同的。因此，如果一个比另一个更连贯，那必须是因为它的分子更大。因此，连贯性随着总体概率增加，前提是保持强度恒定。由于在侦探的案例中，尽管连贯性增加，但总体概率并没有增加，这必须是因为她的承诺的强度产生了更强烈的影响。

Shogenji 的一致性度量受到其他作者的批评，其中许多人提出了自己偏好的度量方法（Akiba 2000; Olsson 2002, 2005; Glass 2002; Bovens & Hartmann 2003; Fitelson 2003; Douven and Meijs 2007）。如果有的话，哪种度量方法是正确的仍然存在争议，Klein & Warfield 反对一贯主义的论点的命运也是如此。另一种概率攻击一贯主义的途径来自 Huemer（1997），并得到 Olsson（2005）的支持。然而，Huemer（2011）后来撤回了这一论点，理由是它给一贯主义者带来了不必要的承诺。关于一贯主义的更多细节，请参阅相关条目。

### 3.2 基础主义

基础主义者认为，一些信念是有正当理由的，而不需要其他信念的支持。哪些信念具有这种特殊的基础地位？基础主义者通常将这些信念确定为关于感知或记忆事项的信念，比如“我面前有一扇门”或“昨天我吃了鸡蛋”，或者关于事物对我们的显现，比如“我面前似乎有一扇门”或“我似乎记得昨天吃了鸡蛋”。无论哪种情况，挑战在于说明这些信念如何能够被证明正当，如果它们不是由其他信念所证明的话。

一种观点是，这些信念是由我们的感知和记忆状态所证明的。当看起来有一扇门在我面前时，这种感知状态使我相信那里有一扇门，前提是我没有理由不信任这种外观。或者，至少，我有理由相信那里似乎有一扇门。因此，基础性信念并非是任意的，它们是由密切相关的感知和记忆状态所证明的。然而，回归到此为止，因为询问什么证明了感知或记忆状态是毫无意义的。这些状态在认识规范领域之外。

经典的基础主义批评现在出现了，这是臭名昭著的塞拉斯困境的一个版本。你必须知道你的（比如）视力是可靠的，才能有理由相信前面有一扇门是因为它看起来是这样吗？如果是这样，我们面临困境的第一个角：理由的回归被重新激活。是什么让你相信你的视力是可靠的？诉诸以前你的视力被证明可靠的案例只是把问题推迟了一步，因为现在同样的问题也出现在你的记忆可靠性上。我们能否说，一扇门的外观本身就足以证明你对门的信念？然后我们面临困境的第二角：这样的信念似乎是武断的，基于一个你没有理由信任的来源，即你的视力（Sellars 1956; Bonjour 1985; Cohen 2002）。

这第二个角被 White (2006)加以锐化，他用概率术语对其进行了形式化。设 A(D)为你面前似乎有一扇门的命题，D 为那里真的有一扇门的命题。合取 A(D)∧¬D 代表了在这种情况下外表可能具有误导性的可能性。它表示似乎有一扇门但实际上并没有。利用概率公理，我们可以证明 p(D∣A(D))≤p(¬(A(D)∧¬D))（见技术补充§3）。换句话说，真的有一扇门的概率，假设看起来有一扇门，不能超过在这种情况下外表不具有误导性的初始概率。因此，似乎任何对 D 的信念的理由 A(D)都必须在之前有一些理由来相信外表不具有误导性，即¬(A(D)∧¬D)。显然，你必须知道（或有理由相信）你的信息来源是可靠的，然后才能信任它们。（Pryor 2013 阐明了这一论证中的一些内隐假设。）

塞拉斯困境的另一角落潜伏着不偏不倚原则（PoI）。根据 PoI，门的外观可能是误导性的初始概率是多少？从某种角度来看，你的视觉可信度可以从 100%到 0%不等。也就是说，我们所看到的东西可能始终准确，从不准确，或者介于两者之间。如果我们将从 0%到 100%的每个可信度程度视为同等可能，那么效果就等同于我们假定经验为 50%可信。PoI 将会分配 p(D∣A(D))=1/2。这一结果实际上接受了怀疑论，因为尽管外观如此，我们仍对门的存在保持不可知论态度。

我们之前看到（§2.1）PoI 根据我们如何划分可能性空间而分配不同的概率。如果我们改为这样划分事物呢：

|            | D   | ¬D |
| ------------ | ----- | ----- |
| 形式认识论 | 1/4 | 1/4 |
| ¬A(D)     | 1/4 | 1/4 |

再次，我们得到了怀疑主义、不可知论的结果，即 p(D∣A(D))=1/2。其他划分可能性空间的方式肯定会带来更好的、反怀疑主义的结果。但是，那么就需要一些偏好于这些划分方式的论证，从而再次引发对理由的回归。

主观主义者拒绝 PoI 并允许对初始概率进行任何分配，只要它遵守概率公理，可能会回应说，将高概率分配给我们的感官是（比如）95%可靠的假设是完全允许的。但他们也必须承认，将高概率分配给我们的感官是 0%可靠的假设，即始终错误，也是允许的。主观主义者可以说，对外部世界的信念是合理的，但他们必须承认怀疑论也是合理的。一些基础主义者可能能够接受这一结果，但许多人试图理解经验如何以更强的方式证明外部世界的信念，以一种可以用来对抗怀疑论者的方式，而不仅仅是同意不同意见。

## 第四个案例研究：知识的界限

到目前为止，我们仅使用了一个形式工具，概率论。我们可以使用其他工具（如 Dempster-Shafer 理论或排名理论）在上述应用中获得许多类似的结果。但让我们转向一个新的应用和一个新的工具。让我们使用模态逻辑来探索知识的界限。

### 4.1 形式认识论模态逻辑

模态逻辑的语言与普通的古典逻辑相同，但额外添加了一个句子运算符□，用于表示必然性。如果一个句子ϕ不仅仅是真的，而且是必然真的，我们写成□ϕ。

有许多种必然性。有些事情在逻辑上是必然的，比如重言式。其他可能不是逻辑上必然的，但在形而上学上是必然的。（赫斯珀鲁斯和金星是相同的这一点是一个常见的例子；更有争议的候选者包括上帝的存在或关于父母起源的事实，例如，阿达·洛芙莱斯的父亲是拜伦勋爵。）

但这里关注的必然性是认识论上的必然性，即根据我们所知道的事实必须为真的必然性。例如，对你来说，本句的作者是人类是认识论上的必然性。如果你之前不知道这一点（也许你还没有考虑过这个问题），那么根据你已知的其他事实，这一点必须为真：即地球上唯一能够构建形式认识论连贯调查的生物是人类，而这正是这样一项调查（我希望）。

在认识模态逻辑中，写成 Kϕ而不是□ϕ是有意义的，其中 Kϕ表示ϕ被认为是真实的，或者至少是从已知为真实的内容推导出来的。由谁知晓？这取决于具体的应用。除非另有规定，让我们假设我们谈论的是你的知识。

形式认识论应包括哪些公理？嗯，命题逻辑的任何重言式都应该是定理，比如 ϕ⊃ϕ。就此而言，类似地真值表有效的带有 K 运算符的公式，比如 Kϕ⊃Kϕ，也应该是定理。因此，我们将以最粗糙的方式，将所有这些公式都作为公理，使它们成为定理。

* (P)任何根据古典逻辑规则真值表有效的命题都是公理。

采用 P 立即使我们的公理清单变得无限。但它们都可以通过真值表方法轻松识别，所以我们不会担心。

超越古典逻辑，所有所谓的“正常”模态逻辑都共享一个在认识应用中看起来相当合理的公理：超越古典逻辑，所有所谓的“正常”模态逻辑都共享一个在认识应用中看起来相当合理的公理：

(K)K(ϕ⊃ψ)⊃(Kϕ⊃Kψ)

如果你知道 ϕ⊃ψ 是真的，那么如果你也知道 ϕ，你也知道 ψ。或者至少，如果 ϕ⊃ψ 和 ϕ 成立，那么 ψ 就是你所知道的。 (这里的“K”代表“Kripke”，而不是“knowledge”。) 所有“alethic”模态逻辑共享的另一个常见公理看起来也不错：

(T)Kϕ⊃ϕ

如果你知道 ϕ，那么它必须是真的。（注意：K 和 T 实际上是公理模式，因为这些形式的任何句子都是公理。因此，每个这些模式实际上都添加了无限多个相同一般形式的公理。）

对于这些公理，我们将添加两条推理规则。第一条，来自古典逻辑，规定从ϕ⊃ψ和ϕ可以推导出ψ。形式上：

(MP)ϕ⊃ψ,ϕ⊢ψ

第二条规则是模态逻辑的具体内容，它表明从ϕ可以推导出 Kϕ。形式上：

(NEC)ϕ⊢Kϕ

NEC 规则立即显得可疑：它难道不是使一切真理为人所知吗？实际上并非如此：我们的逻辑只承认公理和由它们通过 MP 推导出的东西。因此，只有逻辑真理将受到 NEC 规则的约束，而这些是认识上必要的：它们要么已知，要么是从我们所知的东西推导出来的，因为它们是在没有任何假设的情况下推导出来的。（NEC 代表“必要”，在当前系统中是认识上必要的。）

三个公理模式 P、K 和 T，连同推导规则 MP 和 NEC，构成了我们的最小认识模态逻辑。它们使我们能够推导出一些基本定理，其中一个我们将在下一节中使用：

定理 (∧-分配)。K(ϕ∧ψ)⊃(Kϕ∧Kψ)

请参阅技术补充材料以获取证明。这个定理大致表明，如果你知道一个连词，那么你就知道每个连词。至少，每个连词都可以从你所知道的内容中推导出来（我将从现在开始将这个限定词隐含），这似乎是相当明智的。

我们能证明更有趣的事情吗？稍加调整，我们可以得出一些关于我们知识界限的相当引人注目的结果。

### 形式认识论 4.2 知识可能性悖论（又称教会-菲奇悖论）

一切真理都能被认知吗？或者有一些真理在原则上永远无法被认知吗？Fitch（1963）广为人知的论点，最初由 Alonzo Church（Salerno 2009）提出，暗示并非如此：有些真理是无法被认知的。因为如果原则上所有真理都是可知的，我们就可以推导出所有真理实际上已经被认知，这是荒谬的。

该论证需要对我们的认识逻辑进行轻微扩展，以适应可知性的概念。对我们而言，K 代表已知（或由已知蕴含），而可知性则增加了一个额外的模态层：即可知的内容。因此，我们需要在我们的语言中引入一个命题算子◊来表示形而上的可能性。因此，◊ϕ表示“ϕ在形而上上是可能为真的”。实际上，◊ϕ只是¬□¬ϕ的简写，因为不必为假的东西可以为真。因此，我们实际上可以添加□并假设，就像 K 算子一样，它遵守 NEC 规则。（与 K 算子的 NEC 规则一样，我们总是可以从ϕ推导出□ϕ，因为我们只有在ϕ是逻辑真理时才能推导出ϕ。）根据定义，◊只是¬□¬。

有了这个语言补充，我们可以推导出以下引理（有关推导过程，请参阅技术补充）：

引理（未知者是无法知晓的）。¬◊K(ϕ∧¬Kϕ)

这个引理基本上说你不能知道这样的事实：“ϕ是真的，但我不知道它是真的”，这似乎很明智。如果你知道这样的连接词，第二个连接词必须是真的，这与你知道第一个连接词相矛盾。（这就是∧-分配证明有用的地方。）

然而，这个看似合理的引理几乎立即导致了一些真理的不可知性。假设反证法，假设一切真理至少原则上都是可以被知晓的。也就是说，假设我们将其作为一个公理：

**知识无限**
ϕ⊃◊Kϕ

我们随后将能够在短短几行中得出一切真实的事实实际上是已知的，即ϕ⊃Kϕ。

(ϕ∧¬Kϕ)⊃◊K(ϕ∧¬Kϕ)知识无限制¬(ϕ∧¬Kϕ)1，未知是无法知晓的，Pϕ⊃Kϕ2，P

如果 K 代表上帝知道的事情，那就没问题。但如果 K 代表你或我知道的事情，这似乎是荒谬的！我们不知道的真理不仅存在，大多数真理甚至不是基于我们已知的内容。无限知识似乎是问题的罪魁祸首，因此似乎有一些事情我们甚至在原则上也无法知道。但请参阅关于菲奇可知性悖论的条目以获取更多讨论。

### 自我认知

即使我们无法了解某些事情，我们是否至少可以无限接近我们自己的知识？我们是否至少总是能够辨别自己是否知道某事？在形而上必然性逻辑中一个流行的公理是所谓的 S4 公理：□ϕ⊃□□ϕ。这意味着任何必然的事情都必须是必然的。在认识逻辑中，对应的公式是：

(KK)Kϕ⊃KKϕ

这大致表示，每当我们知道某事时，我们知道自己知道它。Hintikka (1962) 以著名的方式主张将 KK 包括为认知逻辑的公理。但由 Williamson (2000) 提出的一项有影响力的论证则持相反观点。

该论点的关键在于知识不能凭运气获得。具体来说，要想知道某事，必须是你不太容易出错。否则，即使你可能是对的，那也只是运气而已。例如，你可能猜对了我桌子上的罐子里有 967 颗软糖豆，但即使你是对的，那也只是运气。你并不知道有 967 颗软糖豆，因为很容易就可能有 968 颗而你没有注意到这个差异。

为了形式化这个“无运气”观念，让命题ϕ1，ϕ2 等表示糖豆的数量至少为 1，至少为 2，等等。我们假设您是在粗略估计瓶子里的糖豆数量，而不是仔细数它们。因为您对大量糖豆的估计是不完美的，您无法知道瓶子里至少有 967 颗糖豆。如果您认为瓶子里至少有 967 颗糖豆，您很容易犯错误，认为至少有 968 颗，这样您就会错了。因此，在这种情况下，我们可以将“不容易出错”的观念形式化如下：

**安全**
Kϕi⊃ϕi+1 when i is large (at least 100 let’s say).

知识需要一个错误边界，至少在我们的例子中是一个糖豆的边界。可能不止一个糖豆，但至少一个。在真实数字的一个糖豆范围内，你无法辨别真相和谬误。（参见 Nozick (1981) 对知识“无运气”要求的不同概念，Roush (2005; 2009) 用概率术语形式化了这一概念。）知识需要一个错误边界，至少在我们的例子中是一个糖豆的边界。可能不止一个糖豆，但至少一个。在真实数字的一个糖豆范围内，你无法辨别真相和谬误。（参见 Nozick (1981) 对知识“无运气”要求的不同概念，Roush (2005; 2009) 用概率术语形式化了这一概念。）

形式认识论已经向你解释了所有这些，现在你知道的另一件事是：安全性命题是真实的。因此我们也有：

**安全知识**
K(Kϕi⊃ϕi+1) 当 i 很大。

将安全知识与 KK 结合起来会产生荒谬的结果：

1. Kϕ100 假设2. KKϕ1001，KK3. K(Kϕ100⊃ϕ101)安全知识4. KKϕ100⊃Kϕ1013，K5. Kϕ1012，4，M6. 重复步骤（2）-（5）对于ϕ101，ϕ102，…，ϕnm7. Kϕnm−1，MPm′8. ϕnm，T

根据第（1）行的假设，即您知道罐子里至少有 100 颗软糖（您可以清楚地看到），我们可以证明罐子里的软糖比星系中的星星还要多。将 n 设定得足够高，软糖甚至超过了宇宙中的粒子数量！（请注意，在这个推导中我们并没有依赖于 NEC，因此可以使用非逻辑假设，比如第（1）行和安全知识。）

如果我们在这些理由上与威廉姆森一起拒绝 KK，哲学上的回报是什么？依赖 KK 的怀疑论证可能会被解除武装。例如，怀疑论者可能会主张，要知道某事，你必须能够排除任何竞争性的替代方案。例如，要知道外部世界是真实的，你必须能够排除你被笛卡尔的恶魔欺骗的可能性（Stroud 1984）。但是，你还必须能够排除你不知道外部世界是真实的可能性，因为这显然是你知道它是真实的一个替代方案。也就是说，你必须 K¬¬Kϕ，因此 KKϕ（Greco 2014）。因此，这种怀疑论论证的驱动前提涉及 KK 命题，而我们已经有理由拒绝它。

其他怀疑论点当然不依赖于 KK。例如，一种不同的怀疑方法始于这样一个前提：笛卡尔的恶魔的受害者与现实世界中的人具有完全相同的证据，因为他们的经验状态是无法区分的。但是，如果在这两种情况下我们的证据是相同的，我们就没有理由相信我们处于其中一种情况而不是另一种情况。Williamson（2000 年：第 8 章）提出了一种类似于他对 KK 的推导的论证，反对在现实世界和恶魔世界中的证据是相同的这一前提。要点在于，我们并不总是知道在特定情况下我们拥有什么证据，就像我们并不总是知道我们知道什么一样。事实上，Williamson 认为，我们自己心智的任何有趣特征都受到类似的论证，包括我们看起来是ϕ：Aϕ⊃KAϕ面临与 Kϕ⊃KKϕ相似的推导。有关进一步分析和批评，请参见 Hawthorne（2005），Mahtani（2008），Ramachandran（2009），Cresto（2012）和 Greco（2014）。

## 第五案例研究：社会认识论

在研究整个社区而不仅仅是孤立个体时，会发生有趣的事情。在这里，我们将研究研究人员之间的信息共享，并发现两个有趣的结果。首先，自由共享信息实际上可能会损害社区发现真相的能力。其次，社区成员之间的不信任可能导致一种极化现象。

我们还将在过程中引入一种新工具：计算机模拟。可以从 GitHub 下载用于重现本节结果的 Python 代码。

### Zollman 效应

想象一下有两种治疗某种医疗状况的方法。一种治疗方法是旧的，其疗效是众所周知的：在任何给定情况下，它有 0.5 的机会治愈该状况。另一种治疗方法是新的，可能稍微好一点或稍微差一点：成功的机会是 0.501，否则是 0.499。研究人员还不确定到底是哪一种。

目前，一些医生对新疗法持谨慎态度，而另一些则更为乐观。因此，一些医生尝试在他们的患者身上使用新疗法，而另一些则坚持旧的方式。事实证明，乐观主义者是正确的：新疗法更为优越，成功的几率为 0.501。

因此，新治疗方法的优越性最终会在社区中形成共识吗？随着对其表现的数据被收集和共享，难道随着时间的推移不应该变得清晰，新治疗方法略有优势吗？

并非一定如此。尝试新疗法的人可能会遇到一连串的厄运。最初的研究可能会得到一系列不太出色的结果，这些结果并不能准确反映新疗法的优越性。毕竟，它只是比传统疗法略微好一点。因此，它可能不会立刻展现出其实力。如果没有展现出来，乐观主义者可能会在它有机会证明自己之前放弃它。

一种减轻这种危险的方法是限制医学界信息的流动。根据 Zollman（2007）的观点，让我们通过模拟来演示这一点。

我们将建立一个“医生”网络，每个医生都有自己的初始确信度，认为新治疗方法更优。那些确信度高于 0.5 的人将尝试新的治疗方法，其他人将坚持使用旧的方法。通过线连接的医生彼此分享他们的结果，然后每个人都使用贝叶斯定理（§1.2.2）根据他们看到的结果进行更新。

我们将考虑不同规模的网络，从 3 到 10 名医生。我们将尝试三种不同的网络“形状”，即完全网络、轮式网络或循环网络。

![Three networks are shown, each with six nodes The first, labeled 'complete', has all six nodes arranged in a hexagon with a line from each node to every other node The second, labeled 'wheel', has five nodes arranged in a pentagon with the sixth node in the center; there are lines around the border of the pentagon and a line from the center node to each of the outer nodes The third, labeled 'cycle', has all six nodes arranged in a hexagon with lines around the border of the hexagon and no interior lines](https://plato.stanford.edu/entries/formal-epistemology/graph-shapes.png)

三种网络配置，每种配置有 6 位医生

我们的猜测是，循环将证明最可靠。一个医生如果得到一连串不幸的误导性结果，将会造成最小的伤害。分享他们的结果可能会阻止他们的两个邻居了解真相。但网络中的其他人可能会继续调查，最终了解新治疗方法的优越性真相。然而，轮子应该更容易受到意外错误信息的影响，而完整的网络最容易受到影响。

首先，每位医生被分配一个随机的确信度，认为新治疗方法更优，从区间[0, 1]均匀选择。那些确信度高于 0.5 的人将尝试在 1,000 名患者身上使用新治疗方法。成功次数将通过进行 1,000 次虚拟硬币“抛掷”，头朝上（治疗成功）的概率为 0.501 来随机确定。

每位医生随后与邻居分享他们的结果，并根据贝叶斯定理更新所有可用数据。然后我们进行另一轮实验，分享和更新，然后再进行另一轮，依此类推，直到社区达成共识。

共识可以通过两种方式实现。要么每个人都学到了真相，即新的治疗方法更好，通过对其产生高度信任（我们将说超过 0.99）。或者，每个人可能对新治疗方法的信任度达到 0.5 或更低。然后没有人会进一步进行实验，因此它不可能再次出现。

这是我们运行每个模拟 10,000 次时发生的情况。网络的形状和医生的数量都会影响社区发现真相的频率。第一个因素是 Zollman 效应：网络连接越少，他们发现真相的可能性就越大。

![A graph showing 'Probability of True Consensus' on the yaxis against 'Number of Agents' on the xxis There are three curves labeled 'cycle', 'wheel', and 'complete', respectively The 'complete' curve goes from a probability under 65 to a probability of 09 as the number of agents increases from 3 to 10 The 'wheel' curve goes from a probability of 08 to a probability of 095 as the number of agents increases from 5 to 10 The 'cycle' curve goes from a probability just over 075 to a probability just over 095 as the number of agents increases from 4 to 10](https://plato.stanford.edu/entries/formal-epistemology/zollman.png)

发现真相的概率取决于网络配置和医生数量。

但请注意，更大的社区也更有可能找到真相。为什么？因为更大、联系较少的网络更能有效地防止误导性结果。有些医生偶尔会得到不反映新治疗真实特性的数据。当这种情况发生时，他们误导性的结果会使社区充斥着错误信息，阻止其他人尝试新治疗。但在网络中的人越多，误导性结果就越有可能被其他人准确、代表性的结果所淹没。看到误导性结果的人越少，受到误导的人也就越少。

这里有一对动画模拟来说明第一个效应。在这里，我将六位医生的起始信念设定为相同，在两个网络中均匀分布：0.3、0.4、0.5、0.6、0.7 和 0.8。我还给了他们相同的随机数据序列。只有网络中的连接不同，在这种情况下这是至关重要的。只有循环学到了真相。完整的网络在很早的时候就变得黑暗，仅在 26 次迭代后就完全放弃了这种新颖的治疗方法。

两个具有相同先验的网络遇到相同的证据，但只有一个发现了真相。
[视频的替代链接]

什么拯救了循环网络的是从 0.8 信任度（左下角）开始的医生。他们起初乐观到在团队遭遇一系列令人沮丧的结果后继续前行。然而，在完整的网络中，他们早期收到如此多的负面证据，以至于几乎立刻放弃。他们的乐观情绪被许多邻居的负面发现所淹没。而循环则让他们接触到较少的这种令人沮丧的证据，给予他们时间继续尝试新的治疗方法，最终赢得了邻居的认可。

Rosenstock, Bruner, and O’Connor (2017)指出：有时候，科学探究结果分享越少越好。但这种效应有多重要？它出现频率如何，实际操作中是否值得担忧？

罗森斯托克（Rosenstock）、布鲁纳（Bruner）和奥康纳（O’Connor）认为，Zollman 效应只影响认识上“困难”的问题。只有因为我们两种处理方式之间的差异在数据中很难辨别，Zollman 效应才是一个问题。如果新的处理方式明显优于旧的处理方式，比如成功的几率为 0.7 而不是我们上面想象的 0.501，那么它的优越性被忽视的可能性不大，对吧？

所以 Rosenstock, Bruner 和 O’Connor 重新运行模拟，使用不同的“epsilon”值，即新治疗带来的成功概率增加。在此之前，我们将 epsilon 固定在 0.001 = 0.501 − 0.5。但现在我们将让它变化到 0.1。为简单起见，这次我们只考虑完整网络与循环，我们将保持医生人数固定为 10。（每轮试验次数仍为 1,000。）

![A graph showing 'Probability of True Consensus' on the yaxis against 'Epsilon' on the xaxis There are two curves labeled 'cycle' and 'complete', respectively The 'complete' curve goes from a probability of just under 09 to a probability of nearly 10 as epsilon goes from just over 0000 to just over 0025 The 'cycle' curve goes from a probability of nearly 0975 to a probability of nearly 10 as epsilon godes from just over 0000 to just over 0025 The 'cycle' curve starts above and rises faster than the 'complete' curve but they come togther when epsilong hits 0025](https://plato.stanford.edu/entries/formal-epistemology/rbo-2.png)

Zollman 效应在两种治疗方法之间的功效差异增大时消失

观察 Zollman 效应随着 epsilon 的增长而缩小。事实上，在这些模拟中，它只能看到大约 0.025。

罗森斯托克（Rosenstock）、布鲁纳（Bruner）和奥康纳（O’Connor）还进行了其他变体，以表明如果我们的医疗团体规模更大，或者每位医生在分享之前收集了更大的样本，那么佐尔曼效应就会消失。不太可能出现不具代表性的样本，从而使整个团体受到阻碍。因此，在自由共享数据方面并没有真正的危害。

然后一个自然的问题是：现实世界的研究社区面临“困难”问题的频率有多高，这种情况下 Zollman 效应是一个真正的关注点？Rosenstock、Bruner 和 O’Connor 承认一些实验室实验发现了类似的效应，即限制受试者之间的交流会导致改善的认识结果。但他们也强调 Zollman 效应并不“稳健”，需要相当特定的情况才能出现（小的 epsilon，小的研究社区，以及不太大的样本量）。由于上述模型既简单又理想化，他们认为，这种缺乏稳健性应该让我们三思，关于它在现实场景中的适用性。

### 5.2 不信任与极化

让我们现在转向这些认识网络模型的另一种用途。到目前为止，我们的医生们更新彼此的数据，就好像那是他们自己的数据一样。但如果他们彼此不信任呢？对于那些意见与自己不同的人，不完全信任是很自然的。毕竟，他们似乎在某个地方误入歧途了。即使不是这样，他们的观点可能会非法地影响他们的研究。

也许我们的医生不会轻易接受他人分享的数据。假设他们反而打折扣，特别是当数据来源的观点与他们自己的观点大相径庭时。O’Connor & Weatherall (2018) 和 Weatherall & O’Connor (即将出版) 探讨了这种可能性，并发现这可能导致极端化。社区并未达成共识，而是一些医生可能会放弃新的治疗方法，而另一些则得出结论认为它更优越。

在下面的示例动画中，蓝色的医生具有大于 0.5 的信任度，因此他们尝试新的治疗方法，并与所有人分享结果。绿色的医生信任度在 0.5 或以下，但仍然可以被说服。他们仍然足够信任蓝色的医生以更新他们的结果 - 尽管他们会根据与生成结果的医生意见相差多大而更多地打折这些结果。最后，红色的医生完全忽视结果。他们与所有蓝色医生相距太远，根本不信任他们。

O’Connor-Weatherall 模型中的极化示例
[[Alternative link to video](https://plato.stanford.edu/entries/formal-epistemology/ow-animate.html)]

在这个模拟中，我们达到了一个没有绿色医生的地步，只剩下红色的不易说服的怀疑论者和蓝色的高度自信的信徒。而蓝色的人变得如此自信，他们不太可能靠近任何红色的人听取意见。因此，我们已经达到了极化的稳定状态。

这种极化发生的频率有多高？这取决于社区的规模和“不信任率”。为了编程这个模型，我们必须决定一个医生对另一个医生的数据给予多少折扣，考虑到他们意见的不同。这个“不信任率”是模型中的一个可调参数。

这两个因素——社区规模和不信任率——如何影响极化的概率。 (请注意，我们这里只考虑完全网络。)

![A graph showing 'Probability of Polarization' on the yaxis against 'Mistrust' on the xaxis There are four curves each for a different number of agents 2, 6, 10, and 20 agents, respectively The curve for 2 agents goes from a probability of 0 to a probability just over 04 as mistrust goes from 10 to 25 The curve for 6 agents goes from a probability of 0 to a probability of 09 as mistrust goes from 10 to 25 The curve for 10 agents goes from a probability of 0 to a probability above 095 as mistrust goes from 10 to 25 The curve for 20 agents goes from a probability of 0 to a probability just under 10 as mistrust goes from 10 to 25](https://plato.stanford.edu/entries/formal-epistemology/ow-2.png)

极化的概率取决于社区规模和不信任的程度。

因此，越是医生倾向于彼此不信任，他们最终极易陷入两极分化。毫不奇怪。但更大的社区也更容易极化。为什么？

根据 O’Connor & Weatherall 的解释，医生数量越多，强烈怀疑论者在调查开始时出现的可能性就越大：那些相信度远低于 0.5 的医生。这些医生往往会忽视那些尝试新治疗方法的乐观主义者的报告。因此，他们为怀疑论人群设定了一个锚定点。

到目前为止，我们已经忽略了 O'Connor & Weatherall 模型的一个重要细节。折扣是如何运作的，医生们如何根据被折扣的证据进行更新？当 X 博士向 Y 博士报告数据 E 时，Y 并不简单地对 E 进行条件化。那意味着他们会直接接受 X 的报告。那么他们会做什么呢？

Y 通过对 p(H∣E) 和 p(H∣¬E) 的加权平均来计算对新治疗优越性的更新信念 p′(H)。这一程序是条件化的著名变体，被称为 Jeffrey Conditionalization。

**杰弗里条件化**
根据先前的概率分配 p(H∣E)和 p(H∣¬E)，在学习到具有确定性水平 p′(E)的 E 后，对 H 的新的无条件概率分配应为：p′(H)=p(H∣E)p′(E)+p(H∣¬E)p′(¬E)。

这个公式看起来很像总概率法则（§1.2.1），但有一个关键的区别。这个加权平均中的权重不是 p(E) 和 p(¬E)。而是 p′(E) 和 p′(¬E)。它们是 Y 分配给 X 的报告及其否定的更新、已经折扣的概率。

O’Connor & Weatherall (2018) 提出了一个计算 p′(E) 和 p′(¬E) 的自然公式，我们在这里不会深入讨论。我们只会指出，公式的选择对极化效应至关重要。不信任并不一定会引入极化的可能性；不信任必须足够强烈（大于上图中的 1.0）。必须有一个点，即代理人彼此完全不信任对方，因为他们的意见差异如此之大。否则，怀疑论者永远不会完全忽视他们乐观的同事，因此他们最终会被他们鼓舞人心的报告所说服。

这说明了像杰弗里条件化这样的更新规则存在一个普遍问题：要应用它们，我们首先需要确定要分配给证据的新概率。从那里我们可以确定其他命题的新概率。但这个基本的输入是我们没有规则的东西；这是形式系统中的一个悬而未决的问题，是留给我们作为模型使用者的事情。关于这一点的认识论意义的讨论，请参见 Field (1978)和 Christensen (1992)。

对于极化的另一种形式方法，请参见 Dorst (2020, Other Internet Resources)。有关网络认识论的其他工作，请参见 Zollman (2013) 和社会认识论条目的 §4.3 部分，以及其中的参考文献。

社会认识论中的其他形式项目包括对社会与个体理性之间关系的研究（Mayo-Wilson, Zollman, and Danks 2011）；对判断集体化/意见汇总的研究（Genest and Zidek 1986；List and Pettit 2002；Russell, Hawthorne, and Buchak 2015）；对从他人信念中学习的研究（Easwaran et al 2016；Bradley 2018）；以及对竞争性更新规则的社会效益的研究，例如条件化与最佳解释推理（Douven and Wenmackers 2017；Pettigrew m.s., 其他互联网资源）。

## 6. 形式认识论之外的应用

工具如概率论和认识逻辑在形式认识论之外的许多哲学领域中有许多用途。在这里，我们将简要地看一下一些例子：如何做决策，上帝是否存在，以及像“如果...那么...”这样的假设性讨论意味着什么。

### 决策理论

如果您继续阅读这一部分，还是停下来去做其他事情呢？这完全取决于：如果您继续阅读，可能会获得什么，以及这些收获是否会超过做其他事情的收获？决策理论权衡这些考虑因素，以确定哪种选择最佳。

看看称重是如何工作的，让我们从一个非常简单的例子开始：押注掷骰子的结果。特别是，假设掷出 5 或 6 会让你赢得 10。你应该接受这个赌注吗？我们可以用表格的形式表示你面临的选择：

|            | Roll 1–4 | Roll 5 or 6 |
| ------------ | ----------- | ------------- |
| 形式认识论 | −10      | +19         |
| 不要打赌   | 0         | 0           |

到目前为止，打赌看起来相当不错：你可以赢得的几乎是你可能失去的两倍。然而，表格没有显示的是，你输掉的可能性是赢的两倍：2/3 对 1/3。因此，让我们添加这些信息进去：

|            | Roll 1–4  | Roll 5 or 6 |
| ------------ | ------------ | ------------- |
| 形式认识论 | −10�=2/3 | +19p=1/3    |
| 不要打赌   | −0�=2/3  | +0p=1/3     |

现在我们可以看到赌博的潜在风险，即损失 10 美元，并不被潜在收益所抵消。你可能赢得的并不是你可能失去的两倍，但失去的概率却是两倍。从形式上讲，我们可以将这种思维方式表达如下：

(−10×2/3)+(19×1/3)=−1/3<0

换句话说，当潜在的损失和收益与它们各自的概率相比较时，它们的总和未能超过 0。但是如果你不下注，你可以期待的是 0。因此，在这个例子中，下注并不完全等同于弃权。

这是决策理论核心的基本思想，但它仍然离令人满意的地方很远。首先，这种计算假设金钱是一切，但实际上并非如此。假设你口袋里正好有 10 美元，这本身是没有用的（即使赌场酒吧里最便宜的饮料也要 10 美元，这并不比留着它更糟糕——无论如何你都可能一文不名。但是获得 19 美元，对你来说是很值钱的。如果你能搭上回家的公交车，你就不必露宿一晚了。

因此，我们必须考虑各种金额对您的价值有多大。失去  0，尽管获得  10)≈u(−  19)≫u(−$0)。

究竟获得  19)=…，到底有多少？如果我们首先设定一个尺度，实际上可以回答这个问题。例如，假设我们想确切知道您如何评价获得  100 的价值。然后我们设定 u(+  100)=1，这样我们的尺度范围从 0 到 1。然后我们可以计算 u(+  100，而不仅仅是  19，没有任何附加条件，与被提供一个（免费）赌局，支付  100 相比，您必须冒险的机会是多少，而不是保证的  100，而不是保证的  100 必须至少为.99，您才会交易保证的  100。那么，从获得  100 的尺度上看，您非常重视获得 19 美元：1 中的.99。（这种测量效用的方法是由冯·诺伊曼和莫根斯特恩（1944）发现和推广的，尽管基本上相同的想法之前由拉姆齐（1964 [1926]）发现。）

我们的完整决策理论依赖于两个函数，即 p 和 u。概率函数 p 反映了您认为行动的各种可能结果获得的可能性有多大，而 u 代表了每个结果有多么可取。面对两种可能行动 A 和¬A 的选择，以及世界可能处于的两种可能状态 S 和¬S，存在四种可能结果 O1,…，O4。例如，如果您押注  1；如果相反地出现了反面，结果 O2 发生，您将损失 1 美元。这类情况的一般形式如下：

|     | S          | ¬S         |
| ----- | ------------ | ------------- |
| A   | 形式认识论 | u(O2)p(¬S) |
| ¬A | 形式认识论 | u(O4)p(¬S) |

将概率和效用相互权衡后，我们接着定义了预期效用的概念

定义。行为 A 的预期效用 EU(A)定义为：EU(A)=p(S)u(O1)+p(¬S)u(O2)。同样，行为¬A 的预期效用 EU(¬A)为：EU(¬A)=p(S)u(O3)+p(¬S)u(O4)。

如果您一遍又一遍地面对相同的决策问题，每次选择选项 A，长期来看，您可以期望您的平均效用大约是 EU(A)。这个想法同样适用于有多种可能结果的情况，只需在表格中添加列并一路相乘/相加。当存在两个以上的可能行动时，我们只需添加更多行并执行相同操作。

最后，我们的决策理论达到以下规范：

**预期效用最大化**
选择具有最高预期效用的选项。(如果出现并列情况，则任何选项均可接受。)

我们对这个规则并没有提出太多的论证，除了它“权衡”了每种可能结果的可取性与其实现的概率。然而，有各种各样的方式可以发展这种权衡的想法。这里详细阐述的一种方式是由 Savage (1954) 提出的。在经济学和心理学等社会科学中，这被认为是经典/正统的方法。然而，哲学家倾向于偏好对 Savage 基本方法的变体：要么是 Jeffrey (1965) 发展的“证据”决策理论，要么是某种形式的“因果”决策理论（见条目）（Gibbard 和 Harper 1978；Skyrms 1980；Lewis 1981；Joyce 1999）。

这些方法都同意一个广泛的观念，即正确的决策规则以线性方式权衡概率和效用：先相乘再相加（参见有关期望效用的条目）。然而，布查克（Buchak）（2013 年，2014 年）最近开创的一种不同方法认为，对风险的（不）容忍将对这个方程式产生非线性影响（另见斯蒂尔（Steele）2007 年）。而考虑到人们的认知局限长期以来一直被认为需要进一步偏离传统的线性模型（卡尼曼和特沃斯基（Kahneman and Tversky）1979 年；佩恩（Payne）、贝特曼（Bettman）和约翰逊（Johnson）1993 年；吉格伦泽（Gigerenzer）、托德（Todd）和团队（Group）1999 年；韦里奇（Weirich）2004 年）。

### 6.2 上帝的存在：微调

17 世纪中叶，布莱兹·帕斯卡和皮埃尔·德·费马特之间的通信中同时出现了概率和决策的数学理论。帕斯卡继续将它们应用于神学问题，并发展了他著名的“赌注”论证（见帕斯卡赌注词条）以支持对上帝的信仰。概率论现在常常出现在讨论有关神的论证的其他论点中，尤其是设计论证。尽管达尔文通常被认为推翻了有关生物设计的神学上诉，但宇宙学和物理学中的新发现似乎支持了一个新的上帝存在的概率论证。

宇宙从大爆炸到现在的发展取决于两个因素：物理定律和大爆炸时的初始条件。这两个因素似乎都被精心安排，以使宇宙能够支持生命。如果物理定律中的某些常数略有不同，智慧生命将永远无法进化。例如，如果束缚原子核的力量稍强或稍弱，只会存在氢。将没有碳、氧或其他元素可用来形成复杂的分子或生物体。同样，如果大爆炸的扩张速度稍有不同，宇宙要么会在大爆炸后不久简单地坍缩回去，要么会分散成漫尘。星球将永远不会形成（Rees 1999）。

这些发现指向一种新型的设计论证，一种不受进化理论影响的论证。进化可能解释有机世界中我们发现的设计，但是是什么解释了我们的宇宙似乎“精确调整”以允许（智能）生命的存在呢？显然，宇宙实际上是经过精确调整的，由一个刻意设计它以包含（智能）生命的创造者。如果没有这样的设计者，宇宙的精确调整将是一个极不可能的巧合。

为了使这个论点严谨，通常会用概率术语来表述。根据 Sober（2005）的观点，我们将采用一个简单而谦逊的表述。让 F 表示我们的宇宙是如上所述的精心调整的证据，让 D 表示“设计假设”，即宇宙是由一个有意创造（智能）生命的智能设计者创造的假设。然后，论证如下：

1. p(F∣D)>p(F∣¬D)
2. 通常情况下，当 p(E∣H)>p(E∣¬H)时，E 支持 H 而非¬H。
3. So F 支持 D 而不是¬D。

论证显然有效，因此讨论集中在前提上。

(1) 的理由是，p(F∣¬D) 很小，因为物理定律和初始常数的可能性非常多，几乎所有的可能性都会导致一个对生命不友好的宇宙。没有设计者来确保恰当的常数和条件，一个对生命友好的结果将会是极其不可能的。但是另一方面，p(F∣D) 相当高：毕竟，构想中的设计者在创造宇宙时的目的是创造生命。

根据我们对确认理论（§1.2）的讨论，可以看到（2）的理由。根据我们对确认的定义，证据确认一个假设，只要 p(H∣E)>p(H)，这等同于贝叶斯定理告诉我们 p(E∣H)>p(E)。同样，E 反驳¬H，只要 p(E)>p(E∣¬H)。现在，我们可以证明如果 p(E∣H)>p(E)，那么 p(E)>p(E∣¬H)。因此，如果 E 确认 H，则 E 反驳¬H，这意味着 E 支持 H 而不是¬H。

然而，需要注意的是，E 支持 H 而不是¬H，并不意味着一旦我们了解了 E，H 就比¬H 更有可能发生。这只是意味着 E 提高了 H 的概率并降低了¬H 的概率。如果 H 一开始就非常不可能发生，那么 E 可能不会足够提高其概率，使其比¬H 更有可能发生。这就是为什么我们对论证的表述如此谨慎。它只旨在表明 F 是支持 D 的证据，反对¬D。它并不声称证据有多强，或者最终是否应该让我们成为有神论者还是无神论者（Sober，2005）。然而，批评者认为，即使这种谨慎的论证也是站不住脚的。我们将考虑四种这样的批评观点。

一种批评观点涉及所谓的“人类学”考虑。这个想法是，一些发现是我们作为观察者的本质的结果，因此反映了关于我们而不是讨论中的现象的某些东西。例如，我可能会注意到，每当我观察一个物体时，观察发生在我清醒时。但我不应该由此得出结论，即只有在我清醒时物体才存在。我的观察的这个特征只是反映了关于我的一些东西：我必须清醒才能进行这些观察。同样，这些批评者认为，我们只能观察到一个具有支持（智能）生命所必需特征的宇宙。因此，我们发现我们的宇宙是精心调整的只反映了我们的局限性，即我们无法观察到相反的情况（McMullin 1993; Sober 2005）。

形式认识论的支持者回应称，我们无法观察到某事并不意味着相反的观察毫无意义。例如，Leslie（1989）指出，被置于专家枪决队面前的人无法观察到自己是否幸存，因为他们已经不在世了，无法做出观察。然而，如果他们确实幸存下来，这就是枪决队有意未命中的强有力证据。专家枪决队很少会因偶然而未命中。Sober（2005）回应称，幸存的枪决队成员确实有证据，但基础不同，这一点并不适用于设计论的支持者。进一步讨论请参阅 Monton（2006）和 Sober（2009）。

一种不同的批评观点认为，p(F∣¬D)毕竟并不低：即使没有设计者，精细调整的发现也是“不可避免的”，因为我们的宇宙只是一个无限序列中的一个，从大爆炸到大坍缩再到大爆炸，每次大爆炸都会出现一组新的常数和初始条件（Wheeler 1973; Leslie 1989）。迟早，这无休止的宇宙重启循环必定会碰巧达到一个支持生命的常数和初始条件配置，因此 p(F∣¬D)甚至可能等于 1，与前提（1）相悖。（我们如何知道这无休止的宇宙循环是一个棘手的问题。关键的证据可能是它解释了为什么我们的宇宙被精心调整。但是，同样的情况也可能适用于设计假设 D。）

黑金（1987）反驳称，这些“振荡宇宙”只能确保在某个序列中的某个时刻有一些宇宙能够支持生命。但这并不意味着这个宇宙更有可能支持生命。在我们的大爆炸时刻，仍然存在着无数种不利于生命的方式来开始，如果没有设计者来确保一个有利于生命的开始，那么所有这些方式同等可能。就像一次又一次地掷一对骰子确保蛇眼（两个骰子都掷出 1）最终会出现一样，无论它们最终掷出什么点数，都极不可能以那种方式结束。如果第 53 次掷出蛇眼，这并不是必然的；事实上，这是相当不太可能的，只有 36 分之 1 的几率。黑金建议，一种不同类型的“多重宇宙”假设可以避免这个问题：卡特（1974）的假设，即所有可能的大爆炸类型的宇宙都是“并排存在”的，而不是在一个振荡序列中。然后，黑金建议，根据演绎推理，我们的宇宙必须存在，所以在所有之后，p（F∣¬D）的结果仍然是 1。但怀特（2000）反驳称，对惠勒模型的诉诸中的谬误也影响了对卡特模型的诉诸。即使有许多宇宙“并排存在”，这个宇宙也不必是少数几个具有有利于生命参数的宇宙之一。

第三条批评线攻击了将低概率分配给 p(F∣¬D) 的基本原理。抱怨是，这个基本原理实际上使 p(F∣¬D)=0，并且还将概率 0 分配给了许多其他直观上更有可能的宇宙可能发展方式。为什么会这样呢？对于低 p(F∣¬D) 的基本原理大致如下：拿我们宇宙中一个明显精细调整的参数来说，比如宇宙的膨胀速度。假设这个速度必须恰好在 9 到 10 千米/秒之间，才能支持生命存在。但考虑到它本可以是从 0 千米/秒到 100 千米/秒再到 1,000,000 千米/秒等任何速度，它最终落入狭窄的 9-10 千米/秒范围，发生的概率极其低，几乎不可能在没有神的指导下发生。但是，反对意见认为，对于像 101-1010 千米/秒这样更大范围也可以这样说。即使是这么大的范围，在所有可能的速度范围中只是一个无限小的部分，从 0 一直到整个正实数线。事实上，任何有限范围在无限中实际上是 0%——事实上，在衡量这些事情的标准方式上，它确实是 0%（Colyvan, Garfield, and Priest 2005）。因此，即使我们的宇宙只需要“粗调整”来支持生命，即使在任何广泛但有限的条件范围内都能支持生命，通过这个基本原理可以证明与（1）类似的前提，并提出一个相应的“粗调整论证”以支持设计（McGrew, McGrew, and Vestrup 2001）。

Collins (2009)指出了这一反对意见的一个令人不安的后果，即如果只有¬D 更适合生命，那么精细调整论将是令人信服的。想象一下，如果物理定律只允许有限范围内的可能扩张速度，比如 0-100 公里/秒，而支持生命所需的速度为 9-10 公里/秒。那么前提(1)将成立，精细调整论将成功：p(F∣¬D)=1/100，而 p(F∣D)可能更高，甚至可能是 1。现在想象一下可能的范围要大得多，比如 0-1010 公里/秒。然后，这个论点变得更加强有力，p(F∣¬D)=1/1010。随着可能扩张速度上限的增加，这个论点变得越来越强大......直到上限变为无穷大，此时根据目前的反对意见，这个论点就失败了。

### 6.3 “如果…那么…”的含义

假设性论述与现实之间存在着令人困惑的联系。假设我断言：“如果国内生产总值继续下降，失业率将上升”，但国内生产总值并没有继续下降，而是保持稳定。我所说的是真是假？这并不明显，因为我的陈述并没有以明显的方式经过世界的检验。如果国内生产总值继续下降，但失业率下降了，那么我的陈述就会经过检验，而且会失败。但是国内生产总值保持稳定，那么我的断言可以经受什么样的检验呢？

在处理命题逻辑时，我们经常使用物质条件符号⊃来翻译普通的“如果...那么...”语句。但是，⊃-语句的概率往往超过了相应的“如果...那么...”语句。例如，如果我每天训练五个小时（T），那么我会赢得奥运会跳水金牌（G）的可能性非常小。奥运跳水运动员在我这个年龄时就已经退役了。然而，p(T⊃G)相当高，原因很简单，因为 T⊃G 等同于¬T∨G，而¬T 是非常可能的。我不会每天训练奥运跳水，更不用说五个小时了。我甚至不会游泳。因此，很难接受⊃作为“如果...那么...”的良好模型，尽管一些哲学家仍然认为它是正确的（Grice 1989; Jackson 1987）。

我们是否可以引入一个与⊃不同语义的新连接词，以获得更好的效果？Lewis（1976）发现的一个引人注目的定理表明不行。该定理依赖于 Stalnaker（1970）提出的一个假设：即“如果 A，则 B”的概率与条件概率 p(B∣A)相同。让我们用 A→B 作为“如果 A，则 B”的简写。

**斯坦内克的假设**
p(A→B)=p(B∣A), 对于任意命题 A 和 B 以及概率函数 p，使得 p(A)≠0。

Stalnaker 的假设乍看之下似乎是显而易见的，甚至是重言式的。p(B∣A)不就是命题 B∣A 的概率吗，这只是“如果 A 成立，则 B 成立”的简写？这是概率论新手常见的误解，Lewis 指出这会导致灾难性的结果。如果我们将 B∣A 看作是由句子 A 和 B 以及连接词∣构建而成的复合命题，概率论就会一团糟（有关证明，请参阅技术补充部分）：

定理（Lewis' Triviality Theorem）。如果 Stalnaker 的假设成立，则对于所有命题 A 和 B，使得 p(A)≠0 且 1>p(B)>0，有 p(B∣A)=p(B)。

显然，没有命题连接词能够遵守斯塔尔内克的假设。如果有一个这样做了，那么每个命题都将独立于其他每个命题（除非事情是绝对确定的）。但是肯定有一些事实与其他一些事实相关。

这告诉我们的一件事是，正确阅读 p(B∣A) 的方式不是将其视为某个句子的概率，而是作为一个双变量函数。 语法 p(B∣A) 是误导性的，更清晰的写法可能是 p(B,A)，这是类似于 f(x,y)=x2+y2 的双变量函数的标准表示法。

但更令人不安的教训是，我们面临一个令人不舒服的选择：要么不存在命题 A→B，要么命题 A→B 的概率并不总是与 p(B∣A)相匹配。第一种选择似乎会使“如果...那么...”形式的断言成为自然语言语义组合性的一个奇特例外（但请参见 Edgington 2000）。第二种选择是违反直觉的，也显然违反了人们通常认为 p(A→B)与 p(B∣A)相同的经验证据（Douven and Dietz 2011）。

这个问题特别引人注目的地方在于它的稳健性。不仅已经有许多相关定理是利用概率论证明的（Hájek 1989; Edgington 1995; Bradley 2000），而且类似的结果也在一个完全独立的形式框架中出现：信念修正理论。

信念修正理论用命题逻辑的句子来表示信念：A，A⊃B，¬(A∧¬B)等等。您的全部信念语料库是我们称之为 K 的这样一组句子（不要与认识逻辑（§4.1）中的命题算子 K 混淆）。重要的是，我们假设 K 包含了由您的信念蕴含的一切内容：例如，如果 A 和 A⊃B 都在 K 中，那么 B 也在其中。

当然，真实的人并不会相信他们的信念所涉及的一切，但假设这一点有助于简化问题。您可以将其视为一种理想化：我们正在理论化，如果您是一位完美的逻辑学家，您的信念应该是什么样子。（请注意，概率论中的公理（2）编码了类似的特征，认识逻辑的 K 公理和 NEC 规则共同产生了类似的效果。）

信念修正理论的主要目的是说明在学习新信息时应如何修正自己的信念。假设您了解到一个新行星 Algernon 的存在。当您了解到这个新事实 A 时，K 应该如何改变？只要 A 不与您现有的信念相矛盾，标准观点是您应该将 A 添加到 K 中，以及从 K 和 A 的成员一起逻辑地得出的一切。我们称这一新信念集为 K+A：将 A 添加到 K 中，以及从逻辑上得出的所有内容（Alchourrón, Gärdenfors, and Makinson 1985）。

如果 A 与您现有的信念相矛盾怎么办？那么 K+A 就行不通，因为这将是不一致的。我们必须删除一些您现有的信念，为 A 腾出空间。幸运的是，对于我们在这里的目的，我们不必担心这是如何运作的。我们只会考虑 A 与 K 一致的情况，在这种情况下，K+A 就行得通。

现在，假设我们想要向我们的语言中添加一个新的连接词→来表示‘如果…那么…’。在什么情况下你应该相信一个形如 A→B 的句子呢？经典的答案来自 Ramsey 的一个想法：我们通过暂时将 A 添加到我们的信念库中，然后看看是否会得出 B 来决定是否接受 A→B（Ramsey 1990 [1929]）。这个想法产生了一个被称为 Ramsey 测试的原则：

**The Ramsey Test is a test for the truth of a sentence. It states that a sentence is true if and only if it is a member of a set of sentences that are all true. The test is named after the philosopher Frank Ramsey**
K 包含 A→B 如果 K+A 包含 B；并且 K 包含 ¬(A→B) 如果 K+A 包含 ¬B。

换句话说，如果将 A 添加到您的信念库中会带来 B，那么您接受 A→B。如果相反，添加 A 会带来¬B，您将拒绝这个条件(Etlin 2009)。

尽管拉姆齐测试是合理的，但戈登福斯（1986）表明，除非您的信念极端偏执，否则它无法成立。我们将比较非正式地陈述这一结果（有关比较非正式证明，请参阅技术补充说明）：

定理（Gärdenfors’ Triviality Theorem）。只要存在两个命题 A 和 B，使得 K 对 A 持不可知态度，A⊃B，以及 A⊃¬B，那么 Ramsey 测试无法成立。

显然，就像没有命题连接词能够在概率论中遵守斯塔尔内克的假设一样，在信念修正理论中也没有一个能够遵守拉姆齐测试。无论我们是用概率还是直接信念来探讨认识论，同样的问题都会出现。我们应该得出结论说条件句没有事实内容吗？这是一个备受争议的问题，关于条件句的条目更多。

## Bibliography

* Akiba, Ken, 2000, “Shogenji’s Probabilistic Measure of Coherence Is Incoherent”, *Analysis*, 60(4): 356–59.
* Alchourrón, Carlos E., Peter Gärdenfors, and David Makinson, 1985, “On the Logic of Theory Change: Partial Meet Contraction and Revision Functions”, *The Journal of Symbolic Logic*, 50(2): 510–30.
* Bertrand, Joseph L.F., 2007 [1888], *Calcul Des Probabilités*, Oxford University Press.
* Bonjour, Laurence, 1985, *The Structure of Empirical Knowledge*, Harvard University Press.
* Bovens, Luc and Stephan Hartmann, 2003, *Bayesian Epistemology*, Oxford University Press.
* Bradley, Richard, 2000, “A Preservation Condition for Conditionals”, *Analysis*, 60(3): 219–22.
* –––, 2018, “Learning From Others: Conditioning Versus Averaging”, *Theory and Decision*, 85(1): 5–20.
* Buchak, Lara, 2013, *Risk and Rationality*, Oxford University Press.
* –––, 2014, “Risk and Tradeoffs”, *Erkenntnis*, 79(6): 1091–1117.
* Carnap, Rudolph, 1950, *Logical Foundations of Probability*, Chicago: University of Chicago Press.
* Carr, Jennifer, 2013, “Justifying Bayesianism”, PhD thesis, Massachusetts Institute of Technology.
* –––, 2017, “Epistemic Utility Theory and the Aim of Belief”, *Philosophy and Phenomenological Research*, 95(3): 511–34.
* Carter, Brandon, 1974, “Large Number Coincidences and the Anthropic Principle in Cosmology”, in *Confrontation of Cosmological Theories with Observational Data*, edited by Malcolm S. Longair, 291–98, Boston: D. Reidel.
* Castell, Paul, 1998, “A Consistent Restriction of the Principle of Indifference”, *British Journal for the Philosophy of Science*, 49(3): 387–95.
* Christensen, David, 1992, “Confirmational Holism and Bayesian Epistemology”, *Philosophy of Science*, 59(4): 540–557.
* –––, 1996, “Dutch Book Arguments Depragmatized: Epistemic Consistency for Partial Believers”, *The Journal of Philosophy*, 93(9): 450–79.
* –––, 2001, “Preference-Based Arguments for Probabilism”, *Philosophy of Science*, 68(3):356–376.
* –––, 2004, *Putting Logic in Its Place*, Oxford University Press.
* Cohen, Stewart, 2002, “Basic Knowledge and the Problem of Easy Knowledge”, *Philosophy and Phenomenological Research*, 65(2): 309–29.
* Collins, Robin, 2009, “The Teleological Argument: An Exploration of the Fine-Tuning of the Universe”, in *The Blackwell Companion to Natural Theology*, edited by William Lane Craig and J.P. Moreland, 202–81. Wiley-Blackwell.
* Colyvan, Mark, Jay L. Garfield, and Graham Priest, 2005, “Problems with the Argument from Fine Tuning”, *Synthese*, 145(3): 325–38.
* Cresto, Eleonora, 2012, “A Defense of Temperate Epistemic Transparency”, *Journal of Philosophical Logic*, 41(6): 923–55.
* Crupi, Vincenzo, and Katya Tentori, 2010, “Irrelevant Conjunction: Statement and Solution of a New Paradox”, *Philosophy of Science*, 77(1): 1–13.
* Douven, Igor, and Richard Dietz, 2011, “A Puzzle About Stalnaker’s Hypothesis”, *Topoi*, 30(1): 31–37.
* Douven, Igor, and Wouter Meijs, 2006, “Bootstrap Confirmation Made Quantitative”, *Synthese*, 149(1): 97–132.
* –––, 2007, “Measuring Coherence”, *Synthese*, 156(3): 405–25.
* Douven, Igor and Sylvia Wenmackers, 2017, “Inference to the Best Explanation versus Bayes’s Rule in a Social Setting”, *British Journal for the Philosophy of science*, 68(2): 535–570.
* Easwaran, Kenny, Luke Fenton-Glynn, Christopher Hitchcock, and Joel D. Velasco, 2016, “Updating on the Credences of Others: Disagreement, Agreement, and Synergy”, *Philosophers’ Imprint*, 16(11): 1–39.
* Edgington, Dorothy, 1995, “On Conditionals”, *Mind*, 104: 235–329.
* –––, 2000, “General Conditional Statements: A Reply to Kölbel”, *Mind*, 109: 109–16.
* Etlin, David, 2009, “The Problem of Noncounterfactual Conditionals”, *Philosophy of Science*, 76(5): 676–88.
* Field, Hartry, 1978, “A Note on Jeffrey Conditionalization”, *Philosophy of Science*, 45(3): 361–367.
* Fisher, Ronald A., 1925, *Statistical Methods for Research Workers*, Edinburgh: Oliver; Boyd.
* Fitch, Frederic B., 1963, “A Logical Analysis of Some Value Concepts”, *The Journal of Symbolic Logic*, 28(2): 135–42.
* Fitelson, Branden, 2003, “A Probabilistic Theory of Coherence”, *Analysis*, 63(3): 194–99.
* –––, 2006, “The Paradox of Confirmation”, *Philosophy Compass*, 1(1): 95.
* Fitelson, Branden, and James Hawthorne, 2010, “How Bayesian Confirmation Theory Handles the Paradox of the Ravens”, in *The Place of Probability in Science*, 284:247–75, New York: Springer.
* Gärdenfors, Peter, 1986, “Belief Revisions and the Ramsey Test for Conditionals”, *The Philosophical Review*, 95(1): 81–93.
* Genest, Christian and James V. Zidek, 1986, “Combining Probability Distributions: A Critique and an Annotated Bibliography”, *Statistical Science*, 1(1): 114–135.
* Gibbard, Allan, and William Harper, 1978, “Counterfactuals and Two Kinds of Expected Utility”, in *Foundations and Applications of Decision Theory*, edited by A. Hooker, J.J. Leach, and E.F. McClennen, Dordrecht: D. Reidel.
* Gigerenzer, Gerd, Peter M. Todd, and The ABC Research Group, 1999, *Simple Heuristics That Make Us Smart*, Oxford University Press.
* Glass, David H., 2002, “Coherence, Explanation, and Bayesian Networks”, *Artificial Intelligence and Cognitive Science*, 2464: 177–82.
* Glymour, Clark, 1980, *Theory and Evidence*, Princeton University Press.
* Good, I.J., 1967, “The White Shoe Is a Red Herring”, *British Journal for the Philosophy of Science*, 17(4): 322.
* Goodman, Nelson, 1954, *Fact, Fiction, and Forecast*, Cambridge, MA: Harvard University Press.
* Greaves, Hilary, and David Wallace, 2006, “Justifying Conditionalization: Conditionalization Maximizes Expected Epistemic Utility”, *Mind*, 115: 607–32.
* Greco, Daniel, 2014, “Could KK Be OK?” *The Journal of Philosophy*, 111(4): 169–197.
* Grice, Paul, 1989, *Studies in the Ways of Words*, Cambridge, MA: Harvard University Press.
* Haack, Susan, 1976, “The Justification of Deduction”, *Mind*, 85(337): 112–19.
* –––, 1993, *Evidence and Inquiry: Towards Reconstruction in Epistemology*, Oxford: Blackwell Publishers.
* Hacking, Ian, 1987, “The Inverse Gambler’s Fallacy: The Argument from Design. the Anthropic Principle Applied to Wheeler Universes”, *Mind*, 96(383): 331–40.
* Harman, Gilbert, 1986, *Change in View: Principles of Reasoning*, Cambridge, MA: MIT Press.
* Hawthorne, John, 2005, “Knowledge and Evidence”, *Philosophy and Phenomenological Research*, 70(2): 452–58.
* Hájek, Alan, 1989, “Probabilities of Conditionals: Revisited”, *Journal of Philosophical Logic*, 18(4): 423–28.
* Hempel, Carl G., 1937, “Le Problème de La Vérité”, *Theoria*, 3(2): 206–44.
* –––, 1945, “Studies in the Logic of Confirmation I”, *Mind*, 54: 1–26.
* Hintikka, Jaakko, 1962, *Knowledge and Belief: An Introduction to the Logic of the Two Notions*, Ithaca, NY: Cornell University Press.
* Horty, John F., 2012, *Reasons as Defaults*, Oxford University Press.
* Hosiasson-Lindenbaum, Janina, 1940, “On Confirmation”, *The Journal of Symbolic Logic*, 5(4): 133–48.
* Howson, Colin, and Peter Urbach, 1993, *Scientific Reasoning: The Bayesian Approach*, Chicago: Open Court.
* Huemer, Michael, 1997, “Probability and Coherence Justification”, *The Southern Journal of Philosophy*, 35(4): 463–72.
* –––, 2011, “Does Probability Theory Refute Coherentism?” *The Journal of Philosophy*, 108(1): 35–54.
* Jackson, Frank, 1987, *Conditionals*, Oxford: Clarendon Press.
* Jeffrey, Richard C., 1965, *The Logic of Decision*, Chicago: University of Chicago Press.
* Joyce, James, 1998, “A Nonpragmatic Vindication of Probabilism”, *Philosophy of Science*, 65(4): 575–603.
* –––, 1999, *The Foundations of Causal Decision Theory*, Cambridge University Press.
* –––, 2009, “Accuracy and Coherence: Prospects for an Alethic Epistemology of Partial Belief”, in *Degrees of Belief*, edited by Franz Huber and Christoph Schmidt-Petri, 342:263–97. Synthese Library, Dordrecht: Springer.
* Kahneman, Daniel, and Amos Tversky, 1979, “Prospect Theory: An Analysis of Decision Under Risk”, *Econometrica*, 47(2): 263–292.
* Keynes, John Maynard, 1921, *A Treatise on Probability*, New York: MacMillan.
* Klein, Peter, and Ted A. Warfield, 1994, “What Price Coherence?” *Analysis*, 54(3): 129–32.
* Leitgeb, Hannes, and Richard Pettigrew, 2010a, “An Objective Justification of Bayesianism I: Measuring Inaccuracy”, *Philosophy of Science*, 77(2): 201–35.
* –––, 2010b, “An Objective Justification of Bayesianism II: The Consequences of Minimizing Inaccuracy”, *Philosophy of Science*, 77(2): 236–272.
* Leslie, John, 1989, *Universes*, London: Routledge.
* Lewis, David, 1976, “Probabilities of Conditionals and Conditional Probabilities”, *The Philosophical Review*, LXXXV(3): 297–315.
* –––, 1981, “Causal Decision Theory”, *Australasian Journal of Philosophy*, 59(1): 5–30.
* –––, 1999, “Why Conditionalize?” in *Papers in Metaphysics and Epistemology*, 403–7, Cambridge University Press.
* List, Christian and Philip Pettit, 2002, “Aggregating Sets of Judgments: An Impossibility Result”, *Economics and Philosophy*, 18(1): 89–110.
* Maher, Patrick, 1996, “Subjective and Objective Confirmation”, *Philosophy of Science*, 63(2): 149–174.
* Mahtani, Anna, 2008, “Williamson on Inexact Knowledge”, *Philosophical Studies*, 139(2): 171–80.
* Mayo, Deborah G., 1996, *Error and the Growth of Experimental Knowledge*, Chicago: University of Chicago Press.
* Mayo, Deborah G., and Aris Spanos, 2011, “Error Statistics”, in *Philosophy of Statistics*, edited by Prasanta S. Bandyopadhyay and Malcolm R. Forster, Vol. 7. Handbook of Philosophy of Science, Elsevier.
* Mayo-Wilson, Conor, Kevin J.S. Zollman, and David Danks, 2011, “The Independence Thesis: When Individual and Social Epistemology Diverge”, *Philosophy of Science*, 78(4): 653–77.
* McGrew, Timothy, Lydia McGrew, and Eric Vestrup, 2001, “Probabilities and the Fine-Tuning Argument: A Skeptical View”, *Mind*, 110(440): 1027–37.
* McMullin, Ernan, 1993, “Indifference Principle and Anthropic Principle in Cosmology”, *Studies in the History and Philosophy of Science*, 24: 359–89.
* Merricks, Trenton, 1995, “On Behalf of the Coherentist”, *Analysis*, 55(4): 306–9.
* Monton, Bradley, 2006, “God, Fine-Tuning, and the Problem of Old Evidence”, *British Journal for the Philosophy of Science*, 57(2): 405–24.
* Neyman, Jerzy, and Karl Pearson, 1928a, “On the Use and Interpretation of Certain Test Criteria for Purposes of Statistical Inference, Part I”, *Biometrika*, 20A(1/2): 175–240.
* –––, 1928b, “On the Use and Interpretation of Certain Test Criteria for Purposes of Statistical Inference, Part I”, *Biometrika*, 20A(3/4): 263–94.
* Nicod, Jean, 1930, *Foundations of Geometry and Induction*, New York: Harcourt, Brace, & Co.
* Nozick, Robert, 1981, *Philosophical Explanations*, Cambridge, MA: Harvard University Press.
* O’Connor, Cailin, and James Owen Weatherall, 2018, “Scientific Polarization”, *European Journal for Philosophy of Science*, 8(3): 855–875.
* Olsson, Erik J., 2002, “What Is the Problem of Coherence and Truth?” *The Journal of Philosophy*, 99(5): 246–72.
* –––, 2005, *Against Coherence: Truth, Probability, and Justification*, Oxford University Press.
* Payne, John W., James R. Bettman, and Eric J. Johnson, 1993, *The Adaptive Decision Maker*, Cambridge University Press.
* Pettigrew, Richard, 2016, “Accuracy, Risk, and the Principle of Indifference”, *Philosophy and Phenomenological Research*, 92(1): 35–59.
* Pollock, John L., 1995, *Cognitive Carpentry*, *Philosophy of Science*, Cambridge: MIT Press.
* –––, 2008, “Defeasible Reasoning”, in *Reasoning: Studies of Human Inference and Its Foundations*, edited by Jonathan E. Adler and Lance J. Rips, Cambridge University Press.
* Pryor, James, 2013, “Problems for Credulism”, in *Seemings and Justification: New Essays on Dogmatism and Phenomenal Conservatism*, edited by Chris Tucker, Oxford University Press.
* Ramachandran, Murali, 2009, “Anti-Luminosity: Four Unsuccessful Strategies”, *Australasian Journal of Philosophy*, 87(4): 659–673.
* Ramsey, Frank Plumpton, 1964 [1926], “Truth and Probability”, in *Studies in Subjective Probability*, edited by Henry E. Kyburg and Howard E. Smokler, 61–92, New York: Wiley.
* –––, 1990 [1929], “General Propositions and Causality”, in *Philosophical Papers*, 145–63, Cambridge: Cambridge University Press.
* Rees, Martin, 1999, *Just Six Numbers*, Basic Books.
* Rinard, Susanna, 2014, “A New Bayesian Solution to the Paradox of the Ravens”, *Philosophy of Science*, 81(1): 81–100.
* Rosenstock, Sarita, Justin Bruner, and Cailin O’Connor, 2017, “In Epistemic Networks, Is Less Really More?”, *Philosophy of Science*, 84(2): 234–252.
* Roush, Sherrilyn, 2005, *Tracking Truth: Knowledge, Evidence, and Science*, Oxford University Press.
* –––, 2009, “Prècis of *Tracking Truth*”, *Philosophy and Phenomenological Research*, 79(1): 213–22.
* Royall, Richard, 1997, *Statistical Evidence: A Likelihood Paradigm*, London: Chapman & Hall.
* Russell, Gillian, and Greg Restall, 2010, “Barriers to Implication”, in *Hume on Is and Ought*, edited by Charles Pigden, Palgrave MacMillan.
* Russell, Jeffrey Sanford, John Hawthorne, and Lara Buchak, 2015, “Groupthink”, *Philosophical studies*, 172(5): 1287–1309.
* Salerno, Joe, 2009, “Knowability Noir”, in *New Essays on the Knowability Paradox*, edited by Joe Salerno, Oxford: Oxford University Press.
* Savage, Leonard J., 1954, *The Foundations of Statistics*, New York: Wiley Publications in Statistics.
* Sellars, Wilfrid, 1956, “Empiricism and the Philosophy of Mind”, in *Minnesota Studies in the Philosophy of Science, Volume I: The Foundations of Science and the Concepts of Psychology and Psychoanalysis*, edited by Herbert Feigl and Michael Scriven, University of Minnesota Press.
* Shafer, Glenn, 1976, *A Mathematical Theory of Evidence*, Princeton University Press.
* Shogenji, Tomoji, 1999, “Is Coherence Truth Conducive?” *Analysis*, 59(4): 338–45.
* Skyrms, Brian, 1980, “The Role of Causal Factors in Rational Decision”, in *Causal Necessity*, Brian Skyrms, pp. 128–139, New Haven: Yale University Press.
* Sober, Elliott, 2005, “The Design Argument”, in *The Blackwell Guide to the Philosophy of Religion*, edited by William E. Mann, 117–47, Blackwell Publishing.
* –––, 2009, “Absence of Evidence and Evidence of Absence”, *Philosophical Studies*, 143(1): 63–90.
* Spohn, Wolfgang, 1988, “Ordinal Conditional Functions: A Dynamic Theory of Epistemic States”, in *Causation in Decision, Belief Change, and Statistics II*, edited by William Leonard Harper and Brian Skyrms, Kluwer.
* –––, 2012, *The Laws of Belief: Ranking Theory and Its Philosophical Applications*, Oxford University Press.
* Stalnaker, Robert, 1970, “Probability and Conditionals”, *Philosophy of Science*, 37(1): 64–80.
* Steele, Katie, 2007, “Distinguishing Indeterminate Belief from ‘Risk-Averse’ Preferences”, *Synthese*, 158(2): 189–205.
* Stroud, Barry, 1984, *The Philosophical Significance of Skepticism*, Oxford University Press.
* Teller, Paul, 1973, “Conditionalisation and Observation”, *Synthese*, 26: 218–58.
* Turri, John, and Peter D. Klein (eds), 2014, *Ad Infinitum: New Essays on Epistemological Infinitism*, Oxford: Oxford University Press.
* van Fraassen, Bas, 1989, *Laws and Symmetry*, Oxford University Press.
* Vineberg, Susan, 1997, “Dutch Books, Dutch Strategies, and What They Show About Rationality”, *Philosophical Studies*, 86(2): 185–201.
* –––, 2001, “The Notion of Consistency for Partial Belief”, *Philosophical Studies*, 102(3): 281–96.
* von Neumann, John, and Oskar Morgenstern, 1944, *Theory of Games and Economic Behavior*, Princeton University Press.
* Vranas, Peter B.M., 2004, “Hempel’s Raven Paradox: A Lacuna in the Standard Bayesian Account”, *British Journal for the Philosophy of Science*, 55: 545–60.
* Weatherall, James Owen, and Cailin O’Connor, forthcoming, “Endogenous Epistemic Factionalization”, *Synthese*, first online 04 June 2020. doi:10.1007/s11229-020-02675-3
* Weintraub, Ruth, 1995, “What Was Hume’s Contribution to the Problem of Induction”, *The Philosophical Quarterly*, 45(181): 460–70.
* Weirich, Paul, 2004, *Realistic Decision Theory: Rules for Nonideal Agents in Nonideal Circumstances*, New York: Oxford University Press.
* Wheeler, John Archibald, 1973, “From Relativity to Mutability”, in *The Physicist’s Conception of Nature*, edited by Jagdesh Mehra. Springer.
* White, Roger, 2000, “Fine-Tuning and Multiple Universes”, *Noûs*, 34(2): 260–76.
* –––, 2006, “Problems for Dogmatism”, *Philosophical Studies*, 131(3): 525–57.
* –––, 2009, “Evidential Symmetry and Mushy Credence”, in *Oxford Studies in Epistemology*, Oxford University Press.
* Williams, P.M., 1980, “Bayesian Conditionalisation and the Principle of Minimum Information”, *British Journal for the Philosophy of Science*, 32(2): 131–44.
* Williamson, Jon, 2007, “Inductive Influence”, *British Journal for the Philosophy of Science*, 58(4): 689–708.
* Williamson, Timothy, 2000, *Knowledge and Its Limits*, Oxford University Press.
* Zollman, Kevin J. S., 2007, “The Communication Structure of Epistemic Communities”, *Philosophy of Science*, 74(5): 574–587.
* –––, 2013, “Network Epistemology: Communication in Epistemic Communities”, *Philosophy Compass*, 8(1): 15–27.

## Academic Tools

> | ![sep man icon](../.gitbook/assets/sepman-icon.png) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=formal-epistemology). |
> | --- | --- |
> | ![sep man icon](../.gitbook/assets/sepman-icon.png) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/formal-epistemology/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
> | ![inpho icon](../.gitbook/assets/inpho.png) | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=formal-epistemology&redirect=True) at the Internet Philosophy Ontology Project (InPhO). |
> | ![phil papers icon](../.gitbook/assets/pp.png) | [Enhanced bibliography for this entry](https://philpapers.org/sep/formal-epistemology/) at [PhilPapers](https://philpapers.org/), with links to its database. |

## Other Internet Resources

* Dorst, Kevin, “[Why Polarization Can Be Rational](https://www.psychologytoday.com/ca/blog/reasonably-polarized/202009/why-polarization-can-be-rational)”, posted at *Psychology Today*, 28 September 2020.
* Hájek, Alan, m.s., “[Staying Regular?](http://philosophy.anu.edu.au/sites/default/files/Staying%20Regular.December%2028.2012.pdf)”
* Pettigrew, Richard, m.s., “[On the Pragmatic and Epistemic Virtues of Inference to the Best Explanation](https://drive.google.com/file/d/1l2gBJ8zjpttXrl0gdMjan7HFKGr7llRb/view)”.
* [The Formal Epistemology Workshop](http://fitelson.org/few/): complete schedules of talks for every year since the first workshop in 2004, including the papers and/or slides.
* [Recent Topics in Formal Epistemology](http://fitelson.org/topics/syllabus.html): syllabus and readings from Branden Fitelson’s 2011 course at Rutgers University.
* [Lecture notes on Probability and Induction](http://fitelson.org/probability/notes.html): from Branden Fitelson’s 2008 course at UC Berkeley.
* [Decisions, Games, and Rational Choice](http://ocw.mit.edu/courses/linguistics-and-philosophy/24-222-decisions-games-and-rational-choice-spring-2008/index.htm): complete materials from Robert Stalnaker’s 2008 course at MIT.
* [“Confirmation & Induction”](http://www.iep.utm.edu/conf-ind/): entry in the *Internet Encyclopedia of Philosophy*, by Franz Huber.
* [“Varieties of Bayesianism”](http://jonathanweisberg.org/publication/2011%20Varieties%20of%20Bayesianism/): a survey of the Bayesian approach to formal epistemology by Jonathan Weisberg.

## Related Entries

[Bayes’ Theorem](https://plato.stanford.edu/entries/bayes-theorem/) | [belief, formal representations of](https://plato.stanford.edu/entries/formal-belief/) | [conditionals](https://plato.stanford.edu/entries/conditionals/) | [confirmation](https://plato.stanford.edu/entries/confirmation/) | [decision theory: causal](https://plato.stanford.edu/entries/decision-causal/) | [Dutch book arguments](https://plato.stanford.edu/entries/dutch-book/) | [epistemic paradoxes](https://plato.stanford.edu/entries/epistemic-paradoxes/) | [epistemic utility arguments for epistemic norms](https://plato.stanford.edu/entries/epistemic-utility/) | [epistemology](https://plato.stanford.edu/entries/epistemology/) | [epistemology: Bayesian](https://plato.stanford.edu/entries/epistemology-bayesian/) | [Fitch’s paradox of knowability](https://plato.stanford.edu/entries/fitch-paradox/) | [game theory](https://plato.stanford.edu/entries/game-theory/) | [induction: problem of](https://plato.stanford.edu/entries/induction-problem/) | [justification, epistemic: coherentist theories of](https://plato.stanford.edu/entries/justep-coherence/) | [justification, epistemic: foundationalist theories of](https://plato.stanford.edu/entries/justep-foundational/) | [learning theory, formal](https://plato.stanford.edu/entries/learning-formal/) | [logic: and probability](https://plato.stanford.edu/entries/logic-probability/) | [logic: conditionals](https://plato.stanford.edu/entries/logic-conditionals/) | [logic: epistemic](https://plato.stanford.edu/entries/logic-epistemic/) | [logic: inductive](https://plato.stanford.edu/entries/logic-inductive/) | [logic: modal](https://plato.stanford.edu/entries/logic-modal/) | [logic: non-monotonic](https://plato.stanford.edu/entries/logic-nonmonotonic/) | [Pascal’s wager](https://plato.stanford.edu/entries/pascal-wager/) | [preferences](https://plato.stanford.edu/entries/preferences/) | [probabilities, imprecise](https://plato.stanford.edu/entries/imprecise-probabilities/) | [probability, interpretations of](https://plato.stanford.edu/entries/probability-interpret/) | [rational choice, normative: expected utility](https://plato.stanford.edu/entries/rationality-normative-utility/) | [reasoning: defeasible](https://plato.stanford.edu/entries/reasoning-defeasible/) | [risk](https://plato.stanford.edu/entries/risk/) | [social choice theory](https://plato.stanford.edu/entries/social-choice/) | [statistics, philosophy of](https://plato.stanford.edu/entries/statistics/)

### Acknowledgments

Thanks to Elena Derksen, Frank Hong, Emma McClure, Julia Smith, and Micah Smith for feedback and corrections on a previous draft of this entry. Thanks to Kevin Zollman, Sarita Rosenstock, and Cailin O’Connor for feedback on a draft of Section 5.

[Copyright © 2021](https://plato.stanford.edu/info.html#c) by  
[Jonathan Weisberg](http://www.philosophy.utoronto.ca/directory/jonathan-weisberg/) <[*jonathan.weisberg@utoronto.ca*](mailto:jonathan%2eweisberg%40utoronto%2eca)>
