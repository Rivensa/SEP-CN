# 统计学哲学 statistics, philosophy of (Jan-Willem Romeijn)

*首次发表于 2014 年 8 月 19 日*

统计学研究并发展了在经验事实的光线下评估假设的具体方法。如果一种方法与特定类型的事实和假设相关，那么它被称为统计方法，也是统计学的研究对象：经验事实必须被编码和结构化为数据集，假设必须以可能的数据集上的概率分布形式进行表述。统计学哲学涉及统计方法的基础和适当解释，以及它们的输入和结果。由于统计学几乎在所有经验科学研究中都被依赖，用于支持和传达科学发现，统计学哲学对科学哲学至关重要。它对科学方法的哲学评估以及科学理论的认识论和本体论地位的辩论产生影响。

统计学哲学涵盖了各种各样的主题和辩论。其中核心问题是归纳问题，即关于从数据推断和预测到一般事实的推理或程序的合理性。进一步的辩论涉及统计学中使用的概率的解释，以及可能为统计方法的正确性提供基础和合理性的更广泛的理论框架。第 1 节和第 2 节对这些主题进行了总体介绍。第 3 节和第 4 节介绍了这些主题在经典统计学和贝叶斯统计学这两个主要统计方法理论中的应用。第 5 节关注统计模型的概念，包括模型选择和简洁性，同时讨论不依赖统计模型的统计技术。第 6 节简要介绍了统计学哲学与科学哲学中的其他主题之间的关系，包括确认理论、证据、因果关系、测量和科学方法论等。

---

## 1. 统计学与归纳

统计学是一门关注数据与假设之间关系的数学和概念学科。数据是科学研究中观察或事件的记录，例如，对人群中个体的一组测量。实际获得的数据有时被称为样本、样本数据或简单地称为数据，而研究中所有可能的样本都被收集在所谓的样本空间中。假设则是关于科学研究目标系统的一般性陈述，例如，表达关于人群中所有个体的某个一般事实。统计假设是一种可以通过样本空间上的概率分布来表达的一般性陈述，即它为每个可能的样本确定了一个概率。

统计方法提供了在样本的基础上评估统计假设的数学和概念手段。为此，这些方法采用概率论及其推广。评估可以确定一个假设的可信度，我们是否可以依靠该假设做出决策，样本对假设的支持有多强等等。有很多关于统计学的好的入门资料（例如，Barnett 1999，Mood and Graybill 1974，Press 2002）。

为了举例说明，我们可以引用费舍尔（1935）的一个例子。

> 品茶女士。
> 考虑一个女士声称她可以通过口味判断牛奶和茶被倒入杯子的顺序。现在想象一下，我们为她准备了五杯茶，抛硬币来确定每杯茶中牛奶和茶的顺序。我们要求她宣布顺序，结果发现她在所有情况下都是正确的！现在，如果她是盲目猜测顺序的话，由于我们准备茶的方式是随机的，她将有 50%的准确率。这是我们的统计假设，称为零假设。它给出了 1/2 的概率来猜对，因此给出了 1/2 的概率来猜错。样本空间包括女士可能给出的所有答案字符串，即所有正确和错误猜测的系列，但我们的实际数据位于这个空间的一个相当特殊的角落。根据我们的统计假设，记录事件的概率仅为 3%，或者更精确地说是 1/25。基于这个理由，我们可以决定拒绝女士在猜测顺序方面的假设。

根据所谓的零假设检验，如果实际获得的数据包含在样本空间内的一个特定区域中，其总概率不超过某个指定的限制，通常设定为 5%，那么这样的决定是有根据的。现在考虑一下刚刚概述的统计检验所实现的内容。我们从对女士实际品茶能力的假设开始，即她没有任何品茶能力。在这个假设的前提下，我们获得的样本数据结果是令人惊讶的，或者更准确地说是高度不可能的。因此，我们决定拒绝女士没有任何品茶能力的假设。样本向我们指出了关于女士能做什么或不能做什么的一个消极但普遍的结论。

统计分析的基本模式与归纳推理中的熟悉模式相似：我们输入迄今为止获得的数据，统计程序输出超越数据的裁决或评估，即不仅仅由数据本身所蕴含的陈述。如果数据确实被认为是唯一的输入，并且统计程序被理解为一种推理，那么统计学关注的是扩大推理：粗略地说，我们得到的比我们投入的要多。由于统计的扩大推理涉及未来或一般的事态，它们是归纳的。然而，统计与扩大推理和归纳推理的关联受到争议，一方面是因为有些人认为统计是非推理的（参见第 3 节），另一方面是因为有些人认为统计是非扩大的（参见第 4 节）。

尽管存在这样的分歧，将统计视为对归纳问题的回应是有洞察力的（参见 Howson 2000 和归纳问题的条目）。这个问题最早由休谟在他的《人性论》（第一卷，第三部分，第 6 节）中讨论，但在古代怀疑论者如塞克斯图斯·经验主义者（参见古代怀疑论的条目）之前就已经预示出来，即从经验到对未来的期望的推理没有适当的理由。转化到统计的背景下，它表明对于将数据作为输入并返回与未来或一般事态相关的裁决、评估或其他建议的程序，没有适当的理由。可以说，统计学的很大一部分是关于如何应对这一挑战的，通过提供统计提供的程序的基础，或者通过重新解释统计的结果以逃避这一挑战。

统计学哲学的哲学家们最终关注的是归纳的合理性这一微妙甚至飘渺的问题，这是有争议的。事实上，许多哲学家和科学家都接受统计学的可变性，并认为更重要的是正确理解和应用统计方法。正如经常发生的情况一样，基本的哲学问题起到了催化剂的作用：归纳问题引导我们对统计方法的运作、正确性和适用条件进行调查。统计学哲学作为这些调查所属的总体标题，并不关注短暂的问题，而是对科学哲学和科学本身提供了重要而具体的贡献。

## 2. 基础和解释

尽管统计程序和推理的组织方式存在很大的差异，但它们都同意使用现代测度论概率理论（科尔莫哥洛夫）或类似的方法来表达假设并将其与数据相关联。单独看，概率函数只是一种特定类型的数学函数，用于表示集合的度量（参见 Billingsley 1995）。

令 W 是一个具有元素 s 的集合，并考虑一个初始的子集集合 W，例如，单例集合{s}。现在考虑给定集合 R 的补集 R¯的操作：补集 R¯恰好包含那些不包含在 R 中的元素 s。接下来考虑给定集合 R 和 Q 的并集 R∪Q 的操作：元素 s 是 R∪Q 的成员当且仅当它是 R、Q 或两者的成员。由补集和并集操作生成的集合称为代数，表示为 S。在统计学中，我们将 S 解释为样本集合，并将集合 R 与特定事件或观察相关联。当 s∈R 时，特定样本 s 包含了用 R 表示的事件的记录。我们将像 R 这样的集合代数视为对样本进行断言的语言。

概率函数被定义为代数上的可加归一化度量：一个函数

P:S→[0,1]

使得 P(R∪Q)=P(R)+P(Q) ，如果 R∩Q=∅ 且 P(W)=1。条件概率 P(Q∣R) 定义为

 P(Q∣R)=P(Q∩R)P(R)，

当 P(R)>0 时。它确定了集合 Q 在集合 R 中的相对大小。通常将其解读为事件 R 发生时事件 Q 的概率。请记住，集合 R 包含了所有包含与 R 相关事件的记录的样本 s。通过观察 P(Q∣R)，我们可以放大这个集合 R 内的概率函数，即我们考虑与相关事件发生的条件。

现在概率函数是什么意思？概率的数学概念并没有提供答案。函数 P 可以解释为

1. 物理上的，即事件发生的频率或倾向，通常称为机会，或者作为
2. 认识论上的，即对事件发生的信念程度，愿意根据其假设行动的意愿，支持或确认程度，或类似的。

这种区别不应与客观概率和主观概率之间的区别混淆。物理概率和认识论概率都可以具有客观和主观的特征，即可以被视为依赖于或独立于一个知识主体及其概念装置。有关概率解释的更多细节，请参阅 Galavotti（2005），Gillies（2000），Mellor（2005），von Plato（1994），Eagle（2010）的选集，Hajek 和 Hitchcock（即将出版）的手册，或确实有关概率解释的条目。在这个背景下，关键点是所有这些解释都可以与统计程序的基础性计划联系起来。尽管匹配并不完全准确，但上述两种主要类型可以分别与统计学的两个主要理论，即经典统计学和贝叶斯统计学相关联。

### 2.1 物理概率和经典统计学

在科学中，概率表达物理状态的观念最为突出，通常被称为机会或随机过程。它们是事件序列中的相对频率，或者是实现这些事件的系统中的倾向或倾向性。更准确地说，事件类型的属性所附加的概率可以理解为该属性在该类型事件的一系列事件中显现的频率或倾向。例如，硬币正面朝上的概率恰好是一半，当在一系列类似的抛硬币中，硬币正面朝上的次数占一半。或者，如果在抛硬币的设置中，两种可能结果都有相同的倾向，那么概率就是一半。数学家文恩（1888 年）和科学家奎特莱和麦克斯韦尔（参见冯·普拉托 1994 年）是这种概率观的早期倡导者。概率倾向的哲学理论最早由皮尔斯（1910 年）提出，并由波普尔（1959 年）、梅洛尔（1971 年）、比格洛（1977 年）和吉尔（1976 年）等人发展；有关最新概述，请参阅汉德菲尔德（2012 年）。概率作为频率的严格理论最早由冯·米塞斯（1981 年）设计，也得到了赖希巴赫（1938 年）的支持，并在范·兰巴尔根（1987 年）的精彩阐述中得到了充分展示。

物理概率的概念与统计方法的一个主要理论之一相关联，这个理论被称为经典统计学。它大致在 20 世纪上半叶发展起来，主要由数学家和工作科学家如费舍尔（1925 年，1935 年，1956 年）、瓦尔德（1939 年，1950 年）、尼曼和皮尔逊（1928 年，1933 年，1967 年）等人推动，并在过去几十年中得到许多经典统计学家的完善。这个统计学理论的关键特征与将概率视为物理机会自然地相吻合，因此与可观察和可重复事件相关。物理概率不能有意义地归因于统计假设，因为假设没有倾向或频率，它们的发生方式是分类的，要么是绝对真实，要么是绝对错误。将概率归因于假设似乎意味着概率是以认识论的方式来解读的。

经典统计学通常被称为频率主义，这是因为在经典程序中事件频率的核心地位以及由冯·米塞斯发展的频率主义概率解释的突出地位。在这种解释中，机会被视为频率，或者是类似事件或物品的一类中的比例。它们最好被视为类似于质量和能量等其他物理量。值得强调的是，频率在概念上先于机会。在倾向性理论中，个体事件或物品的概率被视为自然的倾向，因此频率或类似事件或物品的比例表现为大数定律的结果。相比之下，在频率主义理论中，比例确立了，确实定义了机会是什么。这导致频率主义概率的一个核心问题，即所谓的参考类问题：不清楚将哪个类与个体事件或物品相关联（参见 Reichenbach 1949，Hajek 2007）。可以认为，类需要尽可能狭窄，但在事件的单例类的极端情况下，机会当然变得微不足道，为零或一。由于经典统计学在其程序中使用与单个案例相关的非平凡概率，因此对统计学的完全频率主义理解显然需要对参考类问题做出回应。

为了说明物理概率，我们简要考虑茶品尝女士的物理概率示例。

> **物理概率**
> 我们用 h 来表示女士仅仅是猜测的零假设。假设我们按照上面的例子中所示的规则进行：只要抽样数据 s 包含在一个特定的可能样本集合 R 中，即 s∈R，并且根据零假设，R 的总概率为 5%，我们就会拒绝这个零假设，即否认女士仅仅是在猜测。现在想象一下，我们要评判全国茶室中散布的一群品茶女士。然后，通过进行实验并采用刚才提到的规则，我们知道，对于那些零假设为真的女士中的 5%，即那些实际上仅仅是在猜测的女士，我们将错误地归因于她们具有特殊的品茶才能。换句话说，这个百分比涉及到一组特定事件的物理概率，根据规则，它与我们的判断中的一个特定错误相关联。

现在假设我们找到了一个我们拒绝零假设的女士，即通过了测试的女士。她是否具有品茶能力呢？不幸的是，这不是可以通过手头的测试来回答的问题。一个好的答案可能涉及到那些在分数超过某个阈值的女士中确实具有特殊品茶能力的比例，即那些在五杯茶上都回答正确的女士。但是，这个后一比例，即在通过测试的女士中，零假设为假的女士的比例，与在通过测试的女士中，零假设为假的女士的比例不同。它还将取决于在受审查的人群中具有这种能力的女士的比例。相比之下，测试只涉及到零假设为真的女士群体内的比例：我们只能在假设事件以一定方式分布的情况下考虑特定事件的概率。

### 2.2 认识概率和统计理论

在统计方法中，有一种替代的观点来看待出现的概率：它们可以被视为认识态度的表达。我们再次面临几个相关的选择。粗略地说，认识概率可以是信念论的、决策论的或逻辑的。

#### 2.2.1 认识概率的类型

概率可以被视为对数据和假设的意见，以指定理想理性主体的观点。概率则表达了信念的强度或程度，例如关于品茶女士下一次猜测的正确性。它们也可以被视为决策论的一部分，即作为代理人更复杂的表示的一部分，该表示确定了她对数据和假设的决策和行动的倾向。通常，决策论表示涉及信念态度以及偏好和其他可能的态度。在这种情况下，概率可以表达对女士猜测正确性的愿意打赌。最后，概率可以被视为逻辑的。更准确地说，概率模型可以被视为一种逻辑，即一种固定不确定推理的规范理想的形式表示。根据后一种选择，数据和假设上的概率值具有与演绎逻辑中真值的作用相当的作用：它们用于确保有效推理的概念，而不带有数值指向任何心理上显著的暗示。

概率的认识论观点在 19 世纪和 20 世纪上半叶得到发展，首先是由德摩根（1847 年）和布尔（1854 年）提出，后来由凯恩斯（1921 年）、拉姆齐（1926 年）和德芬尼蒂（1937 年）以及决策理论家、哲学家和归纳逻辑学家如卡纳普（1950 年）、萨维奇（1962 年）、莱维（1980 年）和杰弗里（1992 年）进一步发展。在统计学中，这些观点的重要支持者包括杰弗里斯（1961 年）、爱德华兹（1972 年）、林德利（1965 年）、古德（1983 年）、杰恩斯（2003 年）以及近几十年来的许多贝叶斯哲学家和统计学家（例如，戈尔德斯坦 2006 年，卡达内 2011 年，伯杰 2006 年，道维德 2004 年）。所有这些人都认为概率是属于认识论领域而不是物理领域的，即概率不是世界模型的一部分，而是用来模拟像人类思维这样的代表系统的手段。

上述分类当然不是完整的，而且在边界上有些模糊。首先，关于概率的信念观念主要以行为主义方式进行阐述，借助决策理论的帮助。许多人采用所谓的荷兰书证明来明确确定信念程度，并表明它确实被概率的数学理论所捕捉（参见杰弗里 1992 年）。根据这种论证，对事件发生的信念程度由一个投注合约的价格来确定，该合约在事件发生时支付一单位货币。然而，对于概率作为信念态度的行为主义观点，也有其他选择，例如使用准确性或接近真实性。其中大部分是德芬尼蒂（1974 年）提出的论证的版本或扩展。其他人则基于对信念程度的自然期望进行了公理化方法的发展（例如，考克斯 1961 年）。

此外，正如上面所提到的，在概率的信念观念中，我们可以进一步将其分为主观和客观的信念态度。客观信念概率的定义特征是它受到一些客观事实或情况的约束，或者受到进一步的合理性标准的约束。相比之下，主观信念态度并不受这样的约束：从规范的角度来看，代理人可以自由地相信他们认为合适的事情，只要他们遵守概率公理。

#### 2.2.2 统计学理论

对于目前的关注点，重要的是每个这些概率计算的认识解释都有其自己的统计基础计划。总体而言，认识概率最自然地与贝叶斯统计学相关联，这是统计方法的第二个主要理论（Press 2002，Berger 2006，Gelman et al 2013）。贝叶斯统计学的关键特征直接源于认识解释：在这种解释下，我们可以为统计假设分配概率，并将这种概率理解为我们对假设的强烈信念的表达，并与事件的概率相关联。贝叶斯统计学允许我们表达我们对统计假设的认识态度，无论是逻辑的、决策理论的还是信念的，在数据的影响下如何变化。

为了说明贝叶斯统计学中概率的认识论观念，我们简要回顾一下品茶女士的例子。

> **认识论概率**
> 与之前一样，我们用 h 表示品茶女士随机猜测的零假设，这样分布 Ph 给出了女士任何猜测的概率为 1/2。备择假设 h'是女士比公平硬币猜测得更好。更准确地说，我们可以规定分布 Ph'给出了正确猜测的概率为 3/4。一开始，我们可能认为品茶女士具有特殊的品茶能力相当不太可能。为了表达这一点，我们将她具有这些能力的假设的概率只给予她没有这些能力的假设的一半概率：P(h')=1/3，P(h)=2/3。现在，将数学细节留给第 4.1 节，当我们收到她全部猜对五杯茶的数据后，我们对女士的特殊能力的新信念已经完全改变。我们现在认为女士具有特殊能力的概率大约是她仅仅是随机猜测者的四倍：P(h')=243/307≈4/5，P(h)≈1/5。

要点是贝叶斯方法允许我们以概率分配的方式表达我们对统计假设的认知态度，并且数据以一种受控的方式影响这种认知态度。

值得强调的是，贝叶斯统计并不是唯一使用认知概率概念的方法。事实上，频率主义对于分配给统计假设的概率的理解似乎是荒谬的。但是，完全可以将事件的概率或样本空间中的元素解读为认知的，与所使用的统计方法完全独立。正如下一节中进一步解释的那样，经典统计学的几个哲学发展采用了认知概率，尤其是信度概率（Fisher 1955 和 1956；另请参阅 Seidenfeld 1992 和 Zabell 1992），似然主义（Hacking 1965，Edwards 1972，Royall 1997）和证据概率（Kyburg 1961），或以某种其他方式将经典统计学的程序与推理和支持联系起来。在所有这些发展中，样本空间上的概率和函数被认为是认知的，即作为证据的强度、支持程度或类似的表达方式。

## 3. 经典统计学

可以归类为经典统计学的一系列程序非常广泛且多样化。总体而言，经典统计程序的共同特点是它们仅依赖于样本空间上的概率分配。正如所示，这样做的一个重要动机是这些概率可以被解释为频率，从而产生了频率主义统计学的术语。经典统计程序通常由样本空间上的某个函数定义，该函数通常仅依赖于被考虑的假设分配给样本空间的分布。对于可能获得的样本范围，该函数指向其中一个假设，或者可能指向一组假设，作为与该样本在某种意义上最匹配的假设。或者，相反地，它会排除使样本过于不太可能的候选假设。

总之，经典程序利用数据来缩小一组假设。以这样的一般术语来表述，经典程序对归纳问题提供了一种响应。数据被用于从关于目标系统的弱一般陈述到更强的一般陈述，即从一组候选假设到其中的一个子集。统计学哲学的核心问题是我们如何理解这些程序，以及如何为它们提供合理的解释。请注意，经典统计学的模式类似于排除归纳：根据数据，我们排除了一些候选假设。实际上，经典统计学常常与波普尔的证伪主义松散地联系在一起，但这种联系有些误导。在经典程序中，当观察到的样本过于不太可能时，统计假设会被排除，这当然与排除认为观察到的样本是不可能的假设不同。

### 3.1 经典统计学基础

前文已经提供了一个简短的例子和经典统计程序的大致概述。现在根据 Barnett（1999）作为主要来源，对这些程序进行更详细的说明。以下重点介绍两个非常核心的程序，即假设检验和估计。第一个与比较两个统计假设有关，并引用了 Neyman 和 Pearson 开发的理论。第二个涉及从一组假设中选择一个假设，并采用 Fisher 设计的程序。虽然这些人物与经典统计学有关，但他们的哲学观点有所不同。我们将在下面回到这个问题。

#### 3.1.1 假设检验

Fisher 的零假设检验程序在前文已经简要讨论过。设 h 为感兴趣的假设，并且为了简单起见，设 S 为有限样本空间。假设 h 对样本空间施加了一个分布，记为 Ph。空间中的每个点 s 表示一种可能的数据样本。我们现在定义一个函数 F，该函数在样本空间上标识出我们将拒绝零假设的样本 s，即 F(s)=1。

F(s)={1 如果 Ph(s)<r，否则为 0。

注意，拒绝域的定义 Rr={s:F(s)=1}取决于在假设下数据的概率 Ph(s)。这个表达式通常被称为样本 s 上假设的似然。我们可以将似然的阈值 r 设置为一个合适的值，使得拒绝域 Rr 的总概率低于给定的错误水平，例如 Ph(R)<0.05。

很快就出现了两个竞争假设之间的比较更具信息量，特别是因为如果零假设实际上是错误的，很少能够对错误率做出什么样的说法。Neyman 和 Pearson（1928 年，1933 年和 1967 年）设计了所谓的似然比检验，一种比较两个竞争假设似然的检验。设 h 和 h'分别为零假设和备择假设。我们可以通过以下样本空间上的检验函数 F 来比较这些假设：

F(s)={1 如果 Ph′(s)Ph(s)>r，否则为 0，

其中 Ph 和 Ph′分别是由统计假设 h 和 h′确定的样本空间上的概率分布。如果 F(s)=1，我们决定拒绝零假设 h，否则我们暂时接受 h 并忽略 h′。

接受或拒绝假设的决策与所谓的检验的显著性和功效相关。显著性是根据零假设 h，获得导致我们错误拒绝该假设 h 的数据的概率：

统计学哲学 F=α=Ph(Rr)=∑s∈SF(s)Ph(s)ds,

概率α也被称为第一类错误，通常被表示为显著性或 p 值。功效是根据备择假设 h'，得到能够正确拒绝零假设 h 的数据的概率：

功效 F=1−β=Ph′(F1)=∑s∈SF(s)Ph′(s)ds.

概率β被称为错误地接受零假设的第二类错误。最优的检验是指同时最小化错误α和β的检验。在他们的基本引理中，尼曼和皮尔逊证明了决策在似然比检验函数 F 上具有最优的显著性和功效。也就是说，最优的检验只取决于比值 Ph′(s)/Ph(s)的阈值。

品茶女士的例子可以很容易地说明似然比检验。

> **尼曼-皮尔逊检验**
> 在零假设 h 即女士随机猜测的旁边，我们现在考虑备择假设 h'，即她有 3/4 的机会正确猜测茶和牛奶的顺序。样本 s 是记录正确和错误猜测的二进制 5 元组。为了确定两个假设的可能性，以及每个样本的检验函数的值，我们只需要知道所谓的充分统计量，在这种情况下是正确猜测的数量 n，与顺序无关。用 sn/t 表示女士在 t 次中有 n 次正确猜测的特定序列，我们有 Ph(sn/5)=1/25 和 Ph'(sn/5)=3n/45，因此似然比变为 3n/25。如果我们要求显著性低于 5%，那么可以计算出只有 n=5 的样本可以包含在拒绝域中。因此，我们可以设置截断点 r，使得 r≥34/25 且 r<35/25，例如 r=34/25。

5%显著性水平是统计惯例的一部分，通常在考虑功效之前就已经确定。请注意，统计程序将预期的错误率与拒绝或接受的决策相关联。尤其是 Neyman 以严格的行为主义方式解释了这一点。有关此问题的进一步讨论，请参见第 3.2.2 节。

#### 3.1.2 估计

在本节中，我们简要讨论了最大似然估计的参数估计，这是由费舍尔（1956 年）首次设计的。在前面的部分中，我们使用了一个有限的样本空间，现在我们使用一个具有无限多个可能样本的空间。因此，一个概率分布在样本空间上被写成所谓的密度函数 P(s)ds 的形式，从技术上讲，它表示了在点 s 周围的一个无限小区域 ds 上分配的无限小概率。这个概率密度函数的工作方式很像一个普通的概率函数。

最大似然估计，简称 MLE，是一种确定一组假设中最佳假设的工具，通常称为统计模型。设 M={hθ:θ∈Θ}为模型，由参数θ标记，设 S 为样本空间，Pθ为与 hθ相关联的分布。然后定义最大似然估计器θ^为样本空间上的一个函数：

θ^(s)={θ:∀hθ′(Pθ′(s)ds≤Pθ(s)ds)}.

因此，估计量是一个集合，通常是一个单元素集合，其中包含使得在数据 s 上的 hθ的似然函数最大化的θ的值。我们用 hθ^表示相关的最佳假设。这可以再次用品茶女士的例子来说明。

> **最大似然估计**
> 对于品茶女士的情况，一个自然的统计模型包括了所有可能的准确性水平θ∈[0,1]的假设 hθ。现在，正确猜测的次数 n 和总猜测次数 t 是充分统计量：样本的概率只取决于这些数字。对于任意特定的 t 次猜测中成功 n 次的序列 sn/t，hθ的相关似然函数为
>
> Pθ(sn/t)=θn(1−θ)t−n.
>
> 对于任意次数的试验 t，最大似然估计器变为 θ^=n/t.

我们假设向女士提供的杯子数量固定为 t，因此样本空间再次有限。最后请注意，θ^ 是使数据最有可能的假设，而不是在数据的光线下最有可能的假设。

我们对估计函数可能会有几个要求。其中之一是估计函数必须是一致的。这意味着对于更大的样本，估计函数 θ^ 会收敛到与数据生成系统的分布 θ⋆ 相关的参数值，或者简称为真实参数值。另一个要求是估计函数必须是无偏的，这意味着估计函数的期望值与真实参数值之间没有差异。最大似然估计（MLE）过程当然不是唯一用于基于统计数据估计感兴趣参数值的方法。一种更简单的技术是最小化特定目标函数，例如最小化统计假设的预测与数据点之间距离的平方和，也被称为最小二乘法。沃尔德（Wald）（1950）首次提出了一种更一般的观点，通过使用损失函数来衡量假设的预测与实际数据之间的差异。平方和和似然函数可以被视为这种损失的表达式。

通常，估计与所谓的置信区间相关联（参见 Cumming 2012）。为了方便起见，假设Θ由实数组成，并且每个样本 s 都带有唯一的估计函数值θ<sup>(s)。我们定义集合 Rτ={s:θ</sup>(s)=τ}，即估计函数具有值τ的样本集合。现在我们可以整理出一个样本空间内的区域，在这个区域内，估计函数θ^与参数的真实值θ⋆不会相差太远。例如，

 C⋆Δ={Rτ:τ∈[θ⋆−Δ,θ⋆+Δ]}。

因此，这个集合是所有满足τ∈[θ⋆−Δ,θ⋆+Δ]的 Rτ的并集。现在我们可以设置这个区域，使其覆盖样本空间的大部分，比如真实分布 Pθ⋆所测量的 1−α。我们选择Δ使得

Pθ⋆(C⋆Δ)=∫θ⋆+Δθ⋆−ΔPθ⋆(Rτ)dτ=1−α。

统计学民间传说通常将α设定为 5%。相对于这个数值，Δ的大小反映了估计的质量。如果我们反复收集样本，我们会发现估计器θ^在真实值θ⋆的Δ范围内的样本中出现的概率为 95%。这导致我们定义了对称的 95%置信区间：

CI95=[θ<sup>−Δ,θ</sup>+Δ]

解释与前述相同：通过重复抽样，我们发现在所有样本中，真实值在估计值的Δ范围内的概率为 95%。

至关重要的是，在真实分布的假设下，我们能够对事件θ<sup>∈[θ⋆−Δ,θ⋆+Δ]提供一个无问题的频率解释。在一系列的估计中，估计器θ</sup>离θ⋆的距离超过Δ并因此在这个区间之外的次数的比例将趋于 5%。这个区域越小，估计就越可靠。请注意，这个区间是根据未知的真实值θ⋆来定义的。然而，特别是如果区间 2Δ的大小与真实参数θ⋆无关，将 95%的置信区间与真实值在估计值θ^周围Δ范围内的频率相关联是很诱人的。下面我们将回到这个解释。

当然，估计各种统计目标的程序还有很多，对估计质量的表达也有很多（例如，自助法，参见 Efron 和 Tibshirani 1993）。估计理论通常配备了一个丰富的特定情境的估计准则目录，反映了估计器帮助实现的认识论和实用目标。然而，估计器本身并没有提供信念的指导方针，重要的是，置信区间也没有提供。

### 3.2 经典统计学的问题

经典统计学在统计学哲学中被广泛讨论。接下来，将概述经典方法的两个问题，即其与信念的问题界面以及其违反所谓的似然原则。可以看到，还有更多具体问题可以从这些一般问题中推导出来。

#### 3.2.1 与信念的接口

考虑 Neyman 和 Pearson 的似然比检验。如指出的那样，检验的显著性或 p 值是一个错误率，如果数据收集和测试重复进行，假设零假设实际上是真的，将会显现出来。值得注意的是，p 值并不能告诉我们零假设的真实性有多大的可能性。然而，许多科学家确实以这种方式使用假设检验，并且对于从 p 值中可以推导出什么和不能推导出什么存在很多争议（参见 Berger 和 Sellke 1987，Casella 和 Berger 1987，Cohen 1994，Harlow 等人 1997，Wagenmakers 2007，Ziliak 和 McCloskey 2008，Spanos 2007，Greco 2011，Sprenger 即将发表-a）。毕竟，这个测试导致了要么拒绝假设要么接受它的建议，这在概念上非常接近给出真实性或虚假性的裁决。

尽管 p 值的证据价值存在很多争议，但许多人承认根据假设的数据概率不能直接用作假设可信度的指标（参见 Gillies 1971，Spielman 1974 和 1978）。这种用法会遇到所谓的基本率谬误。茶品尝女士的例子再次具有教育意义。

> **基本率谬误**
> 假设我们在全国范围内进行茶品尝测试，与大量女士一起旅行，并发现有一位女士全部猜对了五杯茶。我们应该得出结论，这位女士具有特殊的品茶才能吗？问题在于这取决于在测试中有多少女士实际上具有特殊的才能。如果这种能力非常罕见，那么将这五次正确的猜测归因于偶然事件更具吸引力。相比之下，想象一下所有女士参加彩票。类比于女士全部猜对茶杯，考虑一位赢得彩票奖品的女士。当然，赢得奖品是非常不可能的，除非与庄家串通，即类似于具有特殊品茶能力的类比。但是，如果一位女士赢得了彩票，这并不是一个断定她一定犯了欺诈行为并要求逮捕她的好理由。同样，如果一位女士全部猜对了茶杯，我们不能简单地得出她具有特殊能力的结论。

如果我们将参数的估计视为对信念的直接建议，就会出现同样的问题，这一点在 Good（1983 年，第 57 页）的一个例子中得到了明确的阐述，该例子在品茶的背景下进行了介绍。在观察到五次正确的猜测后，我们得到了最大似然估计值θ^=1。但是很难相信这位女士在长期内会 100%准确。估计和信念之间存在复杂的关系，这一观点也在 Lindley 的悖论（Lindley 1957，Spanos 2013，Sprenger forthcoming-b）的讨论中提出。简而言之，将经典统计程序的结果转化为信念似乎是错误的。

这是否可以归咎于经典统计学还存在争议。最初，尼曼坚决表示他们的程序不能被视为推理，或以其他方式与假设的认识状态相关。他们自己的统计哲学严格遵循行为主义原则（参见尼曼 1957 年），如果科学家们放弃对经典统计学的错误认识使用，问题可能会消失。正如前文所述，我们可以毫无争议地将错误率与经典程序以及由这些程序产生的决策联系起来。因此，对经典统计学的行为和错误基础的理解似乎是可以接受的。然而，统计学家和哲学家都认为经典统计学可以进行认识论阅读，并且实际上更可取（例如，费舍尔 1955 年，罗亚尔 1997 年）。因此，许多人试图重新解释或发展这一理论，以使其与科学家的认识论导向的统计实践相一致（参见梅奥 1996 年，梅奥和斯帕诺斯 2011 年，斯帕诺斯 2013b 年）。

#### 3.2.2 证据的性质

假设检验和估计有时受到批评，因为它们的结果通常取决于整个样本空间上的概率函数，而不仅仅是观察样本的概率。也就是说，接受或拒绝零假设的决策不仅取决于根据各种假设实际观察到的概率，还取决于可能观察到但未观察到的事件的概率分配。这个问题的一个众所周知的例子是所谓的可选停止（Robbins 1952 年，Roberts 1967 年，Kadane 等 1996 年，Mayo 1996 年，Howson 和 Urbach 2006 年）。

可选停止在内曼和皮尔逊的似然比检验中得到了说明，但是费舍尔的零假设检验以及估计量和置信区间的确定也可以运用类似的方法进行。

> **可选停止**
> 想象两位研究人员同时对同一位女士进行测试，测试她能否确定牛奶和茶倒入杯子的顺序。他们都持有女士是随机猜测的零假设，概率为 1/2，而对女士能够正确猜测的备择假设的概率为 3/4。其中一位更勤奋的研究人员决定记录六次试验。另一位比较急躁的研究人员最多只记录六次试验，但决定在女士第一次猜错时停止记录。现在假设实际上女士除了最后一杯外都猜对了。两位研究人员都得到了相同的数据，即五次成功和一次失败，对于这些数据，两位研究人员的似然函数也是相同的。然而，勤奋的研究人员无法拒绝零假设，而急躁的研究人员可以。

这可能让我们感到奇怪：统计学应该告诉我们数据对假设的客观影响，但在这里，影响似乎取决于研究者的抽样计划，而不仅仅取决于数据本身。正如在第 3.2.3 节中进一步解释的那样，两位研究者的结果之间存在差异，是因为未观察到的样本在程序中的计算方式不同。

有些人会认为这种依赖是不可接受的：研究者的意图和计划与数据的证据价值无关。但其他人认为这是正确的。他们认为数据对假设的影响应该取决于在获取数据时遵循的停止规则或协议，而不仅仅取决于假设对这些数据的可能性（例如 Mayo 1996）。这种观点的动机是，坚持停止规则的无关性会使禁止数据收集中的机会性选择变得不可能。事实上，经典统计学的支持者反驳那些认为可选停止是无关紧要的人。他们认为，这打开了通过持续实验推理到预定结论的可能性：只有在达到首选结果时，我们才决定停止实验。然而，正如 Kadane 等人（1996）所示，并在 Steele（2012）中进一步讨论的那样，只要我们确保使用正确的（在这种情况下是贝叶斯）程序，持续实验并不能保证有效。

对于可选停止的辩论最终关注的是数据的适当证据影响。在这场更广泛的辩论中，一个核心关注点是所谓的似然原则（见 Hacking 1965 和 Edwards 1972）。该原则认为，对于观察数据的假设的似然性完全确定了这些数据对假设的证据影响。根据 Berger 和 Wolpert（1984）的表述，似然原则指出，当考虑一些常数 k 时，当所有假设 hi 下的样本 s 和 s'满足 Pi(s)=kPi(s')时，它们在证据上是等价的。著名的 Birnbaum（1962）从更基本的假设中提供了该原则的证明。这个证明依赖于条件性的假设。假设我们首先抛一枚硬币，发现它朝上，然后进行与这个结果相关的实验，记录样本 s。将其与我们直接进行实验并直接得到样本 s 的情况进行比较，而不是随机选择它。条件性原则指出，第二个样本与第一个样本具有相同的证据影响：我们本可以发现但没有发现的东西对样本的证据价值没有影响。最近，Mayo（2010）对 Birnbaum 关于似然原则的推导提出了质疑。

上面概述的经典观点违反了这一点：观察数据的影响可能因其他样本的概率而异，因为在确定接受和拒绝区域时，这些其他样本会起作用。另一方面，第 4 节讨论的贝叶斯程序坚持似然原则：在确定关于假设的后验分布时，只有先验和观察数据的似然性是重要的。在关于可选停止的辩论以及许多其他经典统计学和贝叶斯统计学之间的辩论中，似然原则是焦点。

#### 3.2.3 探讨：可选停止

数据揭示的内容或其他内容，可能比相关假设的可能性所表达的更多，这一观点值得详细关注。在这里，我们进一步研究了关于可选停止的争议。

让我们通过构建两位研究者的拒绝区域，以数值细节的方式考虑他们的分析。

> **确定拒绝区域**
> 勤奋的研究者将所有的成功和失败的 6 元组视为样本空间，并将它们的数量视为充分统计量。在零假设下，即女士仅仅是猜测的情况下，六次成功或六次正确猜测的事件的概率为 1/26=1/64，而在备择假设下的概率为 36/46。如果我们设定 r<36/26，则该样本被包括在零假设的拒绝域中。在零假设下，五次成功的样本的概率也为 1/64，而在备择假设下的概率为 35/46。通过将似然比降低 3 倍，我们将所有这些样本都包括在拒绝域中。但这将导致错误拒绝的总概率为 7/64，大于 5%。因此，这些样本不能被包括在拒绝域中，因此勤奋的研究者在发现五次成功和一次失败时不会拒绝零假设。
>
> 然而，对于急躁的研究者来说，样本空间要小得多。除了由六次成功组成的样本外，所有的样本都由一系列以失败结束的成功组成，只是系列的长度不同。然而，两个长度为六的样本的概率与勤奋的研究者相同。与之前一样，六次成功的样本再次被包括在拒绝域中。同样，由五次成功后跟一次失败的序列也在零假设下具有 1/64 的概率，而根据备择假设的概率为 35/46。不同的是，将似然比降低以将该样本包括在拒绝域中只会导致该样本的包含。如果我们将其包括在拒绝域中，错误拒绝的概率将变为 1/32，因此不超过 5%。因此，基于这些数据，悠闲的研究者可以拒绝女士仅仅是在猜测的零假设。

考虑为什么急躁的研究人员可以拒绝零假设是有益的。根据他的抽样计划，其他具有五个成功的样本，即那些在超过错误概率的情况下，使勤奋的研究人员无法将观察到的样本包括在拒绝域中的样本，是无法被观察到的。这说明了经典统计程序的结果不仅取决于实际数据的可能性，这些可能性对于两个研究人员来说确实是相同的。它们还取决于我们没有获得的数据的可能性。

在上面的例子中，可能会认为使用可选停止的协议取决于正在记录的数据是令人困惑的。但是，即使没有这种依赖性，关于可选停止的争议也会出现。例如，想象一位第三位研究人员，她会一直抽样直到勤奋的研究人员完成，或者在那之前如果她开始感到饥饿。此外，我们可以假设每次向这位女士提供新的杯子时，感到饥饿的概率为 1/2。如果她完成了六杯的系列，这位饥饿的研究人员也能够拒绝零假设。而且，这种拒绝似乎与统计程序的客观性不符：如果她没有保持吃点心的可能性，她就不会拒绝零假设，即使她实际上没有休息。正如杰弗里所说，这确实是一个“非凡的程序”。

然而，情况并不像看起来那么清晰。首先，饥饿的研究者可以说是同时测试了两个假设，一个是关于品茶女士的能力，另一个是关于她自己的饥饿感。这两个假设的结合对实际样本的可能性与勤奋的研究者考虑的简单假设有所不同。上述的可能性原则规定了这种差异不会影响实际样本的证据影响力，但有些人保留了这种应该的直觉。此外，在某些情况下，这种直觉也被那些坚持可能性原则的人所共享，即当停止规则依赖于已经被问题假设表达的方式之外的过程时（参见 Robbins 1952，Howson 和 Urbach 2006，第 365 页）。就我们的例子而言，如果这位女士只是猜测，那么研究者因为纯粹的无聊而感到饥饿的可能性可能更大，而不是如果这位女士的表现远低于或远高于机会水平。在这种情况下，停止本身就揭示了与问题假设相关的一些东西，这应该反映在假设的可能性中。这将使得数据对假设的证据影响力最终取决于停止规则。

### 3.3 对批评的回应

对上述批评已经有了许多回应。其中一些回应有效地重新解释了经典统计程序只涉及数据的证据影响。其他回应则发展了经典统计理论以适应这些问题。它们的共同核心是建立或至少澄清了两个概念领域之间的联系：统计程序涉及物理概率，而它们的结果涉及证据和支持，甚至涉及假设的拒绝或接受。

#### 3.3.1 证据的强度

经典统计学通常被认为是为我们提供行动建议的。错误概率并不告诉我们在统计程序的基础上应该采取什么认识态度，而是指出如果我们按照它们生活，错误的长期频率。具体来说，尼曼提倡了这种对经典程序的解释。与此相反，费舍尔（1935a，1955），皮尔逊和其他经典统计学家主张更多的认识论解释，许多近期的作者也跟随其后。

在上述关于经典统计学的讨论中，似然的概念是核心，它反映了数据对相关假设的支持程度。在 Hacking（1965）、Edwards（1972）和最近的 Royall（1997）的著作中，似然被视为统计程序的基石，并给予了认识论解释。它们被认为表达了数据所提供的证据的强度，或者数据对假设的支持程度的比较程度。Hacking 在所谓的似然法则（1965 年，第 59 页）中阐述了这个想法：如果样本 s 在 h0 的条件下比在 h1 的条件下更有可能出现，那么 s 对 h0 的支持程度就比对 h1 的支持程度更高。

似然主义的立场基于对概率的特定组合观点。一方面，它只使用样本空间上的概率，避免将概率放在统计假设上。因此，它避免了无法给出物理解释的概率的使用。另一方面，它将样本空间上的概率解释为支持关系的组成部分，因此与认识论而非物理领域相关。值得注意的是，似然主义方法与形式化认识论的悠久历史非常契合，特别是与证实理论（见 Fitelson 2007）相吻合，其中概率论用于阐明数据和假设之间的证实关系。证实度的度量始终将假设的似然性作为输入组成部分。它们提供了对似然法则所描述的支持关系的定量表达。

Mayo（1996）和 Mayo 与 Spanos（2011）提出了另一种关于经典统计学的认识论方法。在过去的十年左右的时间里，他们在科学哲学中推动了经典统计学的议程，该领域曾被贝叶斯统计学所主导。与 Neyman 最初的行为主义倾向相对立，错误统计学方法提出了对经典检验和估计程序的认识论解读。Mayo 和 Spanos 认为，最好将经典程序理解为推理的：它们授权归纳推理。但他们也承认这些推理是可推翻的，即它们可能引导我们走错方向。经典程序总是与特定的错误概率相关，例如错误拒绝或接受的概率，或者估计器落在某个范围内的概率。在 Mayo 和 Spanos 的理论中，这些错误概率具有认识论的作用，因为它们被认为指示了程序授权的推理的可靠性。

Mayo 和其他人的错误统计方法包括科学的一般哲学以及对统计学哲学的特定观点。我们简要讨论后者，通过讨论严格检验的概念（参见 Mayo 和 Spanos 2006）。主张是我们通过严格检验假设来获得实验效应的知识，这可以通过显著性和功效来描述。在 Mayo 的定义中，一个假设在两个条件下通过严格检验：数据必须与假设一致，并且数据与备择假设一致的概率必须非常低。忽略对“一致”和“低概率”精确解释的潜在争议，我们可以在这些要求中识别出 Neyman 和 Pearson 的标准。如果显著性低，则测试是严格的，因为数据必须与假设一致；如果功效高，则数据必须不一致，或者以低概率一致，与备择假设一致。

#### 3.3.2 理论发展

除了对经典统计程序的重新解释外，许多统计学家和哲学家进一步发展了经典统计理论，以实现其结果的认识论作用。我们特别关注两个发展，即置信概率和证据概率。

证据概率理论起源于 Kyburg（1961），他发展了一个逻辑系统，以一致地处理经典统计分析的结果。因此，证据概率属于建立经验主义使用经典统计的尝试之一。Haenni 等人（2010）和 Kyburg 和 Teng（2001）对证据概率进行了深入介绍。该系统基于一种默认推理的版本：统计假设附带有置信水平，并且逻辑系统组织了如何在推理中传播这些置信水平，并因此建议在预测和决策中使用哪个假设。特别关注的是在涉及多个具有不同置信度标记的相同假设的推理中，置信度的传播，其中这些置信度来自于与特定人群相关联的不同数据集。证据概率有助于选择最佳置信水平，从而选择适用于所考虑情况的适当人群。换句话说，证据概率有助于解决前述所提到的参考类问题。

信度概率提供了另一种将经典统计学赋予认识论地位的方式。费舍尔（1930 年，1933 年，1935c 年，1956/1973 年）提出了信度概率的概念，以一种在开始时不假设统计假设的先验概率的方式来推导出对假设的概率分配。信度论证是有争议的，普遍认为其适用性仅限于特定的统计问题。登普斯特（1964 年），哈金（1965 年），爱德华兹（1972 年），塞登费尔德（1996 年）和扎贝尔（1996 年）提供了深入的讨论。塞登费尔德（1979 年）对多参数情况下该论证的受限适用性进行了特别详细的研究和进一步讨论。道维德和斯通（1982 年）认为，为了运用信度论证，必须假设统计问题可以用一个平滑可逆的函数模型来捕捉。登普斯特（1966 年）对分布在θ上的分布不唯一但仅在上下界内受限的情况提出了这一思想的推广（参见 Haenni 等人，2011 年）。关键是，在开始时不假设任何关于θ的分布就可以获得对θ的值的概率分布的这种约束。

#### 3.3.3 附录：信度论证

为了解释信赖区间论证，我们首先建立一个简单的例子。假设我们估计具有单位方差的正态分布的均值θ，该分布是基于变量 X 的。我们收集了一个由测量值 X1，X2，...，Xn 组成的样本 s。θ的最大似然估计器是 Xi 的平均值，即θ<sup>(s)=∑iXi/n。在假设的真实值θ下，我们对估计器θ</sup>(s)有一个以真实值为中心、方差为 1/n−−√的正态分布。值得注意的是，这个分布对于所有的θ值都具有相同的形状。费舍尔认为，由于这一点，我们可以将估计器θ^(s)上的分布作为真实值θ上的分布的替代品。因此，我们可以在不假设先验概率的情况下，基于样本 s 推导出概率分布 P(θ)。

有几种方法可以澄清这种所谓的信赖区间论证。一种方法是使用所谓的功能模型，即通过特定函数来规定统计模型。对于上述模型，该函数为

 f(θ,ϵ)=θ+ϵ=θ^(s)。

它将可能的参数值θ与基于样本的数量相关联，即观测值的估计器θ<sup>。这两者通过一个已知分布的随机组成部分ϵ相关，并且对考虑的所有样本而言，ϵ的分布是相同的。在我们的情况下，ϵ服从方差为 1/n−−√的正态分布。重要的是，ϵ的分布对于θ的每个值都是相同的。现在可以明显地解释函数 f 的解释。相对于选择一个θ的值，该值获得真实值θ⋆的角色，ϵ的分布决定了估计器函数θ</sup>(s)的分布。

现在可以简洁地表达信度论证的思想。它是将随机组成部分的分布投影回可能的参数值上。关键观察是函数关系 f(θ,ϵ)是平滑可逆的，即函数

f−1(θ<sup>(s),ϵ)=θ</sup>(s)−ϵ=θ

将每个θ<sup>(s)和ϵ的组合点映射到唯一的参数值θ。因此，我们可以颠倒前一段的论述：相对于固定θ</sup>的值，ϵ的分布完全决定了θ的分布。因此，基于颠倒的功能模型，我们可以将ϵ的正态分布转化为围绕θ^(s)的θ值。这产生了一个所谓的参数θ的保证概率分布。该分布是由于在估计值的条件下，参数和随机项变得完全相关。然后，对后者的分布自动适用于前者（参见 Haenni 等人，52-55 和 119-122）。

解释相同思想的另一种方式是引入关键量的概念。由于上述统计模型的设置方式，我们可以构造关键量θ<sup>(s)-θ。我们知道这个量的分布，即正态分布，并具有前述的方差。此外，该分布与样本无关，并且固定样本为 s，因此固定θ</sup>的值唯一确定了参数值θ的分布。因此，基于观察到的样本，保证论证使我们能够构建参数值的概率分布。只要我们能够构造类似的关键量，或者等价地，只要我们能够将统计模型表达为功能模型，就可以运行该论证。

这里需要提醒一下。正如上述参考文献中所揭示的，保证论证是极具争议的。数学结果是存在的，但对结果的正确解释仍然有待讨论。为了正确理解精确的推理步骤及其不稳定的概念基础，有必要考虑使用保证概率来解释置信区间。正确理解这一点需要先阅读第 3.1.2 节。

回想一下，置信区间通常被认为是估计质量的指标，经常被解释为认识论的。95%置信区间经常被误解为包含真值的参数值范围，即所谓的置信区间：

P(θ∈[θ<sup>−Δ,θ</sup>+Δ])=0.95.

这种解释与经典统计学相悖，但正如将会明显的，它可以通过应用信度论来解释。假设我们用以下方法替换确定置信区间大小Δ的积分：

∫θ<sup>(s)+Δθ</sup>(s)−ΔPθ(Rθ^(s))dθ=0.95.

换句话说，我们固定估计器 θ<sup>(s)，然后在 Pθ(Rθ</sup>(s)) 中对参数 θ 进行积分，而不是假设 θ⋆，然后在 Rτ 中对参数 τ 进行积分。当然，我们可以计算这个积分。但是，什么保证我们可以将积分视为概率？请注意，它在一系列概率分布上运行，并且，就目前而言，没有理由认为项 Pθ(Rθ^(s)) 相加得到一个适当的 θ 分布。

确保这些项确实相加，并且会出现一个良好行为的分布的假设，这里用函数模型的可逆性来解释。我们可以选择统计模型，使样本统计量 θ<sup>(s) 与参数 θ 以正确的方式相关：相对于参数 θ，我们对统计量 θ</sup> 有一个分布，但是同样地，相对于这个统计量，我们对参数也有一个分布。因此，概率函数 Pθ(Rθ<sup>(s)+ϵ) 关于 ϵ（固定 θ）可以转化为一个基准概率函数 Pθ+ϵ(Rθ</sup>(s)) 关于 ϵ（固定 θ<sup>(s)）。参数 θ 的函数 Pθ(Rθ</sup>) 因此是一个适当的概率函数，可以用来构建置信区间。

即使如此，我们仍然不清楚为什么我们应该将这个分布视为我们信念的适当表达，以便我们可以用它来支持置信区间的认识论解释。因此，争论继续下去。最后，信度概率可能最好被理解为经典统计学和贝叶斯统计学之间的折衷方案。经典统计学起源于对概率的频率解释，因此经典统计方法中出现的概率都被解释为事件的频率。显然，由信度论证生成的假设概率分布不能以这种方式解释，因此对这个分布的认识论解释似乎是唯一的选择。一些作者（例如，Dempster 1964）指出，信度概率在贝叶斯观点中确实是最有意义的。现在我们转向这个观点。

## 4. 贝叶斯统计学

贝叶斯统计方法通常以推理的形式呈现。推理从所谓的先验概率分布开始，该分布表示在收集数据之前对假设的信念程度，到后验概率分布，该分布表示在数据被纳入后的信念程度。后验分布通过概率论的公理从先验分布和假设对于所获得数据的似然度中得出，即假设对数据的概率。因此，贝叶斯方法利用数据来调节我们对一组指定的统计假设的态度，在这方面它们与经典统计程序达到了相同的效果。两种类型的统计方法都是对归纳问题的回应。但是，经典程序从假设集中选择或排除元素，而贝叶斯方法通过后验概率分配来表达数据的影响。这个后验概率完全由先验分布和假设的似然度通过概率论的形式主义确定。

贝叶斯统计学的定义特征是它不仅考虑统计假设上的概率分布，还考虑数据上的概率分布。它完全接受了概率的认识论解释：对于假设的概率被解释为信念程度，即认识不确定性的表达。贝叶斯统计学的哲学关注确定这些输入组成部分的适当解释，以及概率本身的数学形式，最终目的是为了证明输出的合理性。需要注意的是，贝叶斯统计方法的一般模式是累积归纳的：在数据的影响下，我们对假设的概率意见越来越明确。然而，在接下来的内容中，贝叶斯方法也可以被理解为演绎主义的性质。

### 4.1 推理的基本模式

贝叶斯推理总是从一个统计模型开始，即一组统计假设。虽然推理的一般模式是相同的，但我们分别处理具有有限数量和连续数量的假设的模型，并与假设检验和估计进行类比。本文主要基于 Press 2002、Howson 和 Urbach 2006、Gelman 等人 2013 和 Earman 1992。

#### 4.1.1 有限模型

贝叶斯方法的核心是概率论中的贝叶斯定理。相对于先验概率分布和每个假设的样本空间上的概率分布，它告诉我们什么是适当的后验概率。更准确地说，令 s 为样本，S 为样本空间，M={hθ:θ∈Θ}为统计假设的空间，Θ为参数值的空间。函数 P 是整个空间 M×S 上的概率分布，意味着每个元素 hθ都与自己的样本空间 S 和自己的概率分布相关联。对于后者，它完全由假设的似然确定，我们将样本在假设条件下的概率记为 P(s∣hθ)。这与经典统计学的上下文中写作 Phθ(s)的表达式不同，因为与经典统计学家不同，贝叶斯学派接受 hθ作为概率分布的参数。

贝叶斯统计首先在有限假设集的情况下引入，然后提供了对无限情况的推广。假设先验概率 P(hθ)是假设 hθ∈M 上的先验概率。进一步假设似然概率 P(s∣hθ)，即在假设 hθ下给定数据 s 的概率。然后，贝叶斯定理确定了

P(hθ∣s)=P(s∣hθ)P(s)P(hθ).

贝叶斯统计输出后验概率分配 P(hθ∣s)。这个表达式在记录并解释样本 s 之后得到了对 hθ的观点，即修订后的观点。贝叶斯推断的进一步结果都可以从统计假设的后验分布中推导出来。例如，我们可以使用后验分布来确定参数的最可能值，即选择使 P(hθ∣s)最大的假设 hθ。

在这种贝叶斯统计推断的描述中，数据的概率 P(s)并不是预设的，因为它可以通过先验和似然函数的总概率法则计算得出。

P(s)=∑θ∈ΘP(hθ)P(s∣hθ).

贝叶斯统计推断的结果并不总是以后验概率的形式报告。通常只关心比较两个假设的后验比率。根据贝叶斯定理，我们有

P(hθ∣s)P(hθ′∣s)=P(hθ)P(s∣hθ)P(hθ′)P(s∣hθ′),

如果我们假设先验概率相等 P(hθ)=P(hθ′)，我们可以使用假设的似然比，即所谓的贝叶斯因子，来比较假设。

这里是一个贝叶斯程序的例子，涉及品茶女士。

> **贝叶斯统计分析**
> 考虑假设 h1/2 和 h3/4，前文中将其用作零假设和备择假设 h 和 h'。我们不再根据数据选择它们之间的一个，而是对它们分配先验分布，使得零假设的概率是备择假设的两倍：P(h1/2)=2/3，P(h3/4)=1/3。用 sn/5 表示猜对 5 个杯子的特定序列，我们有 P(sn/5∣h1/2)=1/25，P(sn/5∣h3/4)=3n/45。与之前一样，五次猜测的似然比为
>
> P(sn/5∣h3/4)P(sn/5∣h1/2)=3n/25。
>
> 因此，5 次正确猜测后的后验比率为
>
> P(h3/4∣sn/5)P(h1/2∣sn/5)=352512≈4.
>
> 这个后验概率仅仅通过概率论的公理，特别是贝叶斯定理推导而来。它告诉我们在将样本数据纳入我们的信念后，每个假设的可信程度如何。

注意，在上述阐述中，后验概率被写作 P(hθ∣sn/5)。一些贝叶斯推断的阐述更倾向于将修订后的观点表达为一个新的概率函数 P′(⋅)，然后将其等同于旧的 P(⋅∣s)。对于贝叶斯推断的基本形式工作来说，这种区别并不重要。但我们将在第 4.3.3 节中回到这个问题。

#### 4.1.2 连续模型

在许多应用中，模型不是有限的假设集，而是由一个实值参数标记的连续体。这导致了对假设分布和似然函数定义的一些微妙变化。先验和后验必须写成所谓的概率密度函数，P(hθ)dθ。似然函数需要通过极限过程来定义：概率 P(hθ)无限小，因此我们无法以正常方式定义 P(s∣hθ)。但除此之外，贝叶斯机制完全相同：

P(hθ∣s)dθ=P(s∣hθ)P(s)P(hθ)dθ.

最后，求和需要被积分所取代：

P(s)=∫θ∈ΘP(hθ)P(s∣hθ)dθ。

这个表达式通常被称为模型的边际似然：它表达了在整个模型的光下，数据的可能性有多大。

后验概率密度为从样本中得出的结论提供了基础，这些结论类似于估计和估计准确性的度量。首先，我们可以推导出参数θ的期望，假设θ是连续变化的：

 θ¯=∫ΘθP(hθ∣s)dθ。

如果模型由一个凸集参数化，通常情况下是这样的，那么模型中将存在一个假设 hθ¯。这个假设可以作为贝叶斯估计。类似于置信区间，我们还可以从后验概率分布中定义一个所谓的置信区间或可信区间：一个大小为 2d 的区间，围绕期望值θ¯，写作[θ¯−d,θ¯+d]，使得

∫θ¯+dθ¯−dP(hθ∣s)dθ=1−ϵ.

这个θ的取值范围使得相应的 hθ的后验概率加起来等于总后验概率的 1−ϵ。

根据后验密度，还有许多其他定义θ的贝叶斯估计和置信区间的方法。贝叶斯分析提供的具体估计类型可以根据科学家的需求确定。任何贝叶斯估计都在一定程度上类似于最大似然估计器，因为似然函数在贝叶斯形式主义中起着核心作用。然而，输出还取决于关于假设的先验概率，并且一般来说，只有在样本量趋于无穷大时，它才会趋向于最大似然估计器。有关这种所谓的先验概率“洗去”的更多信息，请参见第 4.2.2 节。

### 4.2 贝叶斯方法的问题

大部分关于贝叶斯方法的争议涉及对假设的概率分配。一个重要的问题集围绕着将这些概率解释为信念，与行动意愿或类似的事情有关。另一个问题集涉及确定先验概率分配以及可能规定它的标准。

#### 4.2.1 对假设概率的解释

这里的总体问题是我们应该如何理解对统计假设分配的概率。自然地，解释将是认识论的：概率表达了对假设的信念强度。试图进行物理解释是没有意义的，因为假设不能被视为可重复事件，或者可能具有某种发生倾向的事件。

这留下了几种将概率分配解释为信念强度的解释。一个非常有影响力的概率解释是将概率与愿意以一定赔率进行赌注联系起来（参见 Ramsey 1926，De Finetti 1937/1964，Earman 1992，Jeffrey 1992，Howson 2000）。根据这种解释，例如将一个命题的概率分配为 3/4 意味着如果该命题为真，我们准备支付最多  1，如果该命题为假，则变得毫无价值。声称信念程度在概率分配中得到正确表达的论点得到了所谓的荷兰书证明的支持：如果一个代理人不遵守概率论的公理，一个恶意的博彩商可以提出一组看似公平的赌注，但会导致一定的经济损失，因此被称为荷兰书，可能是因为荷兰人的商业声誉。这种解释将信念直接与其行为后果联系起来：相信某事与愿意参与特定活动（例如赌注）是一样的。

这种对假设的概率分配的解释存在几个问题。首先，以统计假设的真实性进行投注似乎没有多大意义，因为这些假设无法被证伪或验证。因此，对它们的投注合同永远不会兑现。更一般地说，将对统计假设的信念与行为相连接的方式是否适当并不清楚。有人认为（例如，Armendt 1993），这种方式引入了关于信念的实用考虑，即成功地在世界中导航，而这本身更关注信念作为对世界的真实表达。

一个稍微不同的问题是，贝叶斯形式主义，特别是其对统计假设的概率分配的使用，表明贝叶斯统计学家具有非常封闭的思维。回想一下前面的例子，模型 M={h1/2,h3/4}。贝叶斯形式主义要求我们对这两个假设分配一个概率分布，并且进一步要求模型的概率为 P(M)=1。即使对于一个理性的理想代理来说，她确实配备了一个表达她对假设的意见的实值函数，这也是一个非常强的假设。此外，对假设的概率分配似乎意味着贝叶斯统计学家确信真实的假设包含在模型中。这是一个过于强硬的主张，贝叶斯统计学家在分析开始时必须承诺。它与广泛共享的方法论观点（例如，Popper 1934/1956）不符，根据这些观点，科学理论必须随时准备修订（参见 Mayo 1996）。在这方面，贝叶斯统计学似乎没有充分体现科学探究的本质。

刚刚概述的问题在贝叶斯主义者期望具有良好校准性的问题中呈现出更复杂的数学形式。这个问题，如 Dawid（1982）所阐述的那样，涉及到一个贝叶斯预测者，例如，一个天气预报员，他确定了下一天降水的每日概率。然后证明了这样一个天气预报员相信自己在长期内将以概率 1 收敛到正确的概率。然而，合理地假设天气预报员意识到他的气象模型可能存在问题，因此将他的正确预测概率设定为小于 1。这样，天气预报员就会产生不一致的信念。似乎贝叶斯统计分析对于一个理想的代理人来说提出了不切实际的要求。

#### 4.2.2 先验的确定

暂时假设我们可以将假设的概率解释为认识不确定性的表达。那么我们如何确定先验概率呢？也许我们已经对模型中的假设有了直观的判断，以便我们可以根据此确定先验概率。或者我们可能有其他选择先验的标准。然而，确定先验的程序存在几个严重的问题。

首先考虑科学家运行贝叶斯分析并提供先验概率的想法。这个想法的一个明显问题是，科学家的观点可能不够精确，无法确定一个完整的先验分布。假设科学家能够将她的观点转化为模型上的单值函数似乎不现实，尤其是如果模型本身由一系列连续的假设组成。但更紧迫的问题是，不同的科学家将提供不同的先验分布，而这些不同的先验将导致不同的统计结果。换句话说，贝叶斯统计推断在科学方法中引入了一个不可避免的主观成分。

统计结果依赖于科学家的初始观点是一回事。但科学家可能对假设完全没有任何观点。那么她应该如何为假设分配先验概率呢？先验将必须表达她对假设的无知。表达这种无知的主要思想通常是无差别原则：无知意味着我们对任何一对假设都没有偏好。对于有限数量的假设，无差别意味着每个假设具有相等的概率。对于一系列连续的假设，无差别意味着概率密度函数必须是均匀的。

尽管如此，有不同的方法来应用无差别原则，因此有不同的概率分布可以作为无知的表达。这个洞察力在伯特兰悖论中得到了很好的说明。

> **伯特兰悖论**
> 考虑在一个等边三角形周围画一个圆，现在想象一个长度超过圆直径的针被扔到圆上。针在圆内的部分是否比等边三角形的边长更长的概率是多少？为了确定答案，我们需要对针的投掷方式进行参数化，确定使得包含部分确实比三角形边长更长的参数值的子集，并通过参数的概率分布来表达我们对针的确切投掷方式的不确定性，以便推导出所说事件的概率。问题在于我们可以提供任意数量的参数化方式来描述针如何落在圆上。如果我们使用针与圆在交点处的切线所成的角度作为参数，那么只有当角度在 60∘到 120∘之间时，针的包含部分才会更长。如果我们假设我们的不确定性通过这些角度上的均匀分布来表达，这些角度的范围是从 0∘到 180∘，那么事件的概率将是 1/3。然而，我们也可以以不同的方式对针的落点进行参数化，即通过针到圆心的最短距离。在距离上的均匀概率将导致概率为 1/2。

Jaynes（1973 年和 2003 年）对这个谜题提供了非常有洞察力的讨论，并认为可以依靠问题在某些变换下的不变性来解决它。但目前的一般观点是，不确定性原则并不能导致先验选择的唯一性。问题不在于对参数的不确定性难以用概率分布来表达，而是在某些情况下，我们甚至不知道要使用哪些参数来表达我们的不确定性。

在某种程度上，贝叶斯分析的主观性问题可以通过对科学理论采取不同的态度并放弃绝对客观性的理想来解决。实际上，有人会认为，统计方法应该适应科学家之间的意见差异，这是正确的。然而，如果先验分布表达的是无知而不是意见，这种回应就没有抓住问题的关键：似乎很难为不同的无知表达方式所导致的意见差异的合理性辩护。现在，对于客观性的担忧还有一个更积极的回答，基于所谓的收敛结果（例如，Blackwell 和 Dubins 1962 年以及 Gaifman 和 Snir 1982 年）。事实证明，随着数据的积累，先验选择的影响逐渐减小，在极限情况下，后验分布将收敛到一组可能是单一的最佳假设，这些假设由采样数据确定，因此完全独立于先验分布。然而，在短期和中期内，主观先验选择的影响仍然存在。

总结起来，贝叶斯统计对主观输入的敏感性仍然存在问题。经典统计程序的不可否认的优势在于它们不需要任何这样的输入，尽管可以说经典程序反过来对样本空间的选择敏感（Lindley 2000 年）。对此，贝叶斯统计学家指出能够将初步意见纳入统计分析的优势。

### 4.3 对批评的回应

贝叶斯统计学的哲学为上述问题提供了广泛的回应。一些贝叶斯主义者坚持并捍卫贝叶斯方法的本质上主观的特性。其他人则试图通过提供客观动机的方法来确定先验概率，或者强调贝叶斯形式主义本身的客观特性，以弥补或补偿主观性。

#### 4.3.1 严格但以经验为基础的主观主义

贝叶斯统计学中一种非常有影响力的观点认同分析的主观性（例如，Goldstein 2006，Kadane 2011）。所谓的个人主义者或严格主观主义者认为，统计方法不提供任何客观准则是正确的，指出任何形式的知识都具有根本上主观的来源。因此，关于先验分布的解释和选择的问题在某种程度上被解决：贝叶斯统计学家可以任意选择她的先验，并且它们是她信念的表达。然而，值得强调的是，对贝叶斯统计学的主观主义观点并不意味着可以忽视所有来自经验事实的约束。没有人否认，如果您拥有进一步的知识，这些知识对模型或先验施加了约束，那么这些约束必须被纳入考虑。例如，今天的后验概率可以作为明天的先验，在下一次统计推断中使用。关键是这些约束涉及信念的合理性，而不是统计推断本身的一致性。

主观主义观点在那些以实用主义方式解释概率分配并通过上述的荷兰书论证来激励信念与概率分配的表示的人中最为突出。这种方法的核心是 Savage 和 De Finetti 的工作。Savage（1962）提出了将统计学与决策理论结合起来的公理化方法，这是关于实际合理性的数学理论。他认为，单独的概率分配本身并没有任何意义，只有在代理人面临行动选择，即在一系列赌注中进行选择时，它们才能被解释。同样，De Finetti（例如，1974）主张一种关于统计学的观点，其中只有概率信念的经验后果，即愿意下注的意愿，才是重要的，但他并没有将统计推断完全依赖于决策理论。值得注意的是，主观主义对贝叶斯统计的观点似乎基于与 Neyman 和 Pearson 发展经典统计学的行为主义和经验主义相同的动机。

注意，所有这些都使得第 4.2.1 节的解释问题的一个方面重新出现：先验分布如何在行为中显现出来，以便可以合理地解释为信念，这里的信念被理解为一种行动的意愿？对于这个问题的一个回答是转向不同的动机来通过概率分配来表示信念的程度。在 De Finetti 的工作之后，一些作者提出了概率表达信念的辩护，这些辩护不是基于行为目标，而是基于保持准确反映世界的信念的认识目标，例如 Rosenkrantz（1981），Joyce（2001），Leitgeb 和 Pettigrew（2010），Easwaran（2013）。这个想法的一个强大的概括是在 Schervish，Seidenfeld 和 Kadane（2009）中实现的，它建立在使用评分规则实现统计目标的更长传统之上。另一种方法是任何信念的形式化表示必须尊重某些逻辑约束，例如 Cox 提供了一个关于基于部分信念本身的性质来表达信念的论证。

然而，对于难以解释先验假设的问题，最初的主观主义回应来自 De Finetti 的所谓表示定理，该定理表明每个先验分布都可以与其自己的预测集相关联，因此也可以与其自己的行为后果相关联。换句话说，De Finetti 展示了先验确实与可以进行投注解释的信念相关联。

#### 4.3.2 进一步说明：表示定理

De Finetti 的表示定理将预测规则（作为给定样本数据的函数）与贝叶斯统计分析相联系，背景是一个统计模型。有关有用的介绍，请参阅 Festa（1996）和 Suppes（2001）。 De Finetti 考虑生成一系列时间索引观测的过程，然后研究将这些有限段作为输入并返回未来事件概率的预测规则，使用可以分析这些样本并提供预测的统计模型。 De Finetti 的关键结果是，特定的统计模型，即所有分布都是独立同分布的观测的集合，可以与可交换的预测规则类相等，即预测不依赖于观测的顺序。

让我们更详细地考虑表示定理。为简单起见，假设该过程生成时间索引的二进制观测，即 0 和 1。预测规则将长度为 t 的比特串（表示为 St）作为输入，并返回下一个比特串为 1 的事件的概率（表示为 Q1t+1）。因此，我们将预测规则写为部分概率分配 P(Q1t+1∣St)。可交换的预测规则是独立于比特串 St 中比特的顺序而给出相同预测的规则。如果我们将比特串 St 中 1 的总数定义为 Sn/t，则可交换的预测规则可以写为 P(Q1t+1∣Sn/t)。关键属性是预测值不受 0 和 1 在比特串 St 中出现的顺序的影响。

De Finetti 将这个特定的可交换预测规则集与对特定类型的统计模型的贝叶斯推断相关联。 De Finetti 考虑的模型包括所谓的伯努利假设 hθ，即假设为

P(Q1t+1∣hθ∩St)=θ.

这个似然性不依赖于之前的字符串 St。最好将假设视为确定二进制过程的固定偏差θ，其中θ∈Θ=[0,1]。表示定理表明，贝努利假设的先验分布和可交换预测规则之间存在一对一的映射。也就是说，每个先验分布 P(hθ)都可以与一个可交换的预测规则 P(Q1t+1∣Sn/t)关联起来，反之亦然。除了 De Finetti 推导出的原始表示定理之外，还证明了其他几个更一般的表示定理，例如部分可交换序列和马尔可夫过程的假设（Diaconis 和 Freedman 1980，Skyrms 1991），用于聚类预测和分区过程（Kingman 1975 和 1978），甚至用于图形序列及其生成过程（Aldous 1981）。

表示定理将统计假设的先验分布与预测规则等同起来，从而将其赋予了主观和行为解释的概率分配。这消除了上述担忧，即先验分布不能以主观方式解释，因为它不能与作为行动意愿的信念相关联：先验唯一地与特定的预测相关。然而，对于 De Finetti 来说，表示定理提供了一个理由，可以摒弃统计假设，因此也可以将概率的概念除了主观意见之外的其他东西（参见 Hintikka 1970）：可以将其概率性主张视为指涉不可触及的偶然过程的假设是多余的形而上学负担。

并非所有主观主义者对统计假设的使用都持同样的轻视态度。杰弗里（1992）提出了所谓的混合贝叶斯主义，其中将主观解释的假设分布与假设定义的样本空间上的物理解释相结合。罗梅因（2003 年，2005 年，2006 年）认为，对假设的先验是确定归纳预测的一种高效且更直观的方式，而不是直接指定预测系统的属性。使用假设的这种优势似乎与科学实践一致，其中经常使用假设，并且通常是基于对数据生成过程的机械知识的动机。严格来说，统计假设可以被消除，并不减弱它们在进行预测时的实用性。

#### 4.3.3 贝叶斯统计作为逻辑

尽管贝叶斯统计具有不可避免的主观性，但在某种意义上，它可能声称具有客观性。可以证明，贝叶斯形式主义满足某些客观的合理性、一致性和校准性标准。因此，贝叶斯统计在元层面上满足客观性的要求：虽然它处理的观点保留了主观的一面，但它处理这些观点的方式，特别是数据对它们的影响方式，是客观正确的，或者可以这样说。支持贝叶斯处理数据方式的论证是在实用语境中提供的，通过动态荷兰书论证，其中概率被解释为愿意下注的意愿（参见马赫尔 1993 年，范弗拉森 1989 年）。类似的论证也是基于我们的信念必须准确地代表世界的观点，如德·芬内蒂（1974 年）所述，例如格里夫斯和华莱士（2006 年）以及莱特格布和佩蒂格鲁（2010 年）。

在支持贝叶斯证据适应方式的论证中，必须进行一个重要的区分：贝叶斯定理作为一个数学给定和贝叶斯规则作为随时间连贯性原则之间的区别。定理只是概率分配之间的数学关系，

P(h∣s)=P(h)P(s∣h)P(s),

因此不容置疑。支持通过概率分配来表示一个主体的认识状态的论证也为贝叶斯定理作为信念程度的约束提供了支持。条件概率 P(h∣s)可以解释为在获得样本 s 的条件下对假设 h 的信念程度，作为概率分配所捕捉的认识状态的组成部分。相比之下，贝叶斯规则对代表主体在不同时间点的认识状态的概率分配提出了约束。它的表达方式为

Ps(h)=P(h∣s),

并且它确定了新的概率分配，表示样本获得后代理的认知状态与旧的分配有系统关联，表示样本进入之前的认知状态。在统计学哲学中，许多贝叶斯主义者隐含地采用贝叶斯规则，但在接下来的内容中，我只假设贝叶斯统计推断依赖于贝叶斯定理。

无论关注点是贝叶斯规则还是贝叶斯定理，在上述论证中的共同主题是它们从逻辑角度接近贝叶斯统计推断，并关注其内部的一致性或连贯性（参见 Howson 2003）。虽然贝叶斯统计推断在统计学中无疑是归纳的，但贝叶斯推断因此获得了一种演绎的，或者至少是非扩大的特征：推断中得出的一切在前提中已经以某种方式存在。在贝叶斯统计推断中，这些前提由关于假设的先验概率 P(hθ) for θ∈Θ和似然函数 P(s∣hθ)给出，分别为每个假设 hθ确定。这些前提在推断开始时确定了一个单一的概率分配在空间 M×S 上。而结论则是这个概率分配的直接结果。它们可以通过应用概率论定理，尤其是贝叶斯定理来推导出来。因此，贝叶斯统计推断成为概率逻辑的一个实例（参见 Hailperin 1986，Halpern 2003，Haenni et al 2011）。

总结起来，有几个论点表明，通过贝叶斯定理或贝叶斯规则进行统计推断是客观正确的。这些论点邀请我们将贝叶斯统计视为概率逻辑的一个实例。对贝叶斯统计推断的逻辑性的呼吁可能为其主观性提供部分补救。此外，对统计推断的逻辑方法避免了形式主义对代理人提出不切实际的要求，并假设代理人具有某种知识。就像在演绎逻辑中一样，我们不需要假设推断在心理上是真实的，也不需要假设代理人实际上相信论证的前提。相反，这些论证向代理人提出了一种规范理想，并采取条件形式的一致性约束：如果你接受前提，那么这些就是结论。

#### 4.3.4 探讨：归纳逻辑和统计学

概率逻辑的一个重要实例是归纳逻辑，由卡纳普、欣蒂卡等人设计（卡纳普 1950 年和 1952 年，欣蒂卡和苏普斯 1966 年，卡纳普和杰弗里 1970 年，欣蒂卡和尼尼洛托 1980 年，库珀斯 1978 年，巴黎 1994 年，尼克斯和巴黎 2006 年，巴黎和沃特豪斯 2009 年）。从历史上看，卡纳普的归纳逻辑在上述概率逻辑之前发展，并且与统计学哲学的讨论几乎是分开的。但是，卡纳普的逻辑系统可以很容易地放置在贝叶斯推断的逻辑方法的背景下，这样做实际上非常有洞察力。

为简单起见，我们选择一个与表示定理阐述中使用的设置类似的环境，即二进制数据生成过程，即由 0 和 1 组成的字符串。预测规则根据具有长度 t 的给定位串 St，确定事件的概率，表示为 Q1t+1，即下一个位在字符串中为 1 的概率。Carnap 和他的追随者设计了特定的可交换预测规则，大多是直接规则的变体（Reichenbach 1938），

P(Q1t+1∣Sn/t)=n+1t+2,

其中 Sn/t 表示长度为 t 的字符串，其中 n 个条目为 1。Carnap 从对样本的概率分配的约束中推导出这些规则。其中一些约束归结为概率的公理。其他约束，包括可交换性，在逻辑解释概率的呼声下是独立激发的。在这种逻辑解释下，概率分配必须尊重样本空间变换下的某些不变性，类似于约束语言中的真值评估的逻辑原则。

卡尔纳皮安归纳逻辑是概率逻辑的一个实例，因为它的顺序预测都是基于一开始的单一概率分配，并且它依赖于贝叶斯定理来根据样本数据调整预测（参见 Romeijn 2011）。与贝叶斯统计推断的一个重要区别是，对于卡尔纳皮来说，一开始指定的概率分配仅适用于样本，而不适用于假设。然而，根据德芬内蒂的表示定理，卡尔纳皮的可交换规则可以等同于特定的贝叶斯统计推断。另一个区别是，卡尔纳皮的归纳逻辑赋予特定的可交换规则优先地位。根据德芬内蒂的表示定理，这归结为选择特定的优先先验的选择。如下所述，卡尔纳皮的归纳逻辑与客观贝叶斯统计相关。关于概率分配是否可以被视为逻辑的进一步限制，卡尔纳普和他的追随者认为可以，或者是否最好将逻辑的称号保留给孤立的概率形式主义，德芬内蒂和他的追随者提出了不同的观点。

#### 4.3.5 客观先验

对于贝叶斯统计推断的主观性，还有一组对准先验分布直接进行回应的方法：我们可以提供进一步的合理性原则，以便可以客观地选择先验分布。文献中提出了几个关于填充模型先验的客观标准。每个标准都声称是关于模型参数值的完全无知或关于参数的最小信息的正确表达。这里讨论了三个这样的标准。

在伯特兰悖论的背景下，我们已经讨论了无差异原则，即概率应该均匀分布在可用的可能性上。这个思想的进一步发展是要求分布具有最大熵。值得注意的是，熵最大化在确定信念程度方面的应用远不止统计学：类似的思想在不同领域得到了广泛应用，如认识论（例如，Shore 和 Johnson 1980，Williams 1980，Uffink 1996，以及 Williamson 2010）、归纳逻辑（Paris 和 Vencovska 1989）、统计力学（Jaynes 2003）和决策理论（Seidenfeld 1986，Grunwald 和 Halpern 2004）。在客观贝叶斯统计中，这个思想被应用于模型的先验分布（参见 Berger 2006）。对于有限数量的假设，分布 P(hθ)的熵被定义为

 E[P]=∑θ∈ΘP(hθ)logP(hθ)。

这个要求无疑会导致等概率的假设。然而，对于连续模型，最大熵分布在模型参数上的度量关系至关重要。主观性的负担因此转移到了参数化上，但当然我们可能有充分的理由更喜欢某个参数化而不是其他参数化（参见 Jaynes 1973）。

对于先验概率的客观确定还有其他方法。鉴于上述问题，Jeffreys（1961）提出了一种选择连续模型先验的特别有吸引力的方法。所谓的 Jeffreys 先验的一般思想是，分配给参数空间中的一个小区域的先验概率与该区域内分布的密度成比例。直观地说，如果许多分布（即彼此之间有很大差异的分布）被打包在参数空间的一个小区域内，那么与在这个区域内分布变化很小的类似区域相比，这个区域应该被赋予更大的先验概率（参见 Balasubramanian 2005）。从技术上讲，这样的密度由与 Fisher 信息成比例的先验分布表示。这些先验的一个关键优势是它们在参数空间的重新参数化下是不变的：新的参数化自然地导致了调整后的分布密度。

定义先验的最后一种方法被称为参考先验（Berger et al 2009）。该提议从这样的观察开始，即我们应该最小化统计分析结果的主观性，因此应该最小化先验概率对后验的影响。参考先验的思想正是允许样本数据在后验分布中发挥最大的作用。但由于一开始我们不知道将获得什么样的样本，因此先验被选择为最大化数据的预期影响。这个期望本身必须针对样本空间上的某个分布进行，但同样，我们可能有充分的理由选择这个后者分布。

#### 4.3.6 规避先验

对先验主观性的不同回应是扩展贝叶斯形式主义，以便在某种程度上保持先验选择的开放性。在这种情况下，绕过了主观选择先验。将详细考虑两种这样的回应。

请记住，统计假设的先验概率分布表达了我们对哪个假设是正确的的不确定意见。分层贝叶斯模型（Gelman 等人，2013 年）背后的核心思想是，在先验概率分布上放置先验的模式可以在先验本身的层次上重复。更确切地说，我们可能对哪个先验概率分布是正确的存在不确定性。如果我们用一组参数来描述可能的先验，我们可以通过参数的概率分布来表达对先验选择的不确定性，这些参数描述了先验的形状。换句话说，我们将我们的不确定性提升到一个层次：我们考虑多个统计假设的先验，并比较这些先验在样本数据上的表现，就好像这些先验本身是假设一样。

分层贝叶斯建模的思想（Gelman 等人，2013 年）自然地与 Carnapian 预测规则的贝叶斯比较相关（例如，Skyrms，1993 年和 1996 年，Festa，1996 年），也与最佳归纳方法的估计相关（Kuipers，1986 年，Festa，1993 年）。分层贝叶斯建模还可以与选择特定先验分布的另一种工具相关联，即经验贝叶斯方法，该方法估计导致模型边际似然最大化的先验。在科学哲学中，由于 Henderson 等人（2010 年）的出现，分层贝叶斯建模首次亮相。

还有一种回应是完全避免选择先验的选择。这种回应与层次模型的思想相同：我们不再考虑模型中假设的单一先验，而是考虑一个参数化的先验集合。但是，与定义一个分布不同，支持区间值或不精确概率的人声称，我们对先验的认识状态更好地通过这个分布集合来表达，并且尖锐的概率分配因此必须被替换为分配的下界和上界。现在，不确定意见最好由一组概率分配或简称为置信集来捕捉的想法有着悠久的历史，并且得到了广泛的文献支持（例如，De Finetti 1974，Levi 1980，Dempster 1967 和 1968，Shafer 1976，Walley 1991）。鉴于统计学哲学的主要辩论，使用区间值先验确实形成了贝叶斯统计学的有吸引力的扩展：它使我们能够避免选择特定的先验，从而向经典统计学观点靠拢。

这些理论发展可能看起来很有吸引力，但事实上它们在统计学哲学家中主要享有崇拜的地位，并没有影响到街头的统计学家。另一方面，标准贝叶斯统计在过去十年左右的时间里大幅提升了其受欢迎程度，这要归功于良好的软件和数值逼近方法的可用性。而且，贝叶斯统计的大部分实际应用对统计结果的潜在主观因素几乎不敏感，采用均匀先验作为分析的中立起点，并依赖前述的收敛结果来消除剩余的主观性（参见 Gelman 和 Shalizi 2013）。然而，科学家对建模的这种实际态度不应被误解为对统计学哲学中提出的问题的原则性回答（参见 Morey 等人 2013）。

## 5. 统计模型

在前面的内容中，我们已经看到了经典统计学和贝叶斯统计的区别。但是，这两种主要的统计方法也有很多共同之处。最重要的是，所有的统计程序都依赖于统计模型的假设，这里指的是任何一组受限的统计假设。此外，它们都旨在对这些假设做出裁决。例如，经典似然比检验考虑两个假设 h 和 h'，然后给出拒绝和接受的裁决，而贝叶斯比较则给出这两个假设的后验概率。在贝叶斯统计中，模型是一个非常强的假设，而经典统计并没有赋予模型特殊的认识论地位：它们只是科学家目前考虑的假设。但是，在任何统计程序中，采用一个模型都是非常核心的。

一个自然的问题是关于统计模型的质量是否可以有所言论，以及是否可以对统计程序的起点给出任何裁决。肯定有些模型会导致更好的预测，或者更好地指导真相。模型评估涉及到科学哲学中的深层问题，因为统计模型通常决定了研究中的数据生成系统是如何被概念化和处理的（Kieseppa 2001）。模型选择类似于理论、概念方案甚至整个范式的选择，因此似乎超越了研究理论合理性的形式框架（参见 Carnap 1950，Jeffrey 1980）。尽管在模型选择上的一些考虑似乎是超出统计处理范围的，但统计学提供了几种方法来处理统计模型的选择。

### 5.1 模型比较

实际上有很多评估统计模型的方法（Claeskens 和 Hjort 2008，Wagenmakers 和 Waldorp 2006）。首先，这些方法引发了统计模型的比较，但很多时候它们被用于选择一个模型而不是其他模型。接下来，我们只回顾了一些引发了哲学辩论的重要技术：赤池信息准则，贝叶斯信息准则，以及与贝叶斯模型选择相关的边际似然和后验模型概率的计算。我们不讨论使用交叉验证的方法，因为它们在哲学文献中没有得到足够的关注。

#### 5.1.1 赤池信息准则

赤池信息准则，谦称为信息准则或简称为 AIC，基于经典的统计估计过程（参见 Burnham 和 Anderson 2002 年，Kieseppa 1997 年）。它从一个观点出发，即模型 M 可以通过其提供的估计θ^来判断，更具体地说，通过该估计与实际生成数据的分布（即真实分布）之间的接近程度。这种接近程度通常等同于估计的预测准确性的期望，因为如果估计值和真实分布彼此更接近，它们的预测也将更加一致。在推导 AIC 时，使用两个分布的所谓相对熵或库尔巴克-莱布勒散度作为它们接近程度的度量，因此也作为估计的预测准确性的度量。

当然，统计学家评估模型时并不知道真实分布。如果知道的话，整个统计分析将毫无意义。然而，事实证明，我们可以对真实分布与从特定模型估计的分布之间的差异进行无偏估计，

AIC[M]=−2logP(s∣hθ^(s))+2d，

其中 s 是样本数据，θ^(s)是模型 M 的最大似然估计(MLE)，d=dim(Θ)是模型参数空间的维数。模型的 MLE 因此在模型质量的表达中起着概念上与估计函数不同的作用。

如上所示，较小的 AIC 值表示更可取的模型：我们希望在复杂度较低的情况下获得最佳拟合。注意，模型中的维数或独立参数会增加 AIC 值，从而降低模型的可选性：如果两个模型对样本的最大似然估计相同，则较少参数的模型将被优先选择。因此，通过 AIC 进行统计模型选择可以被视为优先选择简单模型而不是复杂模型的独立动机（Sober 和 Forster 1994）。但这个结果也引发了一些批评意见。首先，我们可能会对接近真实值的估计施加除了无偏性之外的其他标准，这将导致不同的近似表达式。此外，对于模型的维数在实际中并不总是清晰明确的。对于曲线拟合来说，这可能很简单，但对于更复杂的模型或不同的模型空间概念化，情况就不那么简单了（参见 Myung 等人 2001 年，Kieseppa 2001 年）。

模型选择的一个典型例子是曲线拟合。给定一个由平面上的一组点(x,y)组成的样本 s，我们被要求选择最适合这些数据的曲线。我们假设考虑的模型是形式为 y=f(x)+ϵ的，其中ϵ是均值为 0 且具有固定标准差的正态分布，f 是一个多项式函数。不同的模型由具有不同参数数量的不同次数的多项式来描述。估计固定这些多项式的参数。例如，对于 0 次多项式 f(x)=c0，我们估计使得数据概率最大的常数 c0<sup>，对于 1 次多项式 f(x)=c0+c1x，我们估计斜率 c1</sup>和偏移量 c0<sup>。现在注意到，对于总共 n 个点，我们总是可以找到一个与所有点都完全相交的 n 次多项式，从而得到一个相对较高的最大似然概率 P(s∣{c0</sup>,…cn<sup>})。然而，应用 AIC，我们通常会发现某个具有次数 k&lt;n 的多项式模型更可取。尽管 P(s∣{c0</sup>,…ck^})会稍低一些，但在 AIC 中通过较少的参数来补偿这一点。

#### 5.1.2 贝叶斯模型评估

其他一些著名的模型选择工具基于贝叶斯统计方法。它们都从一个观点出发，即模型的质量体现在模型在样本数据上的表现：在整体上，使得采样数据最有可能的模型是首选的。因此，与之前提到的层次贝叶斯建模有着密切联系（Gelman 2013）。贝叶斯模型选择工具中的核心概念是模型的边际似然，即使用先验分布作为加权函数对模型的似然进行加权平均：

P(s∣Mi)=∫θ∈ΘiP(hθ)P(s∣hθ)dθ.

这里Θi 是属于模型 Mi 的参数空间。边际似然可以与模型的先验概率 P(Mi)结合起来，使用贝叶斯定理推导出所谓的后验模型概率。一种评估模型的方法，称为贝叶斯模型选择，是通过比较模型的边际似然或者后验概率来进行的（参见 Kass 和 Raftery 1995）。

通常情况下，边际似然无法通过解析方法计算。通常可以获得数值近似，但为了实际目的，使用边际似然的近似已经被证明非常有用且足够。这个近似被称为贝叶斯信息准则，简称 BIC（Schwarz 1978，Raftery 1995）。事实证明，这个近似与 AIC 有着显著的相似性：

BIC[M]=−2logP(s∣hθ^(s))+dlogn.

这里的θ^(s)再次是模型的最大似然估计，d=dim(M)是独立参数的数量，n 是样本中的数据点数量。后者的依赖是与 AIC 的唯一区别，但在模型评估的结果可能会有很大的差异。

AIC 和 BIC 的一致性似乎进一步证明了我们对简单模型优于复杂模型的直观偏好。实际上，其他模型选择工具，如偏差信息准则（Spiegelhalter 等人，2002 年）和基于最小描述长度的方法（Grunwald，2007 年），也会得到惩罚复杂模型的表达式。然而，这并不意味着我们从信息准则中了解到的维度项就穷尽了模型复杂性的概念。在科学哲学中，关于模型选择在简洁性、信息性等概念阐释中的优点存在着持续的辩论（例如，Sober，2004 年；Romeijn 和 van de Schoot，2008 年；Romeijn 等人，2012 年；Sprenger，2013 年）。

### 5.2 没有模型的统计学

还有一些统计方法不使用特定的模型，而是仅仅专注于数据或者对所有可能的模型进行概括。其中一些技术被正确地归类为描述统计学：它们不涉及从数据中推断，而仅仅用于以特定方式描述数据。不依赖于明确模型选择的统计方法在统计学哲学中很不幸没有引起太多关注，但为了完整起见，在这里将简要讨论它们。

#### 5.2.1 数据简化技术

一组方法，对于许多实践统计学家来说非常重要，旨在进行数据降维。通常，样本数据非常丰富，例如，由很多维度空间中的一组点组成。统计分析的第一步可能是从数据中提取出显著的变异性，以便减少分析本身的计算负担。

主成分分析（PCA）技术就是为此目的而设计的（Jolliffe 2002）。给定一个空间中的一组点，它寻找点的变异性较大的一组向量。例如，考虑一个平面上的两个点，参数化为（x，y）：点（0，0）和（1，1）。在 x 方向和 y 方向上的变异性为 1，但在对角线上的变异性最大，即 2-√。对角线上的向量称为数据的主成分。在更丰富的数据结构中，使用更一般的点之间变异性度量，我们可以以类似的方式找到第一个主成分。此外，我们可以在减去沿最后找到的主成分的变异性后重复该过程，通过将数据投影到与该主成分垂直的平面上。这使我们能够建立起一组逐渐减小重要性的主成分。

PCA 只是一系列旨在使数据可管理并找到其中模式的技术中的一个项目，该系列还包括核方法和支持向量机（例如，Vapnik 和 Kotz 2006）。对于目前的目的而言，重要的是强调这些工具不应与统计分析混淆：它们不涉及对样本空间上的分布进行测试或评估，尽管它们构建和评估数据模型。这使它们与确认性和探索性因子分析（Bartholomew 2008）有所区别，后者有时被认为是 PCA 的近亲，因为这两组技术都允许我们在样本空间中识别显著的维度，沿着这些维度，数据显示出较大的变化。

实践统计学家经常使用数据降维工具来得出关于数据抽样自哪些分布的结论。在科学领域，机器学习和数据挖掘技术已经被广泛使用，我们可以预期在未来这些技术的使用将更加普遍，因为现在有大量的数据可供科学分析。然而，在统计学哲学中，对通过这些技术得出的结论的认识论地位尚未进行深入讨论。统计学哲学家们应该在这方面多加关注。

#### 5.2.2 形式学习理论

统计学的完全不同的方法是由形式学习理论提出的。这是一个广阔的研究领域，主要位于计算机科学和人工智能领域。这里简要提到了这门学科，作为另一种避免选择统计模型的统计学方法的例子，它仅仅识别数据中的模式。我们暂且不谈神经网络理论，因为它也涉及到不依赖统计模型的预测系统，而是专注于学习算法理论，因为在所有这些方法中，它们受到了最多的哲学关注。

索洛蒙诺夫（Solomonoff）在形式学习方面进行了开创性的工作（1964 年）。与之前一样，设置是数据由 0 和 1 的字符串组成，代理人试图识别这些数据中的模式。例如，数据可以是形如 0101010101…的字符串，挑战是将其识别为交替序列。索洛蒙诺夫的核心思想是代理人必须考虑所有可能的可计算模式，因此不需要对统计假设进行限制性选择。索洛蒙诺夫随后定义了一个形式系统，在这个系统中，实际上可以考虑所有的模式，有效地使用了一个巧妙构造的先验概率对所有可计算的假设进行贝叶斯分析。

这个普遍的想法也可以在贝叶斯统计学和机器学习的交叉领域中找到，即贝叶斯非参数统计学（例如，Orbanz 和 Teh 2010，Hjort 等 2010）。与其在一开始指定一个有限的分布集合，然后根据数据选择统计分析，这个想法是将数据与可能的无限维分布空间进行对比。然后，考虑的分布集合与获得的数据相关：模型的复杂性随样本的增加而增加。结果是一个预测系统，它在贝叶斯后验模型的同时进行在线模型选择。

当前的形式学习理论是一个活跃的领域，统计学哲学家也在其中做出贡献（例如，Kelly 1996，Kelly 等 1997）。对于目前的关注点来说，特别重要的是，形式学习系统被设置为实现某种适当的普遍预测，而不限制于特定的假设集合，并且对数据中可能的模式集合施加最小的约束。这是否可能是一个有争议的问题，以及形式学习理论的预测在多大程度上依赖于样本空间结构的隐含假设。对此的哲学反思还处于初级阶段。

## 6. 相关主题

在统计学哲学中，有许多与本词条涵盖的主题直接相关的话题。这里提到了一些核心话题，以引导读者前往百科全书中相关的词条。

与统计学哲学紧密相关的一个非常重要的话题是确认理论，这是一种描述和证明科学理论与经验证据之间关系的哲学理论。可以说，统计学理论是确认理论的一部分，因为它描述和证明了统计理论与样本形式的证据之间的关系。将统计程序置于证据和理论之间的更广泛框架中，可能会有洞察力。进一步放大视野，统计学哲学是方法论的一部分，即关于科学如何获取知识的一般理论。因此，统计学被看作是一个包括概念形成、实验设计、操作和观察、确认、修订和理论化在内的大量科学方法的组成部分。

统计学哲学中还有许多特定的科学哲学主题，这些主题以统计学术语来阐述，或者与统计学密切相关。其中一个主题是测量过程，特别是基于统计事实对潜变量进行测量。所谓的表示性测量理论（Kranz 等人，1971 年）依赖于统计学，特别是因子分析，来概念上阐明数学结构如何表示经验现象。科学哲学中的另一个重要主题是因果关系（参见概率因果关系和 Reichenbach 的共同原因原则的条目）。自 Reichenbach（1956 年）以来，哲学家们一直使用概率论来捕捉因果关系，但是因果关系和统计学的最新研究（例如 Spirtes 等人，2001 年）给了概率因果关系理论巨大的推动力。在这里，统计学再次为因果关系的概念分析提供了基础。

还有更多内容。几种特定的统计技术，如因子分析和贝叶斯网络理论，本身就引发了概念讨论。科学哲学中的许多主题都适合进行统计阐释，例如证据的一致性、信息性和意外性。反过来，科学哲学中的许多讨论也有助于正确理解统计学。其中包括关于实验和干预的争论、机会的概念、科学模型的性质和理论术语。读者可以查阅有关这些主题的条目，以进一步了解它们与统计学哲学的关系。

<!--md-padding-ignore-begin-->
## Bibliography

* Aldous, D.J., 1981, “Representations for Partially Exchangeable Arrays of Random Variables”, *Journal of Multivariate Analysis*, 11: 581–598.
* Armendt, B., 1993, “Dutch books, Additivity, and Utility Theory”, *Philosophical Topics*, 21:1–20.
* Auxier, R.E., and L.E. Hahn (eds.), 2006, *The Philosophy of Jaakko Hintikka*, Chicago: Open Court.
* Balasubramanian, V., 2005, “MDL, Bayesian inference, and the geometry of the space of probability distributions”, in: Advances in Minimum Description Length: Theory and Applications, P.J. Grunwald et al (eds.), Boston: MIT Press, 81–99.
* Bandyopadhyay, P., and Forster, M. (eds.), 2011, Handbook for the Philosophy of Science: Philosophy of Statistics, Elsevier.
* Barnett, V., 1999, *Comparative Statistical Inference*, Wiley Series in Probability and Statistics, New York: Wiley.
* Bartholomew, D.J., F. Steele, J. Galbraith, I. Moustaki, 2008, *Analysis of Multivariate Social Science Data*, Statistics in the Social and Behavioral Sciences Series, London: Taylor and Francis, 2nd edition.
* Berger, J. 2006, “The Case for Objective Bayesian Analysis”, *Bayesian Analysis*, 1(3): 385–402.
* Berger, J.O., J.M. Bernardo, and D. Sun, 2009, “The formal definition of reference priors”, *Annals of Statistics*, 37(2): 905–938.
* Berger, J.O., and R.L. Wolpert, 1984, *The Likelihood Principle*. Hayward (CA): Institute of Mathematical Statistics.
* Berger, J.O. and T. Sellke, 1987, “Testing a point null hypothesis: The irreconciliability of P-values and evidence”, *Journal of the American Statistical Association*, 82: 112–139.
* Bernardo, J.M. and A.F.M. Smith, 1994, *Bayesian Theory*, New York: John Wiley.
* Bigelow, J. C., 1977, “Semantics of probability”, *Synthese*, 36(4): 459–72.
* Billingsley, P., 1995, *Probability and Measure*, Wiley Series in Probability and Statistics, New York: Wiley, 3rd edition.
* Birnbaum, A., 1962, “On the Foundations of Statistical Inference”, *Journal of the American Statistical Association*, 57: 269–306.
* Blackwell, D. and L. Dubins, 1962, “Merging of Opinions with Increasing Information”, *Annals of Mathematical Statistics*, 33(3): 882–886.
* Boole, G., 1854, *An Investigation of The Laws of Thought on Which are Founded the Mathematical Theories of Logic and Probabilities*, London: Macmillan, reprinted 1958, London: Dover.
* Burnham, K.P. and D.R. Anderson, 2002, *Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach*, New York: Springer, 2nd edition.
* Carnap, R., 1950, *Logical Foundations of Probability*, Chicago: The University of Chicago Press.
* –––, 1952, *The Continuum of Inductive Methods*, Chicago: University of Chicago Press.
* Carnap, R. and Jeffrey, R.C. (eds.), 1970, *Studies in Inductive Logic and Probability*, Volume I, Berkeley: University of California Press.
* Casella, G., and R. L. Berger, 1987, “Reconciling Bayesian and Frequentist Evidence in the One-Sided Testing Problem”, *Journal of the American Statistical Association*, 82: 106–111.
* Claeskens, G. and N. L. Hjort, 2008, *Model selection and model averaging*, Cambridge: Cambridge University Press.
* Cohen, J., 1994, “The Earth is Round (p < .05)”, *American Psychologist*, 49: 997–1001.
* Cox, R.T., 1961, *The Algebra of Probable Inference*, Baltimore: John Hopkins University Press.
* Cumming, G., 2012, *Understanding The New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis*, New York: Routledge.
* Dawid, A.P., 1982, “The Well-Calibrated Bayesian”, *Journal of the American Statistical Association*, 77(379): 605–610.
* –––, 2004, “Probability, causality and the empirical world: A Bayes-de Finetti-Popper-Borel synthesis”, *Statistical Science*, 19: 44–57.
* Dawid, A.P. and P. Grunwald, 2004, “Game theory, maximum entropy, minimum discrepancy, and robust Bayesian decision theory”, *Annals of Statistics*, 32: 1367–1433.
* Dawid, A.P. and M. Stone, 1982, “The functional-model basis of fiducial inference”, *Annals of Statistics*, 10: 1054–1067.
* De Finetti, B., 1937, “La Prévision: ses lois logiques, ses sources subjectives”, *Annales de l'Institut Henri Poincaré*, reprinted as “Foresight: its Logical Laws, Its Subjective Sources”, in: Kyburg, H. E. and H. E. Smokler (eds.), *Studies in Subjective Probability*, 1964, New York: Wiley.
* –––, 1974, *Theory of Probability*, Volumes I and II, New York: Wiley, translation by A. Machi and A.F.M. Smith.
* De Morgan, A., 1847, *Formal Logic or The Calculus of Inference*, London: Taylor & Walton, reprinted by London: Open Court, 1926.
* Dempster, A.P., 1964, “On the Difficulties Inherent in Fisher's Fiducial Argument”, *Journal of the American Statistical Association*, 59: 56–66.
* –––, 1966, “New Methods for Reasoning Towards Posterior Distributions Based on Sample Data”, *Annals of Mathematics and Statistics*, 37(2): 355–374.
* –––, 1967, “Upper and lower probabilities induced by a multivalued mapping”, *The Annals of Mathematical Statistics*, 38(2): 325–339.
* –––, 1968, “A generalization of Bayesian inference”, *Journal of the Royal Statistical Society*, Series B, Vol. 30: 205–247.
* Diaconis, P., and D. Freedman, 1980, “De Finetti’s theorem for Markov chains”, *Annals of Probability*, 8: 115–130.
* Eagle, A. (ed.), 2010, *Philosophy of Probability: Contemporary Readings*, London: Routledge.
* Earman, J., 1992, *Bayes or Bust? A Critical Examination of Bayesian Confirmation Theory*, Cambridge (MA): MIT Press.
* Easwaran, K., 2013, “Expected Accuracy Supports Conditionalization - and Conglomerability and Reflection”, *Philosophy of Science*, 80(1): 119–142.
* Edwards, A.W.F., 1972, *Likelihood*, Cambridge: Cambridge University Press.
* Efron, B. and R. Tibshirani, R., 1993, *An Introduction to the Bootstrap*, Boca Raton (FL): Chapman & Hall/CRC.
* Festa, R., 1993, *Optimum Inductive Methods*, Dordrecht: Kluwer.
* –––, 1996, “Analogy and exchangeability in predictive inferences”, *Erkenntnis*, 45: 89–112.
* Fisher, R.A., 1925, *Statistical Methods for Research Workers*, Edinburgh: Oliver and Boyd.
* –––, 1930, “Inverse probability”, *Proceedings of the Cambridge Philosophical Society*, 26: 528–535.
* –––, 1933, “The concepts of inverse probability and fiducial probability referring to unknown parameters”, *Proceedings of the Royal Society*, Series A, 139: 343–348.
* –––, 1935a, “The logic of inductive inference”, *Journal of the Royal Statistical Society*, 98: 39–82.
* –––, 1935b, *The Design of Experiments*, Edinburgh: Oliver and Boyd.
* –––, 1935c, “The fiducial argument in statistical inference”, *Annals of Eugenics*, 6: 317–324.
* –––, 1955, “Statistical Methods and Scientific Induction”, *Journal of the Royal Statistical Society*, B 17: 69–78.
* –––, 1956, *Statistical Methods and Scientific Inference*, New York: Hafner, 3rd edition 1973.
* Fitelson, B., 2007, “Likelihoodism, Bayesianism, and relational confirmation”, *Synthese*, 156(3): 473–489.
* Forster, M. and E. Sober, 1994, “How to Tell when Simpler, More Unified, or Less Ad Hoc Theories will Provide More Accurate Predictions”, *British Journal for the Philosophy of Science*, 45: 1–35.
* Fraassen, B. van, 1989, *Laws and Symmetry*, Oxford: Clarendon Press.
* Gaifman, H. and M. Snir, 1982, “Probabilities over Rich Languages”, *Journal of Symbolic Logic*, 47: 495–548.
* Galavotti, M. C., 2005, *Philosophical Introduction to Probability*, Stanford: CSLI Publications.
* Gelman, A., J. Carlin, H. Stern, D. Dunson, A. Vehtari, and D. Rubin, 2013, *Bayesian Data Analysis*, revised edition, New York: Chapman & Hall/CRC.
* Gelman, A., and C. Shalizi, 2013, “Philosophy and the practice of Bayesian statistics (with discussion)”, *British Journal of Mathematical and Statistical Psychology*, 66: 8–18.
* Giere, R. N., 1976, “A Laplacean Formal Semantics for Single-Case Propensities”, *Journal of Philosophical Logic*, 5(3): 321–353.
* Gillies, D., 1971, “A Falsifying Rule for Probability Statements”, *British Journal for the Philosophy of Science*, 22: 231–261.
* –––, 2000, *Philosophical Theories of Probability*, London: Routledge.
* Goldstein, M., 2006, “Subjective Bayesian analysis: principles and practice”, *Bayesian Analysis*, 1(3): 403–420.
* Good, I.J., 1983, *Good Thinking: The Foundations of Probability and Its Applications*, University of Minnesota Press, reprinted London: Dover, 2009.
* –––, 1988, “The Interface Between Statistics and Philosophy of Science”, *Statistical Science*, 3(4): 386–397.
* Goodman, N., 1965, *Fact, Fiction and Forecast*, Indianapolis: Bobbs-Merrill.
* Greaves, H. and D. Wallace, 2006, “Justifying Conditionalization: Conditionalization Maximizes Expected Epistemic Utility”, *Mind*, 115(459): 607–632.
* Greco, D., 2011, “Significance Testing in Theory and Practice”, *British Journal for the Philosophy of Science*, 62: 607–37.
* Grünwald, P.D., 2007, *The Minimum Description Length Principle*, Boston: MIT Press.
* Hacking, I.,1965, The Logic of Statistical Inference, Cambridge: Cambridge University Press.
* Haenni, R., Romeijn, J.-W., Wheeler, G., Andrews, J., 2011, *Probabilistic Logics and Probabilistic Networks*, Berlin: Springer.
* Hailperin, T., 1996, *Sentential Probability Logic*, Lehigh University Press.
* Hájek, A., 2007, “The reference class problem is your problem too”, *Synthese*, 156: 563–585.
* Hajek, A. and C. Hitchcock (eds.), 2013, *Oxford Handbook of Probability and Philosophy*, Oxford: Oxford University Press.
* Halpern, J.Y., 2003, *Reasoning about Uncertainty*, MIT press.
* Handfield, T., 2012, *A Philosophical Guide to Chance: Physical Probability*, Cambridge: Cambridge University Press.
* Harlow, L.L., S.A. Mulaik, and J.H. Steiger, (eds.), 1997, *What if there were no significance tests?*, Mahwah (NJ): Erlbaum.
* Henderson, L., N.D. Goodman, J.B. Tenenbaum, and J.F. Woodward, 2010, “The Structure and Dynamics of Scientific Theories: A Hierarchical Bayesian Perspective”, *Philosophy of Science*, 77(2): 172–200.
* Hjort, N., C. Holmes, P. Mueller, and S. Walker (eds.), 2010, *Bayesian Nonparametrics*, Cambridge Series in Statistical and Probabilistic Mathematics, nr. 28, Cambridge: Cambridge University Press.
* Howson, C., 2000, *Hume's problem: induction and the justification of belief*, Oxford: Oxford University Press.
* –––, 2003, “Probability and logic”, *Journal of Applied Logic*, 1(3–4): 151–165.
* –––, 2011, “Bayesianism as a pure logic of Inference”, in: Bandyopadhyay, P and Foster, M, (eds.), *Philosophy of statistics, Handbook of the Philosophy of Science*, Oxford: North Holland, 441–472.
* Howson, C. and P. Urbach, 2006, *Scientific Reasoning: The Bayesian Approach*, La Salle: Open Court, 3rd edition.
* Hintikka, J., 1970, “Unknown Probabilities, Bayesianism, and de Finetti's Representation Theorem”, in *Proceedings of the Biennial Meeting of the Philosophy of Science Association*, Vol. 1970, Boston: Springer, 325–341.
* Hintikka, J. and I. Niiniluoto, 1980, “An axiomatic foundation for the logic of inductive generalization”, in R.C. Jeffrey (ed.), *Studies in Inductive Logic and Probability*, volume II, Berkeley: University of California Press, 157–181.
* Hintikka J. and P. Suppes (eds.), 1966, *Aspects of Inductive Logic*, Amsterdam: North-Holland.
* Hume, D., 1739, *A Treatise of Human Nature*, [available online](http://www.earlymoderntexts.com/authors/hume.html).
* Jaynes, E.T., 1973, “The Well-Posed Problem”, *Foundations of Physics*, 3: 477–493.
* –––, 2003, *Probability Theory: The Logic of Science*, Cambridge: Cambridge University Press. [first 3 chapters available online](http://bayes.wustl.edu/etj/prob/book.pdf).
* Jeffrey, R., 1992, *Probability and the Art of Judgment*, Cambridge: Cambridge University Press.
* Jeffreys, H., 1961, *Theory of Probability*, Oxford: Clarendon Press, 3rd edition.
* Jolliffe, I.T., 2002, *Principal Component Analysis*, New York: Springer, 2nd edition.
* Kadane, J.B., 2011, *Principles of Uncertainty*, London: Chapman and Hall.
* Kadane, J.B., M.J. Schervish, and T. Seidenfeld, 1996, “When Several Bayesians Agree That There Will Be No Reasoning to a Foregone Conclusion”, *Philosophy of Science*, 63: S281-S289.
* –––, 1996, “Reasoning to a Foregone Conclusion”, *Journal of the American Statistical Association*, 91(435): 1228–1235.
* Kass, R. and A. Raftery, 1995, “Bayes Factors”, *Journal of the American Statistical Association*, 90: 773–790.
* Kelly, K., 1996, *The Logic of Reliable Inquiry*, Oxford: Oxford University Press.
* Kelly, K., O. Schulte, and C. Juhl, 1997, “Learning Theory and the Philosophy of Science”, *Philosophy of Science*, 64: 245–67.
* Keynes, J.M., 1921, *A Treatise on Probability*, London: Macmillan.
* Kieseppä, I. A., 1997, “Akaike Information Criterion, Curve-Fitting, and the Philosophical Problem of Simplicity”, *British Journal for the Philosophy of Science*, 48(1): 21–48.
* –––, 2001, “Statistical Model Selection Criteria and the Philosophical Problem of Underdetermination”, *British Journal for the Philosophy of Science*, 52(4): 761–794.
* Kingman, J.F.C., 1975, “Random discrete distributions”, *Journal of the Royal Statistical Society*, 37: 1–22.
* –––, 1978, “Uses of exchangeability”, *Annals of Probability*, 6(2): 183–197.
* Kolmogorov, A.N., 1933, *Grundbegriffe der Wahrscheinlichkeitsrechnung*, Berlin: Julius Springer.
* Krantz, D. H., R. D. Luce, A. Tversky and P. Suppes, 1971, *Foundations of Measurement*, Volumes I and II. Mineola: Dover Publications.
* Kuipers, T.A.F., 1978, *Studies in Inductive Probability and Rational Expectation*, Dordrecht: Reidel.
* –––, 1986, “Some estimates of the optimum inductive method”, *Erkenntnis*, 24: 37–46.
* Kyburg, Jr., H.E., 1961, *Probability and the Logic of Rational Belief*, Middletown (CT): Wesleyan University Press.
* Kyburg, H.E. Jr. and C.M. Teng, 2001, *Uncertain Inference*, Cambridge: Cambridge University Press.
* van Lambalgen, M., 1987, *Random sequences*, Ph.D. dissertation, Department of Mathematics and Computer Science, University of Amsterdam, [available online](https://eprints.illc.uva.nl/id/eprint/1840).
* Leitgeb, H. and Pettigrew, R., 2010a, “An Objective Justification of Bayesianism I: Measuring Inaccuracy”, *Philosophy of Science*, 77(2): 201–235.
* –––, 2010b, “An Objective Justiﬁcation of Bayesianism II: The Consequences of Minimizing Inaccuracy”, *Philosophy of Science*, 77(2): 236–272.
* Levi, I., 1980, *The enterprise of knowledge: an essay on knowledge, credal probability, and chance*, Cambridge MA: MIT Press.
* Lindley, D.V., 1957, “A statistical paradox”, *Biometrika*, 44: 187–192.
* –––, 1965, *Introduction to Probability and Statistics from a Bayesian Viewpoint*, Vols. I and II, Cambridge: Cambridge University Press.
* –––, 2000, “The Philosophy of Statistics”, *Journal of the Royal Statistical Society*, D (The Statistician), Vol. 49(3): 293–337.
* Mackay, D.J.C., 2003, *Information Theory, Inference, and Learning Algorithms*, Cambridge: Cambridge University Press.
* Maher, P., 1993, *Betting on Theories*, Cambridge Studies in Probability, Induction and Decision Theory, Cambridge: Cambridge University Press.
* Mayo, D.G., 1996, *Error and the Growth of Experimental Knowledge*, Chicago: The University of Chicago Press.
* –––, 2010, An error in the argument from conditionality and sufficiency to the likelihood principle, in: D. Mayo, A. Spanos (eds.), Error and Inference: Recent exchanges on experimental reasoning, reliability, and the objectivity and rationality of science, pp. 305–314, Cambridge: Cambridge University Press.
* Mayo, D.G., and A. Spanos, 2006, “Severe Testing as a Basic Concept in a Neyman-Pearson Philosophy of Induction”, *The British Journal for the Philosophy of Science*, 57: 323–357.
* –––, 2011, “Error Statistics”, in P.S. Bandyopadhyay and M.R. Forster, *Philosophy of Statistics, Handbook of the Philosophy of Science*, Vol. 7, Elsevier.
* Mellor, D. H., 2005, *The Matter of Chance*, Cambridge: Cambridge University Press.
* –––, 2005, *Probability: A Philosophical Introduction*, London: Routledge.
* von Mises, R., 1981, *Probability, Statistics and Truth*, 2nd revised English edition, New York: Dover.
* Mood, A. M., F. A. Graybill, and D. C. Boes, 1974, *Introduction to the Theory of Statistics*, Boston: McGraw-Hill.
* Morey, R., J.W. Romeijn and J. Rouder, 2013, “The Humble Bayesian”, *British Journal of Mathematical and Statistical Psychology*, 66(1): 68–75.
* Myung, J., V. Balasubramanian, and M.A. Pitt, 2000, “Counting probability distributions: Differential geometry and model selection”, *Proceedings of the National Academy of Sciences*, 97(21): 11170–11175.
* Nagel, T., 1939, *Principles of the Theory of Probability*, Chicago: University of Chicago Press.
* Neyman, J., 1957, “Inductive Behavior as a Basic Concept of Philosophy of Science”, *Revue Institute Internationale De Statistique*, 25: 7–22.
* –––, 1971, Foundations of Behavioristic Statistics, in: V. Godambe and D. Sprott (eds.), Foundations of Statistical Inference, Toronto: Holt, Rinehart and Winston of Canada, pp. 1–19.
* Neyman, J. and K. Pearson, 1928, “On the use and interpretation of certain test criteria for purposes of statistical inference”, *Biometrika*, A20:175–240 and 264–294.
* Neyman, J. and E. Pearson, 1933, “On the problem of the most efficient tests of statistical hypotheses”, *Philosophical Transactions of the Royal Society*, A 231: 289–337
* –––, 1967, *Joint Statistical Papers*, Cambridge: Cambridge University Press.
* Nix, C. J. and J. B. Paris, 2006, “A continuum of inductive methods arising from a generalised principle of instantial relevance”, *Journal of Philosophical Logic*, 35: 83–115.
* Orbanz, P. and Y.W. Teh, 2010, “Bayesian Nonparametric Models”, *Encyclopedia of Machine Learning*, New York: Springer.
* Paris, J.B., 1994, *The uncertain reasoner’s companion*, Cambridge: Cambridge University Press.
* Paris, J.B. and A. Vencovska, 1989, “On the applicability of maximum entropy to inexact reasoning”, *International Journal of Approximate Reasoning*, 4(3): 183–224.
* Paris, J., and P. Waterhouse, 2009, “Atom exchangeability and instantial relevance, atom exchangeability and instantial relevance”, *Journal of Philosophical Logic*, 38(3): 313–332.
* Peirce, C. S., 1910, “Notes on the Doctrine of Chances”, in C. Hartshorne and P. Weiss (eds.), *Collected Papers of Charles Sanders Peirce*, Vol. 2, Cambridge MA: Harvard University Press, 405–14, reprinted 1931.
* Plato, J. von, 1994, *Creating Modern Probability*, Cambridge: Cambridge University Press.
* Popper, K.R., 1934/1959, *The Logic of Scientific Discovery*, New York: Basic Books.
* –––, 1959, “The Propensity Interpretation of Probability”, *British Journal of the Philosophy of Science*, 10: 25–42.
* Predd, J.B., R. Seiringer, E.H. Lieb, D.N. Osherson, H.V. Poor, and S.R. Kulkarni, 2009, “Probabilistic Coherence and Proper Scoring Rules”, *IEEE Transactions on Information Theory*, 55(10): 4786–4792.
* Press, S. J., 2002, *Bayesian Statistics: Principles, Models, and Applications* (Wiley Series in Probability and Statistics), New York: Wiley.
* Raftery, A.E., 1995, “Bayesian model selection in social research”, *Sociological Methodology*, 25: 111–163.
* Ramsey, F.P., 1926, “Truth and Probability”, in R.B. Braithwaite (ed.), *The Foundations of Mathematics and other Logical Essays*, Ch. VII, p.156–198, printed in London: Kegan Paul, 1931.
* Reichenbach, H., 1938, *Experience and prediction: an analysis of the foundations and the structure of knowledge*, Chicago: University of Chicago Press.
* –––, 1949, *The theory of probability*, Berkeley: University of California Press.
* –––, 1956, *The Direction of Time*, Berkeley: University of Los Angeles Press.
* Renyi, A., 1970, *Probability Theory*, Amsterdam: North Holland.
* Robbins, H., 1952, “Some Aspects of the Sequential Design of Experiments”, *Bulletin of the American Mathematical Society*, 58: 527–535.
* Roberts, H.V., 1967, “Informative stopping rules and inferences about population size”, *Journal of the American Statistical Association*, 62(319): 763–775.
* Romeijn, J.W., 2004, “Hypotheses and Inductive Predictions”, *Synthese*, 141(3): 333–364.
* –––, 2005, *Bayesian Inductive Logic*, PhD dissertation, University of Groningen.
* –––, 2006, “Analogical Predictions for Explicit Similarity”, *Erkenntnis*, 64: 253–280.
* –––, 2011, “Statistics as Inductive Logic”, in Bandyopadhyay, P. and M. Forster (eds.), *Handbook for the Philosophy of Science*, Vol. 7: Philosophy of Statistics, 751–774.
* Romeijn, J.W. and van de Schoot, R., 2008, “A Philosophical Analysis of Bayesian model selection”, in Hoijtink, H., I. Klugkist and P. Boelen (eds.), *Null, Alternative and Informative Hypotheses*, 329–357.
* Romeijn, J.W., van de Schoot, R., and Hoijtink, H., 2012, “One size does not fit all: derivation of a prior-adapted BIC”, in Dieks, D., W. Gonzales, S. Hartmann, F. Stadler, T. Uebel, and M. Weber (eds.), *Probabilities, Laws, and Structures*, Berlin: Springer.
* Rosenkrantz, R.D., 1977, *Inference, method and decision: towards a Bayesian philosophy of science*, Dordrecht: Reidel.
* –––, 1981, *Foundations and Applications of Inductive Probability*, Ridgeview Press.
* Royall, R., 1997, *Scientific Evidence: A Likelihood Paradigm*, London: Chapman and Hall.
* Savage, L.J., 1962, *The foundations of statistical inference*, London: Methuen.
* Schervish, M.J., T. Seidenfeld, and J.B. Kadane, 2009, “Proper Scoring Rules, Dominated Forecasts, and Coherence”, *Decision Analysis*, 6(4): 202–221.
* Schwarz, G., 1978, “Estimating the Dimension of a Model”, *Annals of Statistics*, 6: 461–464.
* Seidenfeld, T., 1979, *Philosophical Problems of Statistical Inference: Learning from R.A. Fisher*, Dordrecht: Reidel.
* –––, 1986, “Entropy and uncertainty”, *Philosophy of Science*, 53(4): 467–491.
* –––, 1992, “R.A. Fisher's Fiducial Argument and Bayes Theorem”, *Statistical Science*, 7(3): 358–368.
* Shafer, G., 1976, *A Mathematical Theory of Evidence*, Princeton: Princeton University Press.
* –––, 1982, “On Lindley’s paradox (with discussion)”, *Journal of the American Statistical Association*, 378: 325–351.
* Shore, J. and Johnson, R., 1980, “Axiomatic derivation of the principle of maximum entropy and the principle of minimum cross-entropy”, *IEEE Transactions on Information Theory*, 26(1): 26–37.
* Skyrms, B., 1991, “Carnapian inductive logic for Markov chains”, *Erkenntnis*, 35: 439–460.
* –––, 1993, “Analogy by similarity in hypercarnapian inductive logic”, in Massey, G.J., J. Earman, A.I. Janis and N. Rescher (eds.), *Philosophical Problems of the Internal and External Worlds: Essays Concerning the Philosophy of Adolf Gruenbaum*, Pittsburgh: Pittsburgh University Press, 273–282.
* –––, 1996, “Carnapian inductive logic and Bayesian statistics”, in: Ferguson, T.S., L.S. Shapley, and J.B. MacQueen (eds.), *Statistics, Probability, and Game Theory: papers in honour of David Blackwell*, Hayward: IMS lecture notes, 321–336.
* –––, 1999, *Choice and Chance: An Introduction to Inductive Logic*, Wadsworth, 4th edition.
* Sober, E., 2004, “Likelihood, model selection, and the Duhem-Quine problem”, *Journal of Philosophy*, 101(5): 221–241.
* Spanos, A., 2010, “Is Frequentist Testing Vulnerable to the Base-Rate Fallacy?”, *Philosophy of Science*, 77: 565-583.
* –––, 2013a, “Who should be afraid of the Jeffreys–Lindley paradox?”, *Philosophy of Science*, 80: 73–93.
* –––, 2013b, “A frequentist interpretation of probability for model-based inductive inference”, *Synthese*, 190: 1555–1585.
* Spiegelhalter, D.J., N.G. Best, B.P. Carlin, and A. van der Linde, 2002, “Bayesian measures of model complexity and fit”, *Journal of Royal Statistical Society*, B 64: 583–639.
* Spielman, S., 1974, “The Logic of Significance Testing”, *Philosophy of Science*, 41: 211–225.
* –––, 1978, “Statistical Dogma and the Logic of Significance Testing”, *Philosophy of Science*, 45: 120–135.
* Sprenger, J., 2013, “The role of Bayesian philosophy within Bayesian model selection”, *European Journal for Philosophy of Science*, 3(1): 101–114.
* –––, forthcoming-a, “Bayesianism vs. Frequentism in Statistical Inference”, in Hajek, A. and C. Hitchcock (eds.), *Oxford Handbook of Probability and Philosophy*, Oxford: Oxford University Press.
* –––, forthcoming-b, “Testing a precise null hypothesis: The case of Lindley’s paradox”, *Philosophy of Science*.
* Spirtes, P., Glymour, C. and Scheines, R., 2001, *Causation, Prediction, and Search*, Boston: MIT press, 2nd edition.
* Solomonoff, R.J., 1964, “A formal theory of inductive inference”, parts I and II, *Information and Control*, 7: 1–22 and 224–254.
* Steele, K., 2013, “Persistent experimenters, stopping rules, and statistical inference”, *Erkenntnis*, 78(4): 937–961.
* Suppes, P., 2001, *Representation and Invariance of Scientific Structures*, Chicago: University of Chicago Press.
* Uffink, J., 1996, “The constraint rule of the maximum entropy principle”, *Studies in History and Philosophy of Modern Physics*, 27: 47–79.
* Vapnik, V.N. and S. Kotz, 2006, *Estimation of Dependences Based on Empirical Data*, New York: Springer.
* Venn, J., 1888, *The Logic of Chance*, London: MacMillan, 3rd edition.
* Wagenmakers, E.J., 2007, “A practical solution to the pervasive problems of p values”, Psychonomic Bulletin and Review 14(5), 779–804.
* Wagenmakers, E.J., and L.J. Waldorp, (eds.), 2006, *Journal of Mathematical Psychology*, 50(2). Special issue on model selection, 99–214.
* Wald, A., 1939, “Contributions to the Theory of Statistical Estimation and Testing Hypotheses”, *Annals of Mathematical Statistics*, 10(4): 299–326.
* –––, 1950, *Statistical Decision Functions*, New York: John Wiley and Sons.
* Walley, P., 1991, *Statistical Reasoning with Imprecise Probabilities*, New York: Chapman & Hall.
* Williams, P.M., 1980, “Bayesian conditionalisation and the principle of minimum information”, *British Journal for the Philosophy of Science*, 31: 131–144.
* Williamson, J., 2010, *In Defence of Objective Bayesianism*, Oxford: Oxford University Press.
* Ziliak, S.T. and D.N. McCloskey, 2008, *The Cult of Statistical Significance*, Ann Arbor: University of Michigan Press.
* Zabell, S.L., 1992, “R. A. Fisher and Fiducial Argument”, *Statistical Science*, 7(3): 358–368.
* –––, 1982, “W. E. Johnson's ‘Sufficientness’ Postulate”, *Annals of Statistics*, 10(4): 1090–1099.

## Academic Tools

> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=statistics). |
> | --- | --- |
> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/statistics/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
> | ![inpho icon](https://plato.stanford.edu/symbols/inpho.png) | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=statistics&redirect=True) at the Internet Philosophy Ontology Project (InPhO). |
> | ![phil papers icon](https://plato.stanford.edu/symbols/pp.gif) | [Enhanced bibliography for this entry](http://philpapers.org/sep/statistics/) at [PhilPapers](http://philpapers.org/), with links to its database. |

## Other Internet Resources

[Please contact the author with suggestions.]

## Related Entries

[belief, formal representations of](https://plato.stanford.edu/entries/formal-belief/) | [causation: probabilistic](https://plato.stanford.edu/entries/causation-probabilistic/) | [confirmation](https://plato.stanford.edu/entries/confirmation/) | [defaults in semantics and pragmatics](https://plato.stanford.edu/entries/defaults-semantics-pragmatics/) | [evidence](https://plato.stanford.edu/entries/evidence/) | [induction: problem of](https://plato.stanford.edu/entries/induction-problem/) | [learning theory, formal](https://plato.stanford.edu/entries/learning-formal/) | [logic: and probability](https://plato.stanford.edu/entries/logic-probability/) | [logic: inductive](https://plato.stanford.edu/entries/logic-inductive/) | [probability, interpretations of](https://plato.stanford.edu/entries/probability-interpret/) | [reasoning: defeasible](https://plato.stanford.edu/entries/reasoning-defeasible/) | [Reichenbach, Hans: common cause principle](https://plato.stanford.edu/entries/physics-Rpcc/) | [scientific method](https://plato.stanford.edu/entries/scientific-method/) | [simplicity](https://plato.stanford.edu/entries/simplicity/) | [skepticism: ancient](https://plato.stanford.edu/entries/skepticism-ancient/)

[Copyright © 2014](https://plato.stanford.edu/info.html#c) by  
[Jan-Willem Romeijn](https://www.rug.nl/staff/j.w.romeijn/?lang=en) <[*j.w.romeijn@rug.nl*](mailto:j%2ew%2eromeijn%40rug%2enl)>
