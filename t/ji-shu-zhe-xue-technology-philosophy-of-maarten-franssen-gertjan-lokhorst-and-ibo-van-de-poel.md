# 技术哲学 technology, philosophy of (Maarten Franssen, Gert-Jan Lokhorst, and Ibo van de Poel)

*首次发表于 2009 年 2 月 20 日星期五；实质性修订于 2023 年 3 月 6 日星期一*

如果哲学是试图“以最广泛的意义理解事物如何以最广泛的意义相互联系”，正如塞拉斯（1962）所说，那么哲学不应忽视技术。当代社会在很大程度上依赖技术来维系。技术不仅是一种经济力量，而且是一种文化力量，这一点非常重要。事实上，在过去的两个世纪里，当技术逐渐成为一门学科时，技术哲学主要关注的是技术对社会和文化的意义和影响，而不是技术本身。米切姆（1994）将这种类型的技术哲学称为“人文技术哲学”，因为它接受“人文学科在技术之上的首要地位”，并与人文学科（以及一些社会科学）的整体观点保持一致。直到最近，技术哲学的一个分支才开始关注技术本身，并旨在理解设计和创造物品的实践（广义上包括人工过程和系统）以及所创造物品的性质。这个技术哲学的后者分支寻求与科学哲学以及现代哲学分析传统中的其他领域（如行为和决策的哲学）保持连续性，而不是与人文学科和社会科学保持连续性。

这个条目以一个简要的历史概述开始，然后继续介绍现代技术哲学关注的主题。接下来讨论了技术的社会和伦理方面，其中涉及了人文技术哲学的一些关注点。这种双重呈现考虑到技术的发展是工程实践的结果，并受到仅有有限社会控制的标准的引导，以及所创建的技术的实施对社会的影响，这些影响是由仅有有限控制的过程产生的。

---

## 1. 历史发展

### 1.1 古希腊

技术哲学的思考与哲学本身一样古老。我们最古老的证言来自古希腊。有四个突出的主题。一个早期的主题是技术从自然中学习或模仿（柏拉图，《法律》X 899a ff.）。例如，德谟克利特认为，建造房屋和织布最初是通过模仿燕子和蜘蛛分别建造巢穴和网的方式发明的（Diels 1903 和 Freeman 1948: 154）。也许最古老的关于自然典范作用的来源是赫拉克利特（Diels 1903 和 Freeman 1948: 112）。亚里士多德通过重复德谟克利特的例子提到了这一传统，但他并没有坚持认为技术只能模仿自然：“通常情况下，技术在某些情况下完成了自然无法完成的事情，在其他情况下模仿自然”（《物理学》II.8，199a15；另请参阅《物理学》II.2，以及 Schummer 2001 和本百科全书关于知识和技术的条目进行讨论）。

第二个主题是自然事物和人造物之间存在根本的本体论区别的论题。根据亚里士多德（《物理学》II.1），前者的生成和运动原则在内部，而后者，只要它们是人造物，仅由外部原因即人类的目的和人类灵魂中的形式生成。自然产物（动物及其部分、植物和四大元素）通过内在的最终原因移动、生长、变化和繁殖；它们受到自然目的的驱动。另一方面，人造物无法自我繁殖。如果没有人类的照料和干预，它们会在一段时间后失去其人造形式并分解为（自然的）材料。例如，如果一张木床被埋葬，它会分解成土壤或重新变回植物的本质，长出新的枝条。

认为人造产品和自然物质之间存在根本区别的论点产生了长期的影响。在中世纪，伊本·西那批评炼金术，认为它永远无法生产出“真正”的物质（Briffault 1930: 147）。即使在今天，仍有人坚持认为，例如天然和合成维生素 C 之间存在差异。这个主题的现代讨论在第 2.5 节中进行。

亚里士多德的四因说——物质因、形式因、效果因和目的因——可以被视为技术哲学的第三个早期贡献。亚里士多德通过引用房屋和雕像等技术制品来解释这个学说（《物理学》第 2.3 章）。这四个因素在与人造物品的形而上学相关的现代讨论中仍然非常重要。例如，对功能概念的讨论侧重于其固有的目的论或“最终”特征以及这给生物学中的使用带来的困难。而忒修斯之船这个臭名昭著的案例——请参阅本百科全书关于物质构成、时间上的身份、相对身份和种类的条目——由霍布斯引入现代哲学，以显示物质的统一和形式的统一作为个体化原则之间的冲突。许多人认为这种冲突是人造物品的特征。大卫·威金斯（1980: 89）甚至认为这是人造物品的定义特征。

值得一提的第四点是柏拉图和亚里士多德广泛运用技术形象。在他的《提摩斯篇》中，柏拉图将世界描述为一位工匠，即造物主。他对创造细节的描述充满了来自木工、纺织、陶瓷、冶金和农业技术的形象。亚里士多德使用艺术和工艺品的比较来说明最终原因在自然过程中的作用。尽管他们对工匠的生活持消极态度，认为他们过于忙于自己的职业和谋生需求，不够自由，但柏拉图和亚里士多德都认为技术形象对于表达他们对宇宙理性设计的信念是不可或缺的（劳埃德 1973 年：61）。

### 1.2 后来的发展；技术哲学人文学科

尽管罗马帝国和中世纪时期有很多技术进步，但对技术的哲学反思并没有相应增长。维特鲁威斯的《建筑学》（公元前 1 世纪）和阿格里科拉的《金属工艺学》（1556 年）等综合性著作对技术的实际方面给予了很多关注，但对哲学方面的关注很少。

在学院哲学领域，人们开始逐渐欣赏机械艺术。一般认为机械艺术是模仿自然而产生的，并且受限于模仿自然。然而，当炼金术在 12 世纪中叶传入拉丁西方时，这种观点受到了挑战。一些炼金术作家，如罗杰·培根，愿意辩称人类的艺术，即使是通过模仿自然过程学习而来，也能成功地复制自然产品甚至超越它们（Newman 2004）。结果就是一种技术哲学，使人类的艺术在文艺复兴之前的其他著作中没有发现的程度上得到了赞赏。然而，13 世纪后期的最后三十年间，宗教当局对炼金术采取了越来越敌对的态度，最终在 1396 年由宗教裁判官尼古拉斯·埃米里克撰写的《反对炼金术士》中予以谴责（Newman 2004）。

文艺复兴使人们更加欣赏人类及其创造性努力，包括技术。因此，对技术及其对社会的影响的哲学思考也增加了。弗朗西斯·培根通常被认为是第一个提出这种思考的现代作家。他在他的幻想作品《新亚特兰蒂斯》（1627 年）中表达了这种观点。这种积极的态度一直持续到 19 世纪，包括工业革命的前半个世纪。例如，卡尔·马克思并没有因为资产阶级生产方式的弊端而谴责蒸汽机或纺纱机；他认为持续的技术创新为未来更幸福的社会主义和共产主义阶段迈出了必要的步伐。关于马克思的历史发展理论中对技术角色的不同观点的讨论可以在 Bimber 1990 中找到。有关技术发展的广泛历史概述，请参阅 Van der Pot 1985 [1994/2004]。

技术作为社会文化现象的认识在塞缪尔·巴特勒的《埃瑞沃纳》（1872）和达尔文的《物种起源》（1859）的影响下出现了转折点。巴特勒的书描述了一个虚构的国家，所有机器都被禁止，拥有机器或试图建造机器都是一项重罪。这个国家的人民被一种观点所说服，即持续的技术改进很可能会导致一种“机器种族”取代人类成为地球上的主导物种。这引入了一个自那时以来一直在技术认知中具有影响力的主题。

在 19 世纪最后一个季度和 20 世纪的大部分时间里，对技术的哲学反思中占主导地位的是一种批判的态度。这种态度的代表人物，绝大多数都接受了人文学科或社会科学的教育，几乎没有亲身参与工程实践的经验。培根在科学方法上写了大量的著作，并亲自进行物理实验，而巴特勒作为一名牧师，缺乏这样的亲身经验。恩斯特·卡普是第一个在他的著作《技术哲学》（1877 [2018]）中使用“技术哲学”一词的语言学家和历史学家。在 20 世纪，大多数批评技术及其社会文化角色的作者都是具有一般观点的哲学家，例如马丁·海德格尔（1954 [1977]）、汉斯·约纳斯（1979 [1984]）、阿诺德·格伦（1957 [1980]）、冈特·安德斯（1956）和安德鲁·芬伯格（1999）。其他人则具有人文学科或社会科学的背景，例如路易斯·芒福德（1934）的文学批评和社会研究、雅克·埃卢尔（1954 [1964]）的法律、兰登·维纳（1977、1980、1983）的政治科学以及阿尔伯特·博格曼（1984）的文学研究。这些人和其他人的技术哲学形式被卡尔·米切姆（1994）称为“人文学科的技术哲学”，因为它以人文学科和社会科学为出发点，而不是以科学和工程实践为出发点，并且它接受“人文学科在技术上的首要地位”（1994: 39），因为技术起源于人类的目标和价值观。

技术哲学的人文学派哲学家往往对技术现象本身持有默认的态度；他们将其视为一个“黑匣子”，一个给定的、统一的、庞大的、不可避免的现象。他们的兴趣不在于分析和理解这一现象本身，而在于把握它与道德（乔纳斯、格伦）、政治（维纳）、社会结构（曼福德）、人类文化（埃卢尔）、人类状况（汉娜·阿伦特）或形而上学（海德格尔）的关系。在这方面，这些哲学家几乎都公开批评技术：总体而言，他们倾向于对技术对人类社会和文化产生的影响持有负面评价，或者至少单独考虑技术对人类社会和文化的负面影响。这并不意味着技术本身被指出为这些负面发展的主要原因。特别是在海德格尔的情况下，技术在现代社会中的主导地位实际上是某种更为根本的东西的症状，即对存在的错误态度已经持续了近 25 个世纪。因此，海德格尔是否应被视为技术哲学家是值得质疑的，尽管在人文学派的观点中，他被认为是最重要的哲学家之一。关于阿伦特也可以说类似的话，尤其是她在《人的条件》（1958 年）中对技术的讨论，尽管她在人文学派技术哲学的经典著作中的地位并不像海德格尔那样突出。

可以肯定的是，这些人文技术哲学的创始人的工作已经被第二代和第三代学者进一步发展，特别是海德格尔的工作仍然是一个重要的灵感来源，但在这样做时，他们采取了更加中立而不是整体消极的观点来看待技术及其对人类生活和文化的意义。值得注意的例子是伊德（1979 年，1993 年）和韦尔比克（2000 年 [2005 年]）。

在其发展过程中，人文技术哲学受到的影响并不是来自哲学的发展（例如科学哲学、行动哲学、心灵哲学），而是来自社会科学和人文学科的发展。例如，Ihde 和那些以他为出发点的人将他们的工作定位为现象学家或后现象学家，但似乎对哲学中这个模糊概念的过去或现在并不感兴趣，尤其是对于海德格尔在多大程度上可以被认为是现象学家这个并不容易的问题并不感兴趣。特别重要的是在 20 世纪 80 年代出现了“科学与技术研究”（STS），它从广泛的社会科学角度研究社会、政治和文化价值如何影响科学研究和技术创新，以及这些又如何影响社会、政治和文化。我们在第 3 节“技术的伦理和社会方面”中讨论了人文技术哲学的作者，但并没有单独详细介绍这个领域中存在的各种观点。Mitcham 的 1994 年著作仍然提供了一个很好的概述。Coeckelbergh 的（2020a）教材提供了最近的人文技术哲学的涵盖。Olsen、Selinger 和 Riis（2008）以及 Vallor（2022）提供了广泛的贡献集合；Scharff 和 Dusek（2003 [2014]）以及 Kaplan（2004 [2009]）则呈现了这一传统中的综合文集。

### 1.3 技术意义上的基本歧义

Mitcham 将“技术哲学的人文学派”与“技术哲学的工程学派”进行了对比，后者指的是由工程师或技术专家发展的哲学观点，作为“对技术哲学的阐述的尝试”（1994 年：17）。 Mitcham 仅讨论了少数几位工程学派的技术哲学家：恩斯特·卡普，彼得·恩格尔迈尔，弗里德里希·德绍尔，以及雅克·拉菲特，吉尔伯特·西蒙东，亨德里克·范·里森，胡安·大卫·加西亚·巴卡，R·巴克明斯特·富勒和马里奥·邦格等人的讨论较为简短。 “技术哲学的工程学派”这个标签引发了一些严重的问题：许多讨论的人几乎不能被归类为工程师或技术专家。而且，“技术哲学”的概念如何理解也不太清楚。作为哲学家，这些作者似乎都是相对孤立的人物，他们的工作几乎没有重叠之处，主要共同点似乎只是与已建立的哲学学科缺乏“工作关系”。对于“技术哲学的工程学派”的概念背后的问题和关注点并不太清楚。系统哲学的更大作用可能会使其与一些人文学派的技术哲学相当接近，例如雅克·埃卢尔的工作，分析可能会相当相似，剩下的差异可能只是态度或欣赏的差异。

在下一节中，我们将更详细地讨论一种我们认为目前占据人文技术哲学替代地位的技术哲学形式。它在 20 世纪 60 年代出现，并在过去的二十到二十五年间获得了势头。这种技术哲学形式可以称为“分析性”，它主要关注的不是技术与社会之间的关系，而是技术本身。它明确地不将技术视为一个“黑匣子”，而是将其视为应该被详细研究的现象。它不将技术本身视为一种实践，而是将其视为一种基于工程实践的东西。它分析这种实践，它的目标、概念和方法，并将其研究结果与哲学中的各种主题联系起来。

将技术视为工程师维持的实践，类似于科学哲学将科学实践视为科学家维持的方式，分析技术哲学可以被认为是工程哲学。事实上，在下面的 2.3 和 2.4 节中讨论的设计相关问题可以被单独作为工程哲学的主题。然而，在 2.5 节中讨论的形而上学问题则不能，因此分析技术哲学比工程哲学要广泛得多。《技术哲学与工程科学》（Meijers 2009）这本包含了对下一节中所有主题的贡献的最新综述的书名，暗示了技术和工程并不完全相同，但该书并没有明确阐述技术与工程的区别以及它们之间的关系。事实上，人文技术哲学和分析技术哲学并存的存在反映了技术概念中的基本模糊性，而哲学研究在澄清这一模糊性方面几乎没有取得成功。

技术可以说有两个方面或维度，可以称为工具性和生产力。工具性涵盖了人类通过以目的明确和巧妙的方式使用物品来控制自己的生活和环境的所有努力。生产力涵盖了人类通过创造新事物来以一种受控且巧妙的方式实现某些事物的所有努力。对于工具性维度的研究，原则上，我们使用来控制生活和环境的物品是否是我们首先生产的是无关紧要的；如果我们能够依赖自然物体始终可用来满足我们的目的，那么对工具性的分析及其对我们生活方式的影响不一定会受到影响。同样，对于制造工艺品所涉及的分析，以及如何理解工艺品和新事物的概念，人类生活、文化和社会因实际上生产的工艺品而发生的变化在很大程度上是无关紧要的。尽管其基本性质如此，但这里所指的模糊性似乎在文献中很少直接面对。这一问题被劳森（Lawson）（2008 年，2017 年）以及弗兰森（Franssen）和科勒（Koller）（2016 年）所讨论。

人文技术哲学主要关注工具性维度，而分析技术哲学则专注于生产力维度。然而，作为现代社会的基本现象之一，如果不是最基本的现象，技术显然是由以及涉及这两个维度为中心的过程构成的。然而，要找到一个能够充分处理这两个技术维度之间相互作用的总体方法似乎是困难的，这无疑部分是由于这两个传统及其各自焦点所关联的哲学取向和方法论的巨大差异。改善这种情况可以说是技术哲学领域所面临的最紧迫的挑战，因为这两种取向各自独立的延续威胁着它作为一个学科的统一性和连贯性。事实上，在过去的十到十五年里，工程哲学已经确立为技术哲学的一个子学科，最近由 Michelfelder 和 Doorn（2021）编辑了一本综合手册。

在下一节中，我们将介绍分析技术哲学研究的技术和工程中具有哲学相关性的主要问题，然后在第三节中讨论技术对社会所带来的问题和挑战。

## 2. 技术哲学的分析

### 2.1 引言：科学与技术与哲学的不同关系

对于那些对这个话题还不熟悉的人来说，科学哲学和技术哲学领域的差异可能会让人惊讶，因为在我们的社会中，很少有实践像科学和工程学那样密切相关。实验科学现在在实现其研究设备和收集分析数据方面极为依赖技术。现代科学试图研究的现象如果没有通过技术产生，是无法被发现的。

技术内的理论研究往往与科学内的理论研究难以区分，使得工程科学在很大程度上与“普通”或“纯粹”的科学连续。这是一个相对较新的发展，始于 19 世纪中叶，对现代技术和传统的工艺技术之间存在很大差异负有责任。渴望成为科学家和工程师的人所接受的教育培训最初是基本相同的，只是逐渐分化为科学或工程课程。自 17 世纪的科学革命以来，以其两个主要创新，即实验方法和科学理论的数学表达，科学知识的哲学反思一直关注科学知识生成的方法，认为科学理论是真实的或近似真实的原因，以及证据的性质和接受一种理论而拒绝另一种理论的原因。几乎从来没有哲学家提出过不涉及科学界、他们的关注、他们的目标、他们的直觉、他们的论证和选择的问题。相比之下，技术哲学直到最近才发现了工程师群体。

可以说，技术哲学而不是科学哲学首先应关注技术（以及科学）对社会和文化的影响，因为科学只有通过应用为技术才会影响社会。然而，这种说法是不正确的。科学革命开始时，科学对人类文化和思想产生了根本和直接的影响，而不是通过技术的绕道而行。相同的情况也适用于后来的发展，如相对论、原子物理学和量子力学、进化论、遗传学、生物化学以及日益主导的科学世界观。然而，长期以来，科学哲学家给人的印象是他们乐意将涉及科学的规范、社会和文化方面的问题留给其他哲学学科或历史研究。直到最近几十年，这种情况才发生了变化，学者们要么从一开始就专注于这些问题（例如 Longino 1990, 2002），要么将他们的关注重点转向这些问题（例如 Kitcher 2001, 2011）。

现代科技的历史发展与现代科学存在重大差异，这至少部分解释了这种情况，即科学在 17 世纪从哲学本身中崛起。伽利略、惠更斯、牛顿等人给出的答案，开启了经验主义和数学描述的联盟，这是现代科学的显著特征，这些答案是对自古以来一直属于哲学核心业务的问题的回答。因此，科学引起了哲学家的关注。科学哲学可以被看作是在科学出现的背景下对认识论的转变。19 世纪末 20 世纪初，关于原子的实在性、因果关系和概率的地位、空间和时间的问题、量子世界的性质等基础问题，是科学家和哲学家之间密切关系的一个例证。哲学家和工程师或技术人员之间从未存在过这样的亲密关系。他们的世界几乎没有交集。当然，可以提出这样的观点，与自然哲学和科学之间的连续性相比，哲学中与人类行为和实践理性有关的核心问题与技术处理和系统化解决实际问题的方式之间存在类似的连续性。研究这种联系确实可以被视为技术哲学的一个重要主题，在第 2.3 节和第 2.4 节中对此进行了更多的阐述。然而，这种连续性只能事后才能看清，而且模糊不清，因为历史发展最多只是各种关于行动和理性的哲学思考的缓慢汇聚，而不是从单一起源发展出多样性。 重要的是，只有学术局外人埃卢尔以他独特的方式才认识到技术作为回答有关人类行为的所有问题的新兴主导方式，与科学作为回答有关人类知识的所有问题的主导方式相媲美（埃卢尔 1954 [1964]）。但埃卢尔对于研究这种关系并不是那么感兴趣，而是更注重强调和谴责他所看到的社会和文化后果。更重要的是要指出，人文技术哲学不能通过声称只有前者对技术的社会背景感兴趣来区分于技术的分析哲学。有些研究根植于科学的分析哲学，但特别关注技术与社会和文化的关系，以及社会关系对技术实践的相关性，而不对技术采取评价立场；普雷斯顿 2012 年就是一个例子。

### 2.2 技术与科学的关系

工程和科学实践之间的密切关系很容易使技术和科学之间的重要区别被忽视。科学在哲学视野中的主导地位使哲学家们很难认识到技术值得特别关注，因为它涉及到科学中不存在的问题。这种缺乏认识所导致的观点常常被戏剧化地表述为技术“仅仅”是应用科学。

科学与技术之间的关系问题是分析哲学家在早期讨论中的核心问题之一。1966 年，在《技术与文化》杂志的特刊中，亨利克·斯科利莫夫斯基（Henryk Skolimowski）认为技术与科学是完全不同的东西（Skolimowski 1966）。正如他所说，科学关注的是现实，而技术关注的是未来。几年后，在他著名的《人工科学》（1969）一书中，赫伯特·西蒙（Herbert Simon）用几乎相同的措辞强调了这一重要区别，他指出科学家关注事物的现状，而工程师关注事物应该如何。虽然很难想象早期的哲学家对这种取向上的差异视而不见，但他们特别是在逻辑实证主义传统中倾向于将知识视为陈述系统，这可能导致他们相信在技术中没有知识主张起到的作用是科学中找不到的。因此，对技术的研究不会带来新的挑战，也不会对分析哲学的兴趣产生意外之处。

相比之下，马里奥·邦格（1966 年）捍卫了技术是应用科学的观点，但以一种微妙的方式来公正地对待科学和技术之间的差异。邦格承认技术涉及行动，但这种行动在很大程度上是以理论为基础的——这就是区别技术与艺术和手工艺之间的特点，并使其与科学处于同等地位的原因。根据邦格的观点，技术中的理论分为两种类型：实质性理论，提供关于行动对象的知识；操作性理论，关注行动本身。技术的实质性理论实际上在很大程度上是科学理论的应用。相反，操作性理论并不是在科学理论之前产生的，而是在应用研究中产生的。然而，正如邦格所说，操作性理论在某种程度上依赖于科学，因为在这些理论中使用了科学的方法。这包括建模和理想化、使用理论概念和抽象以及通过预测和回溯来吸收经验数据来修改理论等特征。

针对这一讨论，伊恩·贾维（1966 年）提出了技术哲学中重要的问题，即技术陈述的认识论地位以及如何将技术陈述与科学陈述区分开来。这表明需要对实践中出现的各种知识形式进行彻底调查，特别是因为科学知识已经得到了广泛研究，对技术特有的知识形式以及在科学中缺乏或较不突出的知识形式进行研究。吉尔伯特·赖尔（1949 年）在不同的背景下引入了“知道什么”（传统的命题性知识）和“知道如何”（非明确表达甚至无法明确表达的知识）之间的区别。迈克尔·波兰尼（Polanyi 1958）在这个概念上提出了“知道如何”的概念，并将其作为技术的一个核心特征；当前哲学讨论的现状在本百科全书关于知识如何的条目中有所介绍。然而，过分强调非明确知识的作用，即常常被称为“经验法则”的作用，很容易低估了理性方法在技术中的重要性。强调隐性知识可能也不适合区分科学和工程实践，因为隐性知识在科学中的作用可能比当前科学哲学所承认的更为重要，例如在基于经验证据得出因果关系的结论时。这也是托马斯·库恩在科学理论变革方面的著作中的一个重要主题（库恩 1962 年）。

### 2.3 设计对技术的核心地位

声称，与斯科利莫夫斯基和西蒙一样，技术关乎于“应该是什么”或“应该如何”，而不是“是什么”，这可能有助于将其与科学区分开来，但并不足以解释为什么技术的哲学反思如此多地采取了社会文化批判的形式。技术是一种持续的尝试，将世界变得更接近人们希望的样子。而科学的目标是理解世界的本来面目，技术的目标是改变世界。当然，这些都是抽象的。对于一个人来说，他们对世界应该是什么样子的愿望在技术中得到了实现吗？与科学家不同，他们在描述和理解世界时往往有个人动机，工程师被视为为公众提供服务而进行改变世界的尝试，这一点不仅仅是工程师自己的看法。关于应该是什么或应该如何的想法被认为起源于技术之外；然后工程师们自己承担起实现这些想法的责任。然而，这种观点实际上对现实进行了相当程度的扭曲。许多工程师本身就有动机改变世界，特别是改变过去技术塑造的世界。因此，许多技术发展是“技术驱动”的。

要理解技术的“来源”，推动创新过程的因素，不仅对那些好奇了解技术现象本身的人来说很重要，对那些关心技术在社会中角色的人也很重要。技术或工程作为一种实践，关注的是制造物品和越来越重要的基于物品的服务。设计过程，即通向目标的结构化过程，构成了工程实践的核心。在工程文献中，设计过程通常被表示为一系列的翻译步骤；例如，参见 Suh 2001。起点是客户的需求或愿望。在第一步中，这些需求被转化为功能要求的列表，这些要求定义了工程师或工程团队需要完成的设计任务。功能要求尽可能精确地指定了设计设备必须能够完成的功能。这一步是必需的，因为客户通常只关注一两个特性，并且无法明确表达支持所需功能的要求。在第二步中，功能要求被转化为设计规范，这些规范确定了关键组件的确切物理参数，这些参数将满足功能要求。选择满足这些要求的设计参数，并使其更加精确，从而得到设备的蓝图。蓝图包含了必须知道的所有细节，以便进行设备制造的最后一步。诱人的是将蓝图视为设计过程的最终结果，而不是成品的副本作为这个结果。然而，设备的实际副本对于原型制作和测试是至关重要的。 原型制作和测试假设设计过程中的步骤序列通常会包含迭代，从而导致设计参数和/或功能要求的修订。尽管对于大规模生产的物品来说，产品制造交付给客户或市场的过程是在设计阶段结束后进行的，但制造过程通常会反映在设备的功能要求中，例如对设备组成部件数量的限制。设备的复杂性将影响其维护或修理的难度，而维护便捷性或低修理成本通常是功能要求之一。一个重要的现代发展是，现在将物品的完整生命周期视为设计工程师的关注范围，直到其组件和材料的回收和处理的最后阶段，任何设备的功能要求都应该反映这一点。从这个角度来看，蓝图和原型都不能被视为工程设计的最终产品。

这个设计过程方案中最大的理想化可能位于起始阶段。只有少数情况下，设计任务是源于客户对特定产品的需求或愿望。首先，正如前面所提到的，许多设计任务是由工程师自己定义的，例如，他们注意到现有产品中需要改进的地方。然而，设计通常始于某个社会机构指出的问题，然后邀请工程师来解决。然而，许多这样的问题都是模糊或棘手的问题，意味着问题的确切性质以及解决问题的方法并不明确。“问题”是人们（不一定是“处于”问题中的人）认为不令人满意的情况，但通常无法具体说明他们认为更令人满意的情况，除了问题得到解决的情况。特别是，问题的解决方案是否包括某种产品、某种人工系统或过程的提供或安装并不明显。世界各地的工程部门都宣传工程是问题解决，工程师似乎很自信地认为，无论问题的性质如何，他们都是最合适的人来解决问题。这导致了技术解决方案的现象，即通过技术手段解决问题，即提供或安装某种产品或人工过程，至少可以说，这是否解决了问题或者是否是处理问题的最佳方式值得怀疑。

对于全球变暖问题的技术解决方案的一个候选示例是目前备受争议的向平流层注入硫酸盐气溶胶以抵消二氧化碳和甲烷等温室气体的变暖效应。这种地球工程方案将使我们能够避免面对可能非常痛苦的选择，这些选择将导致温室气体排放减少，但同时也允许地球化石燃料储量的耗尽继续进行。有关技术修复的讨论，请参见 Volti 2009: 26–32。鉴于这种情况及其危害，问题的概念和问题分类值得比以往更多地受到哲学关注。

这些棘手的问题通常是广泛的社会问题，最好通过某种形式的“社会行动”来解决，这将导致人们改变行为或以不同的方式行动，从而减轻甚至完全消除问题。为了捍卫工程观点，可以说“已证明有效”的社会行动形式的库存很少。技术修复的诱惑可以被克服-至少工程师可能是这样看的-通过将社会科学纳入系统性的知识开发和应用，解决人类问题。然而，这是一个有争议的观点。社会工程对许多人来说是一个要尽可能保持距离的幽灵，而不是一个追求的理想。卡尔·波普尔将可接受的社会变革实施形式称为“逐步社会工程”，并将其与例如马克思主义提倡的革命性但完全没有根据的计划进行了对比。然而，在卡尔·波普尔的条目中，他选择的措辞被称为“相当不幸”。社会工程的概念及其合理性值得比目前更多地受到关注。

设计过程中的重要输入是科学知识：关于组件行为和它们在特定情况下组成的材料的知识。这是科学应用的点。然而，大部分这些知识并不直接来自科学，因为它通常涉及非常具体情况下的极其详细的行为。因此，这些科学知识通常是由工程科学在技术领域内生成的。但除了这些非常具体的科学知识外，工程设计还涉及各种其他类型的知识。在他的书《工程师知道什么以及他们如何知道》（Vincenti 1990）中，航空工程师沃尔特·文森蒂对工程设计知识进行了六重分类（将生产和操作作为工程实践的另外两个基本组成部分）。文森蒂区分了

1. 基本设计概念，主要包括特定设备的操作原理和正常配置；
2. 准则和规范；
3. 理论工具;
4. 定量数据;
5. 实际考虑;
6. 设计工具。

第四类涉及刚才提到的定量知识，第三类涉及用于获取该知识的理论工具。这两类可以假设与 Bunge 关于实质性技术理论的概念相匹配。然而，剩下的四类的地位要明显不清楚得多，部分原因是它们在科学的充分探索背景中不太熟悉，或者根本不熟悉。Vincenti 声称，这些类别代表的是规范性知识而不是描述性知识。在这里，设计活动引入了一种规范性的元素，这在科学知识中是不存在的。以“操作原理”这样一个基本概念为例，它指的是设备功能实现的方式，或者简单说，它是如何工作的。这仍然是一个纯粹的描述性概念。然而，随后它在寻求为那些通过该设备的操作可以实现目标的人提供行动方案的论证中发挥了作用。在这个阶段，问题从描述性转变为规范性或规范性问题。Houkes（2009）提供了关于与技术相关的各种知识的广泛讨论。

虽然“操作原理”这个术语似乎源自波兰尼（1958），但对其的明确定义似乎并不存在。因此，将技术行为及其组成部分的描述性和规范性方面区分开来的问题，几乎还没有开始解决。这项任务需要对技术的范围和程度有清晰的认识。如果我们按照约瑟夫·皮特在他的著作《思考技术》（1999）中的定义，将技术广义地理解为“人类的工作”，那么区分技术行为和一般行为就变得困难，而对技术行为的研究必须吸收所有描述性和规范性的行为理论，包括实践理性的理论以及大部分理论经济学。确实有人试图对人类行为进行这样全面的解释，例如塔德乌什·科塔宾斯基的《实践学》（1965），但如此广泛的视角使得很难得出足够深入的结果。对于哲学来说，要明确行为形式之间的差异以及它们的推理基础，从而单独研究三个重要领域：技术、组织与管理以及经济学，将是一个挑战。

对这种方法的更为局限的尝试是 Ilkka Niiniluoto（1993）的方法。根据 Niiniluoto 的理论框架，技术作为一种关注世界应该是什么样子而不是实际如何的活动，形成了科学描述框架的对立面，即设计科学。设计科学的内容，即形成科学描述框架内容的理论和解释的对立面，将由技术规范组成，即形式为“如果想要实现 X，就应该做 Y”的陈述。技术规范的概念源自 Georg Henrik von Wright 的《规范与行动》（1963）。技术规范需要与表达自然必然性的 anankastic 陈述相区分，后者形式为“如果要实现 X，就需要做 Y”；后者具有真值，而前者没有。然而，von Wright 本人写道，他不理解这些陈述之间的相互关系。Zwart、Franssen 和 Kroes（2018）提出了详细的讨论。关于设计科学是什么以及可以和应该是什么的想法显然与实践合理性的广泛问题领域有关-请参阅本百科全书关于实践理性和工具理性的条目-以及在下一节中讨论的目的手段推理。

### 2.4 方法论问题：设计作为决策制定

设计是一种受到理性审查的活动，但创造力也被认为是一个重要的角色。由于设计是一种行动形式，是一系列有结构的决策，以某种方式而不是另一种方式进行，与之相关的理性形式是实践理性，即在特定情况下如何行动的标准。这表明了理性审查和创造力所扮演的角色之间的明确分工。理性行动的理论通常将其问题情境看作是在各种行动选择之间进行选择的问题。理性则关注如何在给定的选择中做出决策，而创造力则关注这些选择的生成。这种区别类似于科学中的证明背景和发现背景之间的区别。然而，与这种区别相关的建议，即理性审查仅适用于证明背景的情况，对于技术设计来说很难维持。如果初始的创造性阶段的选择生成工作不认真，设计任务的结果很难令人满意。与科学不同，科学不考虑娱乐特定理论的实际后果，技术发现的背景受到时间和金钱的严格限制，因此对如何最好地进行分析似乎是有必要的。在这个方向上，哲学研究还很少，有关问题的概述可参考 Kroes、Franssen 和 Bucciarelli（2009）的著作。

赫伯特·西蒙关于有限理性的观点（参见西蒙 1982 年）在这里是相关的，因为决策何时停止生成选项以及何时停止收集关于这些选项及其采纳后的后果的信息，在决策过程中是至关重要的，以避免信息过载和计算难题。然而，自从这些观点在 1950 年代提出以来，进一步发展西蒙关于有限理性的观点已经证明是困难的。另一个在这里相关的概念是目的手段推理。为了在这里提供任何帮助，目的手段推理理论不仅应关注给定手段在实现给定目的方面的评估，还应关注为给定目的生成或构建手段。然而，目前还没有一个全面的目的手段推理理论；关于如何在技术制品的背景下发展目的手段推理的提议，请参见休斯、克罗斯和赞瓦特 2007 年的论文。在工程实践中，实现特定功能的替代方案通常是从现有和经过验证的实现的“目录”中选择的。这些目录是通过技术领域的持续研究来扩展的，而不是在特定设计任务的迫切需求下扩展的。

当工程设计被构想为一个由实际理性考虑所主导的决策过程时，下一步是明确这些考虑。几乎所有关于实际理性的理论都将其看作是一种推理过程，寻求信念与欲望或目标之间的匹配。欲望或目标通过其对决策者的价值或效用来表示，决策者的问题是选择一种行动，实现一种在所有可能实现的情况中具有最大价值或效用的情况。如果对特定行动将实现的情况存在不确定性，那么问题被看作是追求最大预期价值或效用。现在，技术的工具性观点意味着在将设计过程视为理性决策过程时，所关注的价值并不是所创建的工艺品的价值。这些价值是技术的使用者所关注的领域。它们应该在定义设计任务的功能要求中得到体现。相反，要最大化的价值是特定设计满足定义设计任务的功能要求的程度。从这个意义上说，工程师们在工程设计上分享了一种整体的优化观点。但尽管优化是一个价值导向的概念，但它本身并不被视为推动工程设计的价值。

定义大多数设计问题的功能要求并没有明确规定应该优化什么；通常它们只是设定了最低达到的水平。然后由工程师决定是否超越这种最低要求。首先，效率，尤其是能源消耗和材料使用效率，通常是一个重要价值。在社会的压力下，其他价值观也被纳入其中，特别是安全性和最近的可持续性。有时候有人声称工程师的最大化目标只是市场成功这一个因素。然而，市场成功只能在事后评估。工程师的最大化努力实际上是针对被认为是市场成功预测因素的内容。满足功能要求、相对高效和安全是合理的预测因素，但是市场研究提供的额外方法可能引入其他因素或导致因素之间的层次结构。

选择最大程度满足所有功能要求（可能但不一定源自潜在用户）以及所有其他被认为相关的考虑和标准的设计选项，然后成为在特定工程设计任务中需要解决的实际决策问题。这会引发一些方法论问题。其中最重要的问题是工程师面临多准则决策问题。各种要求都有其自身的设计参数和测量程序的操作化，用于评估其性能。这导致了一系列排名或定量尺度，代表了各种选项，需要从中进行选择。任务是提出一个最终得分，其中所有这些结果都被“充分”地表示，以便得分最高的选项可以被视为设计问题的最优解。工程师将这种情况描述为需要进行权衡的情况：在评估一个选项相对于其他选项的优劣时，一个准则上的相对差性能可以通过另一个准则上的相对好性能来平衡。一个重要的问题是是否可以制定一种理性的方法来解决这个问题。Franssen（2005）认为，这个问题在结构上与社会选择的著名问题相似，而肯尼斯·阿罗在 1950 年证明了他臭名昭著的不可能定理。因此，只要我们要求解决这个问题的解决方法满足一些规定其普遍性和合理性的要求，就不存在这样的解决方法。在技术设计中，个体选民在社会选择情境中所起的作用由各种设计准则扮演，每个准则都对最终产品的外观产生影响。 这对工程师声称他们的设计是最佳解决方案的主张提出了严重问题，因为阿罗定理暗示在大多数多准则问题中，这种“最佳”的概念无法严格定义，就像在大多数多选人情况下，选民共同想要的最佳或甚至是适当的代表的概念无法严格定义一样。

这个结果似乎将工程活动的一个关键方面排除在哲学审查之外，它可以用来辩护工程至少在某种程度上是一门艺术而不是科学的观点。然而，我们不应该屈服于这个结果，这个结果的意义远远超出了工程甚至决策制定的范畴，我们或许应该得出结论，还有很多工作需要在所谓的“近似”推理形式上进行，暂时地说。这里应该包括一种推理形式，即赫伯特·西蒙的有限理性，以及相关的“满足”概念。自从它们在 1950 年代被引入以来（西蒙 1957 年），这两个术语已经被广泛使用，但我们仍然缺乏有关有限理性的一般理论。近似推理形式（如有限理性）可能本质上无法拥有一个一般理论，但甚至缺乏一个系统性的处理，从中可以得出这样的洞见。

决策视角下工程设计的另一个问题是，在现代技术中，几乎所有的设计都是由团队完成的。这些团队由来自许多不同学科的专家组成。每个学科都有自己的理论、相互依赖的模型、评估标准等等，而属于这些学科的专业人员必须被视为不同客体世界的居民，正如路易斯·布奇亚雷利（1994）所说。因此，不同的团队成员在讨论中对各种设计选项的相对排名和评估很可能存在分歧。在这里，通过算法方法来达成对一个选项的一致意见，作为整体最佳选项，甚至更难以体现工程合理性。相反，社会互动模型，如讨价还价和战略思维，在这里是相关的。Franssen 和 Bucciarelli（2004）提出了一个（抽象）设计问题的这种方法的例子。

以决策过程的方式看待技术设计，是从实践或工具理性的角度来规范地看待它。同时，它也是描述性的，因为它描述了工程方法论通常如何提出解决设计问题的问题。从稍微更高的角度来看，有各种各样的规范性问题，这里没有涉及，比如定义设计问题的功能要求是否可以看作是对一个工件或技术的潜在用户的价值的充分代表，或者通过哪些方法可以最好地引出和代表诸如安全性和可持续性之类的价值在设计过程中。这些问题将在第 3 节中讨论。

### 2.5 形而上学问题：工件的地位和特征

设计工艺的理解是技术哲学中最直接涉及工程实践兴趣的主题。这对于分析性技术哲学中另一个核心问题的地位和特征来说并非完全正确。这或许与科学哲学中的情况相似，工作中的科学家似乎对调查模型和理论的地位和特征不太感兴趣，而哲学家则相反。

人造物品是人类制造的物体：它们有一个作者（参见 Hilpinen 1992 和 Hilpinen 在本百科全书中的文章“artifact”）。与技术相关的人造物品还被制作出来以服务于某种目的。这在所有人造物品的集合中排除了副产品和废品，同样也排除了有争议的艺术作品。副产品和废品是有意制造某物的结果，只是不够精确，尽管工作中的作者可能对其创造有所了解。艺术作品是由一个针对其创作的意图产生的（尽管在概念艺术的特殊情况下，这种指向可能涉及许多中间步骤），但有争议的是艺术家是否在他们对作品的意图中包括了作品服务于某种目的的意图。然而，大多数讨论人造物品形而上学的技术哲学家都将艺术作品排除在其分析之外。关于这一方面的进一步讨论属于艺术哲学。Dipert（1993）提出了一个有趣的一般解释，不排除艺术作品。

技术制品通常是为了某种目的而制造的，一般用于某种用途或作为更大制品的组成部分，而后者又可以是用于某种用途或再次作为组成部分。无论是最终产品还是组成部分，制品都是“为某事而存在的”，而它的用途被称为制品的功能。一些研究者强调，对制品的充分描述必须同时涉及到它们作为有形物体的状态和人们使用它们的意图。Kroes 和 Meijers（2006）将这种观点称为“技术制品的双重性质”；它的最成熟的表述是 Kroes 2012。他们认为这两个方面在“制品功能”的概念中是“相互联系”的。这引发了几个问题。其中一个问题，由于似乎很少有关于它的哲学研究，我们将快速跳过，即结构和功能相互制约，但制约只是部分的。目前尚不清楚是否可能有一个关于这种关系的普遍解释，并且需要解决哪些问题才能达到这个目标。这可能与心灵哲学中的多重实现问题以及科学中的归约问题有有趣的联系；Mahner 和 Bunge 2001 探讨了这个问题的一个例子。

是否可能有一个统一的功能概念的解释是同样具有问题的，但这个问题已经得到了相当多的哲学关注。功能概念对于描述人造物品至关重要，但这个概念被广泛应用。人造物品的功能概念似乎必然涉及到人类的意图。然而，在生物学中，功能也是一个关键概念，其中没有意图的作用，并且在认知科学和心灵哲学中，功能在将意图基于非意图的结构和物理属性上起着至关重要的作用。到目前为止，还没有被广泛接受的关于功能的一般解释，既包括基于意图的人造物品功能的概念，也包括非意图的生物功能的概念，更不用说在其他领域中起作用的概念，比如社会科学。最全面的理论是 Ruth Millikan 的 1984 年的理论，该理论有雄心地解释生物学概念、认知概念和意图概念；关于这个理论的批评和回应，请参见 Preston 1998, 2003；Millikan 1999；Vermaas & Houkes 2003；以及 Houkes & Vermaas 2010。由 Ariew、Cummins 和 Perlman 编辑的论文集（2002）介绍了描述功能概念的主题，尽管重点是生物功能。这个重点在文献中仍然非常强烈，可以从最近的批判性综述（Garson 2016）中判断出来，该综述明确避免讨论人造物品的功能。

反对这种观点，至少在工艺品的情况下，功能的概念必然涉及意图，可以争辩说，在讨论更大设备的组成部分的功能以及这些功能之间的相互关系时，这些功能的意图只是次要的重要性。然而，这将忽视这些组件可能发生故障的可能性。这个概念似乎只能通过实际行为与预期行为之间的不匹配来定义。故障的概念还在描述技术工艺品时，对意图的一般参考中产生了一个模糊之处。这些工艺品通常涉及许多人，这些人的意图可能并不完全一致。可以在实际使用工艺品的用户的意图和工艺品设计者的意图之间进行重要区分。由于工艺品可能被用于与设计者预期的不同目的，而且人们也可能使用自然物体来实现某种目的，因此我们可以允许工艺品具有多个功能，或者在确定工艺品功能时对所有相关意图进行层次分类。在后一种情况下，这是两种其他选择之间的一种折中方式，人们通常区分工艺品的适当功能为设计者预期的功能，而工艺品的偶然功能是由某个用户根据私人考虑赋予的功能。然而，偶然使用可能变得如此普遍，以至于原始功能被遗忘。

与这个问题密切相关的是使用和设计在多大程度上决定了工具的功能的问题。我们似乎使用功能来对工具进行分类：一个物体是刀子，因为它具有切割的功能，或者更准确地说，使我们能够切割。然而，经过更仔细的观察，功能与种类成员资格之间的联系似乎没有那么直接。技术中的基本种类，例如“刀子”、“飞机”和“活塞”。这些种类的成员被设计成用于切割、通过空气运输物品和通过热力膨胀产生机械运动。然而，不能仅仅通过设计某物以用于特定目的的意图来创建某种特定的工具：所创建的种类的成员必须实际上对该目的有用。尽管有无数的设计尝试和声称，永动机并不是一种工具。因此，“刀子”这样的种类的定义不仅取决于其成员的设计者们希望它们各自用于切割的意图，还取决于这些设计者所知道的共享操作原则，并且他们的设计是基于这个原则的。这一点在不同的背景下也得到了 Thomasson 的支持，她在她对一般称之为工具种类的特征化中说，这样一种种类是由设计者有意制作出这种东西的意图、设计者对如何实现这一目标的实质性想法以及他或她在很大程度上成功实现了这一目标来定义的（Thomasson 2003, 2007）。因此，在对工具进行分组的种类中，必须区分“刀子”这样的种类和相应但不同的“切割工具”这样的种类。一个“刀子”指的是一种“切割工具”的特定制作方式。 然而，人们也可以用线、焊接火炬、水射流以及无疑还有其他尚未被想到的方式来切割。'切割器'将指的是一种真正功能性的种类。作为这样一种种类，它受到使用和设计之间的冲突的影响：'切割器'可以指任何可用于切割的东西，也可以指任何被设计用于切割的东西，无论是通过目前已知或未知的操作原理。

这种人工制品种类和功能性种类之间的区别与与其他种类概念的比较有关。科学哲学强调自然种类的概念，例如'水'或'原子'，是科学的基础。另一方面，人们普遍认为，没有所有刀具、飞机或活塞都符合的规律。然而，这种观点仅基于对多重实现性的考虑，这种考虑仅适用于功能性种类，而不适用于人工制品种类。人工制品种类共享一个操作原理，使它们在物理特征上具有一定的共性，一旦将特定的人工制品种类细分为更窄的种类，这种共性就会变得更加明显。由于这些种类是以物理和几何参数来指定的，它们与科学的自然种类更加接近，因为它们支持类似法则的规律性；参见对这一立场的辩护（Soavi 2009）。一本最近的论文集讨论了人工制品和人工制品种类的形而上学问题，即 Franssen，Kroes，Reydon 和 Vermaas 2014。

### 2.6 其他主题

由于它已经产生了大量的分析哲学文献，还应该提及至少一个与技术相关的主题，即人工智能和相关领域。然而，对这个广阔领域的全面讨论超出了本条目的范围。有关信息可以在图灵机、图灵-教堂论题、可计算性和复杂性、图灵测试、中文房间论证、计算心理学理论、功能主义、多重实现性和计算机科学哲学的条目中找到。

## 3. 技术的伦理和社会方面

### 3.1 技术伦理的发展

直到 20 世纪，技术伦理作为哲学的一个系统性和相对独立的子学科的发展才开始。鉴于技术对社会的巨大影响，尤其是自工业革命以来，这种晚期的发展可能令人惊讶。

技术伦理发展较晚的一个合理原因是第 2.2 节提到的技术工具视角。这种视角基本上意味着对技术的积极伦理评价：技术增加了人类的可能性和能力，这在一般情况下是可取的。当然，自古以来就已经认识到新的能力可能被滥用或导致人类的傲慢。然而，通常情况下，这些不良后果被归因于技术的使用者，而不是技术本身或其开发者。这种观点被称为技术工具视角，导致了所谓的中立论。中立论认为技术是一种中立的工具，可以被使用者用于好坏不同的目的。在 20 世纪，这种中立论受到了严厉的批评，最著名的批评者包括海德格尔和埃卢尔，在第 2 节中已经提到，还有法兰克福学派的哲学家，如霍克海默和阿多诺（1947 [2002]），马尔库塞（1964）和哈贝马斯（1968 [1970]）。

技术伦理的范围和议程在很大程度上取决于对技术的概念化。20 世纪下半叶见证了对技术的概念化更加丰富多样，超越了将技术概念化为中立工具、世界观或历史必然性的范畴。这包括将技术概念化为政治现象（Winner、Feenberg、Sclove）、社会活动（Latour、Callon、Bijker 等科学技术研究领域的学者）、文化现象（Ihde、Borgmann）、专业活动（工程伦理学，如 Davis）和认知活动（Bunge、Vincenti）。尽管存在这种多样性，但 20 世纪下半叶的发展具有两个普遍趋势。一是摆脱技术决定论和技术是一个自成体系的现象、自主发展的假设，强调技术发展是选择的结果（尽管不一定是预期的结果）。另一个是从对技术本身的伦理反思转向对具体技术和技术发展阶段的伦理反思。这两个趋势共同导致了对技术提出的伦理问题数量和范围的巨大增加。这些发展还意味着技术伦理必须得到充分的经验支持，不仅要了解具体技术的确切后果，还要了解工程师的行为和技术发展过程。这也为其他学科参与对技术的伦理反思打开了道路，如科学技术研究（STS）和技术评估（TA）。

### 3.2 技术伦理的方法

技术伦理不仅以多样的方法为特征，甚至可以怀疑是否存在类似于技术伦理的子学科，即一群学者共同研究一套共同问题的社群。研究技术伦理问题的学者具有不同的背景（如哲学、科技研究与社会学、技术评估、法律、政治科学和 STEM 学科），他们并不总是将自己视为（主要是）技术伦理学家。为了给读者一个对该领域的概述，将讨论技术伦理中可能区分的三种基本方法或流派。

#### 3.2.1 文化和政治方法

文化和政治方法都建立在 20 世纪上半叶传统的技术哲学和技术伦理基础上。文化方法将技术视为一种影响我们对世界的感知的文化现象，而政治方法将技术视为一种政治现象，即一种由人们之间的制度权力关系统治和体现的现象。

文化方法通常是现象学的性质，或者至少将自己定位为后现象学。这一传统中的哲学家有唐·伊德（Don Ihde）、阿尔伯特·博格曼（Albert Borgmann）、彼得-保罗·弗贝克（Peter-Paul Verbeek）和埃文·塞林格（Evan Selinger）（例如，Borgmann 1984；Ihde 1990；Verbeek 2000 [2005]，2011）。这些方法通常受到 STS（科学技术与社会）领域的发展的影响，特别是技术包含影响人们对世界的感知和人类行为的脚本的观念，以及人类和非人类之间（包括技术制品）没有根本区别的观念（Akrich 1992；Latour 1992, 1993；Ihde & Selinger 2003）。这两种观念的结合使一些人声称技术具有（道德）行为体，这一观点在第 3.3.1 节中进行了讨论。

政治对技术的处理主要可以追溯到马克思，他认为社会中的生产物质结构，其中技术显然是一个重要因素，决定了该社会的经济和社会结构。类似地，朗登·温纳（Langdon Winner）认为技术可以体现特定形式的权力和权威（Winner 1980）。根据他的观点，某些技术在本质上是规范性的，因为它们需要或与某些社会和政治关系高度兼容。例如，铁路似乎需要一种特定的权威管理结构。在其他情况下，技术可能是政治性的，是由于它们被设计的特定方式。一些政治对技术的处理受到（美国）实用主义和较小程度上的话语伦理学的启发。例如，一些哲学家主张技术发展的民主化，并将普通人纳入技术塑造的过程中（Winner 1983；Sclove 1995；Feenberg 1999）。这些想法也在最近的跨学科研究方法中得到了回应，比如负责任的研究与创新（Responsible Research and Innovation，RRI），旨在将创新过程开放给更广泛的利益相关者和关注点（Owen 等，2013）。

尽管政治方法显然具有伦理影响，但最初采用这种方法的许多哲学家并没有进行明确的伦理反思。在政治哲学中，技术似乎并没有成为一个重要的话题。然而，特别是与社交媒体、算法和更普遍的人工智能（AI）等数字技术相关的政治主题最近已经被讨论，例如社交媒体对民主的威胁，大型科技公司的权力以及可能伴随 AI 而来的新形式的剥削、统治和殖民主义（例如，Coeckelbergh 2022; Susskind 2022; Zuboff 2017; Adams 2021）。一个重要的新兴主题也是正义，它不仅包括分配正义（Rawls 1999），还包括承认正义（Fraser 和 Honneth 2003）和程序正义。关于正义的问题不仅被数字技术提出，还被气候变化和能源技术提出，导致了新概念的创造，如气候正义（Caney 2014）和能源正义（Jenkins 等，2016）。

#### 3.2.2 工程伦理

工程伦理始于 20 世纪 80 年代的美国，仅仅是一种教育努力。工程伦理关注的是“属于工程专业的个人或集体所做出的行动和决策”（Baum 1980: 1）。根据这种方法，工程是一种职业，就像医学是一种职业一样。

尽管对于如何准确定义职业没有达成一致，但通常提到以下特征：

* 职业依赖于需要长时间学习的专业知识和技能；
* 职业群体对从事该职业具有垄断权；
* 对于专业工作是否以胜任的方式进行评估是由专业同行进行的，并且普遍认为只有专业同行才能进行评估；
* 专业为社会提供对社会有用或有价值的产品、服务或价值观，并以为社会服务的理想为特征；
* 专业工作的日常实践受到道德标准的规范，这些标准源于或与专业为社会服务的理想相关。

在工程伦理学中讨论的典型伦理问题包括工程师的职业义务，例如工程师的伦理准则，工程师与管理者的角色，能力，诚实，举报，对安全的关注和利益冲突（Davis 1998, 2005）。多年来，工程伦理的范围已经扩大。起初，它通常关注个体工程师的决策以及举报和忠诚等问题，但现在教科书还讨论了这些决策所处的更广泛背景，并关注所谓的多手问题（van de Poel 和 Royakkers 2011; Peterson 2020）（另见第 3.3.2 节）。起初，关注点通常主要集中在安全问题以及能力和利益冲突等问题上，但现在也讨论了可持续性，社会公正，隐私，全球问题以及技术在社会中的作用等问题（Harris，Pritchard 和 Rabins 2014; Martin 和 Schinzinger 2022; Taebi 2021; Peterson 2020; van de Poel 和 Royakkers 2011）。

#### 3.2.3 特定技术的伦理

过去几十年见证了对特定技术的伦理探讨的巨大增长。尤其是在过去二十年中，技术伦理探讨的增长迅速，这可能是讨论的三个领域中最大的一个。如今最为显眼的新领域之一是数字伦理，它起源于计算机伦理（例如，Moor 1985; Floridi 2010; Johnson 2009; Weckert 2007; van den Hoven & Weckert 2008），最近更加关注机器人技术、人工智能、机器伦理和算法伦理（Lin, Abney, & Jenkins 2017; Nucci & Santoni de Sio 2016; Mittelstadt et al. 2016; Bostrom & Yudkowsky 2014; Wallach & Allen 2009, Coeckelbergh 2020b）。其他技术，如生物技术，也引发了专门的伦理调查（例如，Sherlock & Morrey 2002; P. Thompson 2007）。更传统的领域，如建筑和城市规划，也吸引了特定的伦理关注（Fox 2000）。纳米技术和所谓的融合技术导致了所谓的纳米伦理的建立（Allhoff et al. 2007）。其他例子包括核威慑伦理（Finnis et al. 1988）、核能伦理（Taebi & Roeser 2015）和地球工程学伦理（Christopher Preston 2016）。

显然，建立这些新的伦理反思领域是对社会和技术发展的回应。然而，可以问的问题是，社会需求是否最好通过建立新的应用伦理领域来满足。事实上，随着新的领域的出现，这个问题经常被讨论。例如，一些作者认为，没有必要进行纳米伦理学的研究，因为纳米技术并没有引发任何真正新的伦理问题（例如，麦金 2010 年）。这里所谓的新颖之处的缺失得到了支持，因为纳米技术引发的伦理问题是对现有伦理问题的变体，有时是加剧，但几乎没有真正新的问题，并且这些问题可以通过现有的道德哲学理论和概念来处理。关于计算机工程中所谓的伦理问题的新特征的早期类似讨论，请参见塔瓦尼 2002 年的著作。

伦理反思的新领域通常被描述为应用伦理学，即将道德哲学中发展的理论、规范标准、概念和方法应用于实际问题。然而，对于每个元素来说，应用通常并不直接，而需要进一步的具体化或修订。这是因为一般的道德标准、概念和方法通常不足以直接适用于具体的道德问题。因此，“应用”通常会带来新的见解，这可能会导致现有的规范标准、概念和方法的重新制定或至少精炼。在某些情况下，特定领域的伦理问题可能需要新的标准、概念或方法。例如，Beauchamp 和 Childress 提出了一些生物医学伦理学的一般伦理原则（Beauchamp＆Childress 2001）。这些原则比一般的规范标准更具体，但仍然如此一般和抽象，以至于适用于生物医学伦理学中的不同问题。在计算机伦理学中，与隐私和所有权相关的现有道德概念已经被重新定义和调整，以应对计算机时代典型的问题（Johnson 2003）。一个例子是 Nissenbaum 提出的将隐私理解为上下文完整性的建议（Nissenbaum 2010）。伦理应用的新领域可能还需要新的方法，例如，考虑到这些领域的相关经验事实，如技术研究和开发通常是由人们网络而不是个人进行的事实（Zwart 等，2006）。适用于许多新技术的另一个更一般的问题是如何处理通常围绕新兴技术存在的（潜在的）社会和伦理影响的不确定性。Brey（2012）提出的预见性伦理学可以被视为对这一挑战的回应。 预期问题也是近期跨学科领域“负责任研究与创新”（RRI）的中心关注之一（例如，Owen 等人，2013 年）。

尽管不同领域对特定技术的伦理反思可能会引发其自身的哲学和伦理问题，但是否有必要发展独立的子领域甚至子学科是值得质疑的。一个明显的论点可能是，为了对新技术做出有意义的伦理论述，人们需要对特定技术有专业和详细的知识。此外，这些子领域还允许与相关的非哲学专家进行互动，例如法律、心理学、经济学、科学技术研究（STS）或技术评估（TA），以及相关的 STEM（科学、技术、工程、医学）学科。另一方面，也可以提出这样的论点，即伦理学家之间在不同技术领域的专业化之间的互动和讨论可以从与上述两个领域（文化和政治方法以及工程伦理学）的有益互动中获益。特别是对技术的更多政治方法可以补充那些关注特定技术（如人工智能）伦理问题的方法，通过关注公正问题、权力差异和更大的制度和国际背景的作用。目前，在许多情况下，这种互动似乎是缺失的，尽管当然也有例外。

### 3.3 技术伦理中的一些重要主题

现在我们转向技术伦理学中一些特定主题的描述。我们关注一些通用主题，这些主题提供了技术伦理学中一般问题和处理方式的示例。

#### 3.3.1 中立性与道德行为体

技术伦理学中一个重要的通用主题是技术是否具有价值。一些作者认为技术是中立的，即技术只是一种中立的手段，可以被用于好坏不一的目的（例如，Pitt 2000）。从技术被视为仅仅是一个裸露的物理结构的角度来看，这种观点可能有一定的合理性。然而，大多数技术哲学家都同意，技术发展是一个以目标为导向的过程，技术制品的定义就决定了它们具有特定的功能，因此它们可以用于某些目标，但对于其他目标来说，使用起来要困难得多或效果较差。技术制品、功能和目标之间的这种概念联系使得维持技术的中立性变得困难。即使这一点被承认，技术的价值性也可以以多种不同的方式被理解。一些作者认为技术可以具有道德行为体。这种观点表明技术可以在道德意义上自主和自由地“行动”，并且可以对其行为承担道德责任。

技术是否具有道德行为体的争论始于计算机伦理学（Bechtel 1985; Snapper 1985; Dennett 1997; Floridi & Sanders 2004），但后来逐渐扩大。通常，声称技术具有道德行为体的作者经常重新定义行为的概念或其与人的意愿和自由的联系（例如，Latour 1993; Floridi & Sanders 2004, Verbeek 2011）。这种策略的一个缺点是它倾向于模糊人与技术工件之间的道德相关区别。更一般地，声称技术具有道德行为体有时似乎已经成为声称技术在道德上相关的简称。然而，这忽视了技术可以以其他方式具有价值负荷，而不仅仅是具有道德行为体（参见，例如，Johnson 2006; Radder 2009; Illies & Meijers 2009; Peterson & Spahn 2011; Miller 2020; Klenk 2021）。例如，人们可以声称技术在某种程度上具有价值负荷，因为它使得某些人类行为和实现某些人类目标成为可能（甚至邀请），并限制（甚至抑制）其他人类行为和实现其他人类目标，而不声称技术工件具有道德行为体。关于这一争论的很好概述可以在 Kroes 和 Verbeek 2014 中找到。

在智能人工代理设计方面，关于道德行为体和技术的争论现在尤为重要。詹姆斯·摩尔（2006）区分了人工代理可能成为或成为道德行为体的四种方式：

1. 道德影响代理是指在道德上影响其环境的机器人和计算机系统；这对所有人工代理来说可能都是真实的。
2. 隐含的伦理代理是被编程以符合特定价值观的人工代理。
3. 显式的伦理代理是能够代表伦理类别并能够用机器语言“推理”（reason）的机器。
4. 完全的伦理代理还具备一些我们通常认为对人类行为至关重要的特征，如意识、自由意志和意向性。

或许永远不可能在技术上设计出完全符合伦理要求的代理人，即使可能实现，也可能值得质疑是否在道德上有必要这样做（Bostrom＆Yudkowsky 2014; van Wynsberghe 和 Robbins 2019）。正如 Wallach 和 Allen（2009）所指出的，主要问题可能不是设计能够自主运行并能够与环境互动中适应自己的人工代理人，而是在这些机器中构建足够且正确的伦理敏感性。

除了智能人工代理人是否具有道德代理能力的问题外，还存在（更广泛的）关于它们道德地位的问题；例如，它们是否以及在什么条件下可以被视为道德对象，对其人类有一定的道德义务。传统上，道德地位与意识联系在一起，但一些作者提出了更为最低限度的道德地位标准，特别是对于（社交）机器人。例如，Danaher（2020）提出行为主义标准可能足够，而 Coeckelbergh（2014）和 Gunkel（2018）提出了一种关系性方法。Mosakas（2021）认为这些方法并不能为道德地位提供基础，因此人类对社交机器人没有直接的道德责任（尽管它们在其他方面可能仍然具有道德相关性）。其他人则认为，社交机器人有时可能会欺骗我们，使我们相信它们具有某些认知和情感能力（这也可能赋予它们道德地位），而实际上它们并没有（Sharkey 和 Sharkey 2021）。

#### 3.3.2 责任

责任一直是技术伦理学中的一个核心主题。然而，传统的技术哲学和伦理学往往以相当笼统的方式讨论责任，并对工程师能够承担他们开发的技术的责任持悲观态度。例如，埃卢尔将工程师描述为技术的高级祭司，他们珍视技术但无法掌控它。汉斯·约纳斯（1979 [1984]）认为，技术需要一种伦理学，其中责任是中心要求，因为我们有史以来第一次能够摧毁地球和人类。

在工程伦理学中，工程师的责任常常与规范道德规范相关联，这些规范明确规定了工程师的具体责任。这些道德规范强调工程师的三种责任：（1）以诚信和诚实的方式从事职业，并具备专业能力，（2）对雇主和客户负责，（3）对公众和社会负责。关于后者，大多数美国道德规范坚持认为工程师“应将公众的安全、健康和福祉置于至高无上的地位”。

正如几位作者所指出的（Nissenbaum 1996; Johnson & Powers 2005; Swierstra & Jelsma 2006），在工程领域很难确定个人责任。原因是在哲学文献中讨论的适当归因个人责任的条件（如行动自由、知识和因果关系）通常不被个人工程师满足。例如，由于等级制约或市场限制，工程师可能感到被迫以某种方式行动，而负面后果可能很难或不可能事先预测。由于从技术的研发到使用的长链以及参与其中的许多人，因果关系条件通常也很难满足。然而，戴维斯（2012）坚持认为，尽管存在这些困难，个人工程师可以并且确实承担责任。

这场辩论中涉及的一个问题是责任的概念。戴维斯（2012）和拉德（1991）等人主张一种关注责任的概念，该概念较少强调责备，而更强调承担责任的前瞻性或美德性质。但是，许多其他人则关注强调问责、应受责备或法律责任的后顾性责任观念。例如，Zandvoort（2000）主张一种更像法律严格责任概念的工程责任观念，其中责任的知识条件被严重削弱。Doorn（2012）比较了工程领域责任归因的三个视角——基于功绩、基于权利和基于后果论的视角，并认为应用前瞻性责任观念的后果论视角对影响工程实践最有力。

归因个体责任的困难可能导致“多手问题”（PMH）。该术语最早由丹尼斯·汤普森（1980 年）在一篇关于公职人员责任的文章中首次提出。该术语用于描述在集体环境中归因个体责任的问题。多恩（2010 年）提出了一种程序性方法，基于罗尔斯的反思均衡模型，来处理 PMH；处理 PMH 的其他方法包括设计有助于避免 PMH 的机构或强调组织中的善行（范德普尔，罗亚克斯和兹瓦特 2015 年）。

虽然 PMH 指的是在人类集体中归因责任的问题，但技术发展也使得将任务分配给自学习和智能系统成为可能。这些系统可能以难以理解、预测和控制的方式运行和学习，从而导致所谓的“责任缺口”（马蒂亚斯 2004 年）。由于知识和控制通常被视为责任的（必要）前提条件，缺乏这些条件可能使人们越来越难以对智能系统的行为和后果追究人类的责任。

最初，这种责任缺口主要是在讨论自主武器系统和自动驾驶汽车方面（Sparrow 2007; Danaher 2016）。作为可能的解决方案，提出了有意义的人类控制的概念，作为开发和使用这些系统的先决条件，以确保人类能够保持控制，从而对这些系统负责（Santoni de Sio 和 van den Hoven 2018）。Nyholm（2018）认为，许多所谓的责任缺口案例更好地理解为人类与技术合作机构（人类处于监督角色）而不是技术接管控制。虽然责任缺口可能不是不可能的，但更困难的问题可能是将责任归因于涉及的各种人员（这将使 PMH 重新回到桌面上）。

最近，责任缺口在与人工智能相关的更普遍问题上成为一个更普遍的关注点。由于机器学习的进步，人工智能系统可能以难以理解或几乎不可能理解的方式进行学习。最初，在关于责任缺口的文献中，主导的责任概念是指责或有罪，但 Santoni de Sio 和 Mecacci（2021）最近提出了区分他们所称的有罪缺口、道德问责缺口、公共问责缺口和主动责任缺口。

#### 3.3.3 设计

在过去几十年中，人们越来越关注技术使用过程中产生的伦理问题，以及在设计阶段产生的伦理问题。这一发展背后的重要考虑是，在设计阶段，技术及其社会后果仍然可塑，而在使用阶段，技术更多地是给定的，避免负面社会后果可能更加困难，实现积极效果可能更加困难。

在计算机伦理学中，已经发展出一种被称为价值敏感设计（VSD）的方法，以明确解决设计的伦理性质。VSD 旨在以系统的方式将伦理重要价值融入工程设计中（Friedman＆Hendry 2019）。该方法结合了概念、经验和技术调查。还有一系列其他旨在将价值纳入设计的方法。工程中的“面向 X 的设计”方法旨在包括工具性价值（如可维护性、可靠性和成本），但它们还包括可持续性设计、包容性设计和情感设计（Holt＆Barnes 2010）。包容性设计旨在使设计对整个人口包括残疾人和老年人（Erlandson 2008）都可访问。情感设计旨在设计能够引起用户积极情绪，从而有助于人类福祉。Van de Hoven，Vermaas 和 van de Poel 2015 对各种价值和应用领域的价值敏感设计的最新技术发展进行了很好的概述。

如果试图将价值观融入设计中，可能会遇到价值观冲突的问题。由于重量的原因，最安全的汽车不太可能是最可持续的。在汽车设计中，安全性和可持续性存在冲突。工程师在处理这种冲突并在设计中权衡不同要求时，传统方法包括成本效益分析和多准则分析。然而，这些方法存在方法论问题，就像第 2.4 节中讨论的那些问题一样（Franssen 2005; Hansson 2007）。Van de Poel（2009）讨论了处理设计中价值冲突的各种替代方案，包括设定阈值（满足），对价值进行推理，创新和多样性。

#### 3.3.4 技术风险

技术风险是技术伦理学中传统的伦理关注之一。风险不仅引发伦理问题，还引发其他哲学问题，如认识论和决策理论问题（Roeser et al. 2012）。

风险通常被定义为不良事件发生的概率与该事件的影响的乘积，尽管也有其他定义（Hansson 2004b）。总的来说，保持技术风险尽可能小是可取的。风险越大，不良事件发生的可能性或影响就越大。因此，风险降低是技术发展的重要目标，工程伦理准则通常要求工程师在降低风险和设计安全产品方面承担责任。然而，风险降低并不总是可行或可取的。有时候不可行，因为没有绝对安全的产品和技术。但即使风险降低是可行的，从道德角度来看也可能不可接受。降低风险往往需要付出代价。更安全的产品可能更难使用、更昂贵或不够可持续。所以，迟早会面临一个问题：什么程度的安全是足够的？什么使风险（不）可接受？

处理风险的过程通常分为三个阶段：风险评估、风险评价和风险管理。其中，第二个阶段最明显与伦理相关。然而，风险评估已经涉及到价值判断，例如首先应该评估哪些风险（Shrader-Frechette 1991）。一个重要且与道德相关的问题是确定风险所需的证据程度。在基于一系列经验数据来确定风险时，可能会犯两种错误。一种是在实际上没有风险的情况下确定了风险（I 型错误），另一种是错误地得出没有风险的结论，而实际上存在风险（II 型错误）。科学传统上致力于避免 I 型错误。一些作者认为，在风险评估的具体背景下，避免 II 型错误通常更为重要（Cranor 1990；Shrader-Frechette 1991）。原因在于，风险评估不仅旨在建立科学真理，而且具有实际目的，即提供基础知识，以便决策者能够决定是否有必要减少或避免某些技术风险，以保护用户或公众。

风险评价可以通过多种方式进行（参见 Shrader-Frechette 1985）。一种可能的方法是通过将其与其他风险或某些标准进行比较来判断风险的可接受性。例如，可以将技术风险与自然风险进行比较。然而，这种方法存在犯自然主义谬误的危险：自然风险可能（有时）是不可避免的，但这并不一定使它们在道德上可接受。更一般地说，如果 A 和 B 在决策中不是替代方案，那么通过将技术 A 的风险与技术 B 的风险进行比较来判断 A 的风险的可接受性通常是可疑的（有关风险推理中的这种和其他谬误，请参见 Hansson 2004a）。

对风险评估的第二种方法是风险成本效益分析，该方法基于权衡活动的风险与利益。如果进行风险成本效益分析，则可以应用不同的决策标准（Kneese、Ben-David 和 Schulze 1983）。根据 Hansson（2003: 306）的说法，通常应用以下标准：

> …只有当暴露所带来的总利益超过总风险（以概率加权的结果不便性来衡量）时，风险才是可接受的。

第三种方法是基于在人们被告知这些风险后，遭受风险的人的同意来接受风险（知情同意）。这种方法的问题是，技术风险通常会同时影响大量的人。因此，知情同意可能导致“僵局社会”（Hansson 2003: 300）。

一些作者根据哲学和伦理论证提出了替代传统风险评估方法的方案。Shrader-Frechette（1991）基于对当前实践的哲学批判，提出了一系列风险评估和评估程序的改革方案。Roeser（2012）认为情感在判断风险可接受性方面起到了作用。Hansson 提出了以下风险评估的替代原则：

> 如果一个人面临的风险是公平的社会风险承担体系的一部分，并且对她有利，那么这种风险是可接受的。（Hansson 2003: 305）

Hansson 的提议在风险评估中引入了一些传统上未被关注或仅被边缘化的道德考虑因素。这些考虑因素包括个体是否从风险活动中获益以及风险和利益的分配是否公平。

对于可接受风险的问题，也可以用风险强加的术语来表述。问题是，在什么条件下，某个行为体 A 可以对另一个行为体 B 强加风险是可接受的。可接受风险强加的标准在某种程度上与上述讨论的标准相似。例如，如果行为体 B 给予知情同意，或者产生风险的危险活动对行为体 B 有益，那么风险强加可能是（更）可接受的。然而，还有其他考虑因素，比如行为体 A 和行为体 B 之间的关系。父母对子女施加某些风险可能是可以接受的，而政府对子女施加这样的风险则是不恰当的。

如果风险强加导致统治或类似统治的影响，可能会特别成为问题（Maheshwari 和 Nyholm 2022）。这里所理解的统治是由像 Pettit（2012）提出的共和主义哲学家所提出的。摆脱统治并不仅要求人们有不同的选择，还要求他们在这些选择的（可用性中）不受他人（潜在的）任意干涉。因此，非统治要求他人无权任意干涉他人的选择（无论是否行使这种权力）。如果行为体 A（风险强加者）通过对行为体 B（风险承担者）施加风险，可以任意影响行为体 B 可选择的安全选项范围，那么风险强加可能导致统治（或至少类似统治的效果）。

一些作者批评了技术伦理学中对风险的关注。批评的一个方面认为，在新技术投入使用之前，我们经常缺乏可靠评估风险的知识。我们通常不知道某事可能出错的概率，有时甚至不知道可能出错的具体内容和可能的负面后果。为了解决这个问题，一些作者提出将新技术在社会中引入视为一种社会实验，并敦促思考这种实验在何种条件下是道德可接受的（Martin & Schinzinger 2022; van de Poel 2016）。另一方面的批评认为，对风险的关注导致了对技术影响的减少（Swierstra & te Molder 2012）。只有与安全和健康相关的影响被考虑为风险，而“软性”影响，例如社会或心理方面的影响被忽视，从而贫乏了对新技术的道德评价。

<!--md-padding-ignore-begin-->
## Bibliography

* Adams, Rachel, 2021, “Can artificial intelligence be decolonized?”, *Interdisciplinary Science Reviews*, 46(1–2): 176–197. doi: 10.1080/03080188.2020.1840225.
* Agricola, Georgius, 1556 [1912], *De re metallica*, Translated and edited by Herbert Clark Hoover and Lou Henry Hoover, London: The Mining Magazine, 1912. [[Agricola 1556 [1912] available online](https://archive.org/details/deremetallica50agri)]
* Akrich, Madeleine, 1992, “The Description of Technical Objects”, in Bijker and Law (eds) 1992: 205–224.
* Allhoff, Fritz, Patrick Lin, James H. Moor and John Weckert (eds), 2007, *Nanoethics: The Ethical and Social Implications of Nanotechnology*, Hoboken, NJ: Wiley-Interscience.
* Anders, Günther, 1956, *Die Antiquiertheit des Menschen* (Volume I: *Über die Seele im Zeitalter der zweiten industriellen Revolution*; Volume II: *Über die Zerstörung des Lebens im Zeitalter der dritten industriellen Revolution*), München: C.H. Beck.
* Arendt, Hannah, 1958, *The Human Condition*, Chicago: University of Chicago Press.
* Ariew, Andrew, Robert Cummins and Mark Perlman (eds), 2002, *Functions: New Essays in the Philosophy of Psychology and Biology*, New York and Oxford: Oxford University Press.
* Aristotle, *Physics*, Translated in *The Complete Works of Aristotle, Volume 1*, The Revised Oxford Translation 2014, edited by Jonathan Barnes.
* Bacon, Francis, 1627, *New Atlantis: A Worke Vnfinished*, in his *Sylva Sylvarum: or a Naturall Historie, in Ten Centuries*, London: William Lee.
* Baum, Robert J., 1980, *Ethics and Engineering Curricula*, Hastings-on-Hudson: The Hastings Center.
* Beauchamp, Tom L., 2003, “The Nature of Applied Ethics”, in Frey and Wellman (eds) 2003: 1–16. doi:10.1002/9780470996621.ch1
* Beauchamp, Tom L., and James F. Childress, 2001, *Principles of Biomedical Ethics*, fifth edition, Oxford and New York: Oxford University Press.
* Bechtel, William, 1985, “Attributing Responsibility to Computer Systems”, *Metaphilosophy*, 16(4): 296–306. doi:10.1111/j.1467-9973.1985.tb00176.x
* Bijker, Wiebe E., and John Law (eds), 1992, *Shaping Technology/Building Society: Studies in Sociotechnical Change*, Cambridge, MA: MIT Press.
* Bimber, Bruce, 1990, “Karl Marx and the Three Faces of Technological Determinism”, *Social Studies of Science*, 20(2): 333–351. doi:10.1177/030631290020002006
* Borgmann, Albert, 1984, *Technology and the Character of Contemporary Life: A Philosophical Inquiry*, Chicago and London: University of Chicago Press.
* Bostrom, Nick, and Eliezer Yudkowsky, 2014, “The Ethics of Artificial Intelligence”, in *The Cambridge Handbook of Artificial Intelligence*, edited by Keith Frankish and William M Ramsey, Cambridge: Cambridge University Press, 316–334. doi:10.1017/CBO9781139046855.020
* Brey, Philip A.E., 2012, “Anticipatory Ethics for Emerging Technologies”, *NanoEthics*, 6(1): 1–13. doi:10.1007/s11569-012-0141-7
* Briffault, R., 1930, *Rational Evolution (The Making of Humanity)*, New York: The Macmillan Company.
* Bucciarelli, Louis L., 1994, *Designing Engineers*, Cambridge, MA: MIT Press.
* Bunge, Mario, 1966, “Technology as Applied Science”, *Technology and Culture*, 7(3): 329–347. doi:10.2307/3101932
* Butler, Samuel, 1872, *Erewhon*, London: Trubner and Co. [[Butler 1872 available online](http://archive.org/details/erewhonoroverra00butl)]
* Callon, Michel, 1986, “The Sociology of an Actor-Network: the Case of the Electric Vehicle”, in *Mapping the Dynamics of Science and Technology: Sociology of Science in the Real World*, Michel Callon, John Law and Arie Rip (eds.), London: Macmillan, pp. 19–34.
* Caney, Simon, 2014, “Two Kinds of Climate Justice: Avoiding Harm and Sharing Burdens”, *Journal of Political Philosophy* 22(2): 125–149. doi:10.1111/jopp.12030
* Coeckelbergh, Mark, 2014, “The Moral Standing of Machines: Towards a Relational and Non-Cartesian Moral Hermeneutics”, *Philosophy & Technology* 27(1): 61–77. doi: 10.1007/s13347-013-0133-8.
* –––, 2020a, *Introduction to Philosophy of Technology*, Oxford and New York: Oxford University Press.
* –––, 2020b, *AI Ethics*, Cambridge, MA: MIT Press.
* –––, 2022, *The Political Philosophy of AI: An Introduction*, Cambridge: Polity.
* Cranor, Carl F., 1990, “Some Moral Issues in Risk Assessment”, *Ethics*, 101(1): 123–143. doi:10.1086/293263
* Danaher, John, 2016, “Robots, Law and the Retribution Gap”, *Ethics and Information Technology* 18(4): 299–309. doi: 10.1007/s10676-016-9403-3.
* –––, 2020, “Welcoming Robots into the Moral Circle: A Defence of Ethical Behaviourism”, *Science and Engineering Ethics* 26(4): 2023–2049. doi: 10.1007/s11948-019-00119-x.
* Darwin, Charles R., 1859, *On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life*, London: John Murray.
* Davis, Michael, 1998, *Thinking Like an Engineer: Studies in the Ethics of a Profession*, New York and Oxford: Oxford University Press.
* –––, 2005, *Engineering Ethics*, Aldershot/Burlington, VT: Ashgate.
* –––, 2012, “‘Ain’t No One Here But Us Social Forces’: Constructing the Professional Responsibility of Engineers”, *Science and Engineering Ethics*, 18(1): 13–34. doi:10.1007/s11948-010-9225-3
* Dennett, Daniel C., 1997, “When HAL kills, who’s to blame? Computer ethics”, in *HAL’s Legacy: 2001’s Computer as Dream and Reality*, edited by David G. Stork. Cambridge, MA: MIT Press, pp. 351–365.
* Di Nucci, Ezio, and Filippo Santoni de Sio, 2016, *Drones and Responsibility: Legal, Philosophical and Socio-Technical Perspectives on Remotely Controlled Weapons*, Milton Park: Routledge.
* Diels, Hermann, 1903, *Die Fragmente der Vorsokratiker*, Berlin: Weidmann.
* Dipert, Randall R., 1993, *Artifacts, Art Works, and Agency*, Philadelphia: Temple University Press.
* Doorn, Neelke, 2010, “A Rawlsian Approach to Distribute Responsibilities in Networks”, *Science and Engineering Ethics*, 16(2): 221–249. doi:10.1007/s11948-009-9155-0
* –––, 2012, “Responsibility Ascriptions in Technology Development and Engineering: Three Perspectives”, *Science and Engineering Ethics*, 18(1): 69–90. doi:10.1007/s11948-009-9189-3
* Ellul, Jacques, 1954 [1964], *La technique ou L’enjeu du siècle*, Paris: Armand Colin. Translated as *The Technological Society*, by John Wilkinson, New York: Alfred A. Knopf, 1964.
* Erlandson, Robert F., 2008, *Universal and Accessible Design for Products, Services, and Processes*, Boca Raton, LA: CRC Press.
* Feenberg, Andrew, 1999, *Questioning Technology*, London and New York: Routledge.
* Finnis, John, Joseph Boyle and Germain Grisez, 1988, *Nuclear Deterrence, Morality and Realism*, Oxford: Oxford University Press.
* Floridi, Luciano, 2010, *The Cambridge Handbook of Information and Computer Ethics*, Cambridge: Cambridge University Press. doi:10.1017/CBO9780511845239
* Floridi, Luciano, and J.W. Sanders, 2004, “On the Morality of Artificial Agents”, *Minds and Machines*, 14(3): 349–379. doi:10.1023/B:MIND.0000035461.63578.9d
* Fox, Warwick, 2000, *Ethics and the Built Environment*, (Professional Ethics), London and New York: Routledge.
* Franssen, Maarten, 2005, “Arrow’s Theorem, Multi-Criteria Decision Problems and Multi-Attribute Preferences in Engineering Design”, *Research in Engineering Design*, 16(1–2): 42–56. doi:10.1007/s00163-004-0057-5
* Franssen, Maarten, and Louis L. Bucciarelli, 2004, “On Rationality in Engineering Design”, *Journal of Mechanical Design*, 126(6): 945–949. doi:10.1115/1.1803850
* Franssen, Maarten, and Stefan Koller, 2016, “Philosophy of Technology as a Serious Branch of Philosophy: The Empirical Turn as a Starting Point”, in *Philosophy of Technology after the Empirical Turn*, edited by Maarten Franssen, Pieter E. Vermaas, Peter Kroes, and Anthonie W.M. Meijers, Cham: Springer, 31–61. doi:10.1007/978-3-319-33717-3_3
* Franssen, Maarten, Peter Kroes, Thomas A.C. Reydon and Pieter E. Vermaas (eds), 2014, *Artefact Kinds: Ontology and the Human-Made World*, Heidelberg/New York/Dordrecht/London: Springer. doi:10.1007/978-3-319-00801-1
* Fraser, Nancy, and Axel Honneth, 2003, *Redistribution or Recognition?: A Political-Philosophical Exchange*, London and New York: Verso.
* Freeman, K., 1948, *Ancilla to the Pre-Socratic Philosophers* (*A complete translation of the Fragments in Diels, Fragmente der Vorsokratiker*), Cambridge, MA: Harvard University Press.
* Frey, R. G., and Christopher Heath Wellman (eds), 2003, *A Companion to Applied Ethics*, Oxford and Malden, MA: Blackwell. doi:10.1002/9780470996621
* Friedman, Batya, and David Hendry, 2019, *Value Sensitive Design: Shaping Technology with Moral Imagination*, Cambridge, MA: MIT Press.
* Garson, Justin, 2016, *A Critical Overview of Biological Functions*, (SpringerBriefs in Philosophy), Cham: Springer International Publishing. doi:10.1007/978-3-319-32020-5.
* Gehlen, Arnold, 1957, *Die Seele im technischen Zeitalter*, Hamburg: Rowohlt. Translated as *Man in the Age of Technology*, by Patricia Lipscomb, New York: Columbia University Press, 1980.
* Gunkel, David J., 2018, *Robot Rights*, Cambridge, MA: MIT Press.
* Habermas, Jürgen, 1968 [1970], “Technik und Wissenschaft als ‘Ideologie’” in an an anthology of the same name, Frankfurt: Suhrkamp Verlag. Translated as “Technology and Science as ‘Ideology’”, in *Toward a Rational Society: Student Protest, Science, and Politics*, by Jeremy J. Shapiro, Boston, MA: Beacon Press, pp. 81–122.
* Hansson, Sven Ove, 2003, “Ethical Criteria of Risk Acceptance”, *Erkenntnis*, 59(3): 291–309. doi:10.1023/A:1026005915919
* –––, 2004a, “Fallacies of Risk”, *Journal of Risk Research*, 7(3): 353–360. doi:10.1080/1366987042000176262
* –––, 2004b, “Philosophical Perspectives on Risk”, *Techné*, 8(1): 10–35. doi:10.5840/techne2004818
* –––, 2007, “Philosophical Problems in Cost-Benefit Analysis”, *Economics and Philosophy*, 23(2): 163–183. doi:10.1017/S0266267107001356
* Harris, Charles E., Michael S. Pritchard and Michael J. Rabins, 2014, *Engineering Ethics: Concepts and Cases*, fifth edition, Belmont, CA: Wadsworth.
* Heidegger, Martin, 1954 [1977], “Die Frage nach der Technik”, in *Vorträge und Aufsätze*, Pfullingen: Günther Neske. Translated as “The Question concerning Technology”, in *The Question Concerning Technology and Other Essays*, by William Lovitt, New York: Harper and Row, 1977, pp. 3–35.
* Herkert, Joseph R., 2001, “Future Directions in Engineering Ethics Research: Microethics, Macroethics and the Role of Professional Societies”, *Science and Engineering Ethics*, 7(3): 403–414. doi:10.1007/s11948-001-0062-2
* Hilpinen, Risto, 1992, “Artifacts and Works of Art”, *Theoria*, 58(1): 58–82. doi:10.1111/j.1755-2567.1992.tb01155.x
* Holt, Raymond, and Catherine Barnes, 2010, “Towards an Integrated Approach to ‘Design for X’: An Agenda for Decision-Based DFX Research”, *Research in Engineering Design*, 21(2): 123–136. doi:10.1007/s00163-009-0081-6
* Horkheimer, Max, and Theodor W. Adorno, 1947 [2002], *Dialektik der Aufklärung: Philosophische Fragmente*, Amsterdam: Querido Verlag. Translated as *Dialectic of Enlightenment: Philosophical Fragments*, by Edmund Jephcott, and edited by Gunzelin Schmid Noerr, Stanford, CA: Stanford University Press, 2002.
* Houkes, Wybo, 2009, “The Nature of Technological Knowledge”, in Meijers 2009: 309–350. doi:10.1016/B978-0-444-51667-1.50016-1
* Houkes, Wybo, and Pieter E. Vermaas, 2010, *Technical Functions: On the Use and Design of Artefacts*, Dordrecht/Heidelberg/London /New York: Springer. doi:10.1007/978-90-481-3900-2
* Hughes, Jesse, Peter Kroes, and Sjoerd Zwart, 2007, “A Semantics for Means-End Relations”, *Synthese*, 158(2): 207–231. doi:10.1007/s11229-006-9036-x
* Ihde, Don, 1979, *Technics and Praxis*, Dordrecht/Boston/Lancaster: D. Reidel.
* –––, 1990, *Technology and the Lifeworld: from Garden to Earth*, Bloomington: Indiana University Press.
* –––, 1993, *Philosophy of Technology: An Introduction*, New York: Paragon.
* Ihde, Don, and Evan Selinger, 2003, *Chasing Technoscience: Matrix for Materiality*, Bloomington: Indiana University Press.
* Illies, Christian, and Anthonie Meijers, 2009, “Artefacts Without Agency”, *The Monist*, 92(3): 420–440. doi:10.5840/monist200992324
* Jarvie, Ian C., 1966, “The Social Character of Technological Problems: Comments on Skolimowski’s Paper”, *Technology and Culture*, 7(3): 384–390. doi:10.2307/3101936
* Jenkins, Kirsten, Darren McCauley, Raphael Heffron, Hannes Stephan and Robert Rehner, 2016, “Energy Justice: A Conceptual Review”, *Energy Research & Social Science* 11: 174–182. doi:10.1016/j.erss.2015.10.004
* Johnson, Deborah G., 2003, “Computer Ethics”, in Frey and Wellman 2003: 608–619. doi:10.1002/9780470996621.ch45
* –––, 2006, “Computer Systems: Moral Entities But Not Moral Agents”, *Ethics and Information Technology*, 8(4): 195–205. doi:10.1007/s10676-006-9111-5
* –––, 2009, *Computer Ethics*, fourth edition. Upper Saddle River, NJ: Prentice Hall.
* Johnson, Deborah G., and Thomas M. Powers, 2005, “Computer Systems and Responsibility: A Normative Look at Technological Complexity”, *Ethics and Information Technology*, 7(2): 99–107. doi:10.1007/s10676-005-4585-0
* Jonas, Hans, 1979 [1984], *Das Prinzip Verantwortung: Versuch einer Ethik für die technologische Zivilisation*, Frankfurt/Main: Suhrkamp; extended English edition *The Imperative of Responsibility: in Search of An Ethics for the Technological Age*, Chicago and London: University of Chicago Press, 1984.
* Kaplan, David M. (ed.), 2004 [2009], *Readings in the Philosophy of Technology*, Lanham, MD and Oxford: Rowman and Littlefield, first edition 2004, second revised edition 2009.
* Kapp, Ernst, 1877 [2018], *Grundlinien Einer Philosophie Der Technik: Zur Entstehungsgeschichte Der Cultur Aus Neuen Gesichtspunkten*, Braunschweig: Westermann [[Kapp 1877 available online](http://archive.org/details/grundlinieneine00kappgoog)]. Translated as *Elements of a Philosophy of Technology: On the Evolutionary History of Culture*, by Lauren K. Wolfe, and edited by Jeffrey West Kirkwood and Leif Weatherby, Minneapolis, MN: University of Minnesota Press, 2018.
* Kitcher, Philip, 2001, *Science, Truth, and Democracy*, Oxford and New York: Oxford University Press.
* –––, 2011. *The Ethical Project*, Cambridge, MA: Harvard University Press.
* Klenk, Michael, 2021, “How Do Technological Artefacts Embody Moral Values?”, *Philosophy & Technology* 34(3): 525–544. doi: 10.1007/s13347-020-00401-y.
* Kneese, Allen V., Shaul Ben-David and William D. Schulze, 1983, “The Ethical Foundations of Benefit-Cost Analysis”, in *Energy and the Future*, edited by Douglas E. MacLean and Peter G. Brown, Totowa, NJ: Rowman and Littefield, pp. 59–74.
* Kotarbinski, Tadeusz, 1965, *Praxiology: An Introduction to the Sciences of Efficient Action*, Oxford: Pergamon Press.
* Kroes, Peter, 2012, *Technical Artefacts: Creations of Mind and Matter*, Dordrecht/Heidelberg/New York/London: Springer. doi:10.1007/978-94-007-3940-6
* Kroes, Peter, and Anthonie Meijers (eds), 2006, “The Dual Nature of Technical Artifacts”, Special issue of *Studies in History and Philosophy of Science*, 37(1): 1–158. doi:10.1016/j.shpsa.2005.12.001
* Kroes, Peter, Maarten Franssen and Louis Bucciarelli, 2009, “Rationality in Design”, in Meijers (ed.) 2009: 565–600. doi:10.1016/B978-0-444-51667-1.50025-2
* Kroes, Peter, and Peter-Paul Verbeek (eds), 2014, *The Moral Status of Technical Artefacts*, Dordrecht: Springer. doi:10.1007/978-94-007-7914-3
* Kuhn, Thomas S., 1962, *The Structure of Scientific Revolutions*, Chicago: University of Chicago Press.
* Ladd, John, 1991, “Bhopal: An Essay on Moral Responsibility and Civic Virtue”, *Journal of Social Philosophy*, 22(1): 73–91. doi:10.1111/j.1467-9833.1991.tb00022.x
* Latour, Bruno, 1992, “Where Are the Missing Masses?”, in Bijker and Law (eds) 1992: 225–258.
* –––, 1993, *We Have Never Been Modern*, New York: Harvester Wheatsheaf.
* –––, 2005, *Reassembling the Social: An Introduction to Actor-Network-Theory*, Oxford and New York: Oxford University Press.
* Lawson, Clive, 2008, “An Ontology of Technology: Artefacts, Relations and Functions”, *Technè*, 12(1): 48–64. doi:10.5840/techne200812114
* –––, 2017, *Technology and Isolation*, Cambridge and New York: Cambridge University Press. doi:10.1017/9781316848319
* Lin, Patrick, Keith Abney and Ryan Jenkins (eds), 2017, *Robot Ethics 2.0: From Autonomous Cars to Artificial Intelligence*, Oxford/New York: Oxford University Press.
* Lloyd, G.E.R., 1973, “Analogy in Early Greek Thought”, in *The Dictionary of the History of Ideas*, edited by Philip P. Wiener, New York: Charles Scribner’s Sons, vol. 1 pp. 60–64. [[Lloyd 1973 available online](http://xtf.lib.virginia.edu/xtf/view?docId=DicHist/uvaBook/tei/DicHist1.xml;chunk.id=dv1-09;toc.depth=1;toc.id=dv1-09;brand=default)]
* Lloyd, Peter A., and Jerry A. Busby, 2003, “‘Things that Went Well—No Serious Injuries or Deaths’: Ethical Reasoning in a Normal Engineering Design Process”, *Science and Engineering Ethics*, 9(4): 503–516. doi:10.1007/s11948-003-0047-4
* Longino, Helen, 1990, *Science as Social Knowledge: Values and Objectivity in Scientific Inquiry*, Princeton: Princeton University Press.
* –––, 2002, *The Fate of Knowledge*, Princeton: Princeton University Press.
* Maheshwari, Kritika, and Sven Nyholm, 2022, “Dominating Risk Impositions”, *The Journal of Ethics*. doi: 10.1007/s10892-022-09407-4.
* Mahner, Martin, and Mario Bunge, 2001, “Function and Functionalism: A Synthetic Perspective”, *Philosophy of Science*, 68(1): 73–94. doi:10.1086/392867
* Marcuse, Herbert, 1964, *One-Dimensional Man: Studies in the Ideology of Advanced Industrial Society*, New York: Beacon Press, and London: Routledge and Kegan Paul.
* Martin, Miles W., and Roland Schinzinger, 2022, *Ethics in Engineering*, fifth edition, Boston, MA: McGraw-Hill.
* Matthias, Andreas, 2004, “The Responsibility Gap: Ascribing Responsibility for the Actions of Learning Automata”, *Ethics and Information Technology* 6(3): 175–183. doi: 10.1007/s10676-004-3422-1.
* McGinn, Robert E., 2010, “What’s Different, Ethically, About Nanotechnology? Foundational Questions and Answers”, *NanoEthics*, 4(2): 115–128. doi:10.1007/s11569-010-0089-4
* Meijers, Anthonie (ed.), 2009, *Philosophy of Technology and Engineering Sciences*, (Handbook of the Philosophy of Science, volume 9), Amsterdam: North-Holland.
* Michelfelder, Diane P., and Neelke Doorn (eds), 2021, *The Routledge Handbook of the Philosophy of Engineering*, New York and Milton Park, UK: Routledge.
* Miller, Boaz, 2020, “Is Technology Value-Neutral?”, *Science, Technology & Human Values* 46(1): 53–80. doi: 10.1177/0162243919900965.
* Millikan, Ruth Garrett, 1999, “Wings, Spoons, Pills, and Quills: A Pluralist Theory of Function”, *The Journal of Philosophy*, 96(4): 191–206. doi:10.5840/jphil199996428
* Mitcham, Carl, 1994, *Thinking Through Technology: The Path Between Engineering and Philosophy*, Chicago: University of Chicago Press.
* Mittelstadt, Brent Daniel, Patrick Allo, Mariarosaria Taddeo, Sandra Wachter and Luciano Floridi, 2016, “The Ethics of Algorithms: Mapping the Debate”, *Big Data & Society*, 3(2): 1–21. doi:10.1177/2053951716679679
* Moor, James H., 1985, “What is Computer Ethics?” *Metaphilosophy*, 16(4): 266–275. doi:10.1111/j.1467-9973.1985.tb00173.x
* –––, 2006, “The Nature, Importance, and Difficulty of Machine Ethics”, *IEEE Intelligent Systems*, 21(4): 18–21. doi:10.1109/MIS.2006.80
* Mosakas, Kestutis, 2021, “On the Moral Status of Social Robots: Considering the Consciousness Criterion”, *AI & Society* 36(2): 429–443. doi: 10.1007/s00146-020-01002-1.
* Mumford, Lewis, 1934, *Technics and Civilization*, New York: Harcourt, Brace and Company, and London: Routledge and Kegan Paul.
* Newman, William R., 2004, *Promethean Ambitions: Alchemy and the Quest to Perfect Nature*, Chicago: University of Chicago Press.
* Niiniluoto, Ilkka, 1993, “The Aim and Structure of Applied Research”, *Erkenntnis*, 38(1): 1–21. doi:10.1007/BF01129020
* Nissenbaum, Helen, 1996, “Accountability in a Computerized Society”, *Science and Engineering Ethics*, 2(1): 25–42. doi:10.1007/BF02639315
* –––, 2010, *Privacy in Context: Technology, Policy, and the Integrity of Social Life*, Stanford, CA: Stanford Law Books.
* Nyholm, Sven, 2018, “Attributing Agency to Automated Systems: Reflections on Human-Robot Collaborations and Responsibility-Loci”, *Science and Engineering Ethics* 24(4): 1201–1219. doi: 10.1007/s11948-017-9943-x.
* Olsen, Jan Kyrre Berg, Evan Selinger and Søren Riis (eds), 2009, *New Waves in Philosophy of Technology*, Basingstoke and New York: Palgrave Macmillan. doi:10.1057/9780230227279
* Owen, Richard, John Bessant, and Maggy Heintz, 2013, *Responsible Innovation: Managing the Responsible Emergence of Science and Innovation in Society*, Chichester: John Wiley. doi:10.1002/9781118551424
* Peterson, Martin, 2020, *Ethics for Engineers*, New York: Oxford University Press.
* Peterson, Martin, and Andreas Spahn, 2011, “Can Technological Artefacts be Moral Agents?” *Science and Engineering Ethics*, 17(3): 411–424. doi:10.1007/s11948-010-9241-3
* Pettit, Philip, 2012, *On the People’s Terms: A Republican Theory and Model of Democracy*, The Seeley lectures, Cambridge and New York: Cambridge University Press.
* Pitt, Joseph C., 1999, *Thinking About Technology: Foundations of the Philosophy of Technology*, New York: Seven Bridges Press.
* Plato, *Laws*, 2016, M. Schofield (ed.), T. Griffith (tr.), Cambridge: Cambridge University Press.
* –––, *Timaeus and Critias*, 2008, R. Waterfield (tr.), with introduction and notes by A. Gregory, Oxford: Oxford University Press.
* Polanyi, Michael, 1958, *Personal Knowledge: Towards a Post-Critical Philosophy*, London: Routledge and Kegan Paul.
* Preston, Beth, 1998, “Why is a Wing Like a Spoon? A Pluralist Theory of Function”, *The Journal of Philosophy*, 95(5): 215–254. doi:10.2307/2564689
* –––, 2003, “Of Marigold Beer: A Reply to Vermaas and Houkes”, *British Journal for the Philosophy of Science*, 54(4): 601–612. doi:10.1093/bjps/54.4.601
* –––, 2012, *A Philosophy of Material Culture: Action, Function, and Mind*, New York and Milton Park, UK: Routledge.
* Preston, Christopher J. (ed.), 2016, *Climate Justice and Geoengineering: Ethics and Policy in the Atmospheric Anthropocene*, London/New York: Rowman & Littlefield International.
* Radder, Hans, 2009, “Why Technologies Are Inherently Normative”, in Meijers (ed.) 2009: 887–921. doi:10.1016/B978-0-444-51667-1.50037-9
* Rawls, John, 1999, *A Theory of Justice*, Revised Edition, Cambridge, MA: The Belknap Press of Harvard University Press.
* Roeser, Sabine, 2012, “Moral Emotions as Guide to Acceptable Risk”, in Roeser et al. 2012: 819–832. doi:10.1007/978-94-007-1433-5_32
* Roeser, Sabine, Rafaela Hillerbrand, Per Sandin and Martin Peterson (eds), 2012, *Handbook of Risk Theory: Epistemology, Decision Theory, Ethics, and Social Implications of Risk*, Dordrecht/Heidelberg/London/New York: Springer. doi:10.1007/978-94-007-1433-5
* Ryle, Gilbert, 1949, *The Concept of Mind*, London: Hutchinson.
* Santoni de Sio, Filippo, and Giulio Mecacci, 2021, “Four Responsibility Gaps with Artificial Intelligence: Why they Matter and How to Address them”, *Philosophy & Technology* 34(4): 1057–1084. doi: 10.1007/s13347-021-00450-x.
* Santoni de Sio, Filippo, and Jeroen van den Hoven, 2018. “Meaningful Human Control over Autonomous Systems: A Philosophical Account”, *Frontiers in Robotics and AI*. doi: 10.3389/frobt.2018.00015.
* Scharff, Robert C., and Val Dusek (eds), 2003 [2014], *Philosophy of Technology: The Technological Condition*, Malden, MA and Oxford: Blackwell, first edition 2003, second [revised] edition 2014.
* Schummer, Joachim, 2001, “Aristotle on Technology and Nature”, *Philosophia Naturalis*, 38: 105–120.
* Sclove, Richard E., 1995, *Democracy and Technology*, New York: The Guilford Press.
* Sellars, Wilfrid, 1962, “Philosophy and the Scientific Image of Man”, in *Frontiers of Science and Philosophy*, edited by R. Colodny, Pittsburgh: University of Pittsburgh Press, pp. 35–78.
* Sharkey, Amanda, and Noel Sharkey, 2021, “We Need to Talk about Deception in Social Robotics!”, *Ethics and Information Technology* 23(3): 309–316. doi: 10.1007/s10676-020-09573-9.
* Sherlock, Richard, and John D. Morrey (eds), 2002, *Ethical Issues in Biotechnology*, Lanham, MD: Rowman and Littlefield.
* Shrader-Frechette, Kristen S., 1985, *Risk Analysis and Scientific Method: Methodological and Ethical Problems with Evaluating Societal Hazards*, Dordrecht and Boston: D. Reidel.
* –––, 1991, *Risk and Rationality: Philosophical Foundations for Populist Reform*, Berkeley etc.: University of California Press.
* Simon, Herbert A., 1957, *Models of Man, Social and Rational: Mathematical Essays on Rational Human Behavior in a Social Setting*, New York: John Wiley.
* –––, 1969, *The Sciences of the Artificial*, Cambridge, MA and London: MIT Press.
* –––, 1982, *Models of Bounded Rationality*, Cambridge, MA and London: MIT Press.
* Skolimowski, Henryk, 1966, “The Structure of Thinking in Technology”, *Technology and Culture*, 7(3): 371–383. doi:10.2307/3101935
* Snapper, John W., 1985, “Responsibility for Computer-Based Errors”, *Metaphilosophy*, 16(4): 289–295. doi:10.1111/j.1467-9973.1985.tb00175.x
* Soavi, Marzia, 2009, “Realism and Artifact Kinds”, in *Functions in Biological and Artificial Worlds: Comparative Philosophical Perspectives*, edited by Ulrich Krohs and Peter Kroes. Cambridge, MA: MIT Press, pp. 185–202. doi:10.7551/mitpress/9780262113212.003.0011
* Sparrow, Robert, 2007, “Killer Robots”, *Journal of Applied Philosophy* 24(1): 62–77. doi:10.1111/j.1468-5930.2007.00346.x
* Suh, Nam Pyo, 2001, *Axiomatic Design: Advances and Applications*, Oxford and New York: Oxford University Press.
* Susskind, Jamie, 2022, *The Digital Republic: On Freedom and Democracy in the 21st Century*, London: Bloomsbury.
* Swierstra, Tsjalling, and Jaap Jelsma, 2006, “Responsibility Without Moralism in Technoscientific Design Practice”, *Science, Technology & Human Values*, 31(1): 309–332. doi:10.1177/0162243905285844
* Swierstra, Tsjalling, and Hedwig te Molder, 2012, “Risk and Soft Impacts”, in Roeser et al. (eds) 2012: 1049–1066. doi:10.1007/978-94-007-1433-5_42
* Taebi, Behnam, 2021, *Ethics and Engineering: An Introduction*, Cambridge Applied Ethics series, Cambridge and New York: Cambridge University Press.
* Taebi, Behnam, and Sabine Roeser (eds), 2015, *The Ethics of Nuclear Energy: Risk, Justice, and Democracy in the Post-Fukushima Era*, Cambridge: Cambridge University Press. doi:10.1017/CBO9781107294905
* Tavani, Herman T., 2002, “The Uniqueness Debate in Computer Ethics: What Exactly is at Issue, and Why Does it Matter?” *Ethics and Information Technology*, 4(1): 37–54. doi:10.1023/A:1015283808882
* Thomasson, Amie L., 2003, “Realism and Human Kinds”, *Philosophy and Phenomenological Research*, 67(3): 580–609. doi:10.1111/j.1933-1592.2003.tb00309.x
* –––, 2007, “Artifacts and Human Concepts”, in *Creations of the Mind: Essays on Artifacts and Their Representation*, edited by Eric Margolis and Stephen Laurence, Oxford: Oxford University Press, pp. 52–73.
* Thompson, Dennis F., 1980, “Moral Responsibility and Public Officials: The Problem of Many Hands”, *American Political Science Review*, 74(4): 905–916. doi:10.2307/1954312
* Thompson, Paul B., 2007, *Food Biotechnology in Ethical Perspective*, second edition, Dordrecht: Springer. doi:10.1007/1-4020-5791-1
* Vallor, Shannon (ed.), 2022, *The Oxford Handbook of Philosophy of Technology*, Oxford and New York: Oxford University Press.
* van den Hoven, Jeroen, and John Weckert (eds), 2008, *Information Technology and Moral Philosophy*, Cambridge and New York: Cambridge University Press.
* van den Hoven, Jeroen, Pieter E. Vermaas and Ibo van de Poel (eds), 2015, *Handbook of Ethics and Values in Technological Design: Sources, Theory, Values and Application Domains*, Dordrecht: Springer. doi:10.1007/978-94-007-6994-6
* van de Poel, Ibo, 2009, “Values in Engineering Design”, in Meijers (ed.) 2009: 973–1006. doi:10.1016/B978-0-444-51667-1.50040-9
* –––, 2016, “An Ethical Framework for Evaluating Experimental Technology”, *Science and Engineering Ethics*, 22(3): 667–686. doi:10.1007/s11948-015-9724-3
* van de Poel, Ibo, and Lambèr Royakkers, 2011, *Ethics, Technology and Engineering*, Oxford: Wiley-Blackwell.
* van de Poel, Ibo, Lambèr Royakkers and Sjoerd D. Zwart, 2015, *Moral Responsibility and the Problem of Many Hands*, London: Routledge.
* van der Pot, Johan Hendrik Jacob, 1985 [1994/2004], *Die Bewertung des technischen Fortschritts: eine systematische Übersicht der Theorien*, 2 volumes, Assen/Maastricht: Van Gorcum. Translated as *Steward or Sorcerer’s Apprentice? the Evaluation of Technical Progress: A Systematic Overview of Theories and Opinions*, by Chris Turner, 2 volumes., Delft: Eburon, 1994, second edition, 2004, under the title *Encyclopedia of Technological Progress: A Systematic Overview of Theories and Opinions*.
* van Wynsberghe, Aimee, and Scott Robbins, 2019, “Critiquing the Reasons for Making Artificial Moral Agents”, *Science and Engineering Ethics* 25(3): 719–735. doi: 10.1007/s11948-018-0030-8.
* Verbeek, Peter-Paul, 2000 [2005], *De daadkracht der Dingen: Over Techniek, Filosofie En Vormgeving*, Amsterdam: Boom. Translated as *What Things Do: Philosophical Reflections on Technology, Agency, and Design*, by Robert P. Crease, University Park, PA: Penn State University Press, 2005.
* –––, 2011, *Moralizing Technology: Understanding and Designing the Morality of Things*, Chicago and London: The University of Chicago Press.
* Vermaas, Pieter E., and Wybo Houkes, 2003, “Ascribing Functions to Technical Artefacts: A Challenge to Etiological Accounts of Functions”, *British Journal for the Philosophy of Science*, 54(2): 261–289. doi:10.1093/bjps/54.2.261
* Vincenti, Walter A., 1990, *What Engineers Know and How They Know It: Analytical Studies from Aeronautical History*, Baltimore, MD and London: Johns Hopkins University Press.
* Vitruvius, *De architecture*, translated as *The Ten Books on Architecture*, by Morris H. Morgan. Cambridge, MA: Harvard University Press, 1914. [[Vitruvius Morgan’s translation 1914 available online](http://www.gutenberg.org/ebooks/20239)]
* Volti, Rudi, 2009, *Society and Technological Change*, sixth edition, New York: Worth Publications.
* Von Wright, Georg Henrik, 1963, *Norm and Action: A Logical Enquiry*, London: Routledge and Kegan Paul.
* Wallach, Wendell, and Colin Allen, 2009, *Moral Machines: Teaching Robots Right from Wrong*, Oxford and New York: Oxford University Press. doi:10.1093/acprof:oso/9780195374049.001.0001
* Weckert, John, 2007, *Computer Ethics*, Aldershot and Burlington, VT: Ashgate.
* Wiggins, David, 1980, *Sameness and Substance*, Oxford: Blackwell.
* Winner, Langdon, 1977, *Autonomous Technology: Technics-out-of-Control as a Theme in Political Thought*, Cambridge, MA and London: MIT Press.
* –––, 1980, “Do Artifacts Have Politics?” *Daedalus*, 109(1): 121–136.
* –––, 1983, “Techné and Politeia: The Technical Constitution of Society”, in *Philosophy and Technology*, edited by Paul T. Durbin and Friedrich Rapp, Dordrecht/Boston/Lancaster: D. Reidel, pp. 97–111. doi:10.1007/978-94-009-7124-0_7
* Zandvoort, H., 2000, “Codes of Conduct, the Law, and Technological Design and Development”, in *The Empirical Turn in the Philosophy of Technology*, edited by Peter Kroes and Anthonie Meijers, Amsterdam: JAI/Elsevier, pp. 193–205.
* Zuboff, Shoshana, 2017, *The Age of Surveillance Capitalism*, New York: Public Affairs.
* Zwart, Sjoerd, Maarten Franssen and Peter Kroes, 2018, “Practical Inference—A Formal Approach”, in *The Future of Engineering: Philosophical Foundations, Ethical Problems and Application Cases*, edited by Albrecht Fritzsche and Sascha Julian Oks, Cham: Springer, pp. 33–52. doi:10.1007/978-3-319-91029-1_3
* Zwart, Sjoerd, Ibo van de Poel, Harald van Mil and Michiel Brumsen, 2006, “A Network Approach for Distinguishing Ethical Issues in Research and Development”, *Science and Engineering Ethics*, 12(4): 663–684. doi:10.1007/s11948-006-0063-2

### Journals

* *Philosophy & Technology*
* [*Techné: Research in Philosophy and Technology*](http://scholar.lib.vt.edu/ejournals/SPT/)
* *Science and Engineering Ethics*
* [*Science, Technology & Human Values*](http://sth.sagepub.com/)
* *Ethics and Information Technology*
* *NanoEthics*
* *Neuroethics*

### Encyclopedias

* *Encyclopedia of Science, Technology, and Ethics*, 4 volumes, Carl Mitcham (ed.), Macmillan, 2005.
* *Encyclopedia of Applied Ethics*, second edition, 4 volumes, Ruth Chadwick (editor-in-chief), Elsevier, 2012.

## Academic Tools

> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=technology). |
> | --- | --- |
> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/technology/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
> | ![inpho icon](https://plato.stanford.edu/symbols/inpho.png) | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=technology&redirect=True) at the Internet Philosophy Ontology Project (InPhO). |
> | ![phil papers icon](https://plato.stanford.edu/symbols/pp.gif) | [Enhanced bibliography for this entry](https://philpapers.org/sep/technology/) at [PhilPapers](https://philpapers.org/), with links to its database. |

## Other Internet Resources

* [Society for Philosophy and Technology](http://www.spt.org/)
* [Forum for Philosophy, Engineering & Technology](https://philosophyengineering.com/)
* [Online Ethics Center](http://onlineethics.org/)
* [4TU. Centre for Ethics and Technology](https://www.ethicsandtechnology.eu/)
* [Oxford Uehiro Centre for Practical Ethics](http://www.practicalethics.ox.ac.uk/)

## Related Entries

[Aristotle, Special Topics: causality](https://plato.stanford.edu/entries/aristotle-causality/) | [artifact](https://plato.stanford.edu/entries/artifact/) | [artificial intelligence: ethics of](https://plato.stanford.edu/entries/ethics-ai/) | [Bacon, Francis](https://plato.stanford.edu/entries/francis-bacon/) | [Chinese room argument](https://plato.stanford.edu/entries/chinese-room/) | [Church-Turing Thesis](https://plato.stanford.edu/entries/church-turing/) | [computability and complexity](https://plato.stanford.edu/entries/computability/) | [computer science, philosophy of](https://plato.stanford.edu/entries/computer-science/) | [computing: and moral responsibility](https://plato.stanford.edu/entries/computing-responsibility/) | [*episteme* and *techne* [= scientific knowledge and expertise]](https://plato.stanford.edu/entries/episteme-techne/) | [functionalism](https://plato.stanford.edu/entries/functionalism/) | [identity: over time](https://plato.stanford.edu/entries/identity-time/) | [identity: relative](https://plato.stanford.edu/entries/identity-relative/) | [information technology: and moral values](https://plato.stanford.edu/entries/it-moral-values/) | [justice](https://plato.stanford.edu/entries/justice/) | [justice: climate](https://plato.stanford.edu/entries/justice-climate/) | [knowledge how](https://plato.stanford.edu/entries/knowledge-how/) | [material constitution](https://plato.stanford.edu/entries/material-constitution/) | [mind: computational theory of](https://plato.stanford.edu/entries/computational-mind/) | [moral responsibility](https://plato.stanford.edu/entries/moral-responsibility/) | [multiple realizability](https://plato.stanford.edu/entries/multiple-realizability/) | [Popper, Karl](https://plato.stanford.edu/entries/popper/) | [practical reason](https://plato.stanford.edu/entries/practical-reason/) | [rationality: instrumental](https://plato.stanford.edu/entries/rationality-instrumental/) | [responsibility: collective](https://plato.stanford.edu/entries/collective-responsibility/) | [risk](https://plato.stanford.edu/entries/risk/) | [sortals](https://plato.stanford.edu/entries/sortals/) | [Turing machines](https://plato.stanford.edu/entries/turing-machine/) | [Turing test](https://plato.stanford.edu/entries/turing-test/)

[Copyright © 2023](https://plato.stanford.edu/info.html#c) by  
[Maarten Franssen](http://www.tbm.tudelft.nl/en/about-faculty/departments/values-technology-and-innovation/sections/ethicsphilosophy-of-technology/staff/dr-mpm-maarten-franssen/) <[*m.p.m.franssen@tudelft.nl*](mailto:m%2ep%2em%2efranssen%40tudelft%2enl)>  
[Gert-Jan Lokhorst](http://gjclokhorst.nl/) <[*g.j.c.lokhorst@tudelft.nl*](mailto:g%2ej%2ec%2elokhorst%40tudelft%2enl)>  
[Ibo van de Poel](http://www.tbm.tudelft.nl/en/about-faculty/departments/values-technology-and-innovation/sections/ethicsphilosophy-of-technology/staff/profdrir-ir-ibo-van-de-poel/) <[*I.R.vandepoel@tudelft.nl*](mailto:I%2eR%2evandepoel%40tudelft%2enl)>
<!--md-padding-ignore-end-->
