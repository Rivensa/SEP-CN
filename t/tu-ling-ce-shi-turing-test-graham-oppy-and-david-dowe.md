# 图灵测试 Turing test (Graham Oppy and David Dowe)

*首次发表于 2003 年 4 月 9 日，实质性修订于 2021 年 10 月 4 日*

“图灵测试”这个短语最适当地用来指的是图灵（1950 年）提出的一个处理机器是否能思考的问题的提案。根据图灵的观点，机器是否能思考这个问题本身是“毫无意义”的，不值得讨论（442 页）。然而，如果我们考虑更精确且与之相关的问题，即数字计算机是否能在图灵描述的某种游戏中表现出色（“模仿游戏”），那么至少在图灵看来，我们确实有一个可以进行精确讨论的问题。此外，正如我们将看到的，图灵本人认为在不久的将来，我们将拥有能够在模仿游戏中表现出色的数字计算机。

“图灵测试”这个短语有时更普遍地用来指的是对被认为具有心灵、思维或智能的实体进行某种行为测试的测试。因此，例如，有时会提出“图灵测试”在笛卡尔的《方法论讲演》中有预兆。（Copeland（2000:527）在笛卡尔的 de Cordemoy 的 1668 年著作中发现了对该测试的预期。Abramson（2011a）提供了图灵在撰写他的 1950 年论文时意识到笛卡尔的语言测试的档案证据。Gunderson（1964）提供了那些认为图灵的工作在笛卡尔的工作中有预兆的早期例子。）

“图灵测试”这个短语有时也被用来指代某些纯行为主义的、据称在逻辑上足够条件来判断思维、智能或心智存在的条件，或者说是对于被认为有心智的实体的条件。例如，尼德·布洛克的“方块头”思想实验经常被认为是对图灵测试的（假设性的）反驳。（布洛克（1981）在这个背景下直接讨论了图灵测试。）在这里，这种观点的支持者所指的是这样一个想法：一个实体在逻辑上有可能通过笛卡尔和（至少是据称的）图灵所考虑的那种测试，以人类的方式使用词语（也许还有行动），但完全缺乏智能，没有心智等等。

随后的讨论按照引入的顺序对前面的观点进行了讨论。首先，讨论了图灵的论文（1950 年）及其中包含的论证。其次，讨论了对被称为“图灵测试”的各种提议的当前评估（无论是否在将此标签应用于相关提议中有多少价值）。第三，简要讨论了一些关于图灵测试的最近著作，包括对于图灵测试是否为研究人工智能设定了适当目标的讨论。最后，简要讨论了西尔的中文房间论证，特别是这个论证对图灵测试的影响。

对于图灵测试的其他入门讨论，从不同的角度来看，例如：Copeland（2000），Damassino 和 Novelli（2020），French（2000），Korukonda（2003），Moor（2008），Neufeld 和 Finnestad（2020a）（2020b），Proudfoot 和 Copeland（2008），Saygin 等人（2000）和 Shieber（2004）。有关图灵本人的更多信息，请参阅：Cooper 和 van Leeuwen（2013），Copeland 等人（2017），Hodges（1983），Millican 和 Clark（1999）和 Turing（1992）。

---

## 1. 图灵（1950）和模仿游戏

图灵（1950）描述了以下类型的游戏。假设我们有一个人、一台机器和一个询问者。询问者在一个与其他人和机器分开的房间里。游戏的目标是让询问者确定其他两者中哪一个是人，哪一个是机器。询问者通过标签“X”和“Y”来认识其他人和机器，但至少在游戏开始时，不知道其他人和机器中哪一个是“X”，并在游戏结束时说：“X 是人，Y 是机器”或“X 是机器，Y 是人”。询问者可以向人和机器提出以下类型的问题：“X 能告诉我 X 是否下棋吗？”无论是机器还是其他人中的 X 都必须回答针对 X 的问题。机器的目标是试图使询问者错误地得出结论，认为机器是其他人；其他人的目标是试图帮助询问者正确识别机器。关于这个游戏，图灵（1950）说：

> 我相信大约五十年后，将有可能编程计算机，其存储容量约为 10^9，使它们能够很好地进行模拟游戏，以至于一个普通的询问者在五分钟的询问后，正确识别的几率不超过 70％。...我相信在本世纪末，词语的使用和一般受教育的观点将发生如此大的变化，以至于人们将能够谈论机器思考而不期望被反驳。

至少有两种问题可以提出关于图灵对他的模拟游戏的预测。首先，有经验性的问题，例如，现在或不久将来，我们是否已经制造出能够很好地进行模拟游戏的计算机，以至于一个普通的询问者在五分钟的询问后，正确识别的几率不超过 70％？其次，有概念性的问题，例如，如果一个普通的询问者在五分钟的询问后，正确识别的几率不超过 70％，我们是否应该得出结论，认为该机器展示了某种程度的思考、智能或心理能力？

毫无疑问，图灵对二十世纪末的现状肯定会感到失望。参加洛布纳奖竞赛的参赛者们提交的计算机程序远未达到图灵所设想的水平。仅需查看前十年参赛者的记录，就能发现这些程序很容易被一系列不太微妙的问题所识破。此外，该领域的主要参与者经常声称洛布纳奖竞赛令人尴尬，因为我们离拥有一个能够进行五分钟良好对话的计算机程序仍然相距甚远，详见 Shieber（1994）。各方普遍认可，参加洛布纳奖竞赛的程序仅仅是为了赢得年度最佳竞争者的小奖，而没有考虑到所采用的策略是否能够真正通过图灵测试。

在 21 世纪的第二个十年结束时，目前尚不清楚发生了多少变化。一方面，语言生成器方面出现了一些有趣的发展。特别是 Open AI 发布的 GPT-3（Brown 等，2020 年，其他互联网资源）引发了一系列的兴奋。GPT-3 在生成小说、诗歌、新闻稿、代码、音乐、笑话、技术手册和新闻文章方面非常出色。正如 Chalmers（2020 年，其他互联网资源）所推测的那样，GPT-3“暗示了一种通向人工通用智能的潜在无意识路径”。但是，当然，GPT-3 还远未能通过图灵测试：GPT-3 既不感知也不行动，至于它是否具有理解能力，这是一个极具争议的问题。尚待观察的是，在接下来的几代语言生成器（如 GPT-4 或 GPT-5）中，我们是否能够找到一种能够与感知输入和行为输出相连接的方式，从而产生能够通过图灵测试的东西。（有关进一步讨论，请参见 Floridi 和 Chiriatti（2020 年）。）

另一方面，正如 Floridi（2008）抱怨的那样，进展缓慢的方式还有其他。2014 年，有声称计算机程序 Eugene Goostman 在图灵测试 2014 竞赛中欺骗了 33%的评委，因此“通过了图灵测试”。但是还有其他一次性竞赛也取得了类似的结果。早在 1991 年，PC Therapist 就成功欺骗了 50%的评委。而在 2011 年的一次演示中，Cleverbot 的成功率更高。在这三种情况下，试验规模都非常小，并且结果不可靠：在任何情况下，都没有足够的理由认为一个普通的询问者在五分钟的询问后，对于相关程序的正确判断的几率不超过 70%。此外，更重要的是，我们必须区分图灵提出的测试和他对二十世纪末事物发展的特定预测。在测试中，正确识别的百分比几率、测试持续的时间间隔以及所需的对话交流次数都是可调整的参数，尽管它们在图灵的特定预测中是固定的。即使图灵对于二十世纪末事物发展的预测相差甚远，他提出的测试仍然可能是一个好的测试。然而，在认可图灵测试是好的建议之前，有一些异议需要解决。

有人提出图灵测试是沙文主义的：它只承认能够与我们进行对话的事物的智能。为什么不能有一些智能的事物无法进行对话，或者至少无法与像我们这样的生物进行对话呢？（例如，参见 French（1990））。也许这个问题背后的直觉是可以被接受的；也许坚持认为只有能够与我们进行对话的事物才具有智能是过于沙文主义的。（另一方面，人们可能会认为，鉴于有合适资质的翻译人员的可用性，任何说不同语言的两个智能体都应该能够进行某种形式的对话。）但是，无论如何，指责沙文主义完全离题。图灵所声称的只是，如果某个事物能够与我们进行对话，那么我们有充分的理由认为该事物具有与我们相似的智能；他并不声称只有能够与我们进行对话的事物才能拥有我们所具备的那种智能。

其他人认为图灵测试要求不够严格：我们已经有了一些轶事证据，表明相当无智能的程序（例如 ELIZA——详情请参见 Weizenbaum（1966））在相当长的时间内似乎对普通观察者来说是智能的中心。此外，在短时间内——比如图灵在他对 2000 年情况的预测中提到的五分钟内——几乎所有的人类观察者都可能被精心设计但相当无智能的程序所欺骗。然而，重要的是要记住，为了通过图灵测试，计算机程序不仅仅需要在测试所规定的情况之外欺骗“普通观察者”。计算机程序必须能够经受住知道对话中另外两个参与者之一是机器的人的询问。此外，计算机程序必须能够在多次试验中以高度成功的方式经受住这种询问。（图灵对于需要多少次试验没有提及。然而，我们可以安全地假设，为了获得足够的证据，即在五分钟的对话之后，有不超过 70%的机会正确地将机器识别为机器，必须进行相当多的试验。）如果一个计算机程序能够做到这个相当严格的事情，那么我们似乎有至少初步的理由认为我们面前有智能存在。（也许值得再次强调，可能存在各种各样的智能事物，包括智能机器，它们无法通过这个测试。例如，有可能存在一些机器，由于道德考虑，拒绝撒谎或进行伪装。） 由于人类参与者被认为会尽一切可能帮助询问者，问题“你是机器人吗？”将迅速让询问者区分出这种（病态的？）说真话的机器人和人类。)

图灵（1950 年）论文中另一个有争议的方面涉及他将讨论限制在“数字计算机”这种情况下。一方面，显然这种限制只对图灵对 2000 年的预测有重要意义，而对测试本身的细节并没有重要影响。（实际上，如果图灵提出的测试是一个好的测试，那么它将适用于任何类型的实体，包括动物、外星人和模拟计算机。也就是说，如果动物、外星人、模拟计算机或其他任何类型的事物通过了图灵提出的测试，那么我们有足够的理由认为这些事物展示了智能，就像我们有理由认为通过了测试的数字计算机展示了智能一样。）另一方面，关于“思考机器”是否必须是数字计算机的问题实际上是一个极具争议的问题；而且图灵自己是否认为这将是情况也是一个有争议的问题。特别值得注意的是，图灵（1950 年）考虑的第七个反对意见涉及连续状态机的可能性，图灵明确承认这与离散状态机是不同的。图灵似乎声称，即使我们是连续状态机，离散状态机也能够以足够好的方式模仿我们，以满足模拟游戏的目的。然而，他给出的考虑似乎不足以证明，如果有连续状态机通过了图灵测试，那么也有可能制造出通过测试的离散状态机。（图灵本人曾急于指出，为了使关于“思考机器”的问题有趣，必须对“机器”的概念设定一些限制：）

> 我们自然希望允许在我们的机器中使用各种工程技术。我们还希望允许工程师或工程团队构建一台能够工作但其操作方式无法令其构造者满意地描述的机器，因为他们采用了一种主要是实验性的方法。最后，我们希望排除那些以通常方式出生的人类。很难制定定义以满足这三个条件。例如，我们可能坚持认为工程团队的成员应该都是同一性别，但这实际上并不令人满意，因为可能可以从一个人的皮肤细胞（比如说）中培养出一个完整的个体。这样做将是一项值得极高赞扬的生物技术壮举，但我们不倾向于将其视为“构建思考机器”的情况。（435/6）

但是，当然，正如图灵本人所认识到的，存在一大类既不是数字的也不是生物技术的“机器”。更一般地说，关键点似乎在于，尽管图灵认识到机器的类别可能比离散状态机器的类别要大得多，但他本人非常有信心，经过适当设计的离散状态机器可以在模拟游戏中取得成功（而且，在他写作的时候，公众想象中存在着某些离散状态机器——“电子计算机”）。

## 2. 图灵（1950 年）和对反对意见的回应

虽然图灵（1950 年）的论述相当非正式，并且在某些方面相当个人化，但通过考虑图灵对机器（尤其是数字计算机）“思考”的主张可能遭到的异议的讨论，我们可以获得很多收获。图灵对他所考虑的异议给出了以下标签：（1）神学上的异议；（2）“埋头沙中”的异议；（3）数学上的异议；（4）意识论证；（5）各种缺陷的论证；（6）拉夫莱斯夫人的异议；（7）神经系统连续性的论证；（8）行为的非正式性论证；以及（9）超感知的论证。我们将在下面的相应小节中考虑这些异议。（在某些情况下，我们讨论的这些异议的反驳论证也由图灵提供。）

### 2.1 神学上的异议

物质二元论者认为思考是一种非物质的、独立存在的物质的功能，它以某种方式与身体“结合”以形成一个人。因此，论证可能是这样的：仅仅制造一个身体永远不足以保证思想的存在：从本质上讲，数字计算机与任何其他纯粹物质的身体没有任何区别，都无法思考。此外——引入“神学”元素——还可以进一步补充说，当“灵魂”适当地与身体结合时，这总是宇宙的神圣创造者的工作：是否赋予一种特定类型的身体以有思想的灵魂完全取决于上帝。（有关人类“按照上帝的形象造”的命题有众所周知的经文支持。也许还有神学上的支持，即只有上帝才能按照上帝的形象创造事物。）

在这里有几个不同的评论要提出。首先，对于物质二元论有许多严肃的反对意见。其次，对于神论也有许多严肃的反对意见。第三，即使神论和物质二元论都被允许通过，为什么认为思维机器会被这些观点排除仍然不太清楚。考虑到上帝可以将灵魂与人体结合，很难理解为什么认为上帝不能将灵魂与数字计算机（或者岩石）结合。也许，在这些观点的结合中，我们可以制造的事物中，数字计算机是上帝赋予灵魂的唯一一种，这并没有特别好的理由 - 但是似乎很明显，也没有特别好的理由排除上帝选择将灵魂赋予某些类型的数字计算机的可能性。证明上帝坚决反对将灵魂赋予某些类型的数字计算机的想法并不是特别充分的。

### 2.2 “埋头沙”反对意见

如果存在思维机器，那么将会产生各种后果。首先，我们将失去认为自己优于宇宙中一切其他事物的最好理由（因为我们珍视的“理性”将不再是我们独有的）。其次，我们可能被机器“取代”的可能性将成为一个真正的担忧：如果存在思维机器，很可能会有比我们更擅长思考的机器。第三，我们可能被机器“统治”的可能性也将成为一个真正的担忧：如果存在思维机器，谁能说他们不会接管宇宙，并奴役或灭绝我们呢？

就目前而言，我们在这里所面对的并不是反对机器能够思考的论点，而是对于如果存在思考的机器会发生什么的各种担忧的表达。一个认真对待这些担忧并且相信我们确实能够构建思考的机器的人，可能会认为我们在这里有理由放弃尝试构建思考的机器的项目。然而，确定是否真的有任何充分的理由认真对待这些担忧，将是一项重大任务，我们在这里并不打算追求这个问题。

### 2.3 数学上的反对意见

有些人认为在 20 世纪 30 年代期间发现的数学逻辑的某些基本结果——由哥德尔（第一不完全性定理）和图灵（停机问题）发现——对于数字计算和智能思维的问题有重要的影响。（例如，参见卢卡斯（1961）和彭罗斯（1989）；还可以参见霍奇斯（1983:414），他提到了波兰尼与图灵关于这个问题的讨论。）基本上，这些结果表明，在一个足够强大的形式系统中，存在一类可以表达但无法在系统内证明的真实陈述（参见哥德尔的不完全性定理词条）。让我们说这样的系统“受到了卢卡斯-彭罗斯约束”，因为它受到了无法证明系统内可表达的一类真实陈述的限制。

图灵（1950:444）本人观察到，数学逻辑的这些结果可能对图灵测试产生影响：

> 有一些事情[任何数字计算机]无法做到。如果它被设置成像模拟游戏中那样回答问题，那么无论给予多少时间回答，它要么会给出错误答案，要么根本不会给出答案。（444）

因此，在图灵测试的背景下，“受到卢卡斯-彭罗斯约束”的意味着存在一类“无法回答”的问题。然而，图灵指出，在图灵测试的背景下，这些“无法回答”的问题只有在人类能够回答它们的情况下才是一个问题。他的“简短”回答是，人类是否摆脱了这种约束并不清楚。然后图灵继续补充说，他认为这个论点不能“如此轻易地被驳斥”。

为了使论证更加精确，我们可以将其写成如下形式：

1. 设 C 为一台数字计算机。
2. 由于 C 受到 Lucas-Penrose 约束，对于 C 存在一个“无法回答”的问题 q。
3. 如果一个实体 E 不受卢卡斯-彭罗斯约束，那么对于 E 来说就没有“无法回答”的问题。
4. 人类智力不受卢卡斯-彭罗斯约束。
5. 因此，对于人类智力来说就没有“无法回答”的问题。
6. 因此，问题 q 对人类智力来说是“可回答的”。
7. 通过提问问题 q，人类可以确定回答者是计算机还是人类。
8. 因此，C 可能无法通过图灵测试。

一旦将上述论点阐述清楚，就变得明显，前提（3）应该受到质疑。将此放在一边，我们注意到图灵的“简短”回答的一种解释是，主张（4）仅仅是断言，没有任何证明。这个“简短”回答引导我们去考察人类是否摆脱了卢卡斯-彭罗斯的限制。

如果人类受到卢卡斯-彭罗斯的限制，那么这个限制就无法区分人类和数字计算机。如果人类摆脱了卢卡斯-彭罗斯的限制，那么（假设前提 3 成立），数字计算机可能无法通过图灵测试，因此似乎无法思考。

然而，是否摆脱这种限制对于思考能力是否必要仍然存在疑问。可能图灵测试太严格了。根据假设，我们摆脱了卢卡斯-彭罗斯的限制，从某种意义上说，我们在提问和回答问题方面太出色了。假设存在一个受到卢卡斯-彭罗斯限制的思考实体。通过类似上述论证，它可能无法通过图灵测试。因此，一个能够思考的实体将无法通过图灵测试。

通过注意到数学逻辑的结果所暗示的问题的构建（哥德尔、图灵等）非常复杂，并且需要关于数字计算机的语言和内部编程的极其详细的信息（当然，这些信息在模拟游戏中的询问者是不可得的）。至少，需要更多的论证来推翻图灵测试仍然可以作为一种非常高质量的统计测试来检测心智和智能存在，即使数字计算机与人类不同，受到卢卡斯-彭罗斯约束的限制。（有关进一步讨论，请参见 Bowie 1982，Dietrich 1994，Feferman 1996，Abramson 2008 以及关于哥德尔不完全性定理的条目第 6.3 节。）

### 2.4 意识的论证

图灵引用杰斐逊教授 1949 年的利斯特演讲作为他认为属于这个标签的反对意见的来源：

> 直到机器能够因为感受到的思想和情感而写出一首十四行诗或谱写一首协奏曲，而不是仅仅因为符号的偶然落下，我们才能认同机器等同于大脑——也就是说，不仅仅是写出来，还知道它已经写出来了。没有任何机制能够感受到（而不仅仅是人为地发出信号，这是一种简单的构想）在成功时的愉悦，在阀门熔断时的悲伤，被奉承时的温暖，因错误而感到痛苦，被性吸引，当无法得到想要的东西时感到愤怒或沮丧。（445/6）

这里有几个不同的思想被混在一起，解开它们是有益的。一个思想——图灵首先关注的思想——是只有成为机器并感受到自己的思考，我们才能确定机器在思考。第二个思想，也许是心灵存在需要一种特定类型的自我意识（“不仅仅是写出来，还知道它已经写出来了”）。第三个思想是，把心灵看得太狭隘是错误的，即认为可以有一个信仰的智力与在人类行为生成中起着核心作用的欲望和情感分离开来（“没有任何机制能够感受到…”）。

针对唯我论的思路，图灵给出了有效的回答，他表示，如果我们能够达成这样的共识，即我们每个人都有足够的理由认为机器思考，就像我们有理由认为其他人思考一样，他将会满意。（重点不在于图灵认为唯我论是一个严肃的选择；相反，重点是，按照这种论证思路不会得出这样的结论，即在某些方面，数字计算机可能无法成为我们的智力平等或上级。）

对于其他思路，图灵提供了一个小小的“口试”，旨在说明他认为人们可能拥有的证明机器具有智能的证据类型。如果机器能够给出正确的回应，我们自然会将其言辞解释为快乐、悲伤、温暖、痛苦、愤怒、沮丧等的证据。也许——尽管图灵没有明说——制造这种机器的唯一方法是装备传感器、情感状态等，实际上是制造一个人工人。然而，重要的是，如果关于自我意识、欲望、情感等的主张是正确的，那么图灵可以平静地接受这些主张：他的主张是，具有数字计算“大脑”的机器可以拥有成年人所能享受的全部心理状态。

### 2.5 各种缺陷的论证

图灵考虑了一系列人们声称机器永远无法做到的事情：（1）善良；（2）足智多谋；（3）美丽；（4）友善；（5）有主动性；（6）有幽默感；（7）分辨是非；（8）犯错误；（9）坠入爱河；（10）享受草莓和奶油；（11）让某人爱上自己；（12）从经验中学习；（13）正确使用词语；（14）成为自己思想的主题；（15）具有与男人一样多样化的行为；（16）做出真正新颖的事情。

在我们直接回答这些主张之前，一个有趣的问题是，我们是否应该假设来自宇宙其他地方的智能生物一定能够做这些事情。例如，为什么我们要假设一个不喜欢草莓和奶油的生物一定有缺陷呢？当然，我们可以假设一个智能生物应该有能力享受某些事物，但坚持认为智能生物一定要能够享受我们所享受的事物似乎过于沙文主义。（毫无疑问，类似的考虑也适用于智能生物必须是能够让人类爱上它的那种东西的主张。是的，也许，一个智能生物应该是能够爱和被爱的那种东西；但我们有什么特别之处呢？）

撇开那些我们认为过于沙文主义的任务，我们应该问有什么理由认为没有任何数字计算机能够完成列表上的其他事情。图灵认为，最有可能的理由在于我们对各种机器的先前了解：我们迄今为止遇到的任何机器都不能做这些事情。特别是，我们现在熟悉的数字计算机不能做这些事情。（也许除了犯错误：毕竟，即使是数字计算机也会出现“功能错误”。但这可能被视为一个无关紧要的情况。）然而，考虑到即使是最新的数字计算机的存储容量和处理速度的限制，我们在评估这个归纳论证的优点时有明显的理由要谨慎。

（一个值得问的不同问题是，迄今为止在构建能够完成图灵清单上所列任务的机器方面取得了多少进展。关于当前计算机能否犯错、正确使用词语、从经验中学习、具有美感等问题，至少还有争论的余地。此外，关于其他领域的最新进展能否预期将进一步克服这些所谓的缺陷，也还有争论的余地。也许，例如，人工传感器方面的最新进展有一天可以为制造能够享受草莓和奶油的机器做出贡献。当然，如果对机器能够体验任何形式的愉悦感的概念提出异议，那么特定类型的人工传感器的研究是否切题就不清楚了。）

### 2.6 洛夫莱斯夫人的异议

对于声称可以存在思考机器的主张，最受欢迎的异议之一是洛夫莱斯夫人在她对巴贝奇的分析引擎的回忆录中提到的一句话。

> 解释/原理

机器只能执行我们知道如何命令它们执行的任务（或者说机器永远不能做任何真正新颖的事情，或者任何让我们感到惊讶的事情）。正如图灵所说，回应这些挑战的一种方式是问我们是否能够做出任何“真正新颖”的事情。例如，假设世界是确定性的，这意味着我们所做的一切都完全由自然法则和宇宙的边界条件所决定。在确定性的宇宙中，从某种意义上说，没有发生任何“真正新颖”的事情——尽管当然，宇宙的确定性与我们对其内部发生的事件感到惊讶是完全兼容的。此外——正如图灵所指出的——即使是数字计算机也有许多让我们感到惊讶的方式；还需要进一步阐明这个建议的性质是什么。（是的，我们可以假设，数字计算机受到它们的程序的“限制”：它们不能做任何不被它们的程序允许的事情。但是人类也受到他们的生物学和遗传基因的“限制”，可以说这种方式是完全相同的：他们不能做任何不被他们的生物学和遗传基因所允许的事情。如果一个程序足够复杂——并且运行它的处理器足够快——那么很难说剩下的“限制”是否必然与生物学和遗传基因所施加的“限制”在性质上有所不同。)

Bringsjord 等人（2001）声称，图灵对洛夫莱斯异议的回应“神秘”至少，最糟糕的情况下是“无能”（第 4 页）。在他们看来，图灵声称“计算机确实让我们感到惊讶”只有在“惊讶”被赋予非常肤浅的解释时才是真实的。因为，虽然计算机确实会做我们不打算让它们做的事情-因为我们不够聪明，或者因为我们不够小心，或者因为有罕见的硬件错误，或者其他原因-但并不是说有任何情况下我们应该说计算机创造了某些东西。无论这个异议中可能存在什么优点，值得指出的是，在创作的相关意义上，人类在几乎每次进行对话时都会“创造出某些东西”：他们会在自己所处的情况下产生适当的自然语言句子。因此，一方面-尽管 Bringsjord 等人提出了所有的论证-图灵测试是一种完全有效的“创作”（或“创造力”等）存在的测试。另一方面，尽管 Bringsjord 等人提出了所有的论证，数字计算设备是否能够以这种意义上的“创作”（即能够产生适合计算机所处情况的新句子）仍然是一个悬而未决的问题。因此，我们并不过分倾向于认为图灵对洛夫莱斯异议的回应很差；我们甚至更不倾向于认为图灵缺乏提供令人满意的回应的资源。

### 2.7 神经系统连续性的论证

人脑和神经系统与数字计算机相似度不高。特别是，对于大脑是离散状态机的说法，有理由持怀疑态度。图灵观察到，关于神经冲动大小的信息存在微小误差，可能会对输出冲动的大小产生很大影响。基于此，图灵推断出大脑很可能是连续状态机；然后他指出，由于离散状态机不是连续状态机，因此有理由认为没有离散状态机能够具备智能。

图灵对这种论证的回应似乎是，连续状态机可以通过具有非常小误差水平的离散状态机来模拟。就像微分分析仪可以被数字计算机模拟，误差范围非常小，人类的对话也可以被数字计算机模拟，误差范围不会被普通的询问者在模拟游戏中察觉到。图灵是否做出了正确的回应并不清楚。如果有人认为真正的思维（或智能、心灵等）只能存在于连续状态机中，那么离散状态机能够通过图灵测试只能说明图灵测试不好。更好的回答是问为什么我们应该如此自信真正的思维等只能存在于连续状态机中（如果我们确实不是离散状态机的话）。在提出这个问题之前，我们最好考虑一下我们是否真的有足够的理由相信从我们的思维能力的角度来看，我们本质上不是离散状态机。（正如 Block（1981）指出的那样，我们对智能的概念似乎没有排除具有量子化感知设备的智能生物；我们对智能的概念也没有排除具有数字工作部件的智能生物。）

### 2.8 行为非正式的论证

这个论点依赖于这样一个假设，即没有一套规则能够描述一个人在任何可能的情况下应该做什么，而且进一步假设存在一套规则，能够描述一个机器在任何可能的情况下会做什么。从这两个假设出发，人们认为——不知怎么地！——人不是机器。正如图灵所指出的，这个论证的表述中“应该”和“会”之间存在一些差异。然而，一旦我们进行适当的调整，就不清楚人与数字计算机之间是否存在明显的差异。

首先，假设我们关注的问题是，是否存在一套规则，能够描述一个人和一个机器在任何可能的情况下会做什么。如果世界是确定性的，那么对于人和机器来说，都存在这样的规则（尽管可能无法将规则写下来）。如果世界不是确定性的，那么对于人和机器来说，都不存在这样的规则（因为在行为产生过程中，人和机器都可能受到非确定性过程的影响）。无论哪种情况，很难找到任何理由认为人与机器之间存在与他们在所有可能情况下的行为描述相关的差异。（也许可以说，反对意见要求我们假设，即使世界不是确定性的，人类与数字机器的区别正是因为后者的操作确实是确定性的。但是，如果世界是非确定性的，那么没有理由认为数字机器不能被编程为以非确定性方式行为，通过允许它们访问世界的非确定性特征的输入。）

假设我们转而关注的问题是，在每种可能的情况下，是否存在一套规则来描述人和机器应该做什么。无论我们是否认为规范可以被编码，而且与哪种规范有关的问题完全不同，很难看出除了机器不是那种行为可以受到规范约束的事物之外，还有什么依据可以支持这个判断。（而且，在这种情况下，最初的论证表述是严重错误的：应该主张，虽然存在一套规则来描述人在每种可能的情况下应该做什么，但是不存在一套规则来描述机器在所有可能的情况下应该做什么！）

### 2.9 超感知知觉的论证

图灵论文中最奇怪的部分是关于超感知的几段。也许这是一种玩笑，尽管如果是这样的话，图灵没有很好地标明这一点。也许，图灵受到了 J.B.莱恩的明显具有科学可信度的结果的影响。无论如何，从字面上理解这段文字，图灵似乎认为有压倒性的经验证据支持心灵感应（他还准备认真对待透视、预知和念力）。此外，他似乎还认为，如果游戏中的人类参与者具有心灵感应能力，那么询问者可以利用这一事实来确定机器的身份，并为了规避这个困难，图灵提议竞争者应该被安置在一个“防止心灵感应”的房间里。撇开事实上目前没有统计支持心灵感应、透视、预知或念力的观点不谈，值得问一下图灵会倾向于哪种关于心灵感应本质的理论。毕竟，如果人类可以有心灵感应能力，为什么数字计算机也不能呢？如果心灵感应能力是任何足够先进的能够进行人类对话的系统的标准特征，那么数字计算机在这方面也完全可以与人类平起平坐。（也许这个回答假设成功通过模仿游戏的机器参与者需要配备传感器等设备。然而，正如我们上面提到的，这个假设并不是非常有争议的。一个合理的对话者必须与世界上发生的事情保持最新的了解。）

在讨论了上述九个异议之后，图灵继续说他“没有什么令人信服的积极论据来支持我的观点。如果有的话，我就不会费那么大的力气指出相反观点中的谬误。”（454）也许图灵在这个自我评估中有点谦虚。首先，正如他对唯我论的简短讨论所表明的那样，值得问一下我们有什么理由将智能（思想、心灵）归因于其他人。如果我们可以合理地假设我们基于行为测试或行为标准来进行归因，那么他关于在机器的情况下应用适当测试的主张似乎是恰当的，而他关于数字计算机可能通过测试的猜测似乎是一个合理的——尽管有争议的——经验性猜测。其次，心灵哲学的后续发展——特别是功能主义心灵理论的形成——为我们提供了一个更加安全的理论环境，可以在其中进行关于思考机器可能性的推测。如果心理状态是功能状态——并且如果心理状态能够在非常不同的材料中实现——那么有理由认为这是一个经验问题，即思维是否可以在数字计算机中实现。当然，这种建议是可以质疑的；我们将在本评论的后面部分考虑一些重要的哲学异议。

## 3. 出现的一些小问题

在与图灵（1950）的各个部分的解释相关的问题中，存在一些备受争议的问题，我们迄今为止忽略了讨论这些问题。在本文档的前两节中所说的内容构成了我们对图灵观点的解释（也许还加上了我们认为在图灵的言论可以相对容易地改进的那些情况下的其他相关考虑）。但由于对这些解释的一些争议，或许值得注意的是争议的主要焦点在哪里。

### 3.1 解释模仿游戏

图灵（1950）通过描述一个游戏来引入模仿游戏，参与者是一个男人、一个女人和一个人类审问者。审问者与其他两个人分开在一个房间里，并被要求确定哪个是男人，哪个是女人。男人和女人都被要求试图说服审问者他们是女人。图灵建议女人的最佳策略是如实回答所有问题；当然，男人的最佳策略将需要一些谎言。参与这个游戏的人还使用电传打字机相互交流，以避免通过语调等方式提供线索。然后图灵说：“我们现在问一个问题，‘当一台机器扮演 A 的角色时会发生什么？’当游戏像这样进行时，审问者会像在男人和女人之间进行游戏时那样经常做出错误的决定吗？”（434）。

当然，可以将图灵的意图解释为他字面上所说的，即新游戏是一种计算机必须假装成女人的游戏，而游戏中的另一参与者是一个女人。（有关讨论，请参见 Genova（1994）和 Traiger（2000）。）同时，也可以将图灵的意图解释为新游戏是一种计算机必须假装成女人的游戏，而游戏中的另一参与者是一个男人，他也必须假装成女人。然而，正如 Copeland（2000）、Piccinini（2000）和 Moor（2001）所认为的那样，图灵文章的其余部分以及图灵在同一时间写的其他文章中的材料非常有力地支持了我们之前给出的标准解释，即计算机必须假装成人类，而游戏中的另一参与者是一个未指定性别的人类。此外，正如 Moor（2001）所认为的那样，没有理由认为如果计算机必须假装成女人，而游戏中的另一参与者是一个男人假装成女人，测试结果会更好；事实上，有理由认为测试结果会更差。也许，如果计算机必须假装成女人，而另一参与者是一个女人，这对测试的有效性没有影响（就像计算机必须假装成会计师，而另一参与者是会计师一样）；然而，这一考虑仅仅不足以抵消我们在讨论图灵（1950）时给出的对模拟游戏的标准解释的强有力的文本证据。（有关本段讨论中许多问题的异议观点，请参见 Sterrett（2000；2020）。）

### 3.2 图灵的预测

正如我们之前提到的，图灵（1950）提出了以下观点：

> 我相信大约五十年后，将有可能编程计算机，其存储容量约为 10^9，使它们能够很好地进行模拟游戏，以至于一个普通的询问者在五分钟的询问后，正确识别的几率不超过 70％。...我相信在本世纪末，词语的使用和一般受教育的观点将发生如此大的变化，以至于人们可以谈论机器思考而不期望被反驳。

大多数评论者认为这一说法已被证明是错误的：在 2000 年，没有人能够编程计算机，使其在五分钟的询问后，一个普通的询问者在正确识别方面的几率不超过 70％。Copeland（2000）认为这种说法是严重错误的：“大约五十年”绝不等于“正好五十年”，我们可能很快就能够进行所需的编程。然而，正如 Copeland（2000）指出的，图灵（1950）立即提到了“世纪末”的情况，这表明对“大约”不能过多解读。然而，正如 Copeland（2000）指出的，图灵在其他地方还作出了更为谨慎的预测（例如，在机器能够通过他的测试的无限制版本之前，“至少需要 100 年”）；而且在图灵（1950）中还有其他预测似乎得到了证实。特别是，可以合理地认为，在 2000 年，受教育的观点已经发生了变化，以至于在许多领域，人们可以谈论机器思考和机器学习而不期望被反驳。正如 Moor（2001）指出的那样，当图灵开始思考这些问题时，“机器智能”并不是一个自相矛盾的词。

### 3.3 一个有用的区别

在许多关于图灵测试的讨论中，有两个不同的理论主张被混为一谈，可以有益地分开。一个主张认为，图灵的模仿游戏所描述的一般方案为智能的存在提供了一个良好的测试。（如果某物在足够苛刻的测试条件下能够冒充一个人，那么我们有很好的理由认为该物体是智能的。）另一个主张认为，一个适当编程的计算机可以通过第一个主张所描述的测试。我们可以称第一个主张为“图灵测试主张”，第二个主张为“思考机器主张”。对于图灵（1950）中提出的主张的一些反对意见是针对思考机器主张的，而不是针对图灵测试主张的。（例如，考虑 Searle（1982）的论证，我们在第 6 节中进一步讨论。）然而，其他反对意见是针对图灵测试主张的。在我们进入第 6 节之前，我们将把注意力集中在对图灵测试主张的讨论上。

### 3.4 进一步说明

在本文中，我们遵循标准的哲学惯例，即“一个思维”意味着“至少一个思维”。如果“通过图灵测试”意味着智能，那么“通过图灵测试”意味着至少存在一个思维。我们无法在这里探讨关于“群体智能”、“集体智能”等的最新讨论。然而，显然可以清楚地看到，在两个人轮流进行的情况下，“通过图灵测试”，我们应该非常不愿意说存在一个“集体思维”，该集体思维将两个人的思维作为组成部分。

## 4. 对图灵测试当前地位的评估

鉴于我们在文献中对图灵测试的不同解释所做的初始区分，最好的方法可能是通过分案来探讨对图灵测试当前地位的评估问题。确实，我们认为有一个正确的解释，即图灵（1950）提出的测试是什么；但是对图灵测试当前地位的全面讨论应该至少关注其他一些被错误认为是图灵（1950）提出的测试的当前地位。

有几个主要观点需要调查。首先，有人建议图灵测试提供了逻辑上必要且充分的智能归属条件。其次，有人建议图灵测试提供了逻辑上充分但不是必要的智能归属条件。第三，有人建议图灵测试提供了“标准”——可推翻的充分条件——用于智能归属。第四，与前面的观点可能没有重要区别，有人建议图灵测试对智能归属提供了（更或更少强大的）概率支持。我们将依次考虑这些观点。

### 4.1（逻辑上）必要和充分条件

有人明确声称图灵测试旨在提供既是逻辑上必要又是逻辑上充分的智能归属条件的例子是否很少。 （也许 Block（1981）就是这样的案例之一。）然而，一些反对图灵测试的观点只有在假设图灵测试确实提供了逻辑上必要和逻辑上充分的智能归属条件时才有意义；而许多其他反对图灵测试的观点只有在假设图灵测试提供了智能归属的必要和充分条件时才有意义，其中所讨论的模态弱于严格的逻辑，例如 nomic 或因果关系。

例如，考虑那些声称图灵测试是沙文主义的人；特别是那些声称肯定存在某种具有相当智能的东西，但却无法通过图灵测试的人。 （例如：智能生物可能无法通过图灵测试，因为他们不与我们的生活方式相同；智能生物可能无法通过图灵测试，因为他们拒绝参与伪装游戏；智能生物可能无法通过图灵测试，因为他们所说的语言的实用约定与人类语言的实用约定非常不同。等等。）除非图灵测试提供了智能归属的必要条件，否则这些都不能构成对图灵测试的反对意见。

French (1990)提出了巧妙的论点，旨在表明“图灵测试提供的不是智能，而是文化导向的智能的保证。” 但是，当然，任何具有文化导向智能的东西都具有智能；因此，法国的反对意见不能被视为针对图灵测试为智能归因提供充分条件的观点。正如我们后面将看到的那样，法国认为图灵测试建立了绝对无趣的充分条件，没有任何机器能够满足。换句话说，在法国的观点中，图灵测试的问题在于它建立了对智能归因的绝对无趣的充分条件。

Floridi 和 Chiriatti（2020 年：683）表示，图灵测试为智能提供了必要但不充分的条件：未通过图灵测试将使 AI 失去智能资格，但通过图灵测试并不足以使 AI 具备智能资格。然而，他们还说“任何读者...都对测试的性质非常熟悉，因此我们不会对其进行描述。” 他们对图灵测试的解释必须与我们一直提供的图灵测试的解释非常不同。

### 4.2 逻辑上充分的条件

有许多哲学家认为图灵测试旨在提供逻辑上充分的条件来归因于智能。也就是说，有许多哲学家认为图灵测试声称，缺乏智能的事物通过图灵测试在逻辑上是不可能的。（通常，这种假设是根据通过图灵测试需要相当多的解释，例如，产生与整个生命周期内的人类行为无法区分的行为。）

有众所周知的反对意见认为，通过图灵测试或任何其他纯行为测试提供了逻辑上充分的条件来归因于智能。对于这种对智能（心智、思维）分析的标准反对意见是，通过“蛮力”方法产生行为的存在不应被视为智能（具有心智、思考）。

例如，考虑 Ned Block 的 Blockhead。Blockhead 是一个看起来像人类的生物，但是由一个“生命游戏查找树”控制，即在生物的每个阶段，树中都包含了每个可辨别输入的编程响应。如果我们同意 Blockhead 在逻辑上是可能的，并且如果我们同意 Blockhead 不是智能的（没有心智，不思考），那么 Blockhead 就是图灵测试提供智能归因的逻辑充分条件的反例。毕竟，Blockhead 可以被编程为具有与您在整个生命周期内给出的相同输入相同的响应的查找树。

或许只有两种方式可以回应布洛克的论证，声称图灵测试提供了逻辑上足够的条件来归因于智能。首先，可以否认 Blockhead 是一个逻辑上可能的存在；其次，可以声称 Blockhead 是智能的（有思维）。

为了否认 Blockhead 是一个逻辑上可能的存在，似乎需要否认的是可想象性和逻辑可能性之间的常见联系：Blockhead 确实是可想象的，因此，如果（适当限定的）可想象性足以构成逻辑可能性，那么我们似乎有充分的理由接受 Blockhead 是一个逻辑上可能的存在。由于这个问题会让我们偏离我们目前的关注点，我们只是注意到这仍然是一个有争议的问题，即（适当限定的）可想象性是否足以构成逻辑可能性。（有关这个问题的进一步讨论，请参见 Crooke（2002））。

Blockhead 是否智能（有思维）的问题似乎很简单，但尽管布洛克自信地断言 Blockhead“具有烤面包机的所有智能”，我们并不明显地否认 Blockhead 是智能的。Blockhead 可能不是一个特别高效的信息处理器；但至少它是一个信息处理器，并且结合由信息处理产生的行为，这可能足以被视为将某种程度的智能归因于 Blockhead 的充分理由。有关 Block（1981）论证的进一步批判性讨论，请参见 McDermott（2014）和 Pautz 和 Stoljar（2019）。

### 4.3 准则

在他的《哲学研究》中，维特根斯坦著名地写道：“‘内在过程’需要外在准则”（580）。维特根斯坦这句话的确切含义不清楚，但可以有一种解释方式：为了能够合理地将“心理状态”归因于某个实体，必须有关于该实体的可观察行为的一些真实陈述，这些陈述（或许）连同关于该实体的其他真实陈述（不是以“心理学”词汇表达的陈述）一起，可以推导出该实体具有所讨论的心理状态。如果关于该实体的可观察行为没有任何作用于将心理状态归因于该实体的合理化，那么就没有理由将那种心理状态归属于该实体。

主张为了能够合理地将心理状态归因于某个实体，必须有关于该实体的可观察行为的一些真实陈述，这些陈述独立地——即不需要添加任何关于该实体的其他真实陈述——就可以推导出该实体具有所讨论的心理状态，这是一种哲学行为主义观点。我们无法争辩维特根斯坦是否是一位哲学行为主义者；我们也无法争辩图灵是否是一位哲学行为主义者。然而，如果我们按照前一段中给出的解释，那么从图灵测试是评定智能（思维、心灵）的准则这一主张中，只需要得出这样的结论：当将其他真实陈述（不是以心理学词汇表达的陈述）与一个实体通过了图灵测试的主张结合时，那么可以推导出该实体具有智能（思维、心灵）。

（请注意，括号中的限定条件是为了避免以心理学词汇来表达附加的真实主张，这只是避免琐碎化威胁的一种方式。困难在于，无论属于该集合的其他主张是什么，真实主张一个实体具有思维将总是产生一组蕴含该实体具有思维的主张！）

要了解图灵测试仅仅是智能归属的标准这一主张与逻辑行为主义主张不同之处，只需考虑是否存在“手动模拟”图灵测试程序的法定可能性即可。许多人认为，有充分理由否认 Blockhead 是一种法定（或物理）可能性。例如，在《不朽的物理学》一书中，弗兰克·蒂普勒提供了以下论证，以支持这样一种主张：手动模拟通过图灵测试的程序在物理上是不可能的：

> 如果我早先估计的人脑可以编码多达 1015 比特的说法是正确的，那么由于一本平均书籍编码约为 106 比特...需要超过 1 亿本书来编码人脑。至少需要三十五层的大学主图书馆来容纳这么多书籍。我们从经验中知道，我们可以在大约 100 秒内访问我们大脑中的任何记忆，因此通过图灵测试的手动模拟程序需要一个人能够在 100 秒内从书架上取下、浏览并放回这 1 亿本书。如果每本书重约一磅（0.5 千克），并且平均上取书和放回的过程中书籍移动一码（一米），那么在 100 秒内仅移动书籍所消耗的能量为 3 x 1019 焦耳；能量消耗速率为 3 x 1011 兆瓦。由于人类以正常速率使用 100 瓦的能量，所需的功率是 3 x 1015 人的身体功率，大约是地球上整个人口的百万倍。一个典型的大型核电站的功率输出为 1,000 兆瓦，因此人类程序的手动模拟需要相当于 300 亿个大型核电站的功率输出。正如我所说，一个人无法手动模拟通过图灵测试的程序，就像他无法跳到月球一样。事实上，这要困难得多。

尽管提普勒的论点的细节可能有改进的空间，但总体观点似乎是正确的：为了一个人类的查找树所需的组合爆炸，在物理世界的运作规律和边界条件的制约下是不可能的。但是，如果这是正确的，那么虽然“机器人”是一个逻辑上的可能性，但它并不是一个合乎规律或物理上的可能性。然后，似乎自然而然地认为图灵测试确实提供了对智能归属的规律充分条件：根据我们已经知道的关于我们所生活的宇宙的一切，我们完全有理由得出结论，任何能够通过图灵测试的东西都是智能的（具有思维等）。

在前一段的论证中，可能有一些方式可以抵制。至少值得注意的是，我们刚刚重述的论证中存在着一个严重的漏洞。即使我们可以排除智能的“手模拟”，也不能得出我们排除了所有其他形式的智能模拟。也许——根据迄今为止的论证——在产生智能模拟方面存在着合乎规律的可能性。但是，如果是这样的话，那么通过图灵测试并不一定是智能拥有的标准：根据我们已经知道的关于我们所生活的宇宙的一切，我们完全有理由得出结论，任何能够通过图灵测试的东西都是智能的（具有思维等）。

(McDermott (2014) 计算出，一个进行 50 次对话交流的参与者的查找表大约有 1022278 个节点。诱人的是，根据这个计算，可以得出结论，对于“手模拟”图灵测试程序来说，既不是命名上也不是物理上可能存在的，因为所需的节点数量无法放入比整个可观测宇宙还要大得多的空间中。)

### 4.4 概率支持

当我们看图灵提供的测试的初始表述时，很明显他认为通过测试会为智能假设提供概率支持。这里至少有两个不同的观点。首先，图灵的预测本身是概率性的：图灵预测，在他写作的大约五十年后，将有可能编程数字计算机使其在模仿游戏中表现得如此出色，以至于一个普通的询问者在五分钟的询问后，正确识别的几率不会超过七成。其次，图灵预测的概率性质有充分的理由认为，图灵提出的测试本身也是概率性的：在模仿游戏中取得的一定程度的成功会产生（或者至少应该产生）对参与者是否具有智能（是否有思想，是否拥有心智）的信心水平的可指定增加。由于图灵没有告诉我们他认为模仿游戏中的成功程度与参与者是否具有智能的信心增加之间如何相关，因此可以说图灵测试在很大程度上是未明确规定的。相关变量显然包括：游戏中提问的时间段的长度（或者至少是提问的“数量”）；询问者的技能和专业知识（这涉及到提问的“深度”和“难度”）；游戏中第三个参与者的技能和专业知识；以及运行游戏的独立会话的数量（特别是当游戏的其他参与者在每次运行中不同时）。 显然，一台在游戏中多次成功运行，并且持续时间相当长，并且涉及高技能参与者在其他角色中的机器比一台在与高度不熟练的参与者进行的单次短暂游戏中成功的机器更有资格被认为是智能的。一台机器在与不熟练的对手进行的一次短暂游戏中取得成功可能会提供一些理由，增加对该机器智能性的信心：但是很明显，游戏的后续运行结果可能很快推翻这种初步的信心增加。一台机器在模拟游戏中多次长时间比机会更好地对抗各种熟练参与者，无疑提供了更强有力的证据表明该机器是智能的。（如果有足够的这种证据，似乎可以非常有信心地认为该机器是智能的，当然，仍然要认识到自己的判断可能会被进一步的证据推翻，例如一系列短暂的运行，在这些运行中，机器对使用相同策略一遍又一遍揭示机器身份的参与者表现得比机会更差。)

图灵测试的概率性质经常被忽视。足够真实，Moor（1976, 2001）以及其他一些评论者指出，“图灵测试”是“归纳的”，即“图灵测试”只能提供可推翻的智能证据。然而，说“在一个严格的图灵测试中成功只能提供可推翻的智能证据”是一回事，注意到我们在前面段落中提到的概率特征是另一回事。例如，考虑 Moor 的观察（Moor 2001:83）：“……在图灵测试中收集的归纳证据可以被新证据所抵消……如果新证据表明机器是由幕后的人通过遥控操作通过图灵测试的，那么需要重新评估。”这个观点以及其他类似的观点似乎暗示着 Moor 认为“严格的图灵测试”是一个一次性事件，机器要么成功要么失败。但是，这种对图灵测试的解释容易受到 Bringsjord（1994）提出的异议的影响：即使在一个相对有经验的参与者参与的中等长的单次运行中，一个无智能的机器偶然成功地通过模拟游戏也并不那么不可能。在我们看来，只要有足够长的运行时间，并且有不同的足够有经验的参与者，偶然成功的可能性可以被降低到任意小。因此，尽管 Bringsjord 的“偶然性论证”对于某些版本的图灵测试是有力的，但对于图灵实际提出的最合理的测试解释是没有力量的。

值得注意的是，构建更复杂版本的“模仿游戏”以获得更精细的统计数据是相当容易的。例如，与其让评委对游戏中的两个参与者发表是/否的裁决，我们可以让评委提供概率性答案。（“我给 A 是机器的说法 75%的概率，给 B 是机器的说法只有 25%的概率。”）当我们考虑对“图灵测试”中隐含的“方法论”的批评时，这一点非常重要。（有关“图灵测试”概率性质的进一步讨论，请参见 Shieber（2007）。）

## 5. 替代测试

有关图灵测试的一些文献关注的是关于提供适当指导未来人工智能领域研究的测试框架的问题。这里的想法非常简单。假设我们有雄心壮志要制造一个人工智能实体。我们应该采取什么样的测试作为设定目标，以使被认为是智能的人工系统能够实现这些目标？我们应该认为“图灵测试”为这个领域的研究提供了适当的目标吗？在评估这些提议时，需要记住两个不同的问题。首先，问题是 AI 研究是否有用的目标是制造一个能够通过给定测试的机器（在指定的时间长度、指定的成功程度下）？其次，问题是对于成功通过测试的机器的心智能力应该得出什么样的结论（在指定的时间长度、指定的成功程度下）？

对于这些问题的意见存在深刻分歧。有些人认为图灵测试对于人工智能研究并不提供有用的目标，因为很难制造出能够通过测试的系统。其他人认为图灵测试对于人工智能研究并不提供有用的目标，因为它设定了一个非常狭窄的目标（从而对研究的种类设置了不必要的限制）。有些人认为图灵测试为人工智能研究提供了完全适当的目标；而其他人认为在某种意义上，图灵测试并不要求得太多，并且认为图灵测试需要在各种方面进行扩展，以提供适当的人工智能目标。我们将依次考虑每个立场的一些代表性观点。

仍然有一些人支持图灵测试。例如，Neufeld 和 Finnestad（2020a）（2020b）认为图灵测试对于人工智能的进展没有障碍，不需要进行重大重新定义，并且不会关闭其他调查途径。也许我们最好将图灵测试视为定义一个分水岭，而不是一个我们希望逐步取得进展的阈值。

### 5.1 图灵测试太难了

有些人声称，图灵测试对当前人工智能研究来说并不设定一个合适的目标，因为我们明显离达到这个目标还有很长的路要走。在这些人中，有些人继续提出理由，认为我们可能永远无法创造出能够通过图灵测试的机器，或者至少在可预见的未来内我们无法做到这一点。也许这类论证中最有趣的是法国（1990）提出的论证；无论如何，这些是我们将要考虑的论证。（卡伦（2009）提出了类似的考虑。）

根据法国的观点，图灵测试作为一个真正的智能测试是“几乎无用的”，因为没有“人类的潜意识基质”，任何东西都无法通过这个测试，而人工“人类认知基质”的发展几乎是不可能的困难。至少有一些直接的问题集可以揭示“低层次的认知结构”，在法国看来，这些问题集几乎肯定能够成功地区分人类和机器。

首先，如果审问者被允许利用关联启动的研究结果，那么有数据可以很有可能将人类与机器区分开来。例如，有研究表明，如果人类被呈现一系列字母字符串，当一个字符串在他们所说的语言中之前是一个相关的词（在他们所说的语言中），而不是一个无关的词（在他们所说的语言中）或者一个不是词的字母字符串（在他们所说的语言中），他们需要更少的时间来认识到这个字符串是一个词。只要审问者对使用该语言的被试的平均识别时间有准确的数据，审问者可以通过观察适当的一系列字母字符串的识别时间来区分机器和人类。法国人就是这么说的。我们不清楚这是否正确。毕竟，图灵测试的设计使得很难看出审问者如何获得关于一系列符号的响应时间的可靠信息。将计算机放在一个单独的房间，并要求通过电传打字机进行通信，正是为了排除某些无关的识别计算机的方式。如果这些要求还没有排除利用关联启动测试来识别计算机，那么这些要求肯定可以被修改以使其成为可能。也许值得注意的是，法国所设想的测试方式并不是普通的对话；也不是预计除了少数专家审问者之外的人会遇到的事情。因此，即使图灵测试的情况并没有排除法国在这里设想的那种程序，也不清楚图灵测试对机器来说是否会过于困难。

其次，在稍高的认知水平上，有一些“评级游戏”被法国认为是非常可靠的区分人类和机器的方法。例如，“新词评级游戏”要求参与者对虚构的词语按照其作为给定实体名称的适当性进行排序，而“类别评级游戏”要求参与者将一类事物评价为另一类事物。根据法国的观点，这两种评级游戏都有可能在区分人类和机器方面非常可靠。因为在第一种情况下，人类所做的评级依赖于大量的文化习得关联（这些关联几乎不可能被确定和描述，因此（可以说）几乎不可能编程到计算机中）。而在第二种情况下，人们实际上所做的评级非常依赖于特定的社会和文化环境（以及人类生活体验的特定方式）。以法国的例子来说，在技术发达的西方世界，有能力的英语使用者普遍认为“Flugblogs”不是早餐谷物的合适名称，而“Flugly”是一个孩子的玩具熊的合适名称。而在发达国家的英语使用者中，普遍认为笔作为武器的评级要高于钢琴作为手推车的评级。同样，对于法国的论点，我们可以提出一些问题。我们不清楚评级游戏所依赖的数据是否像法国所认为的那样可靠。（我们中至少有一个人认为“Flugly”对于一个孩子的玩具熊来说是完全不合适的名称，这是因为这个虚构词“Flugly”与一个在我们共同就读的本科大学中有一定流行度的词“Fugly”非常相似。） 至少我们中的一位也认为年幼的孩子很可能会喜欢吃一种叫做“Flugblogs”的谷片，并且对于关于评分笔和钢琴的问题，一个好的答案是这完全取决于所涉及的评分笔和钢琴。如果钢琴有轮子呢？如果对手有剑或冲锋枪呢？拒绝参与这种评分游戏并不明显意味着一个人是机器。此外，即使数据是可靠的，也不明显除了一小部分审问者之外，其他人会采用这种揭穿机器的策略；也不明显构建一台能够像典型人类在这些测试中表现的机器是非常困难的。特别是，如果图灵所假设的是可能制造出可以“训练”学习各种任务的学习机器，那么为什么这些机器不能像人类儿童在语言使用方面被“训练”时所获得的“次认知能力”呢，这一点并不清楚。

有其他原因被提出认为图灵测试太难（因此，不适合为当前人工智能研究设定目标）。总的来说，观点是人类认知可能存在一些特别难以模拟的特征，但这些特征在智能（或思维或拥有心灵）方面并非必要。问题不仅仅在于图灵测试确实测试了人类智能，而是在于这个事实——如果这确实是一个事实——人类智能中有一些非常不必要的特征在机器中极其难以复制。如果这个抱怨是合理的——如果确实有一些人类智能的特征在机器中极其难以复制，并且可以并且将会可靠地用于在图灵测试中揭示机器——那么我们有理由担心图灵测试为人工智能研究设定了一个合适的方向。然而，正如我们对法语的讨论所示，我们可能有理由谨慎地认为，在当前部分讨论的考虑中，我们已经有能力说图灵测试确实为人工智能研究设定了不合适的目标。

### 5.2 图灵测试过于狭窄

有些作者认为图灵测试没有为人工智能领域的研究设定足够广泛的目标。在这些作者中，有许多人认为图灵测试太容易。（我们将在下一个小节中考虑其中一些作者。）但也有一些作者认为，即使图灵测试设定的目标确实非常苛刻，但它仍然过于限制。

对于图灵测试提供智能的逻辑充分条件的观点的反对可以适应于展示图灵测试过于限制性的目标。例如，考虑 Gunderson（1964）的观点。Gunderson 对图灵测试有两个主要的抱怨。首先，他认为在图灵的模仿游戏中成功可能是因为其他原因，而不仅仅是拥有智能。但是，他认为在模仿游戏中的成功只是智能生物可以做的事情的一种例子，并且本身不能被视为智能的可靠指标。通过类比，Gunderson 提供了一个吸尘器销售员的案例，他声称他的产品是“多功能”的，但实际上它只是吸尘。根据 Gunderson 的观点，如果图灵准备仅仅基于在模仿游戏中的成功来说一台机器是智能的，那么他就和吸尘器销售员处于同样的位置。就像“多功能”意味着能够做一系列的事情一样，“思考”也意味着拥有一系列的能力（超出仅仅在模仿游戏中成功的能力）。

对于我们在这里归因于冈德森的论点，有一个明显的回应，即能够在模仿游戏中取得成功的机器能够做许多不同类型的事情。为了进行对话，人们需要具备许多不同类型的认知技能，每种技能都能在其他领域应用。除了明显的一般认知能力-记忆、感知等-在模仿游戏的多次运行过程中，还有许多特定的能力-基本算术能力、对游戏规则的理解、对国家政治的基本理解等-都在测试中。不可想象有一台机器在玩模仿游戏方面表现出色，却无法在其他任何可能分配给它的任务上表现良好；同样不可想象有一台机器在模仿游戏中表现出色，却没有广泛的能力范围，可以在相当不同的领域展示出来。在冈德森考虑这一回应的程度上，他所说的只是没有理由认为能够在模仿游戏中取得成功的机器必须具备超出狭窄能力范围的能力；我们认为没有理由相信这个回应应该被认真对待。

最近，Erion（2001）提出了一种与 Gunderson 有些相似的立场。根据 Erion 的说法，机器可能“在特定环境中在有限的任务中胜过人类，但仍然无法像具有常识的人那样熟练地行动”（36）。在理解 Erion 所提出的主张的一种方式上，他也认为图灵测试只能识别出智能人类所具有的一系列独立能力之一，正因为如此，他提出了更全面的“笛卡尔测试”，该测试“涉及对生物语言的更仔细的考察，还测试了生物在各种日常情况下解决问题的能力”（37）。在我们看来，至少在正确理解图灵测试的情况下，很明显通过图灵测试的任何事物都必须具备在各种日常情况下解决问题的能力（因为审问者将利用他们的问题来探究这些和其他能力在玩模仿游戏的人身上的情况）。

### 5.3 图灵测试太简单了

有些作者建议应该用一种更严格的测试来取代图灵测试。目前还不清楚这些测试中是否有任何一个提出了比图灵测试更好的人工智能研究目标。然而，在本节中，我们不打算为这个观点辩护；相反，我们将简单地描述一些已经提出的进一步测试，并对它们偶尔进行评论。（我们希望坚持的一个初步观点是，图灵的模仿游戏是在当时技术限制的背景下设计的。当然，对于游戏来说，使用电报文本设备来防止直接获取有关参与者性别或种类的信息并不是必要的。在接下来的内容中，我们不会提及这些相对平凡的考虑。）

#### 5.3.1 全面图灵测试

Harnad（1989，1991）声称，比图灵测试更好的测试是要求对我们所有的输入做出回应，而不仅仅是对以文本格式呈现的语言输入做出回应。根据 Harnad 的说法，人工智能研究的适当目标是构建一个具有类似人类感知运动能力的机器人。Harnad 还考虑了一个可能的目标是追求“神经分子不可区分性”，但他拒绝了这个建议，理由是一旦我们知道如何制造一个能够通过他的完全图灵测试的机器人，就不会再有未解决的有关心智建模的问题。有趣的问题是，Harnad 提出的测试是否为人工智能研究设定了更合适的目标。特别值得注意的是，目前尚不清楚是否存在一个能够通过图灵测试但无法通过完全图灵测试的系统。由于 Harnad 本人似乎认为“完全的机器人能力对于产生成功的语言表现是必要的”，不清楚为什么有理由用他的扩展测试取代图灵测试。（这一点反对 Harnad 的观点可以在 Hauser（1993:227）和其他地方找到。）

#### 5.3.2 洛夫莱斯测试

Bringsjord 等人（2001 年）提出，对于人工智能来说，一个更令人满意的目标是通过一种他们称之为洛夫莱斯测试的元测试来实现。他们说，只有在满足以下三个条件的情况下，由人类设计的人工智能代理 A 才能通过洛夫莱斯测试：（1）人工智能代理 A 产生输出 O；（2）A 输出 O 不是由于偶然的硬件错误，而是由 A 可以重复的过程产生的结果；（3）H 或者知道 H 所知道并且拥有 H 资源的人无法通过引用 A 的架构、知识库和核心功能来解释 A 如何产生 O。对于这个提议，值得注意的是，对于第三个条件的解释存在一些问题。如果一个计算机程序很长且复杂，那么没有人类代理能够完全详细地解释输出是如何产生的。（为什么计算机输出 3.16 而不是 3.17？）但是，如果我们被允许给出一个高度概要的解释——计算机接收输入，进行一些内部处理，然后产生一个答案——那么似乎很难支持人类代理真正创造性地做任何事情的说法。（毕竟，我们也接收外部输入，进行内部处理，并产生输出。）我们正在考虑的解释中缺少的是关于应该提供的适当解释水平的任何建议。目前还不清楚为什么我们应该认为在任何解释水平上人类和机器之间存在相关差异；但是，如果是这样的话，那么所讨论的测试就是微不足道的。（人们可能还担心，根据提议的测试，使用真正的随机设备可能无法实现最佳的创造力。）

#### 5.3.3 真正的图灵测试

Schweizer (1998)声称，比图灵测试更好的测试方法将涉及测试对象的进化历史。当我们将智能归因于人类时，我们依赖于人类智力成就的广泛历史记录。基于这个历史记录，我们能够声称人类是智能的；并且我们可以依靠这个声称，在基于他们的行为时将智能归因于个体人类。根据 Schweizer 的观点，如果我们要将智能归因于机器，我们需要能够参考一个相当的认知成就的历史记录。因此，只有当机器发展出语言、撰写科学论文、创作交响乐、发明游戏等等时，我们才能够根据它们的行为将智能归因于个体机器。当然，我们仍然可以使用图灵测试来确定一个个体机器是否智能：但我们对这个问题的回答不仅仅取决于机器是否在图灵测试中成功；还有进一步的“进化”条件也必须满足。对于 Schweizer 的观点，值得注意的是，我们之所以根据其他人的行为授予他们智能的原因，并不完全清楚是因为我们事先了解到人类的集体认知成就。

** 5.3.4 进一步的提议**

Damassino (2020)建议，最好要求测试对象在评估性能时提出一个询问，该询问在三个维度上进行评估：（a）与人类表现的比较；（b）完成询问的成功；以及（c）完成询问的效率（最小化提问的数量）。提出这一建议的动机是，因为图灵测试吸引了那些主要目标是愚弄评委的项目，所以它关注的是测试对象在分配的任务上的表现如何。我们认为这里没有任何对图灵测试的诋毁。对于图灵测试来说，公开竞赛以及附带奖励的竞赛导致了作弊并不是对图灵测试的不利因素，因为每个人都知道这些奖励是颁发给明显未通过图灵测试的参赛作品。如果有什么被诋毁的话，那就是公开竞赛，而不是图灵测试本身。

Kulikov (2020)建议，考虑到优先参与测试或有意义的参与测试是有价值的。尽管计算机现在可以击败最优秀的人类国际象棋选手，但许多人更喜欢与人类而不是与专业的国际象棋计算机下棋。也许，即使计算机能够通过图灵测试，人们仍然更愿意与人类进行对话，而不是与专业的对话计算机。我们认为这种推测依赖于对什么可以成为专业对话伙伴的假设。如果我们的对话伙伴需要能够实时更新他们周围的信息，例如在观看一场足球比赛时，那么我们将不认为从 GPT-3 到专业对话伙伴有一条直接的路径。如果只有机器人可以成为专业对话伙伴，那么优先参与测试或有意义的参与测试将很难追踪除了人类中心偏见之外的任何东西。

### 5.4 图灵测试是否应该被视为有害的？

或许对于图灵测试是否为人工智能提供了一个合适的研究目标这一建议最著名的攻击是由海耶斯和福特（1995）提出的。在海耶斯和福特提出的有争议的观点中，至少有以下几点：

1. 图灵建议将模仿游戏作为一个明确的研究目标。
2. 图灵原本打算将图灵测试作为一种性别测试而不是物种测试。
3. 试图制造一台在图灵测试中成功的机器是如此困难，以至于没有人会认真将创造这样一台机器作为研究目标。
4. 图灵测试存在一个基本设计缺陷，即它旨在证实一个“零假设”，即某些机器和人类之间没有行为差异。
5. 任何无效实验都无法提供智能的充分标准，因为总会有疑问产生，即评委们没有足够努力地寻找（也没有提出正确类型的问题）。但是，如果这个问题被悬而未决，那么就没有稳定的调查终点。
6. 无效实验无法测量任何东西：图灵测试只能测试完全成功。（“一个在他说的话中有 10%不像女性的男人几乎总是会失败于模仿游戏。”）
7. 图灵测试实际上是对人类物种辨别其成员与冒名顶替者的能力的测试。（“性别测试...是制造机械变装者的测试。”）
8. 图灵测试是循环的：它无法检测到的东西不能被称为“智能”或“人性”，因为许多人类都无法通过图灵测试。事实上，“由于其中一名参与者必须被判定为机器，所以一半的人类群体都无法通过物种测试”。
9. 图灵测试的观点是傲慢和狭隘的：它错误地假设我们可以在没有首先掌握认知基本原理的情况下理解人类认知。
10. 图灵测试不接受比被认为是人类的智能更弱、不同或甚至更强的形式。

这些主张中有一些显然是错误的。例如，考虑(h)。从什么意义上说，可以声称人类群体中有 50%会“未通过物种测试”？如果“物种测试”要求询问者决定哪个是机器，为什么要认为询问者的裁决对被判定为机器的人的智能评估有任何影响呢？（还要记住，“物种测试”的一个条件是，参赛者中有一个是机器，正如海耶斯和福特最初描述的那样。虽然机器可以通过赢得模拟游戏来“展示”其智能，但人类不能通过失败而“展示”他们的缺乏智能。）

说图灵测试有缺陷，因为它是一个“零效应实验”，似乎是错误的。确实，从某种意义上说，图灵测试确实寻求“零结果”：如果在指定的情况下，普通的评判员无法识别出机器（在一定的成功率下），那么机器是智能的可能性就有一定的概率。但坚持在指定的情况下使用“普通的评判员”的目的，正是为了排除掉无关的识别机器的方式（即与机器是否智能无关的识别方式）。在给定种类的机器和人之间可能存在各种无关的差异，其中并非所有差异都被图灵所描述的实验设置所无法检测到，但只要图灵测试能够忽略这些无关的差异，它仍然是一个好的测试。

似乎也值得怀疑图灵测试只能测试“完全成功”是一个严重的缺陷。一方面，如果一个人有十分之一的机会提出一个明显不是女性的主张，那么我们可以计算出他在回答 N 个问题的游戏中被发现的机会——如果 N 足够小，那么“他几乎总是失败”的结论就不成立了。另一方面，正如我们在 4.4 节末尾所指出的，如果有人担心“图灵测试”的“是/否”性质，那么可以让评委们改为提供概率性的裁决。这种改变保留了图灵测试的特性，但也为其提供了更大的统计学复杂性的空间。

虽然对于海耶斯和福特（1995）所辩护的观点还可以提出（许多）其他批评，但应该承认他们对于图灵测试提供了定义研究人工智能的目标的建议的担忧是正确的。有各种各样的原因使人不愿接受人工智能研究的一个中心目标是产生人工人的观点。然而，值得指出的是，没有理由认为图灵认为图灵测试定义了人工智能研究领域（也没有太多证据表明其他认真的思想家也这样认为）。图灵本人很清楚可能存在非人类形式的智能——参见上面的(j)。然而，所有这些都与这样的建议一致，即图灵测试为人工智能研究设定了一个长期目标：我们最终可能要做的一件事就是产生人工人。如果——正如海耶斯和福特所声称的那样——这个任务几乎是不可能完成的，那么假设这个目标只是一个少数资源应该投入的雄心勃勃的目标也没有什么害处；但我们仍然可能有充分的理由认为这是一个目标。

其他认为我们需要“超越”图灵测试的人包括 Hernández-Orallo（2000）（2020）和 Marcus（2020）。

## 6. 中文房间

在过去的五十年里，有许多不同的反对意见针对图灵测试在文献中出现，但我们尚未讨论。我们无法希望在这里概述所有这些反对意见。然而，有一个论点——西尔的“中文房间”论证——在与图灵测试相关的讨论中被提及得如此频繁，以至于我们觉得有必要以一些讨论来结束。

在《思想、大脑和程序》以及其他地方，约翰·西尔提出反对“适当编程的计算机确实具有认知状态”的观点（64）。很明显，西尔在这里不同意图灵的观点，即适当编程的计算机可以思考。关于西尔的论点有很多争议；我们只考虑一种理解他所辩论的方式。

西尔的论证的基本结构非常著名。我们可以想象一个智能体的“手模拟”——在所描述的情况下，一个会说中文的人——在这种情况下，我们可能非常不愿意承认在模拟行为背后存在任何适当的智能。（因此，我们被邀请假设的逻辑可能性与 Block 邀请我们假设的逻辑可能性并没有太大的不同。然而，西尔继续发展的论证与 Block 所辩护的论证相当不同。）此外——这是西尔论证的关键点——所讨论的“手模拟”在所有相关方面都只是一种特殊类型的数字计算。因此，在一个可能的世界中——无疑是与实际世界相去甚远的世界——数字计算机模拟智能，但数字计算机本身并不具备智能。但是，如果我们考虑实际世界中的任何数字计算机，它与那个遥远可能世界中的计算机在任何可能使实际世界中的计算机比那个遥远可能世界中的计算机更智能的方式上都没有区别。鉴于我们同意“手模拟”中的计算机并不具备智能，我们别无选择，只能得出结论：数字计算机根本就不是可以具备智能的东西。

到目前为止，我们所描述的论证得出的结论是，没有适当编程的计算机能够思考。尽管图灵并不接受这个结论，但重要的是要注意，这与图灵测试是一个衡量智能的良好测试的主张是相容的。这是因为，根据我们所辩论的一切，可能不存在通过“手动模拟”智能的规律可能性（特别是使用任何类型的计算机模拟智能可能是不可能的）。为了将西尔的论证（至少是我们所发展的方式）转化为对图灵测试的反对意见，我们需要有一些理由认为，通过计算机模拟智能至少在规律上是可能的。（如果通过计算机模拟智能在规律上是不可能的，那么数字计算机无法真正拥有智能的所谓事实对图灵测试的有用性根本没有任何怀疑，因为数字计算机在仅仅模拟智能的范围内在规律上被取消资格。）在没有理由相信这一点的情况下，西尔的论证最多只能提出对图灵坚定信念的反对意见，即数字计算机将来会通过图灵测试。（在这里，和其他地方一样，我们假设对于任何类型的生物 C，都存在一个版本的图灵测试，其中 C 扮演图灵所描述的具体测试中的机器角色。这种用于测试智能存在的一般格式不一定会因为西尔的中文房间论证的成功而受到破坏。）

对于我们归因于西尔的论点，可以提出各种不同的回应。一种回应是对于在中文房间的情况下没有智能存在的主张进行争论。（假设“手部模拟”嵌入了一个配备了适当传感器等设备的机器人。进一步假设“手部模拟”涉及到更新“手部模拟”过程等。如果添加了足够多的这类细节，那么我们是否仍然要说我们还没有描述出一个智能系统就变得非常不清楚。）另一种回应是对于在实际世界中的数字计算机与在那个遥远可能的世界中运行的中文房间系统在相关方面可能存在不同的主张进行争论。（如果我们假设中文房间的核心是一种巨大的查找表，那么注意到实际世界中的数字计算机并不以那种方式使用查找表可能是很重要的。）毫无疑问，还有其他可能的回应线路。然而，我们将偏离主题，不再深入讨论这个问题。（进一步讨论这些问题的一个好地方是 Braddon-Mitchell 和 Jackson（1996）。）

## 7. 关于智能的简要说明

对于智能的测量存在着根本不同的观点，本文未对此进行讨论。我们关注的是图灵（1950）及其遗产的讨论。当然，更广泛的讨论还将考虑使用算法信息理论、科尔莫哥洛夫复杂性理论、最小消息长度（MML）理论等数学和计算资源进行智能测量的研究。（有关这方面文献的介绍，请参阅 Hernandez-Orallo 和 Dowe（2010），以及其中包含的参考文献列表。有关人工智能研究的更一般介绍，请参阅 Marquis 等人（2020）。）

更广泛地说，在这篇文章中没有涵盖到关于智能的概念或概念的根本不同观点。例如，关于图灵是否最好解释为使用响应依赖型智能概念存在争议。（赞成：Proudfoot（2013）（2020）；反对：Wheeler（2020）。）相关地，关于智能是否与代理之间的对称关系的识别有某种必要关系的争议，如 Mallory（2020）所示。还有一个更广泛的争议，即我们是否应该认为有用的智能概念总是特定于领域，还是我们应该认为在智能的一般领域中有一些重要的东西。

关于建立普遍智能的最可能途径（假设普遍智能存在）存在根本不同的观点。例如，Crosby（2020）认为，前进的最佳方式可能是尝试制造能够通过动物认知测试的机器，即能够从感官输入中创建对环境的预测模型。（例如，Brooks（1990）中有明确的思路先驱。）


## Bibliography

* Abramson, D., 2008, “Turing’s Responses to Two Objections,” *Minds and Machines*, 18: 147–67.
* –––, 2011a, “Descartes’ Influence on Turing,” *Studies in History and Philosophy of Science*, 42: 544–551.
* –––, 2011b, “Philosophy of Mind is (in Part) Philosophy of Computer Science,” *Minds and Machines*, 21: 203–219.
* Arnold, T. and Scheutz, M., 2016, “Against the Moral Turing Test: Accountable Design and the Moral Reasoning of Autonomous Systems,” *Ethics and Information Technology*, 18: 103–15.
* Barone, P., et al., 2020 “A Minimal Turing Test: Reciprocal Sensorimotor Contingencies for Interaction Detection,” *Frontiers in Human Neuroscience* 14.
* Block, N., 1981, “Psychologism and Behaviorism,” *Philosophical Review*, 90: 5–43.
* Boolos, G. and Jeffrey, R., 1980, *Computability and Logic*, Second Edition, Cambridge: Cambridge University Press.
* Bowie, L., 1982, “Lucas’s Number is Finally Up,” *Journal of Philosophical Logic*, 11: 279–85.
* Braddon-Mitchell, D. and Jackson, F., 1996, *The Philosophy of Mind and Cognition*, Oxford: Blackwell.
* Bringsjord, S., Bello, P. and Ferrucci, D., 2001, “Creativity, the Turing Test, and the (Better) Lovelace Test,” *Minds and Machines*, 11: 3–27.
* Brooks, R., 1990, “Elephants Don’t Play Chess,” *Robotics and Autonomous Signals*, 6: 3–15.
* Chalmers, D., 1995, “On Implementing a Computation,” *Minds and Machines*, 4: 391–402.
* Churchland, P. M. and Churchland, P. S., 1990, “Could a Machine Think?” *Scientific American*, 262 (1): 32–37.
* Clark, A., 1997, *Being There: Putting Brain, Body and World Together Again*, Cambridge: MIT Press.
* Cooper, S. and van Leeuwen, J. (eds.) 2013, *Alan Turing: His Work and Impact*, London: Elsevier.
* Copeland, J. (ed.), 1999, “A Lecture and Two Radio Broadcasts on Machine Intelligence by Alan Turing,” in K. Furukawa, D. Michie, and S. Muggleton (eds.), *Machine Intelligence* 15, Oxford: Oxford University Press.
* –––, 2000, “The Turing Test,” *Minds and Machines*, 10: 519–39.
* Copeland, J. and Sylvan, R., 1999, “Beyond the Universal Turing Machine,” *Australasian Journal of Philosophy*, 77: (1): 46–66.
* Copeland, J., et al. (eds.), 2017, *The Turing Guide*, Oxford: Oxford University Press.
* Crooke, A., 2002, *Confabulating Consciousness*, Ph.D. Dissertation, Philosophy Department, Monash University.
* Crosby, M., 2020, “Building Thinking Machines by Solving Animal Cognition Tasks,” *Minds and Machines*, 30: 589–615.
* Cullen, J., 2009, “Imitation Versus Communication: Testing for Human-Like Intelligence,” *Minds and Machines*, 19: 237–54.
* Damassino, N., 2020, “The Questioning Turing Test,” *Minds and Machines*, 30: 563–87.
* –––, and Novelli, N., 2020, “Rethinking, Reworking and Revolutionising the Turing Test,” *Minds and Machines*, 30: 463–8.
* Davidson, D., 1990, “Turing’s Test,” in K. Said, (ed.), *Modelling the Mind*, Oxford: Oxford University Press, 1–11.
* Dennett, D., 1985, “Can Machines Think?” in M. Shafto (ed.), *How We Know*, Cambridge, MA: Harper and Row.
* Dietrich, E. (ed.), 1994, *Thinking Computers and Virtual Persons: Essays on the Intentionality of Machines*, San Diego: Academic Press.
* Dreyfus, H & Dreyfus, S., 1986, *Mind Over Machine*, New York: Free Press.
* Epstein, R. et al. 2009, *Parsing the Turing Test* Dordrecht: Springer.
* Erion, G., 2001, “The Cartesian Test for Automatism,” *Minds and Machines*, 11: 29–39.
* Feferman, S., 1996, “Penrose’s Gödelian Argument,”, *Psyche*, 2: 21–32.
* Floridi, L., Taddeo, M., and Turilli, M., 2008, “Turing’s Imitation Game: Still an Impossible Challenge for all Machines and some Judges,”, *Minds and Machines*, 19: 145–50.
* Floridi, L. and Chiriatti, N. (2020) “GPT-3: It’s Nature, Scope, Limits and Consequences,” *Minds and Machines*, 30: 681–94.
* French, R., 1990, “Subcognition and the Limits of the Turing Test,” *Mind*, 99: 53–65.
* French, R., 2000, “The Turing Test: The First Fifty Years *Trends in Cognitive Sciences*,” 4: 115–21.
* Genova, J., 1994, “Turing’s Sexual Guessing Game,” *Social Epistemology*, 8: 313–26.
* Gerdes, A. and Øhstrøm, P., 2015, “Issues in Robot Ethics Seen Through the Lens of a Moral Turing Test,” *Journal of Information, Communication and Ethics in Society*, 13: 98–109.
* Gunderson, K., 1964, “Descartes, La Mettrie, Language and Machines,” *Philosophy*, 39: 193–222.
* –––, 1985, *Mentality and Machines*, 2nd edition, Minneapolis: University of Minnesota Press.
* Harnad, S., 1989, “Minds, Machines and Searle,” *Journal of Theoretical and Experimental Artificial Intelligence*, 1: 5–25.
* –––, 1991, “Other Bodies, Other Minds: A Machine Incarnation of an Old Philosophical Problem,” *Minds and Machines*, 1: 43–54.
* Harnad, S. and Dror, I., 2006, “Distributed Cognition, Cognising, Autonomy and the Turing Test,” *Pragmatics and Cognition*, 14: 209–13.
* Haugeland, J., 1981, “Semantic Engines: An Introduction to Mind Design,” in J. Haugeland (ed.), *Mind Design: Philosophy, Psychology, Artificial Intelligence*, Cambridge: MIT Press, 1–34.
* Hauser, L., 1993, “Reaping the Whirlwind: Reply to Harnad’s Other Bodies, Other Minds,” *Minds and Machines*, 3: 219–38.
* Hauser, L., 2001, “Look Who’s Moving the Goalposts Now,” *Minds and Machines*, 11: 41–51.
* Hayes, P., and Ford, K., 1995, “Turing Test Considered Harmful,” *Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence*, Montreal: Morgan Kaufmann, 972–977.
* Hernández-Orallo, J., 2000, “Beyond the Turing Test,” *Journal of Logic, Language and Information*, 9: 447–66.
* –––, 2020, “Twenty Years Beyond the Turing Test: Moving Beyond the Human Judges,” *Minds and Machines*, 30: 533–62.
* Hernández-Orallo, J. and Dowe, D. L., 2010, “Measuring Universal Intelligence: Towards an Anytime Intelligence Test,” *Artificial Intelligence*, 174: 1508–39.
* Hodges, A., 1983, *Alan Turing: The Enigma*, London: Burnett with Hutchinson.
* Hofstadter, D., 1982, “The Turing Test: A Coffee-House Conversation,” in D. Hofstadter and D. Dennett (eds.), *The Mind’s I: Fantasies and Reflections on Self and Soul*, London: Penguin, 69–95.
* Kobosko, S., et al., 2013 “Passing an Enhanced Turing Test: Interacting with Lifelike Computer Representations of Specific Individuals,” *Journal of Intelligent Systems*, 22: 365–415.
* Korukonda, A., 2003, “Taking Stock of the Turing Test: A Review, Analysis and Appraisal of Issues Surrounding Thinking Machines,” *International Journal of Human-Computer Studies* 58: 240–57.
* Kulikov, V., 2020, “Preferential Engagement: What can we Learn from Online Chess?,” *Minds and Machines*, 30: 617–36.
* Leavitt, D., 2007, *The Man Who Knew Too Much: Alan Turing and the Invention of the Computer* London: Phoenix.
* Levesque, H., 2017, *Commonsense, the Turing Test, and the Quest for Real AI*, Cambridge, MA: MIT Press.
* Lewis, D., 1969, “Lucas against mechanism,” *Philosophy*, 44: 231–233.
* –––, 1979, “Lucas against mechanism II,” *Canadian Journal of Philosophy*, 9: 373–376.
* Lucas, J., 1961, “Minds, Machines and Gödel,” *Philosophy*, 36: 120–4.
* Lupowski, P., 2011, “A Formal Approach to Exploring the Interrogator’s Perspective in the Turing Test,” *Logical and Logical Philosophy* 20: 139–58.
* Lupowski, P. and Jurowska, P., 2019, “Minimum Intelligent Signal Test as an Alternative to the Turing Test,” *Diametros*, 59: 35–47.
* Lyre, H. 2020, “The State Space of Artificial Intelligence”, *Minds and Machines*, 30: 325–47.
* Mallory, F. 2020, “In Defence of a Reciprocal Turing Test,” *Minds and Machines*, 30: 659–80.
* Marcus, G., 2020 “The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence,” arXiv:2002.06177.
* Marquis, P., et al. (eds.), 2020, *A Guided Tour of Artificial Intelligence Research*, Cham: Springer.
* Masum, H., Christensen, S., and Oppacher, F., 2003, “The Turing Ratio: A Framework for Open-Ended Task Metrics,” *Journal of Evolution and Technology*, 13(2), [available online](https://www.jetpress.org/volume13/TuringRatio.pdf).
* McDermott, D., 2014, “On the Claim that a Look-Up Table Program could Pass the Turing Test,” *Minds and Machines*, 24: 143–88.
* Millican, P. and Clark, A., (eds.), 1999, *Machines and Thought: The Legacy of Alan Turing*, two volumes, Oxford: Clarendon.
* Moor, J., 1976, “An Analysis of Turing’s Test,” *Philosophical Studies*, 30: 249–57.
* –––, 2001, “The Status and Future of the Turing Test,” *Minds and Machines*, 11: 77–93.
* ___, ed., 2003 *The Turing Test: The Elusive Standard of Artificial Intelligence* Dordrecht: Springer.
* Neufeld, E. and Finnestad, S., 2020a, “In Defense of the Turing Test,” *AI and Society* 35: 819–27.
* Neufeld, E. and Finnestad, S., 2020b, “Imitation Game: Threshold or Watershed?,” *Minds and Machines*, 30: 637–57.
* Pautz, A. and Stoljar, D. (eds.), 2019, *Blockheads! Essays on Ned Block’s Philosophy of Mind and Consciousness*, Cambridge, MA: MIT Press.
* Penrose, R., 1989, *The Emperor’s New Mind*, Oxford: Oxford University Press.
* Piccinini, G., 2000, “Turing’s Rules for the Imitation Game,” *Minds and Machines*, 10: 573–85.
* Proudfoot, D., 2013, “Rethinking Turing’s Test,” *Journal of Philosophy*, 110: 391–411.
* –––, 2020, “Rethinking Turing’s Test and the Philosophical Implications,” *Minds and Machines*, 30: 487–512.
* Proudfoot, D. and Copeland, J. 2008 “Turing’s Test: A Philosophical and Historical Guide,” in R. Epstein et al., (eds.), *Parsing the Turing Test: Philosophical and Methodological Issues*, Dordrecht: Springer, 119–38.
* Rapaport, W., 2000, “How to Pass a Turing Test: Syntactic Semantics, Natural-Language Understanding, and First-Person Cognition,” *Journal of Logic, Language and Information*, 9: 467–90.
* Saygin, A., Cicekli, I., and Akman, V., 2000, “Turing Test: 50 Years Later,” *Minds and Machines*, 10: 463–518.
* Schweizer, P., 1998, “The Truly Total Turing Test,” *Minds and Machines*, 8: 263–72.
* –––, 2012, “The Externalist Foundation of a Truly Total Turing Test,” *Minds and Machines*, 22: 191–212.
* Searle, J., 1981, “Minds, Brains, and Programs,” *Behavioral and Brain Sciences*, 3: 417–57.
* Shah, H. and Warwick, K., 2010, “Hidden Interlocutor Misidentification in Practical Turing Tests,” *Minds and Machines*, 203: 441–54.
* Shieber, S., 1994, “Lessons from a restricted Turing Test,” *Communications of the Association for Computing Machinery*, 37: 70–8. [[Preprint available online](http://www.eecs.harvard.edu/~shieber/Biblio/Papers/loebner-rev-html/loebner-rev-html.html)].
* –––, (ed.), 2004, *The Turing Test: Verbal Behaviour as the Mark of Intelligence*, Cambridge: MIT Press.
* –––, 2007, “The Turing Test as Interactive Proof,” *Noûs*, 41: 686–713.
* –––, 2014, “There can be no Turing-Test-Passing Memory Machines,” *Philosophers’ Imprint*, 14: 1–13.
* Sparrow, R., 2004, “The Turing Triage Test,” *Ethics and Information Technology*, 6: 203–13.
* Srinivasan, B. and Shah, K., 2019, “Towards a Unified Framework for Developing Ethical and Practical Turing Tests,” *AI and Society*, 34: 145–52.
* Sterrett, S., 2000, “Turing’s Two Tests for Intelligence,” *Minds and Machines*, 10: 541–59.
* Sterrett, S., 2020, “The Genius of the ‘Original Imitation Game’ Test,” *Minds and Machines*, 30: 469–86.
* Traiger, S., 2000, “Making the Right Identification in the Turing Test,” *Minds and Machines*, 10: 561–572.
* Turing, A., 1950, “Computing Machinery and Intelligence,” *Mind*, 59 (236): 433–60.
* Turing, A. 1992, *The Collected Works of A. M. Turing*, edited by P. Furbank, London: North-Holland.
* Warwick, K. et al., 2013, “Some Implications of a Sample of Practical Turing Tests,” *Minds and Machines*, 23: 163–77.
* Weizenbaum, J., 1966, “ELIZA-A Computer Program for the Study of Natural Language Communication Between Men and Machines,” *Communications of the ACM*, 9: 36–45.
* Wheeler, M., 2020 “Deceptive Appearances: The Turing Test, Response Dependence, and Intelligence as an Emotional Concept,” *Minds and Machines* 30: 513–32.
* Whitby, B., 1996, “The Turing Test: AI’s Biggest Blind Alley?” in P. Millican and A. Clark (eds.), *Machines and Thought: The Legacy of Alan Turing*, Volume 1, Oxford: Clarendon.
* Zdenek, S., 2001, “Passing Loebner’s Turing Test: A Case of Conflicting Discourse Functions,” *Minds and Machines*, 11: 53–76.

## Academic Tools

> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=turing-test). |
> | --- | --- |
> | ![sep man icon](https://plato.stanford.edu/symbols/sepman-icon.jpg) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/turing-test/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
> | ![inpho icon](https://plato.stanford.edu/symbols/inpho.png) | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=turing-test&redirect=True) at the Internet Philosophy Ontology Project (InPhO). |
> | ![phil papers icon](https://plato.stanford.edu/symbols/pp.gif) | [Enhanced bibliography for this entry](https://philpapers.org/sep/turing-test/) at [PhilPapers](https://philpapers.org/), with links to its database. |

## Other Internet Resources

* Brown, T., et al., 2020, [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165), description of GPT-3 at archive.org.
* Chalmers, D., 2020, “[GPT-3 and General Intelligence](https://dailynous.com/2020/07/30/philosophers-gpt-3/#chalmers),” blog post a dailynous.com.
* [Philosophers on GPT-3](http://dailynous.com/2020/07/30/philosophers-gpt-3/), at dailynous.com.
* [Alan Turing Home Page](http://www.turing.org.uk/turing/Turing.html) (Andrew Hodges, Wadham College, Oxford).
* “[Computing machinery and intelligence](https://www.cs.ox.ac.uk/activities/ieg/e-library/sources/t_article.pdf)” by Alan Turing (1950).
* [The Loebner Prize](https://www.ocf.berkeley.edu/~arihuang/academic/research/loebner.html).
* [Machine Intelligence Part 1: The Turing Test and Loebner Prize](http://www.rci.rutgers.edu/~cfs/472_html/Intro/NYT_Intro/History/MachineIntelligence1.html) (Ashley Dunn).
* [Why CAPTCHAS Have Gotten So Difficult](https://www.theverge.com/2019/2/1/18205610/google-captcha-ai-robot-human-difficult-artificial-intelligence)(Josh Dzieza).
* [There is no General AI: Why Turing Machines Cannot Pass the Turing Test](https://arxiv.org/pdf/1906.05833.pdf) (Jobst Landgrebe and Barry Smith).

## Related Entries

[artificial intelligence](https://plato.stanford.edu/entries/artificial-intelligence/) | [Chinese room argument](https://plato.stanford.edu/entries/chinese-room/) | [functionalism](https://plato.stanford.edu/entries/functionalism/) | [Gödel, Kurt: incompleteness theorems](https://plato.stanford.edu/entries/goedel-incompleteness/) | [logic: provability](https://plato.stanford.edu/entries/logic-provability/) | [Turing, Alan](https://plato.stanford.edu/entries/turing/)

### Acknowledgments

We would like to acknowledge the help of the editors of the *Encyclopedia*, Jose Hernandez-Orallo, and two anonymous referees. The advice that we we have received has led to numerous improvements. We look forward to receiving further suggestions for improvements from those who’ve read what we have written.

[Copyright © 2021](https://plato.stanford.edu/info.html#c) by  
[Graham Oppy](http://profiles.arts.monash.edu.au/graham-oppy/) <[*Graham.Oppy@monash.edu*](mailto:Graham%2eOppy%40monash%2eedu)>  
[David Dowe](http://www.csse.monash.edu.au/~dld/David.Dowe.publications.html) <[*David.Dowe@monash.edu*](mailto:David%2eDowe%40monash%2eedu)>
