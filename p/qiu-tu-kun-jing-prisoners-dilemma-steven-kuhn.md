# 囚徒困境 prisoner’s dilemma (Steven Kuhn)

*首次发表于1997年9月4日；实质性修订于2019年4月2日*

Tanya和Cinque因抢劫Hibernia储蓄银行而被逮捕，并被分别关押在单独的隔离牢房中。他们两个都更关心自己的个人自由，而不是同伙的福祉。一个聪明的检察官向每个人提出以下选择：“你可以选择坦白或保持沉默。如果你坦白而你的同伙保持沉默，我将撤销对你的所有指控，并使用你的证词确保你的同伙被判重刑。同样，如果你的同伙坦白而你保持沉默，他们将获得自由，而你将被判刑。如果你们两个都坦白，我将得到两个定罪，但我会确保你们两个都获得提前假释。如果你们两个都保持沉默，我只能就非法持有武器的指控判你们轻微的刑罚。如果你想坦白，你必须在明天早上我回来之前给狱卒留下一张纸条。”

囚徒们面临的“困境”是，无论对方做什么，每个人都比保持沉默更好地承认。但是，当两个人都承认时，得到的结果对每个人来说都比如果两个人都保持沉默得到的结果更糟糕。一种普遍的观点是，这个谜题说明了个体与群体理性之间的冲突。一个追求理性自利的群体可能会比一个违背理性自利的群体都更糟糕。更一般地说，如果假设回报不代表自利，一个追求任何目标的群体可能会比如果他们没有理性地追求自己的目标时都取得更少的成功。一个密切相关的观点是，囚徒困境游戏及其多人推广模拟了一些常见情况，即很难让理性自私的参与者为了共同利益而合作。现代文献的很大一部分集中在确定玩家在哪些条件下会或应该采取“合作”的举动，即保持沉默。稍微不同的解释认为，这个游戏代表了自私行为和社会上可取的利他主义之间的选择。与承认相对应的举动对演员有利，无论对方做什么，而与保持沉默相对应的举动对另一个玩家有利，无论那个玩家做什么。自己受益并不总是错误的，当然，以自己为代价来使他人受益也不总是道德上必需的，但在囚徒困境游戏中，两个玩家都更喜欢具有利他主义举动的结果而不是具有自私举动的结果。这一观察引导了大卫·高弗和其他人认为囚徒困境对道德的本质有重要的启示。

这是另一个故事。比尔有一顶蓝色的帽子，他更喜欢一顶红色的，而罗斯有一顶红色的帽子，她更喜欢一顶蓝色的。他们都更喜欢两顶帽子而不是一顶，也比不戴帽子更喜欢任何一顶帽子。他们可以选择保留自己的帽子或将其给对方。这个“交换游戏”与关于囚徒的故事具有相同的结构。无论罗斯保留她的帽子还是将其给比尔，比尔保留自己的帽子都更好，而如果她将帽子给他，她会更好。无论比尔保留自己的帽子还是将其给罗斯，罗斯保留自己的帽子都更好，而如果她将帽子给他，他会更好。但是，如果他们交换帽子，他们两个都会更好。这个新故事表明，囚徒困境也占据了我们经济系统的核心位置。似乎任何旨在促进互利交换的市场都需要克服或避免这个困境。

1950 年，梅里尔·弗洛德（Merrill Flood）和梅尔文·德雷舍（Melvin Dresher）讨论了囚徒困境的结构问题，作为兰德公司对博弈论的调查的一部分（兰德公司之所以进行这项调查，是因为可能应用于全球核战略）。囚徒困境的标题和以监禁期作为回报的版本归功于阿尔伯特·塔克（Albert Tucker），他希望使弗洛德和德雷舍的想法更容易被斯坦福大学心理学家的观众理解。最近，有人提出（彼得森，第 1 页）塔克可能正在讨论他著名的研究生约翰·纳什的工作，而纳什 1950 年（第 291 页）确实包含了一个具有囚徒困境结构的游戏，作为六个例子中的第二个，用来说明他的技术思想。尽管弗洛德和德雷舍（以及纳什）没有亲自急于在外部期刊文章中宣传他们的想法，但这个谜题在各个学科中引起了广泛而日益增长的关注。多宁格报告称，在六十年代和七十年代发表了“一千多篇文章”关于这个问题。2018 年，谷歌学术搜索“囚徒困境”返回了 49,600 个结果。

下面的部分提供了囚徒困境的各种更精确的特征描述，从最狭窄的开始，并调查了与类似游戏的一些联系以及在哲学和其他领域的一些应用。特别关注游戏的迭代和进化版本。在前者中，囚徒困境游戏被重复进行，打开了一个可能性，即玩家可以利用其当前的移动来奖励或惩罚对方在以前的移动中的表现，以便在未来诱导合作性的游戏。在后者中，一个群体的成员在囚徒困境游戏中反复与彼此对战，那些获得更高回报的人比那些获得较低回报的人“繁殖”得更快。"囚徒困境"缩写为"PD"。

 
---

## 1. 对称的 2×2 囚徒困境与序数支付

在其最简单的形式中，囚徒困境是一个由支付矩阵描述的游戏：

|   | C   | D   |
| --- | ----- | ----- |
| C | R,R | S,T |
| D | T,S | P,P |

满足以下不等式链：

* (PD1)T>R>P>S

有两名玩家，Row 和 Column。每个玩家有两种可能的行动，“合作”（C）或“背叛”（D），分别对应于上面的说明性轶事中保持沉默或坦白的选项。对于每对可能的行动，Row 和 Column（按顺序）的回报在适当的单元格中列出。R 是每个玩家在两者都合作时获得的“奖励”回报。P 是每个玩家在两者都背叛时获得的“惩罚”。T 是每个玩家作为唯一的背叛者获得的“诱惑”回报，S 是每个玩家作为唯一的合作者获得的“傻瓜”回报。我们在这里假设游戏是对称的，即奖励、惩罚、诱惑和傻瓜回报对于每个玩家都是相同的，并且回报只有序数意义，即它们表明一个回报是否比另一个回报更好，但不告诉我们更好多少。现在很容易看出我们有一个类似故事中的困境的结构。假设 Column 合作。然后 Row 在合作时得到 R，在背叛时得到 T，所以选择背叛对他来说更好。假设 Column 背叛。然后 Row 在合作时得到 S，在背叛时得到 P，所以选择背叛对他来说也更好。Row 的行动 D 被认为严格优于行动 C：无论 Column 做什么，Row 选择 D 比 C 更好。根据对称性，对于 Column 来说，D 也严格优于 C。因此，两个“理性”的玩家将背叛并获得回报 P，而两个“非理性”的玩家可以合作并获得更大的回报 R。在标准处理中，博弈论假设理性和共同知识。每个玩家都是理性的，知道对方是理性的，知道对方知道他是理性的，依此类推。每个玩家还知道对方如何评估结果。但由于 D 对于两个玩家都严格优于 C，这里对于困境的论证只需要每个玩家知道自己的回报即可。（当然，在更强的标准假设下，这个论证仍然有效。) 值得注意的是，两个玩家都背叛的结果(D,D)是游戏唯一的严格纳什均衡，即，这是唯一一个每个玩家通过单方面改变自己的行动只会变得更糟的结果。 Flood 和 Dresher 对他们的困境的兴趣似乎源于他们认为它提供了一个反例，即纳什均衡是游戏的自然“解决方案”的主张。

如果在收益排名中存在“并列”，则可以削弱条件 PD1 而不破坏困境的本质。假设以下条件之一成立：

* (PD2)T>R>P≥S，或者
* T≥R>P>S

然后，对于每个玩家来说，虽然 D 并不严格优于 C，但从某种意义上说，D 仍然是优于 C 的，因为每个玩家总是至少能够做得和有时候更好。在这些条件下，选择 D 仍然是理性的，这导致了两个玩家都不喜欢的回报。让我们称满足 PD2 的游戏为弱 PD。请注意，在不满足 PD1 的弱 PD 中，相互背叛不再是严格意义上定义的纳什均衡。然而，它仍然是唯一的纳什均衡，即没有玩家可以通过单方面改变自己的行动来改善自己的位置。同样，人们可能会认为，如果存在这种较弱类型的唯一纳什均衡，理性的自利玩家将会达到它。

## 2. 不对称性

不假设对称性的情况下，囚徒困境可以用下标 r 和 c 来表示对行和列的回报。

|   | C     | D     |
| --- | ------- | ------- |
| C | Rr,Rc | Sr,Tc |
| D | Tr,Sc | Pr,Pc |

如果我们假设每个玩家的回报按照之前的顺序排序，即当 i=r,c 时，Ti>Ri>Pi>Si，那么与之前一样，D 对于两个玩家来说是绝对优势的移动，但是两个玩家都选择这个移动的结果(D,D)对于每个人来说都比(C,C)更糟糕。然而，现在困境的力量也可以在较弱的条件下感受到。考虑以下三对不等式：

* (PD3) a. Tr>Rr and Pr>Sr
* b.Tc>Rc 和 Pc>Sc
* c.Rr>Pr 和 Rc>Pc

如果这些条件都满足，困境的论证与之前一样。对于每个玩家来说，背叛严格优于合作，而(C,C)对每个玩家来说都严格优于(D,D)。如果条件 a-c 中的两个>符号被弱不等号(≥)替换，我们就得到了一个弱囚徒困境。对于每个玩家来说，背叛弱优于合作（即在所有情况下背叛和合作一样好，而在某些情况下更好），而(C,C)弱优于(D,D)（即对于两个玩家来说至少和(D,D)一样好，对于其中一个玩家来说更好）。由于没有一个子句要求对 r 的回报和 c 的回报进行比较，我们不需要假设>具有任何“人际”意义。

现在假设我们放弃 a 或 b 的第一个不等式（但不是两者都放弃）。满足这些条件的游戏可以称为共同知识囚徒困境。只要每个玩家都知道对方是理性的，并且每个人都知道对方的收益排序，我们仍然感受到困境的力量。假设 a 成立。那么对于 Row 来说，D 是占优的选择。Column 知道 Row 是理性的，知道 Row 会背叛，所以根据 b 中剩余的不等式，Column 也会背叛。同样，如果 b 成立，Column 会背叛，Row 意识到这一点后也会背叛。根据 c，结果为(D,D)对双方来说比(C,C)更糟糕。

## 3. 基数收益和不纯囚徒困境

如果游戏规定了绝对（而不是相对）收益，即使在两人囚徒困境中，普遍合作也可能不是帕累托最优的结果。因为在某些条件下，通过采用混合策略，即以概率 p 合作和以概率（1−p）背叛，两个玩家都能获得更好的结果。这一点在下面的图表中有所说明。

![Figure 1](https://plato.stanford.edu/entries/prisoner-dilemma/fig1--pureimpure.png)

 图 1

这里的 x 轴和 y 轴分别代表了 Row 和 Column 的效用。在第二部分的矩阵中输入的四个结果由标记的点表示。条件 PD3a 和 PD3b（见上文）确保了(C,D)和(D,C)位于(D,D)的西北和东南方向，而 PD3c 反映了(C,C)位于(D,D)的东北方向。首先假设(D,D)和(C,C)位于(C,D)和(D,C)之间的直线的两侧，如左图所示。然后这四个点形成一个凸四边形，混合策略的可行结果的收益由该四边形上或内的所有点表示。当然，每次进行游戏时，玩家实际上只能获得四种可能的收益之一，但是四边形中的点表示了两个玩家的收益的预期值。例如，如果 Row 和 Column 以概率 p 和 q 合作（以概率 p∗=1−p 和 q∗=1−q 背叛），那么 Row 的收益的预期值为 p∗qT+pqR+p∗q∗P+pq∗S。根据标准观点，一个理性的自利玩家应该更喜欢较高的预期收益而不是较低的。在左图中，普遍合作（概率为 1）的收益是所有混合策略的收益中最优的。然而，在右图中，(D,D)和(C,C)都位于(C,D)和(D,C)之间的直线的西南方向，情况更加复杂。在这里，可行结果的收益位于一个由三条不同曲线段界定的图形的东北方。请注意，(C,C)现在位于由实线界定的区域的内部，这表明存在混合策略可以为两个玩家提供比(C,C)更高的预期收益。重要的是要注意，我们在这里谈论的是独立的混合策略。Row 和 Column 使用私人随机设备，并且没有交流。 如果他们能够相关他们的混合策略，以确保，比如说(C,D)的概率为 p，(D,C)的概率为 p∗，可行解的集合将延伸到（并包括）(C,D)和(D,C)之间的虚线。关键在于，即使限于独立策略，也有一些满足囚徒困境 3 的游戏，两个玩家都可以比他们在普遍合作下做得更好。一个普遍合作是帕累托最优的囚徒困境可以称为纯囚徒困境。（这一现象在 Kuhn 和 Moresi 中被发现，并应用于道德哲学中的 Kuhn 1996 年。）纯囚徒困境的特点是在 PD3 的基础上添加以下条件。

* (P)(Tr−Rr)(Tc−Rc)≤(Rr−Sr)(Rc−Sc)

在对称游戏中，P 简化为更简单的条件

* (RCA)R≥12(T+S)

(以使用它的作者 Rapoport，Chammah 和 Axelrod 命名)。

## 4. 多次移动和可选的囚徒困境

一般来说，可以说囚徒困境是一种游戏，在这个游戏中，只有当每个玩家违背理性自利时才能获得“合作”结果，而这个结果被一致地优先于每个玩家坚持理性自利时获得的“自私”结果。我们可以将自私的结果描述为每个玩家追求其占优（强占优）策略的结果，或者是唯一的弱（强）纳什均衡。在一个两步游戏中，这两种描述是一样的 - 一个占优的步骤对是一个唯一的均衡，而一个唯一的均衡是一个占优的步骤对。然而，如下所示的收益矩阵显示，这两个概念在超过两个步骤的游戏中有所不同。

|   | C   | D   | N   |
| --- | ----- | ----- | ----- |
| C | R,R | S,T | T,S |
| D | T,S | P,P | R,S |
| N | S,T | S,R | S,S |

在这里，每个玩家可以选择“合作”（C），“背叛”（D）或“无所谓”（N），并且收益按照之前的顺序排列。背叛不再占优，因为当另一个玩家选择 N 时，每个玩家选择 C 比选择 D 更好。然而，（D，D）仍然是唯一的均衡。让我们将自私结果是唯一均衡的游戏标记为均衡囚徒困境，将自私结果是一对占优步骤的游戏标记为占优囚徒困境。如下所示，通过允许条件策略来“解决”囚徒困境的尝试可能会创建多步游戏，这些游戏本身就是均衡囚徒困境。

具有稍微不同结构的三步游戏在“可选囚徒困境”标签下受到关注。例如，参见 Kitcher（2011），Kitcher（1993），Batali 和 Kitcher，Szabó和 Hauert，Orbell 和 Dawes（1993）以及 Orbell 和 Dawes（1991）。前三个来源还允许可选游戏中的玩家向特定对手发出信号，表示愿意参与（即对特定对手进行 C 或 D 的选择）。本节讨论的没有信号的简单三步游戏在 Batali 和 Kitcher 中被称为“半可选”。S，R，P 和 T 的收益按照之前的顺序排列，但是收益矩阵现在还包含一个介于 P 和 R 之间的“退出”值 O。

|   | C   | D   | N   |
| --- | ----- | ----- | ----- |
| C | R,R | S,T | O,O |
| D | T,S | P,P | O,O |
| N | O,O | O,O | O,O |

在这个版本的游戏中，背叛不再是一种占优势的策略，而且互相背叛也不再是一种均衡结果。如果列方合作，行方通过背叛可以获得最好的结果；如果列方背叛，行方通过选择N可以获得最好的结果；如果列方选择N，那么行方通过选择任何策略都可以获得同样好的结果。在互相背叛的结果中，任何一方都可以通过单方面转变为选择N来获益。但是在互相选择N的结果中，任何一方都无法通过单方面改变策略来获益。因此，可选的囚徒困境是一个弱均衡囚徒困境，其中N扮演着背叛的角色。Orbell和Dawes（1991年和1993年）还增加了一个额外的条件，即退出支付O等于零。在可选的囚徒困境中，只有当一个理性的玩家预期对手会合作时，她才会参与（即选择C或D）。因为如果她的对手合作，她通过参与可以至少得到R的回报，通过不参与可以得到恰好等于O的回报；而如果她的对手不合作，她通过参与最多只能得到P的回报，通过不参与可以得到恰好等于O的回报。当O等于零时，这个特点尤为突出，因为此时只有在对手合作时，参与的回报才是正数。

“不选择”行动和“退出”回报的描述在对可选囚徒困境的解释中有所不同。对于基彻尔来说，它们经常代表了选择“单飞”的机会。例如，一只狒狒可以选择自己梳理而不是与伙伴进行彻底或草率的梳理交换。另一方面，通常有人认为N代表了选择“退出”游戏，也许是为了以后能够找到更合适的伙伴一起玩。这种差异的意义，如果有的话，将在迭代和进化版本的游戏中显现出来（见下面的第11-17节）。那些写关于可选囚徒困境的人经常表达希望，即如果代理人选择与之互动的伙伴，合作是可以实现的。这个想法在下面第19节讨论的社交网络游戏中以稍微不同、也许更直接的方式进行建模。对这个想法的进一步讨论留待下一节。

Orbell 和 Dawes 特别关注一个解释合作行为的原理，该原理基于经验支持的假设，即个体通常根据自己对自己行为和倾向的了解来预期他人的行为。这个假设表明，相比于背叛者，合作者更有可能预期他人合作，因此，如果他是理性的，更有可能参与可选的囚徒困境。Orbell 和 Dawes（1991）证明，如果合作者比背叛者更有可能预期对手合作（前提是对手合作的几率足够高），那么在可选的囚徒困境中，合作者实际上可以期望获得比背叛者更高的回报。Orbell 和 Dawes（1993）提供了实验证据，证明可选的囚徒困境中的参与者获得的平均回报要高于相应的没有 N 步骤的囚徒困境。他们提供了巧妙的统计论证来支持以下假设：有意合作者（在必须参与时合作的人）在可选的囚徒困境中比在相应的囚徒困境中表现更好；有意背叛者通常在可选的囚徒困境中表现更差；在某些条件下，这些收益和损失足以使有意合作者比有意背叛者更好（正如前一篇论文的理论结果所预测的）；最后，那些预期他人合作的人（通过他们的参与行为表现出来）这样做是基于他们自己合作的倾向，而不是对对手性格的直接洞察力。（见下面的透明度。）

## 5. 多个参与者，公地悲剧，投票和公共物品

大多数认为囚徒困境对道德有重要意义的人似乎认为游戏的基本结构反映在更大的群体，甚至整个社会所面临的情况中。从两个玩家到多个玩家游戏的最明显的推广是，如果所有人合作，每个玩家都会得到奖励（R），如果所有人都背叛，每个玩家都会受到惩罚（P），如果一些人合作而另一些人背叛，合作者会得到吃亏的回报（S），而背叛者会得到诱惑（T）。但我们很少面临这种结构的情况。

一种常见观点是，多人囚徒困境结构反映在加勒特·哈丁所普及的“公地悲剧”中。一组相邻农民中的每个成员都更愿意让自己的牛在公地上放牧，而不是将其放在自己不足的土地上，但如果超过某个阈值的人使用公地，公地将变得不适合放牧。更一般地说，如果足够多的人付出成本 C，每个成员都可以获得一些社会利益 B。我们可以将支付矩阵表示如下：

|   | ** 多于 n 个人<br /> 选择 C** | ** n 或更少<br /> 选择 C** |
| --- | --------------------------- | ------------------------ |
| C | C+B                       | C                      |
| D | B                         | 0                      |

成本 C 被假设为一个负数。这里的“诱惑”是在没有成本的情况下获得利益，奖励是在有成本的情况下获得利益，惩罚是既不获得利益也不付出成本，而吃亏的回报是付出成本却没有实现利益。因此，回报按照 B>(B+C)>0>C 的顺序排列。就像在两人游戏中一样，对于所有玩家来说，D 似乎在 C 上强势占优，因此理性的玩家会选择 D 并获得 0，同时希望每个人都选择 C 并获得 C+B。

与更直接的一般化不同，这个矩阵以一种高度理想化的方式反映了常见的社会选择，比如在耗尽和保护稀缺资源之间的选择，在使用污染和非污染的制造或处理方式之间的选择，以及在参与和不参与某个共同目标的团体努力之间的选择。当玩家数量较少时，它代表了所谓的“志愿者困境”的一个版本。一个团体需要一些志愿者，但如果其他人都志愿参加，每个成员都会得到更好的回报。（然而，请注意，在真正的志愿者困境中，只需要一个志愿者，n 为零，右上角的结果是不可能的。在这种情况下，D 不再占优于 C，游戏失去了囚徒困境的特点。）当需要接种一种已知有严重风险的疫苗以防止致命疾病的爆发时，这个游戏的一个特别棘手的表现形式出现了。如果足够多的邻居接种疫苗，每个人可能在不承担风险的情况下得到保护。

这里描述的情况的一个理想化是，合作的成本和收益被假定与合作的人数无关。在超过合作门槛之前，没有人获得收益。之后，每个人都会获得收益。用 Frolich 等人的术语来说，它们是不连续的。这对于，比如说，居民不再往湖里倾倒废物而使湖水变干净，或者用户通过节约来维持燃气供应的情况并不成立。我们将在以后考虑放宽这个理想化。现在，请注意，一个更接近矩阵所描述的情况是由特定政治候选人或提案的支持者所面临的选择是否在多数规则选举中投票。一旦足够多的支持者选择投票，额外的选票将不会增加他们的利益。因此，我们可以称上述矩阵所描述的游戏为投票游戏。

如上所述，投票游戏与两人囚徒困境有一些不同之处。首先，即使每个玩家的行动完全独立于其他玩家，上述公共矩阵中列所代表的选择与行所代表的选择不再独立。我选择 C 必然增加超过 n 人选择 C 的机会。为了确保独立性，我们应该重新绘制矩阵如下：

|   | **超过 n 个其他人选择 C**    | ** n 其他人选择 C** | **少于 n 其他人选择 C选择 C**  |
| --- | ----- | --------------------- | --- |
| C | C+B | C+B                 | C |
| D | B   | 0                   | 0 |

但是现在我们看到，与 2 人囚徒困境中一样，移动 D 并不支配 C。当我们处于足够合作的阈值位置时，即恰好有 n 个其他人选择 C 时，我选择合作更好。同样地，原始囚徒困境中唯一的纳什均衡是相互背叛，而这个游戏有两个均衡。一个是普遍背叛，因为任何一个玩家单方面偏离这个结果都会从收益 0 变为 C。但第二个是最低效合作的状态，此时合作者的数量刚好足够获得利益。一个离开这个结果的背叛者将从 B 变为 B+C，而一个离开的合作者将从 B+C 变为 0。最后，在原始囚徒困境中，除了普遍背叛之外的每个结果都是帕累托最优的——也就是说，只要至少有一个玩家合作，就没有一个结果使得每个玩家至少与之前一样好，而有一个玩家更好。另一方面，在投票游戏中，只有最低效合作的状态是帕累托最优的。如果合作者的数量超过阈值一个或多个，一个新的背叛者将使自己受益而不伤害其他人。

鉴于这些特性，投票游戏似乎比囚徒困境少了很多困境。毕竟，存在着帕累托最优结果的均衡。然而，在实践中，很难看到如何达到这些均衡并避免全面缺陷的均衡。当n很大时，背叛“几乎占主导地位”，而合作则相对较少。例如，在投票案例中，一个玩家可能会合理地推断：如果我的支持者中只有少数人投票，我的投票将是徒劳的；如果他们中有很多人投票，我的投票将是不必要的。即使一个团体处于极少数有效合作的阈值之下的不太可能的情况下，一个潜在的选民也无法知道这一点。在污染和保护的例子中，行动实际上不应该被建模为同时进行（参见下面的异步行动），因此我们可能会更加乐观一些。通过观察那些先前行动的人的行动，一个玩家可能会知道在他的轮到时，最低有效合作的阈值是否接近。然而，在大多数现实情况下，一个玩家只能通过观察这些行动的效果来推断这一点，而这些效果通常只在他行动之后才显现出来。一个明显的例子是导致气候变化的碳排放活动的连续发生。

在哲学家们讨论的囚徒困境的例子中，普遍合作被认为是最有社会价值的结果。在选民困境中，由于最低效合作是帕累托优越的，人们可能认为我们应该以此为目标。但这似乎取决于所涉及选择的性质。在医疗例子中，似乎最好给每个人都接种疫苗。然而，在农业例子中，规定没有人使用公共资源似乎是愚蠢的。在前一种情况下避免接种疫苗的人被视为“搭便车者”。在后一种情况下，未充分利用的公共资源似乎体现了“过剩合作”。所有这些情况似乎都引发了公平性的问题。如果 t+1 是最低效合作的参与者数量，那么在恰好有 t+1 个参与者合作的任何配置中，都是帕累托最优均衡。如果没有理由更喜欢其中一个配置而不是另一个，那么公平可能会决定选择普遍合作的较差结果。

共有资源悲剧的两人版本游戏（阈值为一）产生了一个矩阵，呈现出较少的困境。

|   | C       | D   |
| --- | --------- | ----- |
| C | B+C,B+C | C,0 |
| D | 0,C     | 0,0 |

这个游戏捕捉到了大卫·休谟关于一艘船上有一个船员在左舷，另一个船员在右舷的例子（前提是我们假设休谟的船员必须在休息（D）和努力（C）之间同时做出选择）。如果任何一方单独划船，她会白白努力，这比她仅仅休息要糟糕。在这里，相互合作与最低效合作是相同的，因此既是均衡结果，也是帕累托最优结果。这类游戏在下面的第 8 节中被称为“猎鹿游戏”。

上述对公地悲剧的描述做出了简化假设，即合作的成本和收益对每个参与者都相同，合作的成本与合作的人数无关，并且收益的大小（0或B）仅取决于合作者的数量是否超过阈值。更一般的解释将用函数C(i,j)和B(i,j)替换C和B，表示当玩家i是恰好有j个合作者时，合作对玩家i的成本以及恰好有j个合作者时对玩家i的收益。我们假设存在某个最低有效合作的阈值t，以便只有当j>t时，B(i,j)才有定义。我们还可以假设额外的合作永远不会减少i从有效合作中获得的收益，即当j>t时，B(i,j+1)≥B(i,j)，并且额外的背叛永远不会减少i在合作中承担的成本，即C(i,j+1)≥C(i,j)。现在假设，一旦超过了有效合作的阈值，任何一个额外合作者带来的收益都会被合作的成本所超过，并且无效合作的成本是真实存在的，即对于所有玩家i，当j大于t时，B(i,j)>(B(i,j+1)+C(i,j+1))，当j小于或等于t时，0>C(i,j)。最后，假设每个玩家i的有效合作收益超过了成本，即对于j>t，B(i,j)+C(i,j)>0。这样我们就得到了一个公地悲剧的游戏，它呈现了一个熟悉的困境：在任何情况下（除了恰好有t个其他人合作的情况），背叛都对个体有利，但在任何有效合作的状态下，每个人都比没有合作的状态更好。 这个解释可以很容易地修改，使得最低有效合作的门槛因个体而异（例如，i对清洁水的要求可能比j更严格），或者使得B在任何地方都有定义（从而消除门槛，使我们始终从他人的合作中受益）。得到的游戏仍然具有囚徒困境的特点。

菲利普·佩蒂特指出，可以表示为多人囚徒困境的例子有两种类型。上面讨论的例子可以归类为搭便车问题。我有诱惑力享受其他人承担的负担所带来的好处。另一种类型是佩蒂特所称的“恶意交易者”问题。我有诱惑力通过伤害他人来使自己受益。例如，假设一群人正在申请一份工作，他们的资格相同。如果所有人都诚实填写申请表，他们都有同等的被录用机会。然而，如果有人撒谎，他可以确保自己被录用，同时承担被揭穿的小风险。如果每个人都撒谎，他们再次有同等的就业机会，但现在他们都面临被揭穿的风险。因此，一个孤独的撒谎者通过将其他人的就业机会从微乎其微变为零，将自己的机会从微乎其微变为确定。正如佩蒂特指出的，当最低有效合作水平与人口规模相同时，就没有搭便车的机会（需要每个人的合作），因此囚徒困境必须是恶意交易的类型。但是（尽管佩蒂特的相反说法），并非所有恶意交易的囚徒困境似乎都具有这个特征。例如，假设上述故事中将有两个申请人被录用。那么除非有两个或更多的参与者撒谎，否则每个人都会获得好处（有就业机会而不会面临被揭穿的风险）。然而，撒谎者似乎是恶意交易者而不是搭便车者。对恶意交易困境的更好描述可能是，每个从一般合作状态中的背叛严格降低了合作者的回报，即对于每个玩家i和大于阈值的每个j，B(i,j+1)+C(i,j+1)>B(i,j)+C(i,j)。搭便车者的背叛使自己受益，但本身不会伤害合作者。恶意交易者的背叛使自己受益并伤害合作者。

在 Schelling 的《囚徒困境》中，Molander 1992 以及其他地方标记为多人囚徒困境的游戏要求每个合作者和背叛者的回报都严格随着合作者的数量增加而增加，并且所有参与方的回报总和随着合作者的数量增加而增加（因此，一个参与方从背叛转向合作总是会提高总和）。上述公式不满足这两个条件，人们可能会质疑它们是否适用于给定的例子。胜利的幅度似乎不会提高赢得选举的价值。自然过滤系统可能允许水体吸收一定量的废物而没有任何有害影响。然而，通常可以合理地认为它们在“局部”成立，即对于接近最低有效合作阈值 t 的 j，可以合理地假设：

* 对于每个个体 i，当 j>t 时，B(i,j+1)+C(i,j+1)>B(i,j)+C(i,j)，
* 对于每个个体 i，当 j≤t 时，C(i,j+1)>C(i,j)，并且
  B(1,j+1)+C(1,j+1)+…+B(j+1,j+1)+C(t+1,j+1)+B(j+2,j+1))+…+B(n,j+1) > B(1,j)+C(1,j)+…+B(j,j)+C(j,j)+B(j+1,j)+…+B(n,j).

通过要求其他人的合作始终严格使每个玩家受益，Schelling 和 Molander 对 n 人囚徒困境的表述未能模拟出似乎渗透在许多公地悲剧示例中的过剩合作/搭便车现象。然而，他们的条件可能是某些公共物品困境的合理模型。可以合理地假设，任何对公共卫生、国防、公路安全或清洁空气的贡献对所有人都有价值，无论我们已经拥有多少，但每个人为自己对这些物品的贡献所付出的成本总是超过他从这些贡献中获得的利益。满足上述条件的一个特别简单的游戏是公共物品游戏。每个玩家可以选择不贡献或向共同存储器贡献固定效用 C。对存储器的贡献相加，乘以大于一的某个因子，然后平均分配给小组成员。通过这种方式，一个玩家无论自己是否贡献，都会从其他人的贡献中获得同样的利益，而无论其他人是否贡献，她自己的贡献都会损失同样（较小）的金额。这对于一般的囚徒困境来说并不成立，尽管对于介绍中提到的交换游戏是成立的。

Schelling 和 Per Molander 的表述以及公共物品博弈具有将注意力集中在囚徒困境游戏的质量上的优势。背叛主导合作，而普遍合作被一致地优先于普遍背叛。迈克尔·泰勒在这个方向上更进一步。他对多人囚徒困境的版本只需要刚刚提到的两个囚徒困境条件和一个额外的条件，即当一些人合作时，叛徒总是比没有人合作时更好。 （泰勒的主要关注点是这个游戏的迭代版本，这里不会讨论这个话题。）

这些想法可以通过一些图片更加明确，这些图片提供了额外的细化和扩展。下面的图 2 说明了投票游戏。在图 2(a)中，有 25 名支持者正在选择是否在多数规则选举中投票。对于玩家 i，效用值绘制在除 i 之外的其他人投票的数量上。黑色圆盘代表合作者（投票者），圆圈代表背叛者（不投票者）。当其他投票者少于 12 人或多于 12 人时，背叛击败合作。但当正好有 12 个其他人投票时，对 i 来说投票是有益的。

| ![Figure 2a](https://plato.stanford.edu/entries/prisoner-dilemma/fig2a--voters-discrete.png) | ![Figure 2b](https://plato.stanford.edu/entries/prisoner-dilemma/fig2b--voters-continuous.png) |
| --------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| (a)                                                                                         | (b)                                                                                           |

 图 2

在图2(b)中，通过线条和圆圈绘制了平滑曲线，以说明投票游戏的更一般形式。合作者和背叛者的效用由两个S形曲线表示。曲线在两个地方相交。现在，我们不再只有一个最低效合作点，而是在两条曲线之间有一个小区域，在这个区域内合作胜过背叛。就污染湖泊的例子而言，我们可以假设在第一个交点的左侧，污染非常严重，我的额外贡献不会使情况变得更糟，而在第二个交点的右侧，湖泊非常健康，可以毫无不良影响地处理我的废物。交点都是平衡点，污染和讲究卫生的居民改变行为都会受到损失。就投票的例子而言，我们可以假设非支持者的行为是不确定的，曲线之间的区域表示我的投票增加了获胜的几率，超过了我投票的成本。

更一般的投票游戏满足 Schelling/Molander 条件，即每个玩家的效用仅在合作有效的地区附近严格随着合作水平增加。在下面的图 3 中，S 曲线弯曲，以便在任何地方都满足这个条件。在 3(a)中，两条曲线仍然相交两次。Bovens 对 n 人游戏进行了非常有启发性的分类，将这种形式称为投票游戏，并认为它最能代表文献中描述的共有悲剧情境。请注意，如果有一个值 x，使得两条曲线都位于均衡点之上，那么这里的均衡点就不可能是帕累托最优的（就像上面所称的投票游戏的最简版本中的孤立均衡点一样）。因此，这是一场悲剧。在图 3(b)中，两条曲线之间没有交点。因此，PD 的第二个 Schelling/Molander 条件也得到满足：背叛主导合作。最后一个条件，即合作总是提高效用总和，不容易描绘出来，但是由于两条曲线的斜率是正的，我们可以确定，如果人口足够大，这个条件将得到满足。

| ![Figure 3a](https://plato.stanford.edu/entries/prisoner-dilemma/fig3a--voters-upsloping.png) | ![Figure 3b](https://plato.stanford.edu/entries/prisoner-dilemma/fig3b--PD.png) |
| ---------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------- |
| (a)                                                                                          | (b)                                                                            |

 图 3

在这两个游戏中，利益相对较为平稳，比之前的两个游戏要好一些。通过进一步拉平曲线，可以进一步减少不稳定性。在极限情况下，我们得到了图 4 中第一个图表所示的公共物品游戏。在这里，曲线是直线。每个额外的合作者都为背叛者和合作者提供了相同的额外收益，收益为 mc/n，其中 c 是捐赠的成本，m 是规定的乘数，n 是游戏中的玩家数量。如果曲线足够平坦，它们最多可以相交一次。总共有三种可能性：图 4(a)中所示的游戏，其中两条曲线不相交；图 4(b)中所示的游戏，合作者的效用在相交点左侧高于背叛者，在相交点右侧低于背叛者；以及图 4(c)中所示的游戏，背叛者的效用开始高于合作者，最终低于合作者。在图 4(b)中，当其他人中只有少数人合作时，通过合作可以获益，当大多数人合作时，通过背叛可以获益。Bovens 合理地认为，这应该被视为鸡游戏的多人版本：如果对手转弯，就直行；如果对手直行，就转弯。在图 4(c)中，当大多数人背叛时，通过背叛可以获益，当大多数人合作时，通过合作可以获益。正如 Bovens 所建议的，这可能被视为鹿猎的多人版本：如果对手也这样做，一起狩猎或分开狩猎。（鹿猎在下面的第 8 节中进一步讨论）。正如我们所见，第一种可能性符合与囚徒困境有关的合理条件。

| ![Figure 4a](https://plato.stanford.edu/entries/prisoner-dilemma/fig4a--public-goods.png) | ![Figure 4b](https://plato.stanford.edu/entries/prisoner-dilemma/fig4b--chicken.png) |
| ------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------- |
| (a)                                                                                      | (b)                                                                                 |
| ![Figure 4c](https://plato.stanford.edu/entries/prisoner-dilemma/fig4c--stag-hunt.png)    |                                                                                     |
| (c)                                                                                      |                                                                                     |

 图 4

## 6. 单人解释

囚徒困境通常被认为是个体与集体理性之间的冲突，但多人形式（或类似的形式）也被解释为展示了个体理性的标准概念中存在的问题。其中一种解释，由Quinn阐述，源自Parfit的一个例子。一种医疗设备可以使电流以微小的增量施加在患者的身体上，相邻设置之间没有可察觉的差异。您被连接到该设备上，并在接下来的十年里每天面临以下选择：将设备推进一个设置并获得一千美元，或者将其保持在原位并一无所获。由于相邻设置之间没有可察觉的差异，每天推进设置似乎是理性的选择。但在十年结束时，痛苦变得如此巨大，以至于一个理性的人会牺牲所有财富回到第一个设置。

我们可以将这种情况视为一个多人囚徒困境，其中每个“玩家”是一个人的时间阶段。从这个角度来看，它至少有两个特点，在多人示例中没有讨论到。首先，玩家的行动是顺序的，而不是同时的（每个玩家都知道之前的行动）。其次，存在着渐变的问题。相邻设置之间的电流增加是无法察觉的，因此对于理性决策来说是无关紧要的，但是这些增加的总和是可以察觉的，并且非常重要。然而，这两个特点都不是单人示例所特有的。例如，考虑一下在污染和非污染的废物处理方式之间的选择。湖边社区的每个居民都可以将垃圾倒入湖中，或者使用一个不太方便的垃圾填埋场。可以合理地假设每个人的行为都是在知道其他人之前的行为的基础上进行的。（见下文的“异步行动”）同样，可以合理地假设将一罐垃圾倒入湖中对水质没有可察觉的影响，因此对居民的福利也没有影响。困境仍然存在的事实表明，类似囚徒困境的情况有时涉及的不仅仅是个体与集体理性之间的冲突。在单人示例中，我们理解到我们更关心整体福祉而不是我们的时间阶段的福祉，并不能（仅凭此）消除继续调整设置是理性的论点。同样，在污染的例子中，让集体理性凌驾于个体理性之上的决策可能并不能消除过度倾倒的论点。然而，将这个问题与标准囚徒困境中提出的问题分开似乎是合适的。无法单独察觉但在大量情况下具有重要影响的渐变会导致不传递的偏好。 这是对理性标准解释的一个挑战，无论它是否出现在类似囚徒困境的情境中。

Kavka 在 1991 年提出了对囚徒困境的第二种个人解释。根据 Kavka 的解释，囚徒不是时间阶段，而是反映我在决策中可能考虑的不同期望的“子代理人”。让我们想象一下，我饿了，正在考虑买点心。我可以选择的选项有：

1. 买一勺巧克力冰淇淋。
2. 买一勺橙子雪泥。
3. 买一个燕麦棒。
4. 什么都不买。

我注重健康的一面，"阿诺德"按照以下顺序选择这些选项：c，b，d，a。我注重口味的一面，"埃皮"对它们进行排名：a，b，d，c。这种偏好之间的内部冲突通常可以通过与个体选择的标准观点一致的方式来解决。例如，我的整体偏好排序可能是由阿诺德和埃皮为每个选项分配的效用的加权平均值确定的。卡夫卡还指出，我的内部冲突可能被解决为理性子代之间战略互动的结果。在这种情况下，阿诺德和埃皮可以选择坚持自己的意见（I）或妥协（A）。子代之间的互动可以用以下收益矩阵表示，其中阿诺德在行上进行选择，埃皮在列上进行选择。

|   | A | I |
| --- | --- | --- |
| A | b | a |
| I | c | d |

对表格和偏好排序的检查确认了我们再次面临的是内部囚徒困境。卡夫卡认为，这样的故事可能会"提供一个心理上可信的描述内部冲突如何导致次优行动的图景"。它还削弱了一种标准观点，即选择反映了偏好，而更倾向于选择部分反映了"内部冲突的结构"。

## 7. 具有复制品和因果决策理论的囚徒困境

一个有争议的论点认为，在囚徒困境中合作是理性的，原因在于我犯罪的伙伴很可能会像我一样思考和行动。（例如，参见Davis 1977和1985年对这种论点的同情性陈述，以及Binmore 1994年第3.4章和第3.5章对其进行改进和扩展的反驳。）在极端情况下，我的帮凶是一个与我完全相同的复制品，他的思维方式和我一样，因此我们必然会做出相同的选择。那么，唯一可能的两种结果就是两个玩家都合作或者两个玩家都背叛。由于奖励回报超过惩罚回报，我应该选择合作。更一般地说，即使我的帮凶不是完美的复制品，如果我选择合作，他合作的可能性更大，如果我选择背叛，他背叛的可能性更大。当我们的行为之间的相关性足够强或者回报之间的差异足够大时，如果我选择合作，我的预期回报（通常理解的那种回报）比我选择背叛要高。当然，反对论点是，我的行动与我的复制品的因果关系是独立的。由于我无法影响我的帮凶的行动，并且无论他做什么，如果我选择背叛，我的回报都会更高，所以我应该选择背叛。这些论点与新康姆问题上的两个立场的论证非常相似，新康姆问题是一道在诺齐克哲学家中广为流传的难题。（这种相似性在刘易斯的著作中得到了明确的展示。）新康姆问题要求我们考虑两个盒子，一个是透明的，一个是不透明的。透明盒子里有一千美元。不透明盒子里可能有一百万美元，也可能什么都没有。我们有两个选择：拿走不透明盒子的内容，或者拿走两个盒子的内容。在选择之前，我们知道一个可靠的预测者根据我们的行为预测，在第一种选择上放了一百万美元，在第二种选择上则空着。 为了看到囚徒困境中的每个玩家都面临着一个纽科姆问题，考虑以下收益矩阵。

|   | C     | D     |
| --- | ------- | ------- |
| C | m,m   | 0,m+t |
| D | m+t,0 | t,t   |

通过“合作”（选择不透明盒子），每个玩家确保对方得到一百万美元（以及叛变时额外的一千美元）。通过“叛变”（选择两个盒子），每个玩家确保自己得到一千美元（如果对方合作，还能得到一百万美元）。只要 m>t>0，这个游戏的结构就是一个普通的两个玩家、两个回合的囚徒困境（任何这样的囚徒困境都可以用这种形式表示）。此外，在纽科姆问题中，“单盒选择”和“双盒选择”的论证与囚徒困境中合作和叛变的论证是相同的，其中玩家的动作之间存在正相关性。双盒选择是一种占优策略：无论第一个盒子是满的还是空的，两个盒子都比一个盒子好。另一方面，如果预测者是可靠的，那么单盒选择的预期收益大于双盒选择的预期收益。（然而，有关这两个谜题显著不同的论证，请参见赫利（1991）和贝尔穆德斯（2015）。）

在 Newcomb 问题中，两个盒子都选择的理性选择是两个盒子都选择，或者在囚徒困境中，两个玩家的行动之间存在正相关时，背叛是理性选择，这似乎与理性要求最大化期望的观念相冲突。这种表面上的冲突导致一些人认为，在代理人的行动为其所处的环境提供证据而不引起环境的情况下，标准决策理论需要在某些情况下进行改进。在囚徒困境的情况下，标准（证据性）决策理论要求玩家一比较合作和背叛的预期效用，可以写成 p(C2∣C1)×R+p(D2∣C1)×S 和 p(C2∣D1)×T+p(D2∣D1)×P（例如，p(C2∣C1)是玩家一合作的条件概率）。如果玩家的行动强相关，则 p(C2∣C1)和 p(D2∣D1)将接近于 1，p(C2∣D1)和 p(D2∣C1)将接近于零。根据建议的修订，这些条件概率应该被某种因果条件概率所取代，这种因果条件概率可以（根据某些解释）用诸如“如果玩家一选择合作，玩家二也会选择合作”的短语来表示。当行动是因果独立的时候，这只是玩家二选择合作的概率。

Newcomb 问题中描述的相当牵强的情景最初使一些人对因果决策理论和证据决策理论之间的区别的重要性产生了怀疑。刘易斯认为，与囚徒困境的联系表明，两个决策分歧的情况并不那么罕见，而且关于因果决策理论的最近著作中包含了许多比 Newcomb 问题更不可思议的例子（例如，参见乔伊斯）。

近年来，从博弈论文献的认识基础和各种条件逻辑中，技术机械被用来代表囚徒困境游戏中合作和背叛的论证（以及 Newcomb 问题中的单箱和双箱）。参见 Bonanno 的一个例子和对其他几个例子的讨论。这些表述清楚地揭示了关于理性本质的一些微妙假设，这些假设构成了这些论证的基础。然而，尽管讨论越来越复杂，仍然有人坚持各自的观点。

值得注意的是，这里所称的“复制品之间的囚徒困境”通常在文献中被称为“与孪生兄弟的囚徒困境”。目前的命名方式之一是为了将这些想法与实验文献区分开来，后者报告了与真实（相同或异卵）孪生兄弟进行的囚徒困境游戏。（例如，参见 Segal 和 Hershberger。）事实证明，孪生兄弟在囚徒困境中更有可能合作，但似乎没有暗示他们这样做的推理遵循上述有争议的论证。

## 8. 鹿猎和囚徒困境

引言中提到的囚徒困境模型合作问题的理性代理人之间的问题有时会受到批评，因为在真正的囚徒困境中，合作的结果不是纳什均衡。批评者认为，任何这种性质的“问题”都是一个无法解决的问题。（例如，参见 Sugden 或 Binmore 2005 年第 4.5 章。）通过稍微改变囚徒困境的收益结构，使得奖励收益超过诱惑收益，我们得到一个游戏，其中相互合作和相互背叛都是纳什均衡。这个游戏被称为鹿猎。它可能为合作困难但仍然可能的情况提供更好的模型，也可能更适合囚徒困境有时被赋予的其他角色。更具体地说，鹿猎是一个两个玩家、两个动作的游戏，其收益矩阵与第 1 节中给出的囚徒困境的条件 PD1 替换为：

* (SH)a.R>T
* b.R>P
* c.P>S

这个寓言戏剧化了这个游戏并提供了它的名字，取自卢梭在《不平等论》中的一段话，讲述的是一次狩猎远足，而不是监狱审讯。两个猎人正在寻找一只鹿。成功是不确定的，如果成功，需要两人的努力。另一方面，任何一个猎人都可以抛弃他的伙伴，捕捉一只有很大成功机会的野兔。下面是一个典型的收益矩阵。

|   | C   | D   |
| --- | ----- | ----- |
| C | 4,4 | 0,3 |
| D | 3,0 | 3,3 |

这里的“合作”行动是与伙伴一起狩猎鹿，“背叛”是独自狩猎兔子。在鹿猎中，“诱惑”回报已经不再是一个很大的诱惑，但为了便于阐述，我们保留了回报术语。在这种情况下，诱惑和惩罚的惩罚是相同的，可能反映了我的伙伴选择猎物对我个人在独自狩猎兔子时的成功没有影响。或者，诱惑超过惩罚，可能是因为一起狩猎兔子比独自狩猎更有回报（当然，仍然比一起狩猎鹿少回报），或者惩罚超过诱惑，可能是因为第二个狩猎兔子的人代表了无益的竞争。无论哪种方式，鹿猎的本质保持不变。有两个均衡点，其中一个被一致地优先选择。当理性决定两个玩家选择导致较差均衡的行动时，鹿猎变成了一个“困境”。很明显，如果我确信我的伙伴会狩猎鹿，我应该加入他，如果我确信他会狩猎兔子，我也应该狩猎兔子。因此，具有这种结构的游戏有时被称为“保证”或“信任”游戏。（但这些不应与下一节讨论的“信任游戏”版本的异步囚徒困境混淆。）如果我不知道我的伙伴会做什么，标准决策理论告诉我要最大化期望。然而，这要求我估计我的伙伴玩 C 或 D 的概率。如果我没有信息来形成任何这样的估计，那么一个假定的理性原则（“冷漠”）表明我应该将所有选项视为等可能。根据这个标准，我应该只有满足以下条件时才狩猎兔子：

* （SHD）T+P>R+S

当 SHD 获得时，称野兔狩猎为“风险主导”均衡。让我们称满足这个条件的鹿猎游戏为鹿猎困境。上面的矩阵提供了一个例子。

理性的另一个提出的原则（“最小最大化”）建议我应该考虑在任何行动中我可能获得的最差回报，并选择使这个值最大化的行动。由于傻瓜回报是鹿猎中最差的回报，这个原则表明任何鹿猎都存在困境。然而，最小最大化更适用于零和游戏的理性原则，因为可以假设一个理性的对手试图最小化我的得分，而不适用于鹿猎这样的游戏，其中一个理性的对手可能很高兴看到我做得好，只要他自己也做得好。

鹿猎可以以明显的方式推广，以适应不对称和基数回报。游戏的图形表示形成的四边形是凸的，因此纯/杂的区别不再适用。（换句话说，在鹿猎中，从来没有混合策略优于相互合作。）将游戏推广到多个玩家的最明显的方式是保留存在恰好两个均衡的条件，其中一个均衡被一致地优先于另一个。这可能是一个很好的模型，用于需要全面合作才能成功的合作活动。例如，想象一下，一个单一的污染者会破坏一个湖，或者一个单一的泄漏会破坏一项调查。如果涉及许多代理人，并且通过对冷漠或其他原因的诉求，我们估计每个代理人合作的机会是五五开，那么这些例子将以极端形式表示鹿猎困境。如果所有人都合作，每个人都会受益，但只有一个非常信任的傻瓜才会认为合作是理性的。也许对于多人情况的更广泛推广将代表其他熟悉的社会现象的结构，但这个问题在这里不会追究。

囚徒困境中的合作结果可以通过与前面讨论的相同方式来确保。可以预料到，在两人狩猎中，合作比在两人囚徒困境中更容易实现。这里不会给出详细信息，但感兴趣的读者可以参考 Skyrms 2004，该书对这个游戏的兴趣再次高涨。

## 9. 异步移动和信任游戏

人们经常争论说，理性的自利玩家可以通过将他们的移动条件化为对方玩家的移动来获得合作结果。例如，彼得·丹尼尔森支持互惠合作的策略：如果对方玩家在你合作时也合作，而在你不合作时背叛，那么你就合作，否则就背叛。像这样的条件策略在上述游戏的版本中被排除在外，但在更准确地模拟现实世界情况的版本中可能是可能的。在本节和下一节中，我们考虑两个这样的版本。在本节中，我们消除了两个玩家同时移动的要求。考虑一个公司的情况，其唯一的竞争对手刚刚降低了价格。或者假设一辆汽车的买方刚刚支付了约定的购买价格，而卖方尚未交付车辆所有权证书。我们可以将这些情况看作是一个玩家在另一个玩家已经做出类似选择之后选择合作或背叛的情况。相应的游戏是异步或扩展的囚徒困境。

细致讨论一个异步囚徒困境的例子，正如 Skyrms（1998）和 Vanderschraaf 最近指出的那样，在 David Hume 的著作中就已经发生了，远在 Flood 和 Dresher 对普通囚徒困境的阐述之前。Hume 写到了两个相邻的谷物农民：

> 你的玉米今天成熟了；我的明天就会成熟。我们双方都能从中获利，我今天应该和你一起劳动，你明天应该帮助我。我对你没有好感，我知道你对我也没有好感。因此，我不会为了你而费心，如果我为了自己的利益而和你一起劳动，期望得到回报，我知道我会失望的，我徒劳地依赖你的感激之情。所以我就让你一个人劳动吧：你也以同样的方式对待我。季节变化了；我们两个都因为缺乏相互的信任和安全而失去了收成。

为了尊重 Hume，Skyrms 和 Vanderschraaf 将这种异步囚徒困境称为“农民困境”。将其描绘成一棵树状图是很有启发性的。

![Figure 5](https://plato.stanford.edu/entries/prisoner-dilemma/fig5--farmers.png)

 图 5

在这里，时间向右流动。方形标记的节点表示玩家一的选择点，圆圈标记的节点表示玩家二的选择点。每个玩家的移动和收益与普通囚徒困境中完全相同，但在这里，玩家二可以根据玩家一的行动选择自己的移动。像图 5 这样的树状图被称为广义形式的游戏表示，而之前给出的收益矩阵是正常形式的表示。正如休谟的分析所示，使游戏异步并不能消除困境。玩家一知道，如果他在第一次移动时选择 C，玩家二会在第二次移动时选择 D（因为她更喜欢诱惑而不是奖励），所以他自己最终会得到吃亏的收益。如果玩家一选择 D，玩家二仍然会选择 D（因为她更喜欢惩罚而不是吃亏的收益），他最终会得到惩罚的收益。由于他更喜欢惩罚的收益而不是吃亏的收益，玩家一会在第一次移动时选择 D，两个玩家最终都会得到惩罚的收益。这种“向后”推理，在其中玩家首先评估如果各种游戏历史实现了最后一次移动会发生什么，并根据此确定之前的移动会发生什么，在广义形式的游戏中广泛适用，并且在下面的有限迭代中将讨论更一般的版本。

农民困境可以通过将玩家一理解为在 C 和 D 之间进行选择，将玩家二理解为（同时）在四个条件移动中进行选择来以正常形式表示。这四个条件移动是：无条件合作（Cu），无条件背叛（Du），模仿玩家一的移动（I）和与玩家一的移动相反（O）。结果是一个具有以下矩阵的双人游戏。

|   | Cu  | Du  | I   | O   |
| --- | ----- | ----- | ----- | ----- |
| C | R,R | S,T | R,R | S,T |
| D | T,S | P,P | P,P | T,S |

读者可能会注意到，这个游戏是一个（多步）均衡困境。当玩家一选择 D，玩家二选择 Du 时，唯一的（弱）纳什均衡就会产生，从而使他们自己获得 P 和 P 的较差回报。然而，这个游戏并不是一个支配 PD。实际上，对于任何一方玩家来说，都没有一个支配性的举动。普遍认为，即使没有任何一方玩家有一个支配性的举动，理性自利的玩家也会达到纳什均衡。如果是这样，农民的困境仍然是一个困境。

为了保持普通 PD 所特征的玩家之间的对称性，我们可能希望修改异步游戏。让我们将扩展 PD 作为分阶段进行。首先，每个玩家选择第一步（C 或 D）和第二步（Cu，Du，I 或 O）。接下来，裁判决定谁先行动，给予每个玩家平等的机会。最后，以适当的方式计算结果。例如，假设 Row 玩（D，O）（意味着如果他先行动，他将背叛，如果他后行动，他将做与对手相反的动作），而 Column 玩（C，Du）。然后，如果 Row 先行动，他将得到 P，如果他后行动，他将得到 T，这意味着他的预期回报是 12（P + T）。如果 Column 先行动，她将得到 S，如果她后行动，她将得到 P，这给她带来了预期回报 12（P + S）。计算整个 8x8 回报矩阵是直接的，但是繁琐的。在这样做之后，读者可能会观察到，就像农民的困境一样，扩展 PD 的对称形式是一个均衡 PD，但不是一个支配 PD。唯一的纳什均衡发生在两个玩家都采用策略（D，Du）时，从而实现了（P，P）的较差回报。

一些特别简单而富有启发性的变体已经在“投资者游戏”或“信任游戏”标签下进行了研究（例如，参见 Kreps（1990），Berg（1995）和 Bicchieri 和 Suntuoso（2015），请注意，游戏命名在这些参考文献中并不一致）。玩家一被赋予 s 单位的效用。他可以选择将任何小于 s 的数量 s'传递给“受托人”，受托人将该数字乘以三倍并将其传递给玩家二。玩家二可以选择保留她拥有的单位或将其中一些归还给玩家一。这样制定游戏的优势在于，可以将玩家放弃的效用比例视为她的合作程度。如果限制移动，使得玩家一可以给出零或 s，玩家二可以给出零或 2s，则得到的正好是农民困境）。

在农民困境和信任游戏中，与囚徒困境不同，两个玩家的同名移动似乎具有不同的特点。我们更有可能将玩家一的合作视为慷慨或者也许是经过计算的（即使我们认为所涉及的计算是非理性的），而将玩家二的合作视为公平。只有在玩家一的合作移动方面，信任这个标签才是合适的，尽管玩家二的合作可能被认为表明她值得信任。

值得注意的是，与囚徒困境不同，鹿猎异步版本几乎没有什么有趣的问题。如果第一个玩家在第一天参与鹿猎，第二个玩家应该在第二天参与。如果他在第一天猎兔，她应该在第二天也这样做。第一个玩家意识到这一点，应该在第一天猎鹿。因此，理性的玩家应该没有困难地达到异步鹿猎的合作结果。

## 10. 透明度

引入条件性行动到囚徒困境中的另一种方式是假设玩家具有 David Gauthier 所称的透明度属性。一个完全透明的玩家是其意图对其他人完全可见的玩家。虽然没有人认为我们人类是完全透明的，但我们通常能够成功预测其他人的行为，这表明我们至少是“半透明”的。此外，像公司或国家这样的更大规模的代理人，在行动之前可能需要公开讨论，可能比我们更透明。因此，对于具有透明玩家的囚徒困境的研究可能具有一定的理论兴趣。这样的玩家可能能够执行比（非透明的）扩展游戏玩家更复杂的条件策略，例如基于其他人所采用的条件策略的条件策略。然而，确定这样的玩家可以采用哪些策略存在一些困难。假设 Row 采用策略“与 Column 相同”，而 Column 采用策略“与 Row 相反”。这两种策略都无法同时满足。另一方面，如果每个人都采用策略“模仿对方玩家”，那么有两种方式可以满足这些策略，而无法确定他们将采用其中的哪一种。Nigel Howard 可能是最早系统研究这种条件策略的人，他通过坚持一种严格类型化的游戏层次结构来避免这个困难。在基本层次上，我们有普通的囚徒困境游戏，每个玩家在合作和背叛之间进行选择。对于层次结构中的任何游戏 G，我们可以生成两个新游戏 RG 和 CG。在 RG 中，Column 的移动与游戏 G 中的移动相同，而 Row 可以选择任何将 C 或 D 分配给 Column 的每个可能移动的函数。类似地，在 CG 中，Row 的移动与 G 中的移动相同，而 Column 有一组新的条件移动。 例如，如果[PD]是基本级别的游戏，那么 C[PD]是一个游戏，其中 Column 可以从上述策略 Cu、Du、I 和 O 中选择。霍华德观察到，在两个第三级游戏 RC[PD]和 CR[PD]（以及每个更高级别的游戏）中，存在一个平衡结果，使每个玩家都选择 R。特别是，当一个玩家选择 I，而另一个玩家在对手选择 I 时合作，在对手选择 Cu、Du 或 O 时背叛时，就会达到这样的平衡。请注意，这种最后的策略等同于丹尼尔森在上一节中描述的互惠合作。

对于理性行动来说，这一切的教训并不明确。假设两个囚徒在囚徒困境中足够透明，可以采用更高级别游戏的条件策略。他们如何决定玩哪个级别的游戏？谁选择模仿行动，谁选择互惠合作？在更高级别的游戏中采取行动，可能意味着形成一个对其他玩家可观察的意图。但是，如果忽视这个意图有利可图，为什么任何一方都应该期望这个意图能够得到执行呢？

条件策略在我们将调查的方向不是朝着玩囚徒困境的方向，而是设计能够与各种可能的对手玩得好的代理人时，具有更有说服力的应用。这是Danielson的观点。（参见J.V. Howard对这一观点的早期启发性讨论。）条件策略不是玩家在游戏中形成的一个动作，而是定义一种玩家的确定性算法。事实上，囚徒困境的一个教训可能是，透明的代理人如果能够形成不可撤销的“行动协议”，而不是始终遵循他们在行动时可能形成的意图，那么他们会更好。Danielson并不事先限制自己在Howard的等级体系内的策略。代理人只是一个计算机程序，可以包含允许其他程序读取和执行它的行。我们可以很容易地编写两个这样的程序，每个程序都设计用来确定对手是选择合作还是背叛，并采取相反的行动。当这两个程序玩囚徒困境时，具体实施的细节决定了结果，但很可能它们会“不连贯”，即它们会进入无限循环，无法进行任何移动。为了成功，一个程序应该能够与各种其他程序配对，并且能够获得有价值的结果，包括自身的副本。以直接方式实现I和O的程序不太可能成功，因为它们在彼此配对时会不连贯。实现Du的程序不太可能成功，因为它们在与它们的克隆配对时只能获得P。实现Cu的程序不太可能成功，因为它们在与能够识别和利用它们无条件合作性质的程序配对时只能获得S。成功的标准存在一些模糊性。在Howard的方案中，我们可以将条件策略与该级别的所有可能替代方案进行比较。 在这里，任何两个程序都可以配对，这种方法是没有意义的。然而，某些程序似乎在与各种不同的玩家配对时表现良好。其中一种是 Gauthier 提倡的受限最大化策略的版本。其思想是，如果其他人在 j 合作时也会合作，那么玩家 j 应该合作；否则就背叛。如所述，这似乎是 RC[PD]或 CR[PD]游戏的一种策略。然而，如果与自己配对，不清楚实施该策略的程序会如何移动（如果确实移动）。然而，Danielson 能够构建一个近似的受限最大化策略，使其能够与自己合作。Danielson 的程序（以及其他实施受限最大化策略的程序）不能与所有东西一起配对。然而，它确实移动并且对抗熟悉的策略得分很高。它与 Cu 和自己合作，并对抗 Du。如果它与其他程序配对是一致的，似乎保证获得的回报不会比 P 差。

第二个成功的程序模拟了 Danielson 的互惠合作。同样，不清楚该策略（如上所述）是否允许它与自己合作（或进行任何移动），但是 Danielson 能够构建一个能够与自己合作的近似策略。与自己、Du 和受限最大化策略相比，（近似的）互惠合作表现得同样好。与 Cu 相比，它表现得更好，得到了 T，而受限最大化策略只得到了 R。

## 11. 有限迭代

许多被指称具有囚徒困境结构的情况，例如军事竞争对手的国防拨款或垄断企业的定价，更适合通过游戏的迭代版本进行建模，其中玩家在每一轮都重复玩囚徒困境，并保留对所有先前轮次结果的访问权限。在这些迭代的囚徒困境（以下简称 IPD）中，一个回合中背叛的玩家可能会在后续回合中受到“惩罚”，而合作的玩家可能会得到合作的回报。因此，对于理性自利的玩家来说，适当的策略不再明显。事实证明，对这个问题的理论答案在很大程度上取决于所采用的 IPD 定义和被归因于理性玩家的知识。

IPD 可以通过树状图的广义形式来表示，就像上面农夫困境的那个。

![Figure 6](https://plato.stanford.edu/entries/prisoner-dilemma/fig6--IPD.png)

 图 6

这里我们有一个长度为两个回合的囚徒困境。游戏的每个回合结束都由一条虚线垂直线标记。两个玩家的回报（通过将他们在两个回合的回报相加获得）列在树的每条路径的末尾。与之前的表示不同之处在于，在同一分支内的两个节点标记了两个玩家的同时选择。由于在同一回合中，两个玩家都不知道对方的动作，囚徒困境不符合博弈论中“完美信息游戏”的标准之一。如果玩家是依次移动而不是同时移动（我们可以通过去掉虚线垂直线来表示），则得到的游戏是一个迭代的农夫困境，它符合博弈论家的定义，并且具有使囚徒困境有趣的许多特征。

像农夫困境一样，理论上可以通过将玩家的动作作为策略来表示囚徒困境的正常形式，告诉他们如何在游戏树的回合结束时移动。随着游戏长度的增加，策略的数量迅速增加，以至于在实践中不可能写出除最短的囚徒困境之外的所有正常形式。每对策略确定了游戏的“玩法”，即通过广义形式树的路径。

在这样的游戏中，纳什均衡的概念失去了一些特权地位。回想一下，如果每个动作都是对方的最佳回应，那么一对动作就是纳什均衡。让我们扩展一下在异步囚徒困境讨论中使用的符号，并让Du成为在IPD的每个节点都呼叫背叛的策略。很容易看出，Du和Du形成了一个纳什均衡。但是对于Du来说，一个策略只有在对方在第15个节点（或其他任何节点）合作时才呼叫背叛，将确定与Du本身相同的游戏（因此相同的收益）。呼叫合作的组件从未发挥作用，因为对方在第15个（或其他任何）动作上都不合作。同样，一个策略只有在自己第二次合作之后才呼叫合作也同样有效。因此，这些策略和许多其他策略都与Du形成纳什均衡。从某种意义上说，这些策略显然不是同样合理的。尽管它们在代表实际游戏的路径上产生相同的收益，但如果达到其他节点，它们将不会产生相同的收益。如果玩家一过去合作过，那仍然不能为他现在合作提供充分理由。纳什均衡只要求两个策略在游戏实际发展中是对方的最佳回应。对于广义形式游戏，更强的解决方案概念要求两个策略无论游戏树上的哪个节点被达到，它们仍然是对方的最佳回应。这种子博弈完美均衡的概念在Selten 1975年被定义和辩护。可以通过说策略对是原始游戏的每个子博弈的纳什均衡来表达，其中子博弈是将原始游戏树的一个节点作为根节点，剪除不从它下降的一切。

鉴于这个新的、更强的解决方案概念，我们可以询问关于 IPD 的解决方案。在固定、有限长度的 IPD 和无限或无限长度的 IPD 之间，在这个问题上存在着显著的理论差异。在第一类游戏中，可以通过一种称为反向归纳的论证证明 Du，Du 是唯一的子博弈完美均衡。假设玩家们知道游戏将持续 n 轮。然后，无论达到了哪个节点，在第 n-1 轮，玩家们面对一个普通的（“一次性”）PD，他们会背叛。在第 n-2 轮，玩家们知道，无论他们现在做什么，他们下一轮都会背叛。因此，他们现在也有理由背叛。通过重复这个论证足够多次，理性的玩家推断出他们应该在树上的每个节点都背叛。实际上，由于在每个节点上，背叛都是对任何行动的最佳反应，因此不可能存在其他的子博弈完美均衡。

实际上，在长期固定长度的 IPD 中，人们的行为方式与不确定长度的 IPD 并没有太大的区别（除了最后几轮）。这表明，在反向归纳论证（以及博弈论中的其他地方）中使用的一些理性和共识假设是不现实的。有相当多的文献试图仔细阐述这个论证，检验其假设，并看看放松不现实假设如何改变 PD 和其他固定长度游戏中的理性可接受策略（有关一个小样本，请参见 Bovens、Kreps 和 Wilson、Pettit 和 Sugden、Sobel 1993 和 Binmore 1997）。

玩家一相信玩家二可能会选择“非理性”的策略而不是持续背叛，这可能使她自己频繁合作成为合理的选择。实际上，即使玩家一确信玩家二是理性的，她相信玩家二可能认为她怀有这种疑虑也可能产生同样的效果。因此，在固定长度的囚徒困境中，持续背叛的论证取决于对理性的某种知识的复杂迭代主张。拉比诺维奇和其他人指出，更不现实的假设是每个玩家在前几次行动中出现非理性行为后，仍然相信对方在下一次行动中会理性选择。例如，假设在经过一系列长时间的行动（C，C），…，（C，C）后到达的节点上，玩家一将选择 D，尽管以前从未这样做过。

有些人利用这些观察结果来论证反向归纳论证表明标准的理性假设（以及其他合理的假设）是不一致或自我矛盾的。例如，在固定长度的囚徒困境中，玩家一可以推断出，如果她采取适当的“非理性”策略，玩家二将会理性地做出反应，以便他们在几乎所有回合中实现相互合作。因此，我们的假设似乎既暗示玩家一应该持续背叛，又暗示如果她不这样做，她会做得更好。（参见 Skyrms 1990 年，第 125-139 页和 Bicchieri 1989 年。）

## 12. 蜈蚣和有限囚徒困境

固定长度 IPD 引发的许多问题，甚至可以通过一个更简单的游戏以更加鲜明的形式提出。考虑一个 PD，其中惩罚回报为零。现在迭代这个游戏的异步版本固定次数。想象一下，根据高度“惩罚性”的策略，两个玩家都被限制在对曾经背叛过的玩家始终采取背叛的策略下进行游戏。（这种策略的一个重要变体在下面的 GRIM 标签下讨论。）结果是一个蜈蚣游戏。Sobel 2005 给出了一个特别好的实现。一叠 n 张一美元的钞票放在桌子上。玩家轮流从堆中拿钱，每次拿一张或两张钞票。游戏在堆中的钱用完或其中一名玩家拿走两张钞票时结束（以先到者为准）。两名玩家保留他们到目前为止拿到的钱。下图显示了 n=4 时的游戏的广义形式。

![Figure 7](https://plato.stanford.edu/entries/prisoner-dilemma/fig7--centipede.png)

 图 7

可能真正的蜈蚣游戏应该包含 100 个“腿”，这里讨论的一般形式应该真正被称为“n-tipede”。该游戏似乎首次在 Rosenthal 中讨论。

正如在固定长度的囚徒困境中一样，通过反向归纳论证很容易得出一个合理的玩家应该在第一次行动时拿走两张钞票，这样她的回报就是两到三美元，具体取决于她是先行动还是后行动，并且剩下的 n 美元没有分配。更加技术性地说，游戏的纳什均衡只有那些第一位玩家在第一次行动时拿走两美元的情况，而唯一的子博弈完美均衡是在任何轮次他们应该得到两美元的情况下，两位玩家都拿走两美元。再次，常识和实验证据表明真实的玩家很少以这种方式行动，这引发了关于这种论证需要什么样的假设以及它们是否现实的问题。（除了在有限迭代囚徒困境一节中提到的示例外，还可以参考 Aumann 1998，Selten 1978 和 Rabinowicz 等文献。）这个蜈蚣游戏也引发了关于合作和社会上可取的利他主义的一些问题，就像囚徒困境一样，它是实证研究游戏玩法的一个常用工具。

## 13. 无限迭代

避免深入研究知识和理性条件的可疑结论的一种方法是考虑无限重复的囚徒困境。当然，没有人类参与者能够实际上进行无限重复的游戏，但是无限重复的囚徒困境被认为是模拟一系列互动的适当方式，其中参与者们从不认为当前的互动是他们的最后一次。在这种情况下，一对策略决定了游戏树的无限路径。如果一次性游戏的回报是正数，那么沿着任何这样的路径的总回报是无穷大的。这使得比较策略有些尴尬。在许多情况下，每轮的平均回报随着轮数的增加趋近于一个极限值，因此该极限值可以方便地作为回报。（有关进一步的理由，请参见 Binmore 1992 年第 365 页。）例如，如果我们限制自己只考虑可以由机械设备（具有有限的记忆和计算速度）实施的策略，那么每个参与者的回报序列总是在有限次数的回合之后，会在一个特定的有限回报序列中不断循环。每轮的平均回报极限值将是循环中的平均回报。近年来，Press 和 Dyson 已经证明，对于许多目的来说，对无限重复的囚徒困境的研究可以局限于“记忆一”的策略，其中在任何一轮中合作的概率仅取决于策略之间的上一次会面的情况。每轮的平均回报在极限情况下仍然是明确定义的。Press 和 Dyson 的思想在无限重复的囚徒困境上激发了许多新的研究。（请参见下文的零决策策略。）由于没有最后一轮，很明显，反向归纳不适用于无限重复的囚徒困境。

## 14. 无限迭代

大多数当代对IPD的研究认为它既不是无限的，也不是固定的有限长度，而是长度不确定。这是通过在游戏规范中包含一个概率p（“未来的阴影”）来实现的，以便在每一轮中以概率p继续进行游戏。或者，每一轮后对收益进行“折扣因子”p的应用，使得附近的收益比远处的收益更有价值。从数学上讲，无论将p视为继续的概率还是对收益的折扣，都没有太大区别。在IPD中，合作在某个阶段的价值显然取决于在后续回合中遇到对手的几率。（据说这解释了为什么村庄的礼貌程度比大都市高，为什么顾客在本地餐馆给的小费比远处的多。）当p接近零时，IPD变成了一次性PD，背叛的价值增加。当p接近一时，IPD变成了无限IPD，背叛的价值减少。通常还要坚持游戏具有上述标记为RCA的特性，以便（在对称游戏中）玩家通过在每一轮上合作而不是“轮流”做得更好 - 你在我背叛时合作，然后我在你背叛时合作。

有一个观察，显然起源于Kavka 1983年，并在Carroll中以更数学的形式给出，即只要游戏长度的上限是共知的，那么反向归纳论证就适用。因为如果b是这样的一个上限，那么如果玩家们到达第b阶段，他们会知道这是最后一轮，他们会背叛；如果他们到达第b-1阶段，他们会知道他们在这一轮的行为不会影响下一轮的背叛决定，所以他们会背叛；依此类推。在现实生活中，似乎很容易计算出互动次数的上限。例如，由于商店老板琼斯每秒钟只能进行一次销售，并且他的寿命不会超过一千年，他和顾客史密斯可以（保守地）计算出他们不可能进行超过1012次交易。有必要更仔细地研究这个论证，以突出标准处理无限期IPD和其他无限重复博弈中所做的假设。首先要注意的是，在上述描述的无限期IPD中，游戏长度没有上限。相反，存在一个固定的概率p，即在游戏仍在进行中的任何时间，它将以概率p继续进行。因此，如果将史密斯和琼斯的互动建模为无限期IPD，那么他们在一千年后互动的概率不会是零，而是大于pk的某个数，其中p是他们现在再次互动的概率，k是一千年中的秒数。更现实的建模方法可能是允许p的值随着游戏的进行而减小。然而，只要p始终大于零，就仍然成立没有可能互动次数的上限，即没有未来互动概率变为零的时间点。 假设，另一方面，存在一个数字n，使得游戏继续到第n阶段的概率为零。让p1，...，pn为第1阶段，...，第n阶段后游戏继续的概率。那么必然存在一个最小的i，使得pi变为0。（如果不是更早的话，它会在i=n时发生。）根据我们一直做出的标准共识假设，玩家们会知道这个i的值，而IPD将是一个固定长度的IPD，而不是无限期的IPD。在店主和顾客的情况下，我们假设双方都知道今天他们最后一次互动将发生在2020年6月10日中午。我们最初的合理想法是，即使最小的上限不是共识，对于互动次数的一些上限是共识的，这与我们从一开始就知道所有继续概率pi的假设是不兼容的。

正如贝克尔和卡德聪明地观察到的那样，我们不需要对可能的迭代次数设定上限，才能对背离进行反向归纳的论证。如果玩家们从一开始就知道所有的 pi 值，那么只要 pi 的值变得并保持足够小，他们（以及我们）就可以计算出一个阶段 k，在这个阶段未来惩罚的风险和未来奖励的机会不再超过立即背离的好处。所以他们知道对手会在第 k 阶段背离，归纳开始。然而，这种对卡夫卡/卡罗尔论证的修改只进一步暴露了其假设的不可信性。不仅史密斯和琼斯被期望相信他们将在一千年后进行交互的概率不为零，而且还期望他们能够计算出未来交互变得并保持如此不太可能的确切日期，以至于他们预期的未来回报被那一天的回报所超过。此外，每个人都被期望相信对方已经进行了这个计算，并且对方预期他已经进行了这个计算，依此类推。

### 阿克塞尔罗德和“以牙还牙”

囚徒困境的迭代版本在游戏设计之初就被讨论过，但在罗伯特·阿克塞尔罗德在80年代初发表了有影响力的著作后，人们对此产生了更大的兴趣。阿克塞尔罗德邀请专业的博弈论学者提交用于进行迭代囚徒困境游戏的计算机程序。所有的程序都参加了一场锦标赛，每个程序与其他所有程序（包括自己的克隆和一个随机合作和背叛的策略）对战数百次。很容易看出，在这样的游戏中，没有一种策略是“最好的”，即在任何一组竞争者中，它的得分都是最高的。如果其他策略在选择下一步行动时从不考虑之前的互动历史，那么无条件地背叛是最好的选择。如果其他策略都从合作开始，然后通过在随后的回合中背叛对方来“惩罚”任何违约行为，那么无条件合作的策略更好。然而，就像在透明游戏中一样，一些策略具有似乎使它们在各种环境中表现良好的特点。在阿克塞尔罗德最初的锦标赛中得分最高的策略是“以牙还牙”（以下简称TFT），它在第一轮合作，然后模仿对手之前的行动。也许比TFT的初次胜利更重要的是，它赢得了阿克塞尔罗德的第二次锦标赛，该锦标赛的63个参赛者都获得了第一次锦标赛的结果。在分析他的第二次锦标赛时，阿克塞尔罗德指出，可以将每个参赛者分配给五种“代表性”策略之一，以便通过其对这些代表性策略的成功来准确预测其对一组其他策略的成功。为了进一步证明TFT的强大之处，他计算了每种策略在代表性策略在原始锦标赛中出现的五倍的锦标赛中将会获得的得分。 在所有这些假设性比赛中，TFT 在除一个之外的所有比赛中获得了最高分。

Axelrod 将 TFT 的成功归因于四个特性。它是友好的，意味着它永远不会首先背叛。Axelrod 比赛中的八个友好策略是排名最高的八个策略。它是报复性的，这使得它很难被不友好的规则所利用。它是宽容的，意味着它愿意与那些对它进行过背叛的人合作（前提是他们的背叛不是在上一轮）。一个不宽容的规则在对手背叛一次后就无法获得奖励回报。而且它是清晰的，这可能使其他策略更容易预测它的行为，以促进互利互惠的互动。

尽管 Axelrod 的讨论具有启发性，但值得注意的是，这些想法并没有被精确地阐述，以允许对 TFT 的优越性进行严格的证明。例如，人们不知道可能具有所述四个属性的策略类别的范围有多大，或者由此可能暗示的成功标准是什么。的确，如果对手正在玩 TFT（并且未来的阴影足够大），那么通过一种在每一轮都导致相互合作的策略可以获得最大的回报。由于 TFT 本身就是这样一种策略，这意味着 TFT 在所有策略空间中与自身形成纳什均衡。但这并没有特别区分 TFT，因为 Du，Du 也是一种纳什均衡。实际上，迭代博弈论的“民间定理”（现在广泛发表——例如，参见 Binmore 1992 年，第 373-377 页）暗示，对于任何 p，0≤p≤1，存在一种纳什均衡，其中 p 是相互合作发生的次数的比例。实际上，在某些方面，TFT 比许多其他均衡策略更糟糕，因为民间定理可以被进一步加强为关于子博弈完美均衡的类似结果。总的来说，TFT 通常不是子博弈完美的。因为，如果一个 TFT 玩家（不可能的情况下）在一轮中背叛另一个玩家，第二个玩家作为无条件合作者会更好。

### Axelrod 之后

在Axelrod, 1984出版之后，人们发现了一些被普遍认为能改进TFT的策略。（由于在IPD锦标赛中的成功取决于其他策略的存在，因此不清楚这个说法具体意味着什么，以及如何证明它。）其中第一个是Nowak和Sigmond的Pavlov，也被称为Win-Stay Lose-Shift（WSLS），它根据自己的上一次移动和对手的移动来决定每一次非初始移动。更具体地说，如果它和对手上一次移动相同，它就会合作；如果它们上一次移动不同，它就会背叛。等价地，它在成功（诱惑或奖励）后重复自己的移动，在失败（惩罚或受骗）后改变自己的移动。因此得名。这种策略在像Axelrod的锦标赛这样的环境中表现良好，但在存在许多无条件背叛者或随机玩家时表现不佳。在下面关于错误和进化的部分中，我们将进一步讨论这个策略，标记为P1。第二个策略家族是Gradual Tit for Tat（以下简称GrdTFT）。GrdTFT与TFT在两个方面不同。首先，它逐渐增加对手每次背叛的惩罚性背叛反应。其次，它在随后的两轮中通过合作来道歉每一串背叛。第一个特性确保（与TFT不同）它会越来越频繁地对抗随机玩家。第二个特性确保（与TFT不同）它会迅速与可疑版本的TFT（即在第一次移动上背叛的TFT版本）建立互相合作的制度。Beaufils等人表明，当每次被利用时增加一次背叛的GrdTFT版本在由作者在研究之前的锦标赛中选择的一系列“好”的IPD策略（包括TFT）中获胜。 Tzafestas（1998）认为，在每一步行动中，GrdTFT依赖于整个游戏的先前历史，这导致了不可取的内存要求。她建议可以通过一种“自适应”策略来取得相同的成功，该策略在最近的一系列行动中跟踪对手的合作性或响应性的度量，并根据这个度量（即“世界”）是否超过某个阈值来选择自己的行动。这种批评似乎是误导性的：维护先前背叛的计数似乎并不比更新世界变量更加繁重。然而，Tzafestas能够展示出她所确定的一种策略在Beaufils构建的同样环境中胜过了TFT和GrdTFT。

在最近几年，对TFT的热情逐渐被日益增长的怀疑所冲淡。（例如，参见Binmore 2015（第30页）和Northcott和Alexandrova（第71-78页）。有证据表明，TFT在Axelrod的比赛中取得的惊人成功可能部分归因于Axelrod的设置中的特定特征。Rapoport等人（2015）建议，不要进行每个策略与每个策略对战的循环赛，而是将初始策略人群随机分成相等大小的小组，在每个小组内进行循环赛，然后在小组获胜者之间进行冠军循环赛。他们发现，在Axelrod的第一次比赛中，与排名第一的TFT相比，排名第二和第六的策略表现都要好得多，而初始策略人群与Axelrod的第一次比赛中相同。Kretz（2011）发现，在只能根据少量先前动作进行条件的策略人群之间的循环赛中（其中TFT显然是其中之一），策略的相对表现对PD矩阵中的收益值敏感。（有趣的是，即使所有PD都满足或不满足R+P=T+S的条件，即交换游戏的特征，以及所有PD都满足或不满足RCA条件，R>½（T+S）。

或许同样有说服力的是，最近一次使用与 Axelrod 相同参数的锦标赛的结果。为了纪念 Axelrod 的书出版二十周年，2004 年在波特兰举办了一系列类似的锦标赛，并在 2005 年的 Colchester 的 IEEE 计算进化大会和 IEEE 计算智能与游戏研讨会上举办。Kendall 等人在 2007 年描述了这些锦标赛，并包含了一些提交获胜作品的作者的论文。大多数锦标赛都故意设计得与 Axelrod 的不同（其中一些在下面的信号部分简要讨论）。在最接近 Axelrod 锦标赛的那个中，TFT 只排名第十四，而共有五十种策略参赛。

在 Axelrod 提出的五个成功标准中，后来的锦标赛最明显削弱的是“清晰度”。最高得分的两种策略，Adaptive Pavlov (APavlov)和 Omega Tit for Tat (ΩTFT)，都没有 Rapoport 的 tit-for-tat 那样的简单性。两者都在 Tzafestas 的意义上具有广泛的适应性，但第一种比 Tzafestas 的更加狭窄，因为设计者预期锦标赛环境会是这样，而第二种则用一对旨在测量“僵局”和随机性的指标取代了 Tzafestas 的世界变量。

Li（2007）明确表示，APavlov的想法是对参赛策略进行有根据的猜测，找到一种准确且低成本的方式，在游戏的初始阶段识别出每种策略，并针对每种已识别的策略采取最优策略进行对抗。例如，在补充表中描述的Cu、Du、GRIM、RANDOM、TFT、TFTT、TTFT和P1等策略都在之前的比赛中出现过。通过在第一轮背叛，在第三轮合作，并在第二轮选择与对手第一轮行动相反的策略，可以在三轮中识别出这九种策略中的任何一种。然而，这种识别过程是有成本的，因为通过第一步行动，它消除了与GRIM合作的机会。李选择在前六轮中使用TFT作为他的识别策略，以减少成本，但牺牲了准确性和范围。值得注意的是，TFT无法区分满足Axelrod的友好条件（从不主动背叛）的任何一对策略。这意味着它放弃了利用无条件合作者的机会。李的参赛策略之所以获胜，仅仅是因为他猜测到无条件合作者不会太多。再次教训是要记住成功取决于环境。

ΩTFT 除非其死锁或随机性的度量超过指定的阈值，否则将以 TFT 策略进行游戏。死锁度量旨在检查ΩTFT 和其对手是否陷入了一个无效的循环中，他们轮流背叛对方。当超过其阈值时，该策略合作并重置度量。当随机性度量超过其阈值时，ΩTFT 切换到无条件背叛。与其名称所暗示的相反，当 OmegaTFT 被无条件背叛者反复利用时，随机性增加。然而，与 APavlov 一样，该策略与无条件合作者合作。详细信息可在 Slany 和 Kienreich（第 184 页）中找到。

在上述策略表中总结了本条目中提到的所有 IPD 策略。

## 15. 带有错误的迭代

在上述结果发表几年后的一项调查中，阿克塞尔罗德和迪昂记录了TFT的几个成功案例和对其进行的修改。他们得出结论：“研究表明，阿克塞尔罗德的许多发现可以推广到与原始的两人重复囚徒困境游戏非常不同的环境中。” 但是，在几种合理的情况下，TFT存在严重的缺点。阿克塞尔罗德和迪昂在调查中指出的一个案例是，当试图纳入玩家受到执行和感知错误的合理假设时。这可以通过多种方式实现。例如，本多考虑了“嘈杂的回报”。当一名玩家在对手背叛时合作，其回报为S+e，其中e是一个随机变量，其期望值为0。每个玩家从自己的回报中推断出对方的动作，因此，如果e足够高，其推断可能是错误的。萨格登（第112-115页）考虑了一种情况，即玩家有一定的概率在执行上出错，这对他们自己而言是显而易见的，但对他们的对手而言则不是。这样的玩家可以通过采取策略来“补偿”错误的背叛，即在后续回合中比本来计划的背叛更加合作。然而，假设玩家们自己无法区分错误的移动或观察与真实的移动或观察，模拟错误的必然性最简单的方法就是完全禁止像TFT这样的确定性策略，取而代之的是“不完美”的对应策略，例如“以99%的概率模仿对手的上一次动作，并以1%的概率反对它。” 不完美的TFT比其确定性的兄弟策略更不具吸引力，因为当两个不完美的TFT策略相互对战时，任何一方的“错误”都会引发一系列长时间的轮流背叛的动作。 在两个不完美的 TFT 之间进行长期迭代游戏中，任何错误概率为 p 的情况下，0<p<12，玩家的平均收益将接近于两个策略之间选择合作和背叛的随机游戏的平均收益，即 14(R+P+S+T)。这比当 p=0 时的 R 的收益要差得多。

主流观点似乎是，当不完美是不可避免的时候，成功的策略将不得不对对手的背叛更加宽容（因为这些背叛很可能是无意的）。Molander 1985 证明了，将 TFT 与 Cu 混合的策略在错误概率接近于零时接近于 R 的收益。当这些混合策略相互对战时，它们从 Cu 到 TFT 的比例更高的比例中受益，但如果它们变得太慷慨，它们就会面临与 TFT 混合背叛的“吝啬”策略的利用风险。Molander 计算出，当混合策略设置为，在背叛之后，以概率 g(R,P,T,S)=min{1−(T−R)/(R−S),(R−P)/(T−P)}合作，慷慨的策略将在彼此之间获得最高分数，而不允许吝啬的策略比 TFT 对它们更好。根据 Nowak 和 Sigmund 的说法，我们将这种策略标记为慷慨的 TFT，或 GTFT。当支付具有常见值 5,3,1,0（如 Axelrod 1984）时，GTFT 在对手合作的每个实例之后以及对手背叛的 25%之后合作。

存在缺陷会导致更多的宽恕或慷慨的想法只在缺陷水平较低时才是合理的。随着缺陷水平接近 12，不完美的 TFT 与随机策略无法区分，而非常吝啬的 Du 是最佳回应。Kollock 的模拟似乎证实，在高水平的缺陷下，更加吝啬比更加宽恕更好。但是，Bendor、Kramer 和 Swistak 指出，Kollock 模拟中使用的策略并不具有代表性，因此结果必须谨慎解释。

第二个想法是，不完美的环境鼓励策略更仔细地观察对手的行动。在类似于 Axelrod 的锦标赛（Donninger）中，每个玩家的移动都有 10%的机会被改变，TFT 在 21 种策略中排名第六。按照主流观点的预测，它被更慷慨的 Tit-for-Two-Tats（即 TFTT，除非连续两次受到背叛，否则合作）击败。然而，它也被 Downing 的两个版本击败，Downing 是一个根据对手对其先前移动的反应进行最佳估计的程序。在 Axelrod 的两个原始锦标赛中，Downing 在提交的程序中排名靠后的三分之一。Bendor（1987）从逻辑上证明，对于不完美的策略，将自己的背叛概率基于更长的历史比 TFT 更有优势。

一种巧妙的实现是，一个在不完美环境中的策略应该注意其先前的互动的想法，是由Kraines和Kraines研究的“巴甫洛夫”策略家族。对于每个自然数n，n-Pavlov或Pn根据上一轮的表现调整其合作的概率，单位为1n。更确切地说，如果Pn在上一轮以概率p合作，那么在这一轮中，如果它在上一轮中获得了奖励支付，它将以概率p[+]1n合作；如果它在上一轮中获得了惩罚支付，它将以概率p[−]1n合作；如果它在上一轮中获得了诱惑支付，它将以概率p[+]2n合作；如果它在上一轮中获得了吸血鬼支付，它将以概率p[−]2n合作。[+]和[−]是有界的加法和减法，即x[+]y是x+y的和，除非该数字超过了1，此时它是1（或者尽可能接近1，允许误差的可能性），x[−]y同样要么是x-y，要么接近于零。严格来说，只有在给出合作的初始概率之后，Pn才能完全确定，但是在足够长的游戏中，该参数的值对大多数目的来说变得微不足道，并且可以安全地忽略。可能看起来Pn需要比TFT更多的计算资源来实现。后者的每一步只取决于对手的最后一步，而Pn的每一步都是根据两个玩家先前移动的整个历史的函数。然而，Pn始终可以通过仅跟踪其当前合作概率和上次支付来计算其下一步。正如其作者所坚持的那样，这似乎是“动物世界中的一种自然策略”。可以计算出，对于n>1，Pn对抗随机策略的表现比TFT更好。更一般地说，对于总是以固定概率p≥12合作的慷慨不响应策略Cp，Pn的表现与TFT一样好或更好（因为偶尔的诱惑支付可以教会它利用不响应的策略）。) 在这些情况下，具有较高 n 值的“慢学习者”版本的帕夫洛夫比具有低值的“快学习者”稍微好一些。与其他帕夫洛夫策略和 TFT 一样，Pn 及其对手对于反应性策略最终达到（几乎）恒定的合作状态。总体回报与“训练时间”成反比，即达到该状态所需的回合数。由于 Pn 的训练时间与 n 呈指数变化，Kraines 和 Kraines 认为 P3 或 P4 比其他帕夫洛夫策略更可取，并且接近于“理想”的 IPD 策略。然而，值得注意的是，当（确定性的）TFT 与自身对战时，根本不需要训练时间，而当帕夫洛夫策略与 TFT 或其他帕夫洛夫策略对战时，训练时间可能很长。因此，帕夫洛夫相对于 TFT 的优越性的论证的说服力取决于其在受到缺陷影响时表现出的退化程度较小的观察结果。还值得记住的是，在 IPD 中，没有一种策略在每个环境中都是最好的，而且用于捍卫各种策略的标准模糊且异质。下一节讨论的 IPD 的进化版本的一个优点是它们允许更仔细地制定和评估成功标准。

## 16. 进化

或许关于囚徒困境最活跃的研究领域是游戏的进化版本。一群采用各种策略的玩家在彼此之间进行 IPD 对战。得分较低的策略数量减少，得分较高的策略增加，这个过程不断重复。因此，在进化囚徒困境（以下简称 EPD）中取得成功需要与其他成功策略表现良好，而不是在广泛的策略范围内表现良好。

初始EPD人口可以用一组配对{(p1,s1),…(pn,sn)}来表示，其中p1…pn分别是人口中玩策略s1,…,sn的比例。上述给出的EPD描述并没有明确指定每个IPD之后如何重建策略人口。通常的假设，也是在生物应用中最合理的假设，是每一轮中的得分表示下一轮中的“后代”数量的相对值。假设整个人口的规模保持不变，因此更成功的策略的出生正好抵消了不那么成功的策略的死亡。这相当于每个策略si在后继人口中的比例p∗i由方程p∗i=pi(Vi/V)确定，其中Vi是si在上一轮中的得分，V是人口中所有得分的平均值。因此，每个得分高于人口平均值的策略都会增加数量，而每个得分低于平均值的策略都会减少数量。这种演化被称为“复制者动力学”或根据“比例适应度”规则的演化。还有其他可能的演化规则。Bendor和Swistak认为，在社会应用中，将玩家视为从一种策略转换到另一种策略而不是存在与否更有意义。由于理性玩家可能只会转换到在前几轮中获得最高回报的策略，因此只有得分最高的策略会增加数量。Batali和Kitcher采用一种动态方式，其中得分最低的策略被混合了最高得分策略特征的策略所取代。Kuhn 2004中描述和比较了各种其他可能的演化动态。然而，这里的讨论主要涉及具有比例适应度规则的EPD。

阿克塞尔罗德（Axelrod）借鉴特里弗斯（Trivers）和梅纳德·史密斯（Maynard Smith）的观点，对具有比例适应度的 EPD 进行了描述，并对他的 IPD 锦标赛的进化版本进行了简要分析。对于阿克塞尔罗德来说，EPD 提供了更多支持 TFT 的证据：

> TIT FOR TAT 在最初的锦标赛中稍微领先，并且在模拟的世代中从未失去这个领先地位。到了第一千代，它成为了最成功的策略，并且以比其他策略更快的速度增长。

然而，阿克塞尔罗德的 EPD 锦标赛包含了几个可能被视为人为的特征。首先，它允许在无噪声环境中使用确定性策略。如上所述，TFT 在模拟错误不可避免的条件下可能表现更差。其次，它仅从原始 IPD 锦标赛中选择了 63 种策略。对于那些可能存在于自然界中的所有策略而言，对象象牙塔中构想出的策略的成功并不意味着成功。第三，每个阶段只允许上一阶段的幸存者进行竞争。可以说，更现实的模型应该允许新的“突变”策略在任何阶段进入游戏。改变这第三个特征很可能会对 TFT 造成伤害。因为 TFT 人口的大规模增长将使得采用更天真策略（如 Cu）的突变体有机会重新获得立足点，并且这些天真策略的存在可能会使得像 Du 这样的更恶劣策略优于 TFT。

Nowak和Sigmund模拟了两种避免三个可疑特征的锦标赛。第一个考察了“反应性”策略家族。对于任意的概率y、p和q，R(y,p,q)是一种策略，即在第一轮以概率y合作，之后如果对方在上一轮合作，则以概率p合作，如果对方背叛，则以概率q合作。这是一个广泛的家族，包括许多已经考虑过的策略。Cu、Du、TFT和Cp分别是R(1,1,1)、R(0,0,0)、R(1,1,0)和R(p,p,p)。当支付为5,3,1,0时，GTFT是R(1,1,.25)。为了捕捉错误的必然性，Nowak和Sigmund在他们的锦标赛中排除了确定性策略，其中p和q恰好为1或0。与以前一样，如果游戏足够长（且p和q不是整数），则可以忽略第一步，并将反应性策略与其p和q值进行标识。特别关注接近Molander的GTFT的策略，其中p=1，q=min{1−(T−R)/(R−S),(R−P)/(T−P)}。Nowak和Sigmund的第一系列EPD锦标赛以反应性策略的代表样本开始。对于大多数这样的锦标赛，他们发现进化不可逆地导致了Du。那些最接近R(0,0)的策略R(p,q)蓬勃发展，而其他策略则灭亡。然而，当初始策略中有一个非常接近TFT时，结果会发生变化。

> TFT 和所有其他的互惠策略（接近（1,0））似乎已经消失了。但是，一个奋战的少数派仍然存在并进行反击。当“傻瓜”被消灭得如此之惨，以至于剥削者无法再以他们为食时，局势开始逆转。最初缓慢，但逐渐积聚力量，互惠者回来了，而剥削者现在衰落了。但是，导致这种命运逆转的类似 TFT 的策略不会从中获利：它消灭了剥削者，被其使命抢走，并被最接近 GTFT 的策略所取代。进化随之停止。即使我们偶尔引入另一种策略的 1％，它也会消失。

根据 Nowak 和 Sigmund 在反应性策略之间的锦标赛基础上的猜测，虽然 TFT 对于合作的出现至关重要，但实际上在生物界中持续合作模式的策略更有可能是 GTFT。

第二系列的模拟实验涉及更广泛的策略类别，然而，这迫使他们修改了自己的观点。第二系列中考虑的策略允许每个玩家根据自己的上一次行动和对手的行动来决定合作的概率。现在，一个策略可以表示为S(p1,p2,p3,p4)，其中p1、p2、p3、p4分别是在(C,C)、(C,D)、(D,C)和(D,D)之后合作的概率，即在获得奖励、吃亏、诱惑和惩罚报酬之后。（同样，只要pi不为零或一，我们可以忽略第一次行动的背叛概率。）这些锦标赛中的初始人口都采用随机策略S(.5,.5,.5,.5)，每经过100代，会引入一小部分随机选择的（非确定性的）突变体，并且人口通过比例适应性进化。结果与之前完全不同。经过107代，90%的模拟试验达到了稳定的相互合作状态。但是，这些状态中不到8.3%的人口使用了TFT或GTFT策略。剩下的91.7%被接近S(1,0,0,1)的策略所主导。这正是Kraines和Kraines的巴甫洛夫策略P1，它在获得R或T后重复上一次行动，并在获得P或S后改变行动。Kraines和Kraines对P1持有一定的轻视态度。他们回忆起Rapoport和Chammah在博弈论早期就将其称为“简单ton”，并评论道“这个称号当之无愧”。事实上，P1有一个不幸的特点，即每隔一次就试图与Du合作，在与TFT对抗时可能会陷入较差的重复报酬系列T,P,S,T,P,S,...。但是，Nowak和Sigmund将这个策略重新命名为“赢者留下，输者转变”，并宣扬其优势。他们的模拟实验表明，在进化环境中，这里提到的缺陷并不太重要。 一个原因可能是 P1 有助于使其环境对其敌人不利。杜在一个有慷慨策略的环境中表现良好，比如 Cu 或 GTFT。正如我们所见，TFT 允许这些策略蓬勃发展，这可能为杜铺平道路。因此，尽管 TFT 对抗杜的表现比 P1 差，但 P1 在保持其环境不受杜的影响方面更好。

在确定性策略的宇宙中进行的模拟产生的结果与 Nowak 和 Sigmund 的结果非常不同。Bruce Linster（1992 年和 1994 年）提出，可以通过将策略表示为简单的 Moore 机来定义自然类别的策略和现实的进化机制。例如，P1 由下图所示的机器表示。

![Figure 8](https://plato.stanford.edu/entries/prisoner-dilemma/fig8-Moore.png)

 图 8

这台机器有两个状态，用圆圈表示。它从最左边的状态开始。左圆圈中的C表示机器在第一步上合作。从左到右的箭头表示机器在合作（处于C状态）并且对手背叛（箭头标有d）之后会缺陷（进入D状态）。林斯特进行了演化囚徒困境的模拟，其中的策略可以用两状态的摩尔机器来表示。结果发现，这些策略正是诺瓦克和西格蒙德的S策略的确定性版本。由于这些策略是确定性的，我们必须区分在第一轮合作和第一轮背叛的版本。在第一轮合作者中，S(1,1,1,1)、S(1,1,1,0)、S(1,1,0,1)和S(1,1,0,0)都代表无条件合作的策略Cu。同样，第一轮背叛者中的四个都代表Du。其他的每个S(p1,p2,p3,p4)，其中p1、p2、p3、p4都是零或一，代表着独特的策略，并且每个策略有两种变体，根据它在第一轮是合作还是背叛。通过从这32个确定性版本的诺瓦克和西格蒙德策略中删除这六个重复的，我们得到了林斯特考虑的26个“两状态”策略。

林斯特在两种状态策略之间模拟了各种EPD锦标赛。其中一些使用了“均匀突变”，即种群中的每个策略突变为其他策略的概率相等。其中一些使用了“风格化突变”，只允许那些可以理解为Moore机器图中单个“断链”结果的突变。在某些情况下，突变被假定发生在每一代中的一小部分人口中；在其他情况下，“突变体”代表了原始人口的百分之一的入侵力量。在某些情况下，对于需要更多状态或更多链接的机器，通过减少支付来对增加复杂性进行惩罚。正如人们所预料的，结果在一定程度上取决于条件。然而，林斯特的所有结果与诺瓦克和西格蒙德的结果之间存在一些显著差异。在林斯特的锦标赛中，没有单一策略能够在幸存人口中像诺瓦克和西格蒙德的P1和GTFT那样占主导地位。唯一普遍占据超过百分之五十人口的策略是最初合作版本的S(1,0,0,0)。这是一种策略，其不完美的变体在诺瓦克和西格蒙德的研究中似乎竞争力较差。在博弈论文献中，它经常被称为GRIM或TRIGGER。它在对手背叛一次之前合作，然后在游戏的剩余时间里背叛。根据Skyrms（1998）和Vanderschraaf的说法，霍布斯和休谟都认为它是我们在重要的囚徒困境类似情境中合作行为的基础策略。GRIM在林斯特的研究中表现出色，而在诺瓦克和西格蒙德的研究中表现较差的差异可能与其在存在错误的情况下急剧恶化有关。在两个不完美的GRIM之间的比赛中，任何一方的“错误”背叛都会导致长时间的相互背叛。 因此，从长远来看，不完美的 GRIM 在与自身对战时表现不佳。在 Linster 的锦标赛中幸存下来的其他策略（数量较少）包括 TFT，P1，Cu 和最初合作的 S（1,0,1,1）。 （请注意，不完美的 GRIM 也很可能在与这些策略的不完美版本对战时表现不佳。）观察到进化可能导致策略的稳定混合（也许每个策略都用于保护其他策略免受特定类型的入侵者的侵害），而不是单一的主导策略是有启示意义的。同样具有启示意义的是在一些特殊条件下获得的结果，其中进化导致人口组合的循环重复。

人们可能期望能够预测在满足各种条件的 EPD 中将占主导地位的策略，并通过正式证明来证明这样的预测。然而，直到最近，对 EPD 的数学分析一直受到关于“进化稳定性”的概念混乱的困扰，即如 Nowak 和 Sigmund 所说的“进化停止”的条件。Axelrod 和 Axelrod＆Hamilton 声称展示了 TFT 的进化稳定性。Selten 1983 年提供了一个没有进化稳定策略的游戏示例，并且 Selten 的论证明显适用于 EPD 和其他进化博弈。Boyd 和 Lorberbaum 以及 Farrell 和 Ware 提出了不同的证明，证明 EPD 没有进化稳定的策略。毫不奇怪，这个悖论通过观察到三组作者各自使用略有不同的进化稳定性概念来解决。Bendor 和 Swistak 的一系列论文解开了这个概念混乱。下面描述并应用了两个中心稳定性概念于 EPD。希望与文献中出现的其他一些概念进行比较的读者可以参考以下简要指南：

> 进化博弈中的稳定性概念。

一种进化博弈的策略 s 具有普遍的强窄稳定性（“usn 稳定性”），如果一个玩策略 s 的群体在任何进化规则下，都会将任何足够小的入侵者群体驱逐到灭绝，而这些入侵者都采用相同的策略。一个进化博弈具有 usn 稳定性，只有当它满足 Maynard Smith 所确定的关于收益的简单条件时：

* （MS）对于所有的策略 j，V(i,i)>V(j,i)或者 V(i,i)=V(j,i)且 V(i,j)>V(j,j)。

（在此及以下，符号 V(i,j)表示当 i 采用 j 策略时的收益。）Maynard Smith 表示，任何入侵者对于本土居民来说都比本土居民自己对待本土居民时表现得更差，或者他们对待本土居民的收益与本土居民自己对待本土居民的收益完全相同，但是本土居民对待入侵者的收益要比入侵者自己对待自己的收益更好。

对于 IPD 中的任何策略 i（或者实际上是在任何迭代有限游戏中的任何策略），然而，存在与 i 不同的策略 j，j 在与 i 或 j 对战时模仿 i 的玩法。这些“中性突变体”的存在意味着 MS 无法满足，因此没有 EPD 具有 usn 稳定性。当然，这个论证使用了迭代游戏中的任何策略都是可能入侵者的假设。可能有充分的理由限制可用的策略。例如，如果假设玩家没有关于先前互动的知识，那么将可用的策略限制为无条件策略可能是合适的。由于在迭代游戏的每一轮中，一对玩家都获得相同的回报，我们可以将进化游戏的每一轮视为每一对玩家之间的一次性游戏，而不是迭代游戏。事实上，这是梅纳德·史密斯本人考虑的进化游戏的一种类型。在这个框架中，任何策略 S，使得（S，S）是基础一次性游戏中的严格纳什均衡（包括 PD 中的无条件背叛），满足 MS 条件。因此，在某些情况下，MS 和 usn 稳定性是非平凡的条件。

如果策略 s 具有受限弱广泛稳定性（rwb 稳定性），则当进化按比例适应度规则进行，并且本地种群正在玩 s 时，任何（可能是异质的）小规模入侵者群体都将无法使本地种群灭绝。这个条件事实上等同于由 Bendor 和 Swistak 确定的 MS 的一个弱化版本。

* （BS）对于所有策略 j，V（i，i）> V（j，i）或者 V（i，i）= V（j，i）且 V（i，j）≥ V（j，j）。

BS和rwb稳定性是更一般的进化框架中的非平凡条件：满足rwb稳定性的EPD策略确实存在。然而，这并不特别证明上述讨论的任何策略。Bendor和Swistak证明了一个类似于之前提到的民间定理的结果：如果未来的阴影足够大，就会有支持从零到一度合作的rwb稳定策略。区分满足BS的策略的一种方法是通过推翻本地人所需的入侵规模，或者等价地，通过维持稳定性所需的本地人比例。Bendor和Swistak表明，这个数值，即最小稳定频率，永远不会超过1/2：没有人口能够抵抗与自身规模相同的每个入侵群体。他们认为，这个结果确实使他们能够开始为Axelrod的观点提供理论上的证明。他们能够证明，随着未来的阴影接近于一，任何一个友好的策略（意味着它永远不会首先背叛）和报复性的策略（意味着它在被背叛后立即背叛）都有一个接近一半的最小稳定频率。TFT具备这两个特性，实际上，它们是Axelrod引用的四个对TFT成功至关重要的特性中的前两个。当然，还有许多其他友好和报复性的策略，还有一些策略（如P1）不具备报复性，但仍满足rwb稳定性。但是，Bendor和Swistak至少能够证明，任何“最大程度上稳健”的策略，即其最小稳定频率接近一半的策略，在无限重复的PD中除了有限次数的移动选择合作。

Bendor和Swistak的结果必须谨慎解释。首先，应该记住，没有概率性或噪声敏感的策略能够符合“友好”或“报复性”策略的定义。此外，TFT的不完美版本不满足rwb稳定性。它们可以被任意小的确定性TFT入侵推翻，或者实际上可以被任意小的任何不完美TFT入侵推翻。其次，必须记住，关于最小稳定频率的结果只涉及弱稳定性。如果世代数与初始人口相比较大（在生物应用中经常如此），一个最初完全由采用相同最大鲁棒策略的玩家组成的人口，可能会接受一系列小的入侵群体，最终将原始策略减少到不到人口的一半。在那一点上，原始策略可能会被推翻。

很可能这两个警告都在解释 Bendor/Swistak 的结果和 Nowak/Sigmund 模拟之间的明显差异中起到了一定的作用。人们会期望 Bendor/Swistak 的最小稳定频率能够提供一些关于人口玩特定策略的时间长度的指示。一个需要大规模入侵才能推翻的策略很可能比一个只需要小规模入侵的策略更长时间地存在。一个简单的计算显示 P1 的最小稳定频率相对较低。它被超过人口的 10%的无条件背叛者入侵所推翻。然而在 Nowak/Sigmund 的模拟中，类似 P1 的策略占主导地位，而不是类似 TFT 的策略。由于这些模拟需要不完美性，并且生成的突变体序列远远大于原始人口，所以这里并没有真正的矛盾。然而，这种差异表明我们对于足以预测在各种合理条件下会出现的策略的 EPD 的理论理解还不够。

像 usn 稳定性一样，rwb 稳定性的概念在相对于特定策略集合时可以更具有区分性。例如，Molander 在 1992 年对 Schelling 的多人版本的 PD 进行的研究将注意力限制在{TFT-like 策略的家族{S1,...,Sn}上。采用 Si 的玩家在第一轮和至少 i 个其他人合作之后的每一轮都合作。通过将稳定性解释为对其他家族成员入侵的抵抗力，Molander 能够证明在某些条件下，两个 Si 的特定组合（其中一个等同于 Du）是唯一稳定的。然而，这类结果的意义取决于对可允许策略集合的限制的合理性。

### 进化和可选 PD

在迭代和进化版本的可选囚徒困境中，我们想象来自某个群体的玩家会被重复配对，并有机会玩囚徒困境（选择C或D）或选择退出（选择N）。选择N意味着玩家放弃了在下一次配对中获得奖励或诱惑回报的机会。在我脑海中的大多数人类互动中，拒绝与特定伙伴合作并不代表与其他人合作的机会损失相同，与选择合作相比。如果我从一个不诚实的经销商那里买了一辆车，我将不得不等很长时间才能在下次购车时做得更好；但如果我拒绝与她合作，我可以立即开始与附近的经销商进行谈判。然而，在人与人之间（更有可能是在非人类动物、国家或公司之间），可能存在适合用进化版本的可选囚徒困境进行建模的情况。

我们可以将进化可选囚徒困境的策略表示为三元组⟨p,q,r⟩，其中p、q和r是实数，相加为1，表示玩C、D和N的概率。这些策略都不满足BS条件，因此在这个族群中没有一种策略是rwb稳定的。如果一个群体的所有成员都无条件地拒绝参与（采用⟨0,0,1⟩），那么它们可以被更具合作性的策略的小规模入侵所渗透并最终取代。而这些合作策略又会被背叛策略推翻，当背叛者的浓度足够大时，再次拒绝参与的“孤独者”可以再次掌权。将不参与的选项添加到进化囚徒困境中确实可以摆脱普遍背叛的不幸状态，但却导致了一个只稍微不那么理想的结果，即人口会反复循环进入普遍不参与的状态。（Szabó和Hauert在他们的著作中有一个很好的插图来说明这个现象。）

在允许依赖先前互动的策略中，Batali 和 Kitcher 喜欢一个他们称之为“歧视性利他主义者”（以下简称 DA）的 GRIM 类似物。DA 与从未对其进行过叛变的任何玩家合作，否则拒绝参与。他们表明，在五种简单策略的群体中，将出现一个循环模式，其中“反社会”（叛变）策略被“非社交”（不参与）策略所取代，然后再被“社交”（DA）策略所取代，再次被“反社会”策略所取代。然而，他们的分析导致他们得出结论，如果一个群体的成员被限制在这五种策略中，进化将使他们“大部分时间处于高度合作的状态”（尽管不像在“完全可选”的游戏中那样，在每一轮中，只有那些准确表示愿意参与的人才会配对）。据说，允许任何策略的代理人之间的模拟，其中一步取决于对手的前两步移动，提供了粗略的证实。这里需要一些谨慎。对于模拟中合作人群的基础策略几乎没有分析，实际上，对于只回顾两场比赛的代理人来说，DA 不是一个选项。奇怪的是，与普通 PD 相比，完全可选版本的游戏报告的合作性稍微较低（尽管在每种情况下，合作性都显著高于普通 PD）。所采用的进化动力学和采用的合作性度量具有足够的特殊性，使得与其他工作进行比较变得困难。尽管存在所有这些警告，但可以安全地得出结论，将参与视为可选项可以为有时被建模为进化 PD 的互动模式中几乎不见普遍、不懈的叛变提供另一种解释。

## 17. 信号传递

当Kendall等人开始组织他们的IPD锦标赛来庆祝Axelrod有影响力的书籍出版20周年时，他们收到了一个看似无辜的询问：一个参赛者可以提交多个方案吗？如果他们没有立即意识到这个问题的重要性，那么当格拉茨技术大学的一个团队试图向第一届锦标赛提交超过10,000个个别命名的策略时，他们肯定会意识到。其中大多数有抱负的参赛方案都被禁止。然而，事实证明，获胜的策略来自南安普顿大学的一个团队，他们自己提交了223个被允许的策略中的一半以上。正如格拉茨和南安普顿的团队意识到的（而Axelrod早期锦标赛的参与者显然没有意识到），在循环赛IPD中获胜的一个好方法是将参赛者与一支“助推者”军队一起提交，以提高其相对于其他人的得分。在极端情况下，主策略及其助推者通过播放一系列C和D的短代码序列来进行识别。此后，助推者始终与主策略合作（允许自己被利用），并对其他所有人进行背叛（从而降低主策略竞争对手的得分）。主策略对助推者进行背叛，并对其他所有人采取合理的策略（如TFT）。在这种情况下，主策略的得分仅取决于两个因素：其助推军队的规模，以及识别代码序列的准确性和成本。如果外部策略“意外”以代码序列开始游戏，则准确性不完美。成本是通过使用早期动作来发信号而不是遵循更有成效的策略而失去的回报价值。较长的代码产生更高的准确性，但成本也更高。 对这些想法有更好的理解后，Kendall等人在2005年组织了额外的比赛，其中一个限制每个作者只能提交一篇作品，另一个限制每个作者只能提交二十个作品的团队（尽管如Slany和Klienrich所观察到的，这样的限制很难或不可能执行）。)

人们不禁会想，这种信号传递和团队合作是否只是展示竞争学者如何在循环对策囚徒困境锦标赛中获胜的重要性。在进化环境中，使者军团将迅速走向灭绝，只留下一个主策略面对得分高的竞争者。当然，动物物种和人类社会中都有成功的“团队”例子，其中大量人员被少数人利用。可以推测，在这些情况下，剥削者向被剥削者转移足够的利益，以确保后者的持续可用性。也许在旨在探索这些问题的囚徒困境锦标赛中，应该允许团队内部进行这种利益转移。然而，即使没有这样的规则变化，在进化环境中仍然存在较不极端的团队合作形式，其表现更好。如果允许使者相互识别和合作，他们将获得相当大的收益，而不会损害他们的主策略，除非使者错误地将外部人士误认为是自己人。如果允许他们对外部人士采取合理的策略，他们将获得更多收益，尽管这会给他们的主策略带来更大的风险（通过外部人士的收益）。即使不允许团队被主策略剥削，他们也可以通过在团队内部采取C策略，在外部人士面前采取D策略，或者在团队内部采取C策略，在外部人士面前采取合理策略来获益。Slany和Kienreich（格拉茨小组）将这些方法标记为EW、EP、DW和DP，并观察到（除其他特性外），对于规模相等且足够大的团队来说，这个顺序反映了团队中表现最好的成员从最好到最差的顺序。

错误的可能性给团队合作带来了特殊的困难，尤其是在这种信号传递中：可能会意外发送错误的信号，或者正确的信号可能会被误解。罗杰斯等人（南安普敦小组）意识到，在可能发生错误的情况下发送和接收信号的问题是计算机科学中一个被广泛研究的问题：在嘈杂的信道上可靠通信。在2004年和2005年，肯德尔等人组织的IPD锦标赛中引入了噪声来模拟错误的可能性。南安普敦小组采用了一些标准的纠错码作为他们的信号协议，以应对在嘈杂的信道上的通信，结果以较大的优势赢得了比赛。

在像Axelrod和Kendall等人的IPD锦标赛中，玩家除了在游戏中的动作之外对彼此一无所知，因此他们无法使用其他信息来表明他们属于一个群体。在现实世界中，似乎会有更多的沟通途径可用。合作结果可能通过玩家之间的这种沟通来促进，这在博弈论中是一个古老的想法。Santos等人展示了这是如何可能的。他们的工作借鉴了Arthur Robson（1990）的一篇有影响力的论文。想象一个进化博弈，其基本的收益结构可以是狩猎鹿或囚徒困境，其中所有玩家只能在“C”和“D”之间选择（无条件的）。如果基本游戏是囚徒困境，人口将稳定于普遍背叛。（如果是狩猎鹿，它可能稳定于所有人都选择“D”（较差的均衡）或所有人都选择“C”（较优的均衡）。为了说明沟通的有益可能性，让我们假设是前者。）现在假设一小群突变体进入人口，他们发出一个信号（“秘密握手”）并对那些发出信号的人选择“C”，对其他人选择“D”。由于这些玩家对外部人和对自己的表现与原始玩家一样好，对自己的表现更好，他们很快就会接管人口。（而对于其他可能具有类似资源的突变体，比如那些对自己发出信号并对外部人选择“D”，对自己选择“C”的突变体，这种情况则不成立。）因此，沟通似乎有助于合作。然而，如果基本游戏是囚徒困境，一旦新的统一合作人口接管了，它本身就会变得脆弱。它可以被一个“欺骗”的入侵者所入侵和取代，后者对发出信号的人选择“D”。然后，其他非发出信号的背叛者可以渗透（但不能取代）这个人口。 因此，罗布森得出结论，信号传递可以在进化的囚徒困境中将人口从劣势均衡转移到优势均衡，但只能延迟普遍背叛的建立。然而，桑托斯等人观察到，如果有第二个信号可用，普遍背叛的人口可能会被一小群使用它作为新秘密握手的突变体所取代。当然，这个群体本身也容易受到模仿第二个信号但对所有人背叛的突变体的攻击。然而，在这种情况下，产生的黑暗时代可能不再是永久的。如果一个信号一握手者的突变体群体在任何信号一背叛者漂移到人口之前重新出现，他们将再次接管，并且循环将重复。（当然，如果有第三个信号可用，合作的回归将更容易。）这个故事不再是“进化停止”的故事：相反，人口在普遍背叛和普遍合作的状态之间循环。在每个状态中花费的时间取决于囚徒困境的回报和可用信号的数量。然而，桑托斯等人证明，对于具有足够缓慢的突变率和大量可用信号的有限人口，合作在具有信号传递的囚徒困境中占主导地位。

## 18. 空间囚徒困境

之前的一节讨论了一个有争议的论点，即在囚徒困境中，当每个玩家知道对方足够像自己，以使他们很可能选择相同的行动时，合作是理性的。在进化的背景下，这个论点的类比更明显地是有力的。如果代理人不是随机配对，而是更有可能与采用类似策略的其他人玩游戏，那么合作行为更有可能出现。

至少有三种机制可以实现玩家之间的这种“关联”。在进化囚徒困境中，一种被广泛研究的机制被称为“空间囚徒困境”。玩家被排列在某种“地理”布局中。例如，这可以是一个带有矩形边界的数组，或者是一个圆形，或者是一个没有边界的球面或环面。根据地理布局，为每个玩家确定了两种（可能相同的）邻域。代理人只与其“交互”邻域中的人见面，进化动力学只考虑其“比较”邻域中的人的收益。通常，采用的进化动力学是在交互邻域内进行“胜者模仿”。（这可以模拟每个玩家被其最成功的邻居入侵的想法，或者每个玩家采用其看到的最成功策略的想法。）由于进化和交互都是“局部”的，玩家在空间囚徒困境中更有可能（在第一轮之后）遇到那些玩类似自己策略的人，而不是在普通的进化博弈中。除了“关联”效应外，还应该记住，空间囚徒困境的结果可能会受到胜者模仿动力学的影响，这可能会导致在普通的进化囚徒困境中可能存活并最终占主导地位的策略灭绝。

通常，研究空间 SPD 的动力似乎来自 Axelrod。Axelrod 的比赛中提交的 63 种策略的每种策略都有四份副本，排列在一个具有球形几何结构的网格上，以便每个单元格都有四个邻居进行交互和比较。对于每个初始的随机分布，最终得到的 SPD 最终达到一种状态，其中每个单元格中的策略都与其所有邻居合作，此时不可能再进化。在这些最终状态中，只剩下 63 种原始策略中的大约十种。剩下的策略不再随机分布，而是分散成各种大小的团块。Axelrod 还表明，在特殊条件下，SPD 中的进化可以产生一系列复杂的对称模式，这些模式似乎不会达到任何稳定的平衡状态。

为了了解为什么合作行为可能在这种类似框架中传播，考虑两个位于合作和非合作亚群体之间边界的代理。合作代理看到一个合作的邻居，他的四个邻居都合作，因此在与他们进行游戏后，他将获得四倍的奖励回报。因此，他将模仿这个邻居的策略并保持合作。另一方面，非合作代理看到他的合作对应物，他从合作邻居那里获得三个奖励回报和一个吸血鬼回报。他将这与他的非合作邻居的回报进行比较。他们能做到的最好的是获得三次惩罚和一次诱惑。因此，只要 3R+S 超过 3P+T，边界上的非合作代理将采用他的合作邻居的策略。Axelrod 的回报为 T、R、P 和 S 的值分别为 5、3、1 和 0，满足这个条件。

Nowak和May对只允许使用Cu和Du两种策略的SPD进行了更详细的研究。（这些策略适用于缺乏记忆或识别能力的个体。）他们发现，对于各种空间配置和策略分布，进化方式都以一种统一的方式依赖于相对回报。当诱惑回报足够高时，Du的集群增长，Cu的集群缩小；当诱惑回报足够低时，Du的集群缩小，Cu的集群增长。在一个狭窄的中间值范围内，我们得到了类似Axelrod所注意到的复杂模式的连续。不断演化的模式呈现出极大的多样性。然而，对于给定的空间配置，Cu和Du策略的比率似乎对于所有初始策略分布和特定范围内的诱惑回报都趋近于相同的常数值。这些模拟部分解释了合作在自然界中持续存在的观点受到了质疑，因为它们假设了确定性（无误差）的移动和更新。但是作者报告了在各种错误条件下出现类似现象，尽管这时需要更低的相对诱惑值来维持合作者的生存，并且错误水平不能超过一定的阈值。（参见Mukherjii等人的文章，以及紧随其后的Nowak等人的回复。）

Grim、Mar和St Denis报告了一系列具有更多初始策略的SPD模拟。总的来说，他们的观察证实了一个合理的猜想，即在SPD中合作的结果比普通的EPD更常见。模拟从Nowak和Sigmund的所有纯反应策略开始（即上述描述的所有R(y,p,q)策略，其中y、p和q都是0或1），最终都以TFT（即R(1,1,0)）作为唯一的幸存者（尽管其他结果，包括Du是唯一幸存者以及Cu和TFT交替出现的结果，也是可能的）。模拟从所有64种可能的纯策略开始，其中一步可能取决于对手的前两步行动，最终以使用各种类似TFT的策略的混合幸存者群体结束。他们在双方都背叛（DD）后都背叛，尽管不一定在单方背叛（CD或DC）后背叛；他们在双方合作后都合作，尽管不一定在单方合作后合作；他们在游戏的第二轮合作，尽管不一定在第一轮合作。 （同样，其他结果也是可能的。）模拟从Nowak和Sigmund的许多（即100个）均匀分布的混合反应策略样本开始，往往会被R（.99，.1）接管，这是一种比GTFT慷慨度少一半的慷慨TFT版本。从这些策略中随机选择几个（即8个）开始的模拟往往会演变成由一种慷慨TFT版本主导的混合稳定或循环模式。R（.99，.6）似乎是一个经常获胜的策略，比GTFT慷慨度高出两倍以上。

Szabó和 Hauert 对可选囚徒困境的空间版本进行了详细研究。他们的研究发现，在特定（中间）收益范围内，一个在方形格子上玩“纯”策略的代理人群体将演化到一个唯一的平衡状态，其中存在所有三种策略。这与上述非空间化版本的演化可选囚徒困境的连续循环形成对比。与早期的观察类似，这可能有助于解释一个群体如何实现除了普遍背叛之外的状态，但无法解释一个群体如何实现普遍合作的状态。

SPD 的“地理”方面不必过于字面理解。对于社会应用，甚至对于许多生物应用，似乎没有任何特定几何排列的动机。（例如，为什么不是“蜂窝”结构，每个代理人有六个邻居，而不是每个代理人有四个或八个的网格结构？）对于 SPD 的兴趣显然在于，我的“互动邻居”和我的“比较邻居”远小于整个人口，即使最终结果并不受物理地理细节的限制。尽管如此，特定几何排列中合作演化的 SPD 模型给我们提供了一些引人思考和美丽的图片。本条目末尾的链接提供了几个示例。

## 19. 囚徒困境和社交网络

使局部互动的想法在某些应用中更加现实的一种方法是让代理人根据过去互动中的收益选择与之互动的伙伴。Skryms（2004）考虑了一群无条件合作者和背叛者之间的迭代囚徒困境。最初，像往常一样，每个代理人从人口中剩下的成员中随机选择一个伙伴。然而，在随后的互动中，选择该伙伴的几率会根据以前选择该伙伴时的收益或（更现实地说）与该伙伴互动的以前时间的收益进行调整（无论哪个是“选择者”）。在典型的囚徒困境中，诱惑、奖励、惩罚和吃亏的收益分别为3、2、1和0，合作者和背叛者最终都只选择合作者。由于合作者被合作者和背叛者选择，所以他们比只有在他们选择时才参与的背叛者更频繁地参与。如果我们假设合作者和背叛者之间有平等的分配，那么合作者在成为选择者时可以期望获得一个奖励收益，而在成为被选择者时可以期望获得奖励和吃亏收益的五五开。因此，他们每次互动的预期收益将为（3R+S）/2。背叛者每次参与可以期望获得一个诱惑收益，但他们的参与次数只有合作者的一半。在给定的收益结构下，3R+S>T，所以即使在这种“单向”关联下，合作者的表现更好。

故事在Skyrms所称的“减弱型”囚徒困境中可能会有些不同，其中回报分别为2.01、2、1.98和0。（我们可以将其视为“只要别当傻瓜”游戏。）在这里，与之前一样，合作者很快学会不选择背叛者作为合作伙伴。无论他们选择合作者还是背叛者作为合作伙伴，背叛者的回报几乎相同。然而，由于他们很快不再被合作者选择，与合作者的互动回报将小于与背叛者的回报，他们很快将选择与其他背叛者合作。（在这里重要的是要理解，决定我与代理人a互动的概率的学习算法取决于与a互动的总回报（或最近与a互动的总回报），而不是与a互动的平均回报。）因此，在减弱型游戏中，我们最终得到了完美的关联：背叛者与背叛者互相合作，合作者与合作者互相合作。由于奖励回报略高于惩罚回报，合作者再次比背叛者表现更好。

上述考虑的社交网络游戏在上述意义上并不是真正的进化囚徒困境。交互模式会发展变化，但是人口的策略配置保持不变。允许策略和交互概率同时演化，随着收益的分配。在这种情况下，合作、背叛（或者两者都不）在人口中占主导地位取决于多种因素：收益的价值、策略的初始分布、策略和交互概率调整的相对速度以及这两种进化动态的其他属性。Skyrms 2004 年的一般讨论和一些有启发性的例子，但它并没有提供（或旨在提供）社交网络囚徒困境的全面解释或对精确公式的仔细分析，以正确地模拟特定现象。仍有很多未知。

## 20. 零决定策略

在社交网络游戏中，代理人从潜在对手的人口中进行选择；在 Axelrod 感兴趣的 IPD 版本中，代理人必须与他们所属的人口中的每个其他成员进行游戏。然而，Dresher 和 Flood 对 IPD 的最初描述涉及到一对重复玩同一 PD 游戏的玩家。在一篇简短但有影响力的论文中，两位杰出的物理学家 William Press 和 Freeman Dyson 最近重新关注了 IPD 的这个原始版本，或者更确切地说是它的无限重复版本。

让我们称这个版本的游戏为（无限）两人囚徒困境，或者 2IPD。在其他版本的囚徒困境中，来自更大人口的配对会重复地进行游戏，一个成功的策略是得分高的策略。“高”可能意味着（如在复制动态下的进化中）得分至少与人口平均得分一样高，或者（如在模仿动态下的进化中）至少与人口中最成功代理的得分一样高。在这些条件下，在游戏的某一轮中，提高自己的得分比降低对手的得分更为重要。Axelrod 反复（并有理由）建议他的锦标赛参与者不要嫉妒。然而，在 2IPD 中，人口规模为两个。在这种情况下，降低对手的回报与提高自己的回报同样有价值，甚至降低自己的回报可能有益，如果这样做比降低对手的回报更多。

2IPD 的另一个值得注意的特点，在 Press 和 Dyson（附录 A）中得到了严格证明，即长期记忆对于游戏的好表现是不必要的。假设我采用一个记忆一的策略，即我只根据我们上次的互动来决定每一步。然后 Press 和 Dyson 证明，你不能通过使用更长的记忆来获益：无论你采用什么策略，都存在一个等效的记忆一策略，你本可以采用它来使我们两个得分相同。通过自己采用记忆一策略，我确保更长的记忆对你没有好处。因此，我们可以不失一般性地将 2IPD 游戏视为具有记忆一策略的代理之间的游戏。

两个记忆一代理之间的 2IPD 游戏（实际上是任何两个记忆一代理之间的两个玩家、两个移动的游戏）可以以一种特别明晰的方式表示。让 O1、O2、O3、O4 表示四种结果 CC、CD、DC 和 DD。记忆一策略（如上面的演化讨论中所述）是在结果 O1、O2、O3、O4 之后以概率 p1、p2、p3、p4 合作的策略 S(p1,p2,p3,p4)。（如果我们假设游戏无限次重复，并且对于 i=1,2,3,4，0<pi<1，则可以忽略初始移动。）让 S(p1,p2,p3,p4)和 S(q1,q2,q3,q4)分别是玩家一和玩家二的策略。（对于玩家二，下标被交换，所以 p2 和 q2 都表示在收到吸血鬼支付后合作的概率，p3 和 q3 表示在收到诱惑后合作的概率。）让 p′i=1−pi 和 q′i=1−qi（对于 i=1,2）（这样 p′i 和 q′i 就是背叛的几率）。然后我们可以将 One 和 Two 之间的 2IPD 表示为“马尔可夫转移矩阵”，显示从任何状态转移到任何状态的几率。

|    | O1   | O2     | O3     | O4       |
| ---- | ------ | -------- | -------- | ---------- |
| O1 | p1q1 | p1q′1 | p′1q1 | p′1q′1 |
| O2 | p2q3 | p2q′3 | p′2q3 | p′2q′3 |
| O3 | p3q2 | p3q′2 | p′3q2 | p′3q′2 |
| O4 | p4q4 | p4q′4 | p′4q4 | p′4q′4 |

例如，从状态 O2（其中 One 合作而 Two 背叛）转移到状态 O4（两个玩家都背叛）的几率在第二行和第四列给出：p′2q′3。

以这种方式观察游戏使得可以应用矩阵代数和马尔可夫链的机制，这导致了普雷斯和戴森对零决策者（ZD）策略类的识别。（Hilbe 等人的附录 A 中给出了更简单的普雷斯和戴森核心结果的证明，使用了更为适度的数学机制。）ZD 策略是一种玩家可以确保自己的长期平均收益与对手之间存在固定线性关系的策略。例如，TFT（=S（1,0,1,0））被证明是任何囚徒困境的这种策略。如果我采用 TFT，那么我保证无论你选择什么策略，我们都会得到相同的收益。如果你选择无条件合作（=S（1,1,1,1））或 GTFT（=S（1，.25,1，.25）），我们都会得到奖励的收益，如果你选择无条件背叛，我们都会接近惩罚的平均值。对于其他选择，你可能会得到惩罚和奖励之间的收益。然而，无论你选择什么，你仍然会得到和我一样的收益。

对于 IPD（实验囚徒困境）（实际上对于大多数两人、两步游戏），存在各种各样的 ZD 策略。对于标准的囚徒困境，收益为 5、3、1、0，还有其他三种代表性的 ZD 策略如下：

SET-2EXTORT-2GEN-2=S（34,14,12,14），=S（78,716,38,0），=S（1,916,12,18）。

Press和Dyson强调像SET-2和EXTORT-2这样的策略。如果玩家一采用SET-2，那么无论玩家二采用什么策略，她都会得到2的回报。在记忆一2IPD中，玩家可以将对手的策略设置为惩罚和奖励回报之间的任何值。Hilbe等人将这种策略称为“均衡器”策略，但在我们的背景下，也许“独裁者”会是一个更好的标签。如果玩家一知道独裁者策略，并且知道玩家二是一个天真的效用最大化者，他可以通过提高他设置她的回报的水平来欺骗她，当她最近的行动满足他的欲望时。当然，一个更明智的玩家二可能会意识到同样的独裁者策略也适用于她。然而，除非它们导致玩家一的行为发生变化，否则这些策略将毫无用处。如果独裁者策略对于两个玩家来说是共同知识，那么他们可能会有利可图地同意将彼此的得分设置为奖励回报。由于每个人都在使用独裁者策略，短期内没有人可以通过偏离来获益。如果有人偏离以期望长期收益，另一个人可以通过自己回报的变化来察觉，并采取报复行动。当然，这样的协议是否稳定取决于玩家是否能使他们的报复威胁可信。

EXTORT-2是“勒索”ZD策略的一个例子。如果玩家一采用EXTORT-2，那么他的回报V(1,2)将始终为2V(2,1)−1（其中V(2,1)是玩家二的回报）。玩家二当然可以通过持续背叛来保证自己至少获得一分回报。如果她这样做，玩家一将越来越频繁地背叛，他们的平均回报都将接近惩罚值。然而，由于他们回报之间的线性关系，如果她做得比这更好，她必然会输给玩家一。实际上，她自己得分超过惩罚回报的任何增加都只会使对手得分增加一半。对于一个天真的效用最大化对手来说，EXTORT-2比SET-2更有效。不需要任何花招。无论天真的对手得分超过惩罚回报多少，她都会输给勒索者。无论她做什么来增加自己的回报，都会必然使勒索者的回报增加两倍。她对抗EXTORT-2能做的最好的事情就是无条件合作。这将导致双方实现CC和DC的结果比例为三比一，给她一个平均回报为2.25，而勒索者则获得3.5。她唯一的逃脱希望就是放弃效用最大化，获得Press和Dyson所称的“心灵理论”。如果她意识到她的行为可能导致勒索者放弃他的策略，她可能会采取勒索策略。这将在短期内降低他们两人的回报，但她可能希望在长期内获得更好的结果。Press和Dyson的结论是，虽然勒索策略将始终击败天真的效用最大化者，但勒索者与更复杂的智能体之间的2IPD变成了一种最后通牒游戏。勒索者提出了一种不公平的联合回报分配，让对手面临接受它或使双方都变得更糟的不愉快选择。 （值得注意的是，这种分析忽略了被勒索方意识到对手和自己的回报，并意识到IPD只是在两个代理之间进行，因此试图将对手的回报与自己的回报之间的差异最小化。采取这种态度可能会导致她采取无条件背叛的策略。然后，两个玩家的回报将接近惩罚值，勒索者的回报从下方接近，被勒索者的回报从上方接近。）)

在人口较大的进化环境中，独裁和敲诈策略似乎都不太可能取得成功。根据定义，在进化框架中，成功的策略会变得更加普遍，因此更有可能面对与自身类似的策略。由于独裁者和敲诈者在面对自身时表现不佳，他们在进化环境中的任何成功都会受到限制。Hilbe等人证实了这些直觉。他们表明，当一个非常小的一般记忆一策略人口面临突变和进化时，代理人花费在近似零和策略上的时间相对较高，而可能的策略数量相对较低，特别是花费在近似独裁策略上的时间更高，而花费在近似敲诈策略上的时间更高。然而，随着人口规模的增加，花费在这三个类别上的时间比例迅速下降。当人口超过十个时，作为这些策略典型代表的时间几乎为零。在大约相同的人口水平上，幸存代理人的策略S(x,y,z,w)的平均组成部分x和z迅速上升，而y和w的平均组成部分缓慢下降，因此在人口较大的群体中，策略的平均值看起来像是S(1,.9,.1,.1)——P1的一个不完美版本。（正如预期的那样，随着策略的平均值接近P1，平均回报增加并接近奖励值。这表明在某些情况下，合作在大群体中比小群体更困难的常见观念完全相反。）

尽管勒索性的ZD策略在进化中表现不佳，Hilbe等人认为它们在进化合作中扮演了重要的角色，作为“催化剂”。他们详细探讨了在一些策略选择受限的代理人之间的进化过程，包括无条件背叛、勒索性ZD策略和熟悉的（相对合作的）策略P1。在没有勒索者的情况下，无条件背叛在任何规模的人口中占主导地位。然而，在存在勒索者的情况下，随着人口规模的增加，P1变得更加成功。在人口超过五十人的群体中，它占主导地位。当加入无条件合作作为策略选择时，基本结果相同。在没有勒索策略的情况下，TFT可以发挥类似的催化作用，使P1在无条件背叛者（有或没有无条件合作者）中占主导地位。简单来说，TFT和勒索策略都可以作为中性突变体进入无条件背叛者的人群中，并且TFT的比例可以在一段时间内增长。然而，最终，P1将比两者都表现更好。

应该注意的是，Hilbe等人捍卫并采用了一种与先前讨论的进化动力学截然不同的“成对比较”模型。在每个阶段，随机选择一对代理人，第一个代理人以与第二个代理人的收益差异成正比的概率采用第二个代理人的策略。在这种动力学下，如果突变率足够低，人口将始终向“固定”状态移动，即每个代理人都采用相同的策略。达到固定状态的时间随着人口规模的增加而增加，如果每个策略对其他策略都有相同的收益，那么策略s变得固定的几率与采用s的人口比例成正比。这些特征对应于人口遗传学中的熟悉属性，但对于复制动力学来说并非如此。

在对介绍ZD策略的文章进行评论时，斯图尔特和普洛特金（2012）指出，像GEN-2这样更慷慨的ZD策略在普雷斯和戴森的研究中相对被忽视。如果玩家一在传统收益矩阵的2IPD中采用GEN-2策略，那么他的收益V(1,2)将为2V(2,1)−3。然后，玩家二可以让玩家一获得从惩罚值到奖励值之间的任何收益，同时确保自己的收益更大。她最高收益的反应是Cu，这导致两个玩家的长期平均收益为三。如果她愿意采用一种将她的平均收益降低到奖励水平以下的策略，她将使玩家一的平均收益减少两倍。斯图尔特和普洛特金（2012）报告称，像GEN-2这样的策略在模拟的IPD锦标赛中得分最高，该锦标赛类似于阿克塞尔罗德的锦标赛，包括TFT、GTFT、P1、GRIM和其他在以前的著作中提出的策略。EXTORT-2的一个版本得分第二低。值得注意的是，EXTORT-2版本赢得了第二多的“一对一”比赛，而GEN-2版本赢得了第四少的比赛。正如阿克塞尔罗德在与TFT相关的强调中所强调的那样，在PD锦标赛中，击败对手并不是成功的途径。然而，斯图尔特和普洛特金的评论虽然具有启示性，但仍然没有回答像GEN-2这样的ZD策略是否导致了它们的成功。

在最近的研究中，Stewart 和 Plotkin（2013）提出了一些证据，支持对这个开放问题的有条件的肯定回答。他们的工作借鉴了 Ethan Akin 对无限 IPD 进行的详细数学研究。Akin（2013）关注满足我们对 2IPD 道德上适当的“解决方案”的条件的策略：（1）双方玩家的使用确保合作回报，（2）双方玩家的使用构成纳什均衡，即策略对给予每个玩家的回报，他不能通过单方面偏离它来改善，并且（3）双方玩家的使用防止被任何一方利用-任何一方玩家策略的改变，如果减少了对手的回报，也会减少自己的回报。Akin 将这样的策略标记为“好”的，并推导出了一个非常简单的特征描述。如果策略 S（p1，p2，p3，p4）满足以下条件，则它是好的：

p1（p2，p3，p4）p3（T−R）（R−S）p4（T−R）（R−P）=1，≠（1,0,0），<(1−p2)，并且<(1−p2)。

容易检查到，使用标准 PD 回报，GRIM，TFT，GTFT 和 GEN-2 都满足这些条件，但 EXTORT-2，SET-2 和 P1 不满足条件（当回报满足 R>12（T+P）时，P1 满足条件）。

斯图尔特和普洛特金表明，既是好策略又是 ZD 的策略恰好是慷慨的 ZD 策略，即像 GEN-2 这样的策略，它们在惩罚和奖励之间让对手获得更大的收益份额。当 Hilbe 等人的研究扩展到包括对好策略的关注，特别是对慷慨的 ZD 策略的关注时，展现出的模式会有很大不同。在小人群中，策略在这两个群体中很少时间接近这些策略（相对于机会），而在较大的人群中，它们在这里花费了更大比例的时间。在大人群中，进化最强烈支持的策略中有很高比例的策略既是好的又是 ZD 的。然而，情况并不完全简单。好但不是 ZD 的策略在进化中受到适度的支持，而一些既不是 ZD 也不是好的策略也受到了强烈的支持。

毫无疑问，ZD 策略的识别为对简单游戏和特别是 IPD 的研究注入了新的活力。它对进化 PD 和合作的出现的启示尚未完全理解。

## 21. 群体选择和干草堆 PD

第三种机制是通过考虑更复杂的进化动力学，使玩家更有可能与类似自己的人相遇。生物学家和生物哲学家之间一直存在着关于自然选择作用的适当“选择单位”的激烈辩论。最近，人们重新提出了这样一种观点，即在许多情况下，将这些单位视为个体群体（而不是或者除了基因或个体之外）是有道理的和可信的观点（请参见Sober和Wilson或Wilson和Sober，了解这种观点的历史和激情的辩护）。对于文化进化来说，这个观点同样可信 - 群体内的行为可能处于平衡状态，但不同群体达到的平衡可能是不同的。不成功的群体可能会模仿、被更成功的群体取代，或者失去成员。Sober和Wilson有时写得好像进化博弈论是对群体选择的一种替代观点，但重要的是要理解，这只适用于像上面介绍的简单进化模型这样的情况。更复杂的进化博弈是可能的。例如，考虑一种最初由约翰·梅纳德·史密斯描述的简化版本的干草堆模型。来自大群体的玩家成对随机配对。每对玩家占领一个干草堆。这对玩家进行囚徒困境，并且个体的回报决定了该个体在下一代中的后代数量（父母在孩子出生时死亡）。在固定的若干代中，群体成员与其他成员随机配对并进行囚徒困境。然后拆除干草堆，群体混合并随机成对占领下一个季节的干草堆。 一种简单的表示 n 代干草堆囚徒困境的方法是将其视为两个初始创始人之间的游戏，创始人的回报被设定为使用其策略的后代数量。（这个想法是在 Bergstrom 的建议下提出的，并在 Skyrms 2004 年的报告中提到。）例如，假设 n=3，诱惑、奖励、惩罚和吸血鬼的回报分别设定为 5、3、1、0。那么，如果玩家一合作而玩家二背叛，玩家一的回报将为 0，因为合作者在第二代和任何后续的一代中都没有后代。玩家二的回报将为 5，因为背叛者在第二代中有五个（志同道合的）后代，并且每个后代在第三代中都有一个，因为没有合作者可以相遇。四代干草堆囚徒困境的完整回报矩阵，其回报为 3、2、1 和 0，如下所示。

|   | C   | D   |
| --- | ----- | ----- |
| C | 8,8 | 0,3 |
| D | 3,0 | 1,1 |

正如 Skyrms 2004 年所指出的，这个矩阵表征了一个普通的狩猎鹿游戏，如上所定义。事实上，Skyrms 的观察通常是正确的。对于任何囚徒困境游戏 g，如果 n 足够大，g 的 n 代干草堆版本就是一个狩猎鹿游戏。关于这个结果的一个简单论证在下面的非常简短的补充文件中给出：

> 干草堆囚徒困境变成了狩猎鹿游戏。

## Bibliography

* Akin, Ethan, 2013, “The Iterated Prisoner’s Dilemma: Good Strategies and Their Dynamics,” arXiv:1211.0969v3 [math.DS].
* Aumann, Robert, 1995, “Backward Induction and Common Knowledge of Rationality,” *Games and Economic Behavior*, 8: 97–105.
* –––, 1998, “Note on the Centipede Game,” *Games and Economic Behavior*, 23: 97–105.
* Axelrod, Robert, 1981, “The Emergence of Cooperation Among Egoists,” *The American Political Science Review*, 75: 306–318.
* –––, 1984, *The Evolution of Cooperation*, New York: Basic Books.
* Axelrod, Robert and Douglas Dion, 1988, “The Further Evolution of Cooperation,”*Science*, 242 (December 9): 1385–1390.
* Axelrod, Robert and William Hamilton, 1981, “The Evolution of Cooperation,” *Science*, 211 (March 27): 1390–1396.
* Batali, John and Philip Kitcher, 1995, “Evolution of Altruism in Optional and Compulsory Games,” *Journal of Theoretical Biology*, 178: 161–171.
* Beaufils, Bruno & J.P. Delahaye, and P. Mathieu, “Our Meeting With Gradual: A Good Strategy For The Iterated Prisoner's Dilemma,” *Proceedings of the Fifth International Workshop on the Synthesis and Simulation of Living Systems*, MIT Press, 202–212.
* Becker, Neal and Ann Cudd, 1990, “Indefinitely Repeated Games: A Response to Carroll,” *Theory and Decision*, 28: 189–195.
* Bendor, Jonathan, 1987, “In Good Times and Bad: Reciprocity in an Uncertain World,” *American Journal of Political Science*, 31: 531–558.
* –––, 1993, “Uncertainty and the Evolution of Cooperation,” *Journal of Conflict Resolution*, 37: 709–733.
* Bendor, Jonathan, and Piotr Swistak, 1995, “Types of Evolutionary Stability and the Problem of cooperations,” *Proceedings of the National Academy of Sciences*, 92 (April): 3596–3600.
* Bendor, Jonathan, and Piotr Swistak, 1996, “The Controversy about the Evolution of Cooperation and the Evolutionary Roots of Social Institutions,” in Gasparski, Wojciech et al (eds), *Social Agency*, New Brunswick, N.J.: Transaction Publishers.
* Bendor, Jonathan, and Piotr Swistak, 1997, “The Evolutionary Stability of Cooperations,” *American Political Science Review*, 91 (2): 290–307.
* Bendor, Jonathan, and Piotr Swistak, 1998, “Evolutionary Equilibria: Characterization Theorems and Their Implications,” *Theory and Decision*, 45: 99–159.
* Bendor, Jonathan, Roderick Kramer and Piotr Swistak, 1996, “Cooperation Under Uncertainty: What is New, What is True and What is Important?” *American Sociological Review*, 61 (April): 333–338.
* Berg, Joyce, John Dickhaut and Kevin McCabe, 1995,  “Trust, Reciprocity and Social History?” *Games and Economic Behavior*, 10 (July): 122–142.
* Bergstrom, T., 2002, “Evolution of Social Behavior: Individual and Group Selection Models,” *Journal of Economic Perspectives*, 16: 231–238.
* Bicchieri, Cristina, 1989, “Self-refuting Theories of Strategic Interaction,” *Erkenntinis*, 30: 69–85.
* Bicchieri, Cristina and Allesandro Sontuoso, “I Cannot Cheat on You After We Talk,” in Martin Peterson (ed) 2015, 101–114.
* Binmore, Kenneth, 1992, *Fun and Games*, Lexington, MA: D.C. Heath and Company.
* –––, 1994, *Playing Fair: Game Theory and the Social Contract 1*, Cambridge, MA: MIT Press.
* –––, 1997, “Rationality and Backward Induction,” *Journal of Economic Methodology*, 4: 23–41.
* –––, 2005, *Natural Justice*, New York, NY: Oxford Univsity Press.
* –––, 2015,“Why All the Fuss: The Many Aspects of the Prisoner's Dilemma,” in Peterson (ed.), 16–34.
* Bonanno, Giacomo, 2015, “Counterfactuals and the Prisoner's Dilemma,” in Martin Peterson (ed.) 2015, 133–155.
* Bovens, Luc, 2015, “The Tragedy of the Commons as a Voting Game,” in Martin Peterson (ed.) 2015, 133–156-176.
* Boyd, Robert and Jeffrey Lorberbaum, 1987, “No Pure Strategy is Evolutionarily Stable in the repeated Prisoner's Dilemma Game,” *Nature*, 327 (May 7): 58–59.
* Carroll, J.W., 1987, “Indefinite Terminating Points and the Iterated Prisoner’s Dilemma,” *Theory and Decision*, 22: 247–256.
* Cambell, Richmond and Lanning Snowden, 1985, *Paradoxes of Rationality and Cooperation*, Vancouver: University of British Columbia Press.
* Danielson, Peter, 1992, *Artificial Morality: Virtual Robots for Virtual Games*, London: Routledge.
* Davis, Laurence, 1977, “Prisoners, Paradox and Rationality,” *American Philosophical Quarterly*, 14: 319–327; reprinted in Campbell and Snowden, 45–58.
* –––, 1985, “Is the Symmetry Argument Valid?,” in Campbell and Snowden 1985, 255–262.
* Donninger, Christian, 1986, “Is It Always Efficient to be Nice?” in Dickman and Mitter (eds.), *Paradoxical Effects of Social Behavior*, Heidelberg: Physica Verlag, 123–134.
* Farrell, Joseph, and Roger Ware, 1989, “Evolutionary Stability in the Repeated Prisoner's Dilemma,” *Theoretical Population Biology*, 36: 161–167.
* Gauthier, David, 1986, *Morals by Agreement*, Oxford: Clarendon Press.
* Grim, Patrick, Gary Mar and Paul St. Denis, 1998, *The Philosophical Computer*, Cambrige, Mass: MIT Press.
* Hardin, Garret, 1968, “The Tragedy of the Commons,” *Science*, 162 (December 13): 1243–1248.
* Hilbe, Christian, Martin A. Nowak, and Karl Sigmund, 2013, “Evolution of extortion in Iterated Prisoner's Dilemma games,” *Proceedings of the National Academy of Sciences*, 110 (17): 6913–6918.
* Howard, Nigel, 1971, *Paradoxes of Rationality*, Cambridge, MA: MIT Press.
* Howard, J.V., 1988, “Cooperation in the Prisoner's Dilemma,” *Theory and Decision*, 24: 203–213.
* Hurley, S.L., 1991, “Newcomb's Problem, Prisoners' Dilemma, and Collective Action,” *Synthese*, 86: 173–196.
* Joyce, James, 1999, *The Foundations of Causal Decision Theory*, Cambridge University Press.
* Jurišić, Marko, D. Kermek and M. Konecki, 2012, “A Review of Iterated Prisoner’s Dilemma Strategies,” *Proceedings of the 35th International Convention MIPRO*, 1093–1097.
* Kavka, Gregory, 1983, “Hobbes War of All Against All,” *Ethics*, 93: 291–310.
* –––, 1986, *Hobbesean Moral and Political Theory*, Princeton: Princeton University Press.
* –––, 1991, “Is Individual Choice Less Problematic than Collective Choice?” *Economics and Philosophy*, 7: 291–310.
* Kitcher, Philip, 1993, “The Evolution of Human Altruism” *Journal of Philosophy*, 90: 497–516.
* –––, 2011, *The Ethical Project*, Cambridge, MA: Harvard University Press.
* Kendall, Graham, Xin Yao and Siang Yew Chong, 2007, *The Iterated Prisoners’ Dilemma: 20 Years On*, Singapore: World Scientific Publishing Co.
* Kollock, Peter, 1993, “An Eye For an Eye Leaves Everybody Blind: Cooperation and Accounting Systems,” *American Sociological Review*, 58: 768–786.
* Kraines, David and Vivian Kraines, 1989, “Pavlov and the Prisoner's Dilemma,” *Theory and Decision*, 26: 47–79.
* –––, 1993, “Learning to Cooperate with Pavlov: an Adaptive Strategy for the Iterated Prisoner's Dilemma with Noise,” *Theory and Decision*, 35: 107–150.
* Kreps, David, 1990, “Corporate Culture and Economic Theory,” in Alt, J and K Shepsle (eds.), *Perspectives on Positive Political Economy* Cambridge: Cambridge University Press, 90–142.
* Kreps, David, Paul Milgrom, John Roberts and Robert Wilson, 1982, “Rational Cooperation in the Finitely Repeated Prisoner's Dilemma,” *Journal of Economic Theory*, 27: 245–252.
* Kretz, Tobias, 2011, “A Round-Robin Tournament of the Iterated Prisoner's Dilemma with Complete Memory-Size-Three Strategies,” *Complex Systems* 19: 363–389.
* Kuhn, Steven, 1996, “Agreement Keeping and Indirect Moral Theory” *Journal of Philosophy*, 93: 105–128.
* –––, 2004, “Reflections on Ethics and Game Theory” *Synthese*, 141: 1–44.
* Kuhn, Steven, and Serge Moresi, 1995, “Pure and Utilitarian Prisoner's Dilemmas” *Economics and Philosophy*, 11: 123–133.
* Lewis, David, 1979, “Prisoner's Dilemma Is a Newcomb Problem,” *Philosophy and Public Affairs* 8: 235–240.
* Linster, Bruce, 1992, “Evolutionary Stability in the Infinitely Repeated Prisoners' Dilemma Played by Two-State Moore Machines,” *Southern Economic Journal*, 58: 880–903.
* –––, 1994, “Stochastic Evolutionary Dynamics in the Repeated Prisoners' Dilemma,” *Economic Inquiry*, XXXII: 342–357.
* Maynard Smith, John, 1978, “The Evolution of Behavior,” *Scientific American*, 239: 176–192.
* Molander, Per, 1985, “The Optimal Level of Generosity in a Selfish, Uncertain Environment,” *Journal of Conflict Resolution*, 29 (December): 611–619.
* –––, 1992, “The Prevalence of Free Riding,” *Journal of Conflict Resolution*, 36 (December): 756–771.
* Mukherji, Arijit, Vijay Rajan and James Slagle, 1996, “Robustness of Cooperation,” *Nature*, 379 (January 11): 125–126.
* Nash, John, 1950, *Non Cooperative Games*, Princeton University PhD dissertation, reprinted in *Annals of Mathematics* 54, 1951 (September) 286–295.
* Northcott, Robert and Anna Alexandrova, 2015,“Prisoner's Dilemma Doesn't Explain Much,” in Peterson (ed), 64–84.
* Nowak, Martin, and Robert May, 1992, “Evolutionary Games and Spatial Chaos,”*Nature*, 359 (October 29): 826–829.
* Nowak, Martin and Karl Sigmund, 1992, “Tit for Tat in Heterogeneous Populations,” *Nature*, 355 (January 16): 250–253.
* –––, 1993, “A Strategy of Win-stay, Lose-shift that Outperforms Tit-for-tat in the Prisoner's Dilemma Game,” *Nature*, 364 (July 1): 56–58.
* Nowak, Martin, Robert May, and Karl Sigmund, 1995, “The Arithmetics of Mutual Help,” *Scientific American*, (June): 76–81.
* Nozick, Robert, 1969, “Newcomb's Problem and Two Principles of Choice”, in N. Resher (ed.), *Essays in Honor of Carl G. Hempel*, Dordrecht: D. Reidel, 114–146; reprinted in Cambell and Snowden 1985, 107–132.
* Orbell, John, and Robyn Dawes, 1993, “A ‘Cognitive Miser Miser’ Theory of Cooperative Advantage,” *American Political Science Reveiw*, 58: 787–800.
* Orbell, John, and Robyn Dawes, 1993, “Social Welfare, Cooperators' Advantage and the Option of Not Playing the Game,” *American Sociological Reveiw*, 58: 787–800.
* Peterson, Martin (ed), 2015, *The Prisoner's Dilemma*, Cambridge: Cambridge University Press.
* Pettit, Phillip, 1986, “Free Riding and Foul Dealing,” *Journal of Philosophy*, 83: 361–379.
* Pettit, Phillip and Robert Sugden, 1989, “The Backward Induction Paradox,” *Journal of Philosophy*, 86: 169–182.
* Poundstone, William, 1992, *Prisoner's Dilemma* New York: Doubleday.
* Press, William and Freeman Dyson, 2012, “Iterated Prisoner's Dilemma Contains Strategeis That Dominate Any Evolutionary Opponent,” *Proceedings of the National Academy of Sciences*, 109: 10409–10413.
* Quinn, Warren, 1990, “The Paradox of the Self-Torturer,” *Philosophical Studies*, 59: 79–90.
* Rabinowicz, Wlodek, 1998, “Grappling with the Centipede: Defense of Backward Induction for BI-Terminating Games,” *Economics and Philosophy*, 14: 95–126.
* Rapoport Ammon, DA Seale and AM Colman, 2015, “Is Tit-for-Tat the Answer? On the Conclusions Drawn from Axelrod's Tournaments,” *PLoS ONE*, 10(7): e0134128.
* Rogers , Alex, R.K. Dash , S.D. Ramchurn, P. Vytelingum and N.R. Jenning, 2007, “Error Correcting Codes for Team Coordination within a Noisy Iterated Prisoner’s Dilemma Tournament”, Chapter 9 of Kendall et al.
* Rosenthal, R., 1981, “Games of Perfect Information, Predatory Pricing, and the Chain Store,” *Journal of Economic Theory*, 25: 92–100.
* Santos, Francisco C., Jorge M. Pacheco and Brian Skyrms, 2011, “Co-evolution of Pre-play Signaling and Cooperation,” *Journal of Theoretical Biology*, 274 (1),30–35. .
* Schelling, Thomas, 1978, *Micromotives and Macrobehavior* New York: Norton.
* Segal, Nancy and Scott Hershberger, 1999, “Cooperation and Competition Between Twins: Findings from a Prisoner's Dilemma Game,” *Evolution and Human Behavior*, 20: 29–51
* Selten, Reinhard, 1975, “Reexamination of the Perfectness Concept of Equilibrium in Extensive Games,” *International Journal of Game Theory*, 4: 25–55.
* –––, 1978, “The Chain-Store Paradox,” *Theory and Decision*, 9: 127–159.
* –––, 1983, “Evolutionary Stability in Extensive Two-person Games,” *Mathematical Social Sciences*, 5: 269–363.
* Sigmund, Karl, 1993, *Games of Life: Explorations in Ecology Evolution and Behavior*, Oxford: Oxford University Press.
* Skyrms, Brian, 1990, *The Dynamics of Rational Deliberation*, Cambridge, MA: Harvard University Press.
* –––, 1996, *Evolution of the Social Contract*, Cambridge, Cambridge University Press.
* –––, 1998, “The Shadow of the Future,” in Coleman and Morris (eds.), *Rational Commitment and Social Justice: Essays for Gregory Kavka*, New York, Cambridge University Press.
* –––, 2004, *The Stag Hunt and the Evolution of Social Structure*, Cambridge, Cambridge University Press.
* Slany, Wolfgang and W. Kienreich, 2007, “On some winning strategies for the Iterated Prisoner’s Dilemma, or, Mr. Nice Guy and the Cosa Nostra,” Chapter 8 of Kendall et al.
* Sobel, J.H., 2005, “Backward Induction Without Tears?,” in D. Vanderveken (ed.), *Logic, Thought and Action*, Berlin: Springer, 433–461.
* –––, 1993, “Backward Induction Arguments: A Paradox Regained,” *Philosophy of Science*, 60: 114–133.
* Sober, Elliott and David Sloan Wilson, 1998, *Unto Others: The Evolution and Psychology of Unselfish Behavior*, Cambridge, MA: Harvard University Press.
* Stewart, Alexander and Joshua Plotkin, 2012, “Extortion and Cooperation in the Prisoner's Dilemm,” *Proceedings of the National Academy of Sciences*, 109: 10134–10135.
* –––, 2013, “From Extortion to Generosity, Evolution in the Iterated Prisoner's Dilemm,” *Proceedings of the National Academy of Sciences*, 110: 15348–15353.
* Sugden, R., 1986, *The Economics of Rights, Cooperation and Welfare*, New York, Basil Blackwell; 2nd edition, 2004, Basingstoke, UK: Palgrave MacMillan.
* Szabó:, György and Christoph Hauert, 2002, “Evolutionary Prisoner's Dilemma Games with Optional Participation,” *Physical Review E*, 66: 062903.
* Taylor, Michael, 1987, *The Possibility of Cooperation*, Cambridge: Cambridge University Press.
* Trivers, Robert, 1971, “The Evolution of Reciprocal Altruism,” *Quarterly Review of Biology*, 46: 35–57.
* Tzafestas, Elpida, 2000 “Toward adaptive cooperative behavior,” *Proceedings of the Sixth International Conference on the Simulation of Adaptive Behavior*, SAB-2000, 2, 334–340.
* Vanderschraaf, Peter, 1998, “The Informal Game Theory in Hume's Account of Convention,” *Economics and Philosophy*, 14: 215–247.
* Williamson, Timothy, 1992, “Inexact Knowledge,” *Mind*, 101: 217–242.
* Wilson, D.S. and E. Sober, 1994, “Reintroducing Group Selection to the Human Behavioral Sciences,” *Behavioral and Brain Sciences*, 17: 585–654.

## Academic Tools

> | ![sep man icon](../.gitbook/assets/sepman-icon.png) | [How to cite this entry](https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=prisoner-dilemma). |
> | --- | --- |
> | ![sep man icon](../.gitbook/assets/sepman-icon.png) | [Preview the PDF version of this entry](https://leibniz.stanford.edu/friends/preview/prisoner-dilemma/) at the [Friends of the SEP Society](https://leibniz.stanford.edu/friends/). |
> | ![inpho icon](../.gitbook/assets/inpho.png) | [Look up topics and thinkers related to this entry](https://www.inphoproject.org/entity?sep=prisoner-dilemma&redirect=True) at the Internet Philosophy Ontology Project (InPhO). |
> | ![phil papers icon](../.gitbook/assets/pp.png) | [Enhanced bibliography for this entry](https://philpapers.org/sep/prisoner-dilemma/) at [PhilPapers](https://philpapers.org/), with links to its database. |

## Other Internet Resources

* [Interactive Prisoner's Dilemma](http://serendip.brynmawr.edu/playground/pd.html) (at the Serendip pages at Bryn Mawr).
* [20th Anniversary IPD Tournaments](http://www.prisoners-dilemma.com/) (This site includes complete results of the tournaments described in Kendall, et al.)
* Spatial IPD Pictures
  * [Dirk Helbing](https://www.researchgate.net/figure/Representative-simulation-results-for-the-spatial-prisoners-dilemma-with-payoffs-T_fig1_24035250)
  * [Gani Parrott](https://www.youtube.com/watch?v=WWt3Zwj2yck)
  * [Graeme Cumming](https://www.researchgate.net/figure/Spatial-depiction-of-an-implementation-of-the-prisoners-dilemma-game-in-NetLogo_fig3_278661104)
* [Split or Steal](https://www.youtube.com/watch?v=p3Uos2fzIJ0) (British Quiz show illustrating strategy considerations in playing one-shot PD.)
* [More Interactive PD Materials from gametheory.net](http://www.gametheory.net/applets/prisoners.html)
* Vincent Knight's Axelrod-Python repository on GitHub. (Allows users to write strategies for the iterated prisoner's dilemma in Python, and conduct tournaments against a multiple of others stored here.)
  * [Blog post explaining the project](https://vknight.org/unpeudemath/code/2015/02/20/an-iterated-prisoners-dilemma-on-github.html)
  * [Documentation](https://axelrod.readthedocs.io/en/stable/)
  * [Repository](https://github.com/Axelrod-Python)

## Related Entries

[decision theory: causal](https://plato.stanford.edu/entries/decision-causal/) | [game theory](https://plato.stanford.edu/entries/game-theory/) | [game theory: and ethics](https://plato.stanford.edu/entries/game-ethics/) | [game theory: epistemic foundations of](https://plato.stanford.edu/entries/epistemic-game/) | [game theory: evolutionary](https://plato.stanford.edu/entries/game-evolutionary/)

### Acknowledgments

The current (2019) version of this article has benefited from the advice and assistance of Clark Donley.

[Copyright © 2019](https://plato.stanford.edu/info.html#c) by  
[Steven Kuhn](http://explore.georgetown.edu/people/kuhns/?PageTemplateID=189) <[*kuhns@georgetown.edu*](mailto:kuhns%40georgetown%2eedu)>
